# oil_app_ui.py
import streamlit as st
import pandas as pd
from datetime import datetime, date, time, timedelta
dt_time = time
from pathlib import Path
from ui import header
import sys
import os
import shutil
import asyncio
from io import BytesIO
import base64
import streamlit.components.v1 as components
from reportlab.lib.pagesizes import A4, landscape
from reportlab.pdfgen import canvas
from reportlab.lib.units import cm, mm
from reportlab.lib import colors
from reportlab.lib.utils import ImageReader
import math
CONDENSATE_M3_TO_BBL = 6.289
WAT60_CONST = 999.012
from db import get_session, init_db, engine
from material_balance_calculator import MaterialBalanceCalculator as MBC
from sqlalchemy import text, func, and_, or_
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
import plotly.graph_objects as go
from logger import log_info, log_error, log_warning, log_debug
from security import SecurityManager
from task_manager import TaskManager
from typing import Any, Dict, Optional, List, Tuple
from collections import defaultdict
from functools import lru_cache
import re
# Models (aligned with models.py)
from models import (
    Tank, TankStatus, YadeBarge,
    CalibrationTank, YadeCalibration, Table11,
    TankTransaction, Operation, MeterTransaction,
    YadeVoyage, YadeDip,
    CargoKind, DestinationKind, LoadingBerthKind,
    OTRRecord, GPPProductionRecord, RiverDraftRecord, ProducedWaterRecord,
    TOAYadeStage, TOAYadeSummary, YadeSealDetail, YadeSampleParam, AuditLog, User, LoginAttempt,
    Task, TaskActivity, TaskStatus, TaskType,
    OFSProductionEvacuationRecord, LocationTankerEntry, RecycleBinEntry,
)
from uuid import uuid4
import hashlib
import html
from timezone_utils import format_local_datetime, get_local_time
from recycle_bin import RecycleBinManager
# --- paths for assets ---
from pathlib import Path
BASE_DIR = Path(__file__).resolve().parent
ASSETS   = BASE_DIR / "assets"
LOGOS    = ASSETS / "logos"
ICONS    = ASSETS / "icons"
OUTPUT   = BASE_DIR / "output"
OUTPUT.mkdir(exist_ok=True)
import reportlab
# Initialize the database
init_db()

# --- Convoy Status constants ---
CONVOY_STATUS_ALLOWED_LOCATIONS = {"agge", "utapate", "lagos ho", "lagos (ho)"}
CONVOY_STATUS_YADE_STATUS_OPTIONS = [
    "AT JETTY",
    "AT AGGE",
    "TOWARDS JETTY",
    "TOWARDS AGGE",
    "SALVAGE",
    "MAINTENANCE",
    "GROUNDED",
    "TANK CLEANING",
]
CONVOY_STATUS_VESSEL_NAMES = [
    "MT VEDMATA",
    "MT VISHWAMATA",
    "MT SUNDARI",
    "MT VARUNI",
    "MT VAMIKA",
    "MT SURBHI",
    "MT SATYA",
    "MT SIDDHI",
    "MT RADHIKA",
    "MT TULJA TANVI",
    "MT TULJA KALYANI",
]
CONVOY_STATUS_SPECIAL_VESSEL_LOCATIONS = {
    "MT TULJA TANVI": ("agge",),
    "MT TULJA KALYANI": ("utapate", "oml-13"),
}
CONVOY_STATUS_SPECIAL_VESSEL_ORDER = ["MT TULJA TANVI", "MT TULJA KALYANI"]
CONVOY_STATUS_SPECIAL_VESSELS = set(CONVOY_STATUS_SPECIAL_VESSEL_LOCATIONS.keys())
CONVOY_STATUS_VESSEL_STATUS_OPTIONS = [
    "ANCHOR POSITION",
    "O/A EMPTY",
    "O/A LOADED",
    "I/A EMPTY",
    "I/A LOADED",
    "RECEIVING YADE",
    "EXPORT",
    "DRY DOCK",
    "MAINTENANCE",
    "TOWARDS FSO",
    "TOWARDS AGGE",
    "DISCHARGING",
    "BUNKERING",
]
FSO_MATERIAL_BALANCE_STATE_KEYS = [
    "fso_mb_df",
    "fso_mb_table",
    "fso_material_balance_df",
    "fso_mb_daily",
    "fso_mb_cache",
    "fso_mb_summary_df",
    "fso_mb_pivot",
    "fso_mb_records",
]

# --- detect / load reportlab at runtime (avoids "install reportlab" loop) ---
import importlib

# --- Report Builder Source Metadata ------------------------------------------------------------
REPORT_DAY_START_TIME = time(6, 1)
REPORT_SOURCE_DEFINITIONS = [
    {
        "key": "otr_vessel",
        "table": "otr_vessel",
        "label": "OTR Vessel",
        "class_name": "OTRVessel",
        "date_field": "date",
        "time_field": "time",
        "location_field": "location_id",
        "sort": ("date", "time"),
        "aliases": ["OTRVessel"],
    },
    {
        "key": "convoy_status_vessel",
        "table": "convoy_status_vessel",
        "label": "Convoy Status (Vessel)",
        "class_name": "ConvoyStatusVessel",
        "date_field": "date",
        "time_field": None,
        "location_field": "location_id",
        "sort": ("date", "vessel_name"),
        "aliases": ["ConvoyStatusVessel"],
    },
    {
        "key": "convoy_status_yade",
        "table": "convoy_status_yade",
        "label": "Convoy Status (YADE)",
        "class_name": "ConvoyStatusYade",
        "date_field": "date",
        "time_field": None,
        "location_field": "location_id",
        "sort": ("date", "yade_barge_id"),
        "aliases": ["ConvoyStatusYade"],
    },
    {
        "key": "fso_operations",
        "table": "fso_operations",
        "label": "FSO Operations",
        "class_name": "FSOOperation",
        "date_field": "date",
        "time_field": "time",
        "location_field": "location_id",
        "sort": ("date", "time"),
        "aliases": ["FSOOperation"],
    },
    {
        "key": "gpp_production_records",
        "table": "gpp_production_records",
        "label": "GPP Production",
        "class_name": "GPPProductionRecord",
        "date_field": "date",
        "time_field": None,
        "location_field": "location_id",
        "sort": ("date",),
        "aliases": ["GPPProductionRecord"],
    },
    {
        "key": "tank_transactions",
        "table": "tank_transactions",
        "label": "Tank Transactions",
        "class_name": "TankTransaction",
        "date_field": "date",
        "time_field": "time",
        "location_field": "location_id",
        "sort": ("date", "time"),
        "aliases": ["TankTransaction"],
    },
    {
        "key": "location_tanker_entries",
        "table": "location_tanker_entries",
        "label": "Location Tanker Entries",
        "class_name": "LocationTankerEntry",
        "date_field": "date",
        "time_field": None,
        "location_field": "location_id",
        "sort": ("date", "serial_no"),
        "aliases": ["LocationTankerEntry"],
    },
    {
        "key": "meter_transactions",
        "table": "meter_transactions",
        "label": "Meter Transactions",
        "class_name": "MeterTransaction",
        "date_field": "date",
        "time_field": None,
        "location_field": "location_id",
        "sort": ("date",),
        "aliases": ["MeterTransaction"],
    },
    {
        "key": "ofs_production_evacuation_records",
        "table": "ofs_production_evacuation_records",
        "label": "OFS Production & Evacuation",
        "class_name": "OFSProductionEvacuationRecord",
        "date_field": "date",
        "time_field": None,
        "location_field": "location_id",
        "sort": ("date", "serial_no"),
        "aliases": ["OFSProductionEvacuationRecord"],
    },
    {
        "key": "produced_water_records",
        "table": "produced_water_records",
        "label": "Produced Water Records",
        "class_name": "ProducedWaterRecord",
        "date_field": "date",
        "time_field": None,
        "location_field": "location_id",
        "sort": ("date",),
        "aliases": ["ProducedWaterRecord"],
    },
    {
        "key": "river_draft_records",
        "table": "river_draft_records",
        "label": "River Draft Records",
        "class_name": "RiverDraftRecord",
        "date_field": "date",
        "time_field": None,
        "location_field": "location_id",
        "sort": ("date",),
        "aliases": ["RiverDraftRecord"],
    },
    {
        "key": "tanker_transactions",
        "table": "tanker_transactions",
        "label": "Tanker Transactions",
        "class_name": "TankerTransaction",
        "date_field": "transaction_date",
        "time_field": "transaction_time",
        "location_field": "location_id",
        "sort": ("transaction_date", "transaction_time"),
        "aliases": ["TankerTransaction"],
    },
    {
        "key": "toa_yade_summary",
        "table": "toa_yade_summary",
        "label": "TOA YADE Summary",
        "class_name": "TOAYadeSummary",
        "date_field": "date",
        "time_field": "time",
        "location_field": None,
        "sort": ("date", "time"),
        "aliases": ["TOAYadeSummary"],
    },
    {
        "key": "otr_records",
        "table": "otr_records",
        "label": "OTR Records",
        "class_name": "OTRRecord",
        "date_field": "date",
        "time_field": "time",
        "location_field": "location_id",
        "sort": ("date", "time"),
        "aliases": ["OTRRecord"],
        "extra_fields": [
            "Net Rece/Disp (bbls)",
            "Net Water Rece/Disp (bbls)",
        ],
    },
    {
        "key": "toa_tanker",
        "table": "toa_tanker",
        "label": "TOA Tanker",
        "class_name": "TOATanker",
        "date_field": "transaction_date",
        "time_field": None,
        "location_field": "location_id",
        "sort": ("transaction_date", "tanker_name"),
        "aliases": ["TOATanker"],
    },
    {
        "key": "material_balance",
        "table": "material_balance",
        "label": "Material Balance",
        "class_name": None,
        "date_field": "Date",
        "time_field": None,
        "location_field": None,
        "sort": ("Date",),
        "aliases": ["MaterialBalance"],
        "type": "material_balance",
    },
    {
        "key": "fso_material_balance",
        "table": "fso_material_balance",
        "label": "FSO Material Balance",
        "class_name": None,
        "date_field": "Date",
        "time_field": None,
        "location_field": None,
        "sort": ("Date",),
        "aliases": ["FSO-MaterialBalance"],
        "type": "fso_material_balance",
    },
    {
        "key": "condensate",
        "table": "tank_transactions",
        "label": "Condensate Receipts",
        "class_name": "TankTransaction",
        "date_field": "date",
        "time_field": "time",
        "location_field": "location_id",
        "sort": ("date", "time"),
        "aliases": ["Condensate"],
        "filter_mode": "condensate_only",
    },
]
REPORT_SOURCE_MAP = {entry["key"]: entry for entry in REPORT_SOURCE_DEFINITIONS}
REPORT_SOURCE_ALIAS_MAP = {}
for entry in REPORT_SOURCE_DEFINITIONS:
    REPORT_SOURCE_ALIAS_MAP[entry["key"].lower()] = entry["key"]
    for alias in entry.get("aliases", []):
        REPORT_SOURCE_ALIAS_MAP[alias.lower()] = entry["key"]

PRIMARY_SOURCE_ORDER = [
    "otr_vessel",
    "convoy_status_vessel",
    "convoy_status_yade",
    "fso_operations",
    "gpp_production_records",
    "tank_transactions",
    "location_tanker_entries",
    "meter_transactions",
    "ofs_production_evacuation_records",
    "produced_water_records",
    "river_draft_records",
    "tanker_transactions",
    "toa_yade_summary",
    "otr_records",
    "toa_tanker",
    "material_balance",
    "fso_material_balance",
    "condensate",
]

@lru_cache(maxsize=None)
def _get_model_class(class_name: str):
    models_module = importlib.import_module("models")
    return getattr(models_module, class_name)

def _resolve_source_key(value: Optional[str]) -> Optional[str]:
    if not value:
        return None
    key = str(value).strip()
    if not key:
        return None
    if key in REPORT_SOURCE_MAP:
        return key
    lowered = key.lower()
    return REPORT_SOURCE_ALIAS_MAP.get(lowered, None)

def _get_source_meta(value: Optional[str]) -> Optional[dict]:
    key = _resolve_source_key(value)
    if not key:
        return None
    return REPORT_SOURCE_MAP.get(key)

@lru_cache(maxsize=None)
def _get_source_fields(value: Optional[str]) -> list[str]:
    meta = _get_source_meta(value)
    if not meta:
        return []
    model_name = meta.get("class_name")
    if not model_name:
        return []
    try:
        model_cls = _get_model_class(model_name)
        fields = list(model_cls.__table__.columns.keys())
    except Exception:
        fields = []
    if meta.get("extra_fields"):
        fields.extend(meta["extra_fields"])
    return fields

@lru_cache(maxsize=None)
def _get_model_columns(value: Optional[str]) -> list[str]:
    meta = _get_source_meta(value)
    if not meta:
        return []
    try:
        model_cls = _get_model_class(meta["class_name"])
        return list(model_cls.__table__.columns.keys())
    except Exception:
        return []

def _available_primary_source_keys() -> list[str]:
    ordered_keys = []
    for key in PRIMARY_SOURCE_ORDER:
        if key in REPORT_SOURCE_MAP and key not in ordered_keys:
            ordered_keys.append(key)
    for key in REPORT_SOURCE_MAP.keys():
        if key not in ordered_keys:
            ordered_keys.append(key)
    return ordered_keys

def _format_source_label(key: str) -> str:
    meta = REPORT_SOURCE_MAP.get(key)
    if not meta:
        return key
    return f"{meta['label']} ({meta['table']})"

def _format_source_option(value: str) -> str:
    meta = _get_source_meta(value)
    if meta:
        return _format_source_label(meta["key"])
    if value:
        return f"{value} (legacy)"
    return "(legacy)"

def _derive_report_date(base_date: Optional[date], maybe_time) -> Optional[date]:
    if not base_date:
        return None
    if maybe_time is None:
        return base_date
    t_obj = convert_to_time_object(maybe_time)
    if not isinstance(t_obj, time):
        return base_date
    if t_obj < REPORT_DAY_START_TIME:
        return base_date - timedelta(days=1)
    return base_date

def _combine_for_bucket(base_date: Optional[date], maybe_time) -> Optional[datetime]:
    if not base_date:
        return None
    t_obj = convert_to_time_object(maybe_time) if maybe_time is not None else REPORT_DAY_START_TIME
    if not isinstance(t_obj, time):
        t_obj = REPORT_DAY_START_TIME
    return datetime.combine(base_date, t_obj)

def _pluck_value(row: Any, field: Optional[str]):
    if not field:
        return None
    try:
        return getattr(row, field)
    except Exception:
        if isinstance(row, dict):
            return row.get(field)
    return None

def _matches_operation_filter(row: Any, expected: str) -> bool:
    if not expected:
        return True
    op_val = _pluck_value(row, "operation")
    if op_val is None:
        return False
    op_text = getattr(op_val, "value", op_val)
    return str(op_text) == expected

def _get_location_obj(session, loc_id: Optional[int]):
    if not loc_id:
        return None
    try:
        from models import Location
        return session.query(Location).filter(Location.id == int(loc_id)).one_or_none()
    except Exception:
        return None

def _calculate_material_balance_rows(session, location_id: Optional[int], date_from: date, date_to: date):
    loc_obj = _get_location_obj(session, location_id)
    if not loc_obj:
        return []
    try:
        rows = MBC.calculate_material_balance(
            None,
            getattr(loc_obj, "code", ""),
            date_from,
            date_to,
            location_id=location_id,
        )
    except Exception:
        rows = []
    return rows or []

def _material_balance_columns_for_location(location_id: Optional[int]) -> list[str]:
    if not location_id:
        return []
    try:
        with get_session() as s_loc:
            sample_rows = _calculate_material_balance_rows(s_loc, location_id, date.today() - timedelta(days=7), date.today())
    except Exception:
        sample_rows = []
    if not sample_rows:
        return ["Date"]
    try:
        df_tmp = pd.DataFrame(sample_rows)
        return list(df_tmp.columns)
    except Exception:
        sample = sample_rows[0]
        if isinstance(sample, dict):
            return list(sample.keys())
    return ["Date"]

_COL_INDEX_PATTERN = re.compile(r"\bcolumn\s*(\d+)\b", re.IGNORECASE)
_BRACKETED_COL_PATTERN = re.compile(r"\[(.+?)\]")

def _normalize_calc_expression(expr: str, columns: list[str]) -> str:
    def _idx_repl(match):
        idx = int(match.group(1)) - 1
        if 0 <= idx < len(columns):
            return f"`{columns[idx]}`"
        return match.group(0)
    result = _COL_INDEX_PATTERN.sub(_idx_repl, expr)
    def _bracket_repl(match):
        name = match.group(1).strip()
        return f"`{name}`" if name else match.group(0)
    result = _BRACKETED_COL_PATTERN.sub(_bracket_repl, result)
    return result

def _fetch_source_rows(
    source_key: str,
    session,
    location_id: Optional[int],
    date_from: date,
    date_to: date,
):
    meta = REPORT_SOURCE_MAP.get(source_key)
    if not meta:
        return []
    special_type = meta.get("type")
    if special_type == "material_balance":
        return _calculate_material_balance_rows(session, location_id, date_from, date_to)
    if special_type == "fso_material_balance":
        return []
    try:
        model_cls = _get_model_class(meta["class_name"])
    except Exception:
        return []
    query = session.query(model_cls)
    location_field = meta.get("location_field")
    if location_field and location_id:
        try:
            query = query.filter(getattr(model_cls, location_field) == location_id)
        except Exception:
            pass
    date_attr = getattr(model_cls, meta["date_field"], None)
    if date_attr is not None:
        range_start = date_from - timedelta(days=1) if meta.get("time_field") else date_from
        range_end = date_to + timedelta(days=1) if meta.get("time_field") else date_to
        query = query.filter(date_attr >= range_start, date_attr <= range_end)
    sort_fields = meta.get("sort") or (meta["date_field"],)
    for field_name in sort_fields:
        sort_attr = getattr(model_cls, field_name, None)
        if sort_attr is not None:
            query = query.order_by(sort_attr.asc())
    try:
        rows = query.all()
    except Exception:
        rows = []
    if meta.get("filter_mode") == "condensate_only":
        rows = [r for r in rows if getattr(r, "condensate_qty_m3", None) not in (None, 0)]
    return rows

def _load_rows_for_any_source(
    source_name: Optional[str],
    session,
    location_id: Optional[int],
    date_from: date,
    date_to: date,
) -> tuple[list[Any], Optional[str]]:
    canonical = _resolve_source_key(source_name)
    if canonical:
        return _fetch_source_rows(canonical, session, location_id, date_from, date_to), canonical
    if not source_name:
        return [], None
    normalized = str(source_name).strip()
    legacy_key = normalized.lower().replace("-", "").replace("_", "")
    legacy_map = {
        "materialbalance": "material_balance",
        "fsomaterialbalance": "fso_material_balance",
        "condensate": "condensate",
    }
    mapped = legacy_map.get(legacy_key)
    if mapped:
        return _fetch_source_rows(mapped, session, location_id, date_from, date_to), mapped
    return [], None

def _discover_source_fields(source_value: Optional[str], src_location_id: Optional[int]) -> list[str]:
    key = _resolve_source_key(source_value) or str(source_value or "")
    if key == "material_balance":
        return _material_balance_columns_for_location(src_location_id)
    if key == "fso_material_balance":
        return [
            "Date",
            "Opening Stock",
            "Opening Water",
            "Receipts",
            "Exports",
            "Closing Stock",
            "Closing Water",
            "Loss/Gain",
        ]
    if key == "condensate":
        return _get_source_fields("tank_transactions")
    try:
        return _get_source_fields(key)
    except Exception:
        return []
# ---- Streamlit safe rerun helper (prevents 'DeltaGenerator.rerun' errors) ----
def _st_safe_rerun():
    try:
        import streamlit as _stmod
        _stmod.rerun()
    except Exception:
        import streamlit as _stmod
        _stmod.experimental_rerun()

def _open_pdf_blob(pdf_bytes: bytes, filename: str = "OTMS.pdf") -> None:
    """Open a PDF blob in a new browser tab via base64 injection."""
    b64 = base64.b64encode(pdf_bytes).decode("ascii")
    components.html(
        f"""
        <script>
        (function(){{
            const b64="{b64}";
            const bytes=atob(b64);
            const len=bytes.length;
            const out=new Uint8Array(len);
            for(let i=0;i<len;i++){{out[i]=bytes.charCodeAt(i);}}
            const blob=new Blob([out],{{type:"application/pdf"}});
            const url=URL.createObjectURL(blob);
            const win=window.open(url,"_blank");
            if(!win){{alert("Please allow pop-ups for OTMS to display the PDF.");}}
            setTimeout(()=>URL.revokeObjectURL(url),120000);
        }})();
        </script>
        """,
        height=0,
    )

def _current_user_audit_context():
    """Return (username, user_id, location_id) from session safely."""
    u = st.session_state.get("auth_user") or {}
    username = u.get("username", "unknown")
    user_id = u.get("id")
    location_id = st.session_state.get("active_location_id")
    return username, user_id, location_id


def _list_supervisors(location_id: Optional[int] = None) -> List[Dict[str, Any]]:
    """Return active supervisors (optionally filtered by location)."""
    with get_session() as s:
        supervisors = (
            s.query(User)
            .filter(
                User.role == "supervisor",
                User.is_active == True,  # noqa: E712
            )
        )
        if location_id:
            supervisors = supervisors.filter(
                or_(User.location_id == location_id, User.location_id.is_(None))
            )
        supervisors = supervisors.order_by(User.full_name, User.username).all()
        return [
            {
                "username": sup.username,
                "full_name": sup.full_name or sup.username,
                "location_id": sup.location_id,
            }
            for sup in supervisors
        ]


def _supervisor_dropdown(label: str, key: str, location_id: Optional[int]) -> tuple[Optional[str], Optional[str]]:
    """Render a supervisor selector and return (username, display_label)."""
    supervisors = _list_supervisors(location_id)
    if not supervisors:
        st.warning("No supervisors available for approval.")
        return None, None
    options = {
        f"{sup['full_name']} ({sup['username']})": sup["username"] for sup in supervisors
    }
    display = st.selectbox(label, list(options.keys()), key=key)
    return options.get(display), display


def _convoy_canonical_fso_code(value: Optional[str]) -> str:
    """Normalize FSO location codes (AGGE / OML-13)."""
    if not value:
        return ""
    text = str(value).strip().upper()
    simplified = text.replace(" ", "").replace("-", "")
    aliases = {
        "UTAPATE": "OML-13",
        "OML13": "OML-13",
        "OML 13": "OML-13",
        "OML-13": "OML-13",
        "AGGE": "AGGE",
    }
    if text in aliases:
        return aliases[text]
    return aliases.get(simplified, text)


def _convoy_fetch_mb_closing_value(
    selected_date: date, location_code: Optional[str]
) -> Tuple[Optional[str], Optional[float]]:
    """Fetch closing stock display/value from cached Material Balance artifacts."""
    canon_code = _convoy_canonical_fso_code(location_code)
    if not canon_code:
        return None, None
    target_norm = canon_code.replace("-", "").replace(" ", "")

    for state_key in FSO_MATERIAL_BALANCE_STATE_KEYS:
        if state_key not in st.session_state:
            continue
        raw_obj = st.session_state.get(state_key)
        try:
            df = raw_obj.copy() if isinstance(raw_obj, pd.DataFrame) else pd.DataFrame(raw_obj)
        except Exception:
            continue
        if df is None or df.empty:
            continue

        date_col = next(
            (c for c in df.columns if str(c).strip().lower() in {"date", "mb date", "as of", "asof"}),
            None,
        )
        if not date_col:
            continue

        dfx = df.copy()
        dfx[date_col] = pd.to_datetime(dfx[date_col], errors="coerce").dt.date
        dfx = dfx[dfx[date_col] == selected_date]
        if dfx.empty:
            continue

        loc_col = next(
            (c for c in dfx.columns if str(c).strip().lower() in {"location", "loc", "site", "code"}),
            None,
        )
        if loc_col:
            dfx["_convoy_loc_norm"] = (
                dfx[loc_col]
                .astype(str)
                .str.upper()
                .str.replace(" ", "", regex=False)
                .str.replace("-", "", regex=False)
            )
            dfx = dfx[dfx["_convoy_loc_norm"] == target_norm]
            if dfx.empty:
                continue

        close_candidates = [
            "closing stock (bbls)",
            "closing stock",
            "closing_stock",
            "closing_stock_bbl",
        ]
        close_col = None
        columns_lower = {str(col).strip().lower(): col for col in dfx.columns}
        for cand in close_candidates:
            if cand in columns_lower:
                close_col = columns_lower[cand]
                break
        if not close_col:
            continue

        display_value = None
        numeric_value = None
        for raw_val in dfx[close_col]:
            if raw_val is None:
                continue
            raw_str = str(raw_val).strip()
            if not raw_str:
                continue
            numeric_series = pd.to_numeric(pd.Series([raw_val]), errors="coerce").dropna()
            if numeric_series.empty:
                continue
            display_value = raw_str
            numeric_value = float(numeric_series.iloc[-1])
        if display_value is not None or numeric_value is not None:
            return display_value, numeric_value

    return None, None


def _convoy_fallback_closing_from_ops(
    selected_date: date, location_id: Optional[int], vessel_name: Optional[str]
) -> Optional[float]:
    """Fallback closing stock lookup from FSOOperation entries."""
    if not location_id or not vessel_name:
        return None
    from models import FSOOperation  # local import to avoid circular deps

    ext_from = selected_date - timedelta(days=1)
    ext_to = selected_date + timedelta(days=1)
    with get_session() as s:
        rows = (
            s.query(FSOOperation)
            .filter(
                FSOOperation.location_id == location_id,
                FSOOperation.fso_vessel == vessel_name,
                FSOOperation.date >= ext_from,
                FSOOperation.date <= ext_to,
            )
            .order_by(FSOOperation.date, FSOOperation.time)
            .all()
        )
    if not rows:
        return None

    win_start = datetime.combine(selected_date, dt_time(6, 1))
    win_end = datetime.combine(selected_date + timedelta(days=1), dt_time(6, 0))

    def _safe_time(val):
        if isinstance(val, dt_time):
            return val
        try:
            return datetime.strptime(str(val), "%H:%M").time()
        except Exception:
            return dt_time(0, 0)

    period_rows = []
    for row in rows:
        try:
            ts = datetime.combine(row.date, _safe_time(row.time))
        except Exception:
            continue
        if win_start <= ts <= win_end:
            period_rows.append(row)
    if not period_rows:
        return None
    period_rows.sort(key=lambda r: datetime.combine(r.date, _safe_time(r.time)))
    last_entry = period_rows[-1]
    try:
        return float(last_entry.closing_stock or 0.0)
    except Exception:
        return None


def _normalize_date_value(val: Any) -> Optional[date]:
    """Convert supported date/datetime values to date objects."""
    if isinstance(val, datetime):
        return val.date()
    if isinstance(val, date):
        return val
    return None


def _derive_filter_bounds(date_values: List[Any], fallback_days: int = 14) -> tuple[date, date]:
    """
    Return (min_date, max_date) bounds for live filters.
    When there are no valid dates fall back to a recent rolling window ending today.
    """
    today_local = date.today()
    normalized = [
        d for d in (_normalize_date_value(v) for v in date_values) if d is not None
    ]
    if normalized:
        min_date = min(normalized)
        max_date = min(max(normalized), today_local)
        if min_date > max_date:
            min_date = max_date
    else:
        max_date = today_local
        min_date = today_local - timedelta(days=fallback_days)
    return min_date, max_date


def _ensure_date_key_in_bounds(
    key: str,
    min_value: date,
    max_value: date,
    default_value: Optional[date] = None,
) -> date:
    """Clamp st.session_state[key] within [min_value, max_value] and return it."""
    if default_value is None:
        default_value = min_value
    current = st.session_state.get(key, default_value)
    normalized = _normalize_date_value(current) or default_value
    if normalized < min_value:
        normalized = min_value
    if normalized > max_value:
        normalized = max_value
    st.session_state[key] = normalized
    return normalized


EDIT_LOCK_HOURS = 24


def _record_created_timestamp(record: Any) -> Optional[datetime]:
    """Best-effort extraction of the datetime a record was created."""
    ts = getattr(record, "created_at", None) or getattr(record, "timestamp", None)
    if isinstance(ts, datetime):
        return ts.replace(tzinfo=None)
    date_val = getattr(record, "date", None)
    time_val = getattr(record, "time", None)
    if date_val:
        if isinstance(time_val, time):
            return datetime.combine(date_val, time_val)
        return datetime.combine(date_val, datetime.min.time())
    return None


def _is_edit_lock_active(record: Any, hours: int = EDIT_LOCK_HOURS) -> tuple[bool, Optional[datetime]]:
    """Return (locked, created_at) tuple for a record."""
    created_at = _record_created_timestamp(record)
    if not created_at:
        return False, None
    return (datetime.utcnow() - created_at) > timedelta(hours=hours), created_at


def _deny_edit_for_lock(record: Any, resource_type: str, label: Optional[str] = None) -> bool:
    """Check and block editing if record is older than the configured window."""
    locked, created_at = _is_edit_lock_active(record)
    if not locked:
        return False
    label = label or getattr(record, "ticket_id", None) or getattr(record, "id", "record")
    ts_display = format_local_datetime(created_at) if created_at else "unknown time"
    message = (
        f"Editing locked - {resource_type} {label} was created on {ts_display}. "
        f"Records older than {EDIT_LOCK_HOURS} hours cannot be modified."
    )
    st.warning(message)
    try:
        username, user_id, location_id = _current_user_audit_context()
        SecurityManager.log_audit(
            None,
            username,
            "UPDATE_BLOCKED",
            resource_type=resource_type,
            resource_id=str(getattr(record, "id", label)),
            details=message,
            user_id=user_id,
            location_id=location_id,
            success=False,
        )
    except Exception:
        pass
    return True


def _archive_record_for_delete(
    session,
    record: Any,
    resource_type: str,
    reason: Optional[str] = None,
    label: Optional[str] = None,
    extra_payload: Optional[Dict[str, Any]] = None,
):
    """Push the record into the recycle bin and log the action."""
    username, user_id, location_id = _current_user_audit_context()
    payload = RecycleBinManager.snapshot_record(record)
    if extra_payload:
        payload.update(extra_payload)
    entry = RecycleBinManager.archive_payload(
        session,
        resource_type=resource_type,
        resource_id=str(payload.get("id") or label or resource_type),
        payload=payload,
        username=username,
        user_id=user_id,
        location_id=location_id,
        reason=reason,
        label=label or payload.get("ticket_id") or payload.get("id"),
    )
    session.delete(record)
    try:
        SecurityManager.log_audit(
            session,
            username,
            "DELETE",
            resource_type=resource_type,
            resource_id=entry.resource_id,
            details=reason or f"Moved {resource_type} {entry.resource_id} to recycle bin.",
            user_id=user_id,
            location_id=location_id,
        )
    except Exception:
        pass
    return entry


def _archive_payload_for_delete(
    session,
    resource_type: str,
    resource_id: str,
    payload: Dict[str, Any],
    reason: Optional[str] = None,
    label: Optional[str] = None,
):
    """Archive raw payloads (for bulk deletes)."""
    username, user_id, location_id = _current_user_audit_context()
    entry = RecycleBinManager.archive_payload(
        session,
        resource_type=resource_type,
        resource_id=resource_id,
        payload=payload,
        username=username,
        user_id=user_id,
        location_id=location_id,
        reason=reason,
        label=label,
    )
    try:
        SecurityManager.log_audit(
            session,
            username,
            "DELETE",
            resource_type=resource_type,
            resource_id=resource_id,
            details=reason or f"Archived {resource_type} {resource_id} payload to recycle bin.",
            user_id=user_id,
            location_id=location_id,
        )
    except Exception:
        pass
    return entry


TEMP_LIMITS = {
    "C": (0.0, 60.0),
    "F": (32.0, 120.0),
}
API_MIN, API_MAX = 15.0, 70.0
DENSITY_MIN, DENSITY_MAX = 600.0, 1000.0


def _normalize_temp_unit(unit: Optional[str]) -> str:
    """Normalize temperature units to either "C" or "F".

    The original implementation attempted to strip an unknown replacement
    character (�) that appeared when the degree symbol (°) was lost during
    encoding. In the corrected version we explicitly remove the degree
    symbol to ensure that inputs like "°C" and "°F" are handled properly.
    """
    label = (unit or "").strip().upper().replace("°", "")
    return "F" if label.startswith("F") else "C"


def _temperature_bounds(unit: Optional[str]) -> tuple[float, float]:
    norm = _normalize_temp_unit(unit)
    return TEMP_LIMITS.get(norm, TEMP_LIMITS["C"])


def _clamp_value(value: Optional[float], min_value: float, max_value: float) -> float:
    if value is None:
        return min_value
    try:
        numeric = float(value)
    except Exception:
        return min_value
    return max(min(numeric, max_value), min_value)


def _session_state_proxy():
    try:
        state = st.session_state
        if hasattr(state, "__contains__"):
            return state
    except Exception:
        return None


def _coerce_numeric_state(key: str, min_value: float, max_value: float):
    state_key = str(key)
    state = _session_state_proxy()
    if state is not None and state_key in state:
        state[state_key] = _clamp_value(state[state_key], min_value, max_value)


def _bounded_number_input(
    label: str,
    key: str,
    min_value: float,
    max_value: float,
    *,
    value: Optional[float] = None,
    **kwargs,
):
    state_key = str(key)
    state = _session_state_proxy()
    if state is not None:
        _coerce_numeric_state(state_key, min_value, max_value)
    params = dict(kwargs)
    params["min_value"] = min_value
    params["max_value"] = max_value
    params["key"] = state_key
    if "step" not in params:
        params["step"] = 0.1
    if value is not None:
        params["value"] = _clamp_value(value, min_value, max_value)
    return st.number_input(label, **params)


def _temperature_input(
    label: str,
    unit: Optional[str],
    key: str,
    *,
    value: Optional[float] = None,
    **kwargs,
):
    min_value, max_value = _temperature_bounds(unit)
    return _bounded_number_input(label, key, min_value, max_value, value=value, **kwargs)


def _observed_value_bounds(mode: str) -> tuple[float, float]:
    return (
        (DENSITY_MIN, DENSITY_MAX)
        if "density" in (mode or "").lower()
        else (API_MIN, API_MAX)
    )


_original_streamlit_error = st.error


def _otms_error(message, *args, **kwargs):
    """Wrap Streamlit error to auto-create admin tasks for critical failures."""
    result = _original_streamlit_error(message, *args, **kwargs)
    try:
        text_message = str(message)
        if TaskManager.should_capture_error(text_message):
            TaskManager.log_ui_error_task(
                text_message,
                st.session_state.get("auth_user"),
                st.session_state.get("active_location_id"),
            )
    except Exception:
        log_error("Unable to record UI error as task", exc_info=True)
    return result


st.error = _otms_error


def _format_task_timestamp(value):
    try:
        return format_local_datetime(value) if value else "-"
    except Exception:
        return "-"


# ------------------ OFS Production & Evacuation Helpers ------------------
def _next_ofs_serial(session, location_id: int) -> int:
    """
    Compute the next serial number for OFS production records for a location.
    Serial numbers increment by 1 per location and never reset unless records
    are purged. If no records exist, start from 1.
    """
    try:
        max_serial = session.query(func.max(OFSProductionEvacuationRecord.serial_no)).filter(
            OFSProductionEvacuationRecord.location_id == int(location_id)
        ).scalar() or 0
        return int(max_serial) + 1
    except Exception:
        return 1


def _next_tanker_serial(session, location_id: int) -> int:
    """Return next serial number for tanker entries per location."""
    try:
        max_serial = (
            session.query(func.max(LocationTankerEntry.serial_no))
            .filter(LocationTankerEntry.location_id == int(location_id))
            .scalar()
            or 0
        )
        return int(max_serial) + 1
    except Exception:
        return 1

def render_ofs_production_page(active_location_id: int, loc: Any, user: Dict[str, Any]):
    """
    Render the OFS Production & Evacuation tab for a given location.

    This page allows users to add, edit and view daily production and evacuation
    entries for OFS locations (e.g. OML-157). A simple form captures metrics
    for Oguali and Ukpichi production, other locations, evacuation and tanker
    counts. Records are displayed below with edit/delete controls and live
    date filters. Deletion is disabled for operator role.
    """
    import pandas as pd  # local import to avoid polluting top-level namespace
    from permission_manager import PermissionManager
    from security import SecurityManager

    user_role = (user.get("role") or "").lower()
    # Determine permissions: allow creation/edit if user can make entries
    with get_session() as _sess:
        can_make_entries = PermissionManager.can_make_entries(_sess, user_role, active_location_id)
    # Deletion is disabled for operators
    can_delete = can_make_entries and user_role != "operator"

    today = date.today()

    # Ensure session state defaults for form values
    def _ensure_ofs_defaults():
        ss = st.session_state
        ss.setdefault("ofs_form_date", today)
        ss.setdefault("ofs_form_oguali", 0.0)
        ss.setdefault("ofs_form_ukpichi", 0.0)
        ss.setdefault("ofs_form_other_locations", 0.0)
        ss.setdefault("ofs_form_evacuation", 0.0)
        ss.setdefault("ofs_form_tankers_oguali", 0.0)
        ss.setdefault("ofs_form_tankers_ukpichi", 0.0)
        ss.setdefault("ofs_form_other_tankers", 0.0)
        ss.setdefault("ofs_edit_id", None)

    def _reset_ofs_form():
        ss = st.session_state
        ss["ofs_edit_id"] = None
        ss["ofs_form_date"] = today
        ss["ofs_form_oguali"] = 0.0
        ss["ofs_form_ukpichi"] = 0.0
        ss["ofs_form_other_locations"] = 0.0
        ss["ofs_form_evacuation"] = 0.0
        ss["ofs_form_tankers_oguali"] = 0.0
        ss["ofs_form_tankers_ukpichi"] = 0.0
        ss["ofs_form_other_tankers"] = 0.0

    _ensure_ofs_defaults()
    is_editing = st.session_state.get("ofs_edit_id") is not None

    st.markdown("#### OFS Production & Evacuation")
    if is_editing:
        st.info(f"Editing record for {st.session_state.get('ofs_form_date')}")

    # ---- Input form ----
    with st.container(border=True):
        entry_cols = st.columns([0.15, 0.15, 0.15, 0.15, 0.1, 0.1, 0.1, 0.1])
        # Date
        with entry_cols[0]:
            date_val = st.date_input(
                "Date",
                value=st.session_state.get("ofs_form_date", today),
                key="ofs_prod_date_input",
            )
            st.session_state["ofs_form_date"] = date_val
        # Oguali Production
        with entry_cols[1]:
            oguali_val = st.number_input(
                "Oguali Production",
                min_value=0.0,
                step=1.0,
                value=float(st.session_state.get("ofs_form_oguali", 0.0)),
                key="ofs_prod_oguali_input",
            )
            st.session_state["ofs_form_oguali"] = oguali_val
        # Ukpichi Production
        with entry_cols[2]:
            ukpichi_val = st.number_input(
                "Ukpichi Production",
                min_value=0.0,
                step=1.0,
                value=float(st.session_state.get("ofs_form_ukpichi", 0.0)),
                key="ofs_prod_ukpichi_input",
            )
            st.session_state["ofs_form_ukpichi"] = ukpichi_val
        # Other Locations Production
        with entry_cols[3]:
            other_loc_val = st.number_input(
                "Other Locations",
                min_value=0.0,
                step=1.0,
                value=float(st.session_state.get("ofs_form_other_locations", 0.0)),
                key="ofs_prod_other_loc_input",
            )
            st.session_state["ofs_form_other_locations"] = other_loc_val
        # Evacuation
        with entry_cols[4]:
            evacuation_val = st.number_input(
                "Evacuation",
                min_value=0.0,
                step=1.0,
                value=float(st.session_state.get("ofs_form_evacuation", 0.0)),
                key="ofs_prod_evac_input",
            )
            st.session_state["ofs_form_evacuation"] = evacuation_val
        # Tankers - Oguali
        with entry_cols[5]:
            t_oguali_val = st.number_input(
                "Tankers - Oguali",
                min_value=0.0,
                step=1.0,
                value=float(st.session_state.get("ofs_form_tankers_oguali", 0.0)),
                key="ofs_prod_tankers_oguali_input",
            )
            st.session_state["ofs_form_tankers_oguali"] = t_oguali_val
        # Tankers - Ukpichi
        with entry_cols[6]:
            t_ukpichi_val = st.number_input(
                "Tankers - Ukpichi",
                min_value=0.0,
                step=1.0,
                value=float(st.session_state.get("ofs_form_tankers_ukpichi", 0.0)),
                key="ofs_prod_tankers_ukpichi_input",
            )
            st.session_state["ofs_form_tankers_ukpichi"] = t_ukpichi_val
        # Other Tankers
        with entry_cols[7]:
            t_other_val = st.number_input(
                "Other Tankers",
                min_value=0.0,
                step=1.0,
                value=float(st.session_state.get("ofs_form_other_tankers", 0.0)),
                key="ofs_prod_tankers_other_input",
            )
            st.session_state["ofs_form_other_tankers"] = t_other_val

        # Action buttons
        action_cols = st.columns([0.2, 0.2, 0.6])
        save_label = "Update" if is_editing else "Save"
        save_clicked = action_cols[0].button(
            save_label,
            type="primary",
            disabled=not can_make_entries,
            key="ofs_save_btn",
        )
        cancel_clicked = False
        if is_editing:
            cancel_clicked = action_cols[1].button("Cancel", key="ofs_cancel_btn")

        if cancel_clicked:
            _reset_ofs_form()
            _st_safe_rerun()

        if save_clicked:
            errors: List[str] = []
            if date_val is None:
                errors.append("Date is required.")
            # At least one production or evacuation or tankers should have positive value
            total_sum = (
                float(oguali_val or 0)
                + float(ukpichi_val or 0)
                + float(other_loc_val or 0)
                + float(evacuation_val or 0)
                + float(t_oguali_val or 0)
                + float(t_ukpichi_val or 0)
                + float(t_other_val or 0)
            )
            if total_sum <= 0:
                errors.append("At least one entry must be greater than zero.")
            if errors:
                for err in errors:
                    st.error(err)
            else:
                try:
                    with get_session() as sess:
                        if is_editing:
                            rec = (
                                sess.query(OFSProductionEvacuationRecord)
                                .filter(
                                    OFSProductionEvacuationRecord.id == int(st.session_state["ofs_edit_id"]),
                                    OFSProductionEvacuationRecord.location_id == active_location_id,
                                )
                                .one_or_none()
                            )
                            if not rec:
                                st.error("Selected record no longer exists.")
                            else:
                                rec.date = date_val
                                rec.oguali_production = float(oguali_val or 0.0)
                                rec.ukpichi_production = float(ukpichi_val or 0.0)
                                rec.other_locations = float(other_loc_val or 0.0)
                                rec.evacuation = float(evacuation_val or 0.0)
                                rec.tankers_oguali = float(t_oguali_val or 0.0)
                                rec.tankers_ukpichi = float(t_ukpichi_val or 0.0)
                                rec.other_tankers = float(t_other_val or 0.0)
                                rec.updated_by = user.get("username", "unknown")
                                SecurityManager.log_audit(
                                    sess,
                                    user.get("username", "unknown"),
                                    "UPDATE",
                                    resource_type="OFSProductionEvacuationRecord",
                                    resource_id=rec.id,
                                    details=f"Updated OFS record for {rec.date}",
                                    user_id=user.get("id"),
                                    location_id=active_location_id,
                                )
                                sess.commit()
                                st.success("Record updated successfully.")
                                _reset_ofs_form()
                                _st_safe_rerun()
                        else:
                            # Create new record with next serial
                            next_serial = _next_ofs_serial(sess, active_location_id)
                            rec = OFSProductionEvacuationRecord(
                                location_id=active_location_id,
                                serial_no=next_serial,
                                date=date_val,
                                oguali_production=float(oguali_val or 0.0),
                                ukpichi_production=float(ukpichi_val or 0.0),
                                other_locations=float(other_loc_val or 0.0),
                                evacuation=float(evacuation_val or 0.0),
                                tankers_oguali=float(t_oguali_val or 0.0),
                                tankers_ukpichi=float(t_ukpichi_val or 0.0),
                                other_tankers=float(t_other_val or 0.0),
                                created_by=user.get("username", "unknown"),
                            )
                            sess.add(rec)
                            sess.flush()
                            SecurityManager.log_audit(
                                sess,
                                user.get("username", "unknown"),
                                "CREATE",
                                resource_type="OFSProductionEvacuationRecord",
                                resource_id=rec.id,
                                details=f"Created OFS record for {date_val}",
                                user_id=user.get("id"),
                                location_id=active_location_id,
                            )
                            sess.commit()
                            st.success("Record saved successfully.")
                            _reset_ofs_form()
                            _st_safe_rerun()
                except Exception as ex:
                    st.error(f"Failed to save record: {ex}")

    with get_session() as sess:
        rows = (
            sess.query(OFSProductionEvacuationRecord)
            .filter(OFSProductionEvacuationRecord.location_id == active_location_id)
            .order_by(
                OFSProductionEvacuationRecord.date.desc(),
                OFSProductionEvacuationRecord.serial_no.desc(),
            )
            .all()
        )

    ofs_dates = [r.date for r in rows if isinstance(r.date, date)]
    ofs_min_date, ofs_max_date = _derive_filter_bounds(ofs_dates)
    ofs_from_default = _ensure_date_key_in_bounds(
        "ofs_filter_from", ofs_min_date, ofs_max_date, ofs_min_date
    )
    ofs_to_default = _ensure_date_key_in_bounds(
        "ofs_filter_to", ofs_min_date, ofs_max_date, ofs_max_date
    )

    # ---- Filters ----
    st.markdown("##### Live Filters")
    filter_cols = st.columns([0.3, 0.3, 0.4])
    with filter_cols[0]:
        filt_from = st.date_input(
            "From date",
            value=ofs_from_default,
            min_value=ofs_min_date,
            max_value=ofs_max_date,
            key="ofs_filter_from",
        )
    with filter_cols[1]:
        filt_to = st.date_input(
            "To date",
            value=ofs_to_default,
            min_value=ofs_min_date,
            max_value=ofs_max_date,
            key="ofs_filter_to",
        )
    with filter_cols[2]:
        search_term = st.text_input(
            "Search (not used yet)",
            key="ofs_filter_search",
        ).strip().lower()

    # ---- Load & display records (single table with actions) ----
    records_list = []
    for r in rows:
        records_list.append(
            {
                "id": r.id,
                "S.No": r.serial_no,
                "Date": r.date,
                "Oguali Production": r.oguali_production,
                "Ukpichi Production": r.ukpichi_production,
                "Other Locations": r.other_locations,
                "Evacuation": r.evacuation,
                "Tankers - Oguali": r.tankers_oguali,
                "Tankers - Ukpichi": r.tankers_ukpichi,
                "Other Tankers": r.other_tankers,
                "Created By": r.created_by,
                "Updated By": r.updated_by,
                "Updated At": r.updated_at,
            }
        )

    df = pd.DataFrame(records_list)
    if not df.empty:
        df["Date"] = pd.to_datetime(df["Date"]).dt.date
        if filt_from:
            df = df[df["Date"] >= filt_from]
        if filt_to:
            df = df[df["Date"] <= filt_to]
        # Note: search_term reserved for future use

    st.caption(f"{len(df)} record(s) shown")

    if df.empty:
        st.info("No records found for the selected filters.")
        return

    # ---------- Single table with header + rows + Actions ----------
    display_cols = [
        "S.No",
        "Date",
        "Oguali Production",
        "Ukpichi Production",
        "Other Locations",
        "Evacuation",
        "Tankers - Oguali",
        "Tankers - Ukpichi",
        "Other Tankers",
    ]

    st.markdown("##### Saved OFS Records")

    # Header row
    header_cols = st.columns([0.06, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.12])
    header_labels = display_cols + ["Actions"]
    for col, label in zip(header_cols, header_labels):
        col.markdown(f"**{label}**")

    # Sort by date descending then serial descending
    manage_records = (
        df.sort_values(by=["Date", "S.No"], ascending=[False, False])
        .to_dict("records")
    )

    for rec in manage_records:
        cols = st.columns([0.06, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.12])
        cols[0].write(int(rec["S.No"]))
        cols[1].write(str(rec["Date"]))
        cols[2].write(f"{rec['Oguali Production']:,}")
        cols[3].write(f"{rec['Ukpichi Production']:,}")
        cols[4].write(f"{rec['Other Locations']:,}")
        cols[5].write(f"{rec['Evacuation']:,}")
        cols[6].write(f"{rec['Tankers - Oguali']:,}")
        cols[7].write(f"{rec['Tankers - Ukpichi']:,}")
        cols[8].write(f"{rec['Other Tankers']:,}")

        # Actions column: place edit and delete buttons side by side
        with cols[9]:
            e_col, d_col = st.columns(2)
            edit_btn = e_col.button(
                "✏️", key=f"ofs_edit_{rec['id']}", disabled=not can_make_entries
            )
            delete_btn = d_col.button(
                "🗑️", key=f"ofs_delete_{rec['id']}", disabled=not can_delete
            )

        if edit_btn:
            allow_edit = True
            with get_session() as _lock_s:
                obj = (
                    _lock_s.query(OFSProductionEvacuationRecord)
                    .filter(
                        OFSProductionEvacuationRecord.id == int(rec["id"]),
                        OFSProductionEvacuationRecord.location_id == active_location_id,
                    )
                    .one_or_none()
                )
                if obj and _deny_edit_for_lock(obj, "OFSProductionEvacuationRecord", f"{obj.date}"):
                    allow_edit = False
            if allow_edit:
                st.session_state["ofs_edit_id"] = rec["id"]
                # populate form values
                st.session_state["ofs_form_date"] = rec["Date"]
                st.session_state["ofs_form_oguali"] = rec["Oguali Production"]
                st.session_state["ofs_form_ukpichi"] = rec["Ukpichi Production"]
                st.session_state["ofs_form_other_locations"] = rec["Other Locations"]
                st.session_state["ofs_form_evacuation"] = rec["Evacuation"]
                st.session_state["ofs_form_tankers_oguali"] = rec["Tankers - Oguali"]
                st.session_state["ofs_form_tankers_ukpichi"] = rec["Tankers - Ukpichi"]
                st.session_state["ofs_form_other_tankers"] = rec["Other Tankers"]
                _st_safe_rerun()

        if delete_btn:
            try:
                with get_session() as dsess:
                    row = (
                        dsess.query(OFSProductionEvacuationRecord)
                        .filter(
                            OFSProductionEvacuationRecord.id == int(rec["id"]),
                            OFSProductionEvacuationRecord.location_id == active_location_id,
                        )
                        .one_or_none()
                    )
                    if not row:
                        st.warning("Record already removed.")
                    else:
                        _archive_record_for_delete(
                            dsess,
                            row,
                            "OFSProductionEvacuationRecord",
                            reason=f"Marked OFS record for {row.date} for deletion.",
                            label=f"{row.date}",
                        )
                        dsess.commit()
                        st.success("Record moved to recycle bin.")
                        _reset_ofs_form()
                        _st_safe_rerun()
            except Exception as ex:
                st.error(f"Failed to delete record: {ex}")

def render_ofs_reports_tab(active_location_id: int, loc: Any, user: Optional[Dict[str, Any]] = None) -> None:
    """
    Render OFS Production & Evacuation reporting tab. This report is only shown for locations
    whose code normalizes to OML-157. It provides live date filters and allows export to
    CSV/XLSX/PDF or viewing the PDF inline.
    """
    import base64
    from io import BytesIO
    from datetime import date, timedelta

    import pandas as pd
    import streamlit as st
    import streamlit.components.v1 as components
    from reportlab.lib import colors
    from reportlab.lib.enums import TA_CENTER
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet
    from reportlab.lib.units import cm
    from reportlab.platypus import Paragraph, SimpleDocTemplate, Spacer, Table, TableStyle

    from db import get_session
    from models import OFSProductionEvacuationRecord

    st.subheader("OFS Production & Evacuation Report")

    with get_session() as s:
        rows = (
            s.query(OFSProductionEvacuationRecord)
            .filter(OFSProductionEvacuationRecord.location_id == active_location_id)
            .order_by(OFSProductionEvacuationRecord.date, OFSProductionEvacuationRecord.id)
            .all()
        )

    data = []
    for r in rows:
        data.append(
            {
                "S.No": r.serial_no,
                "Date": r.date,
                "Oguali Production": r.oguali_production,
                "Ukpichi Production": r.ukpichi_production,
                "Other Locations": r.other_locations,
                "Evacuation": r.evacuation,
                "Tankers - Oguali": r.tankers_oguali,
                "Tankers - Ukpichi": r.tankers_ukpichi,
                "Other Tankers": r.other_tankers,
            }
        )

    df = pd.DataFrame(data)
    ofs_report_dates = df["Date"].tolist() if not df.empty else []
    rpt_min, rpt_max = _derive_filter_bounds(ofs_report_dates)
    rpt_from_default = _ensure_date_key_in_bounds(
        "ofs_rpt_from", rpt_min, rpt_max, rpt_min
    )
    rpt_to_default = _ensure_date_key_in_bounds(
        "ofs_rpt_to", rpt_min, rpt_max, rpt_max
    )

    # ---- Live Filters ----
    with st.container(border=True):
        c1, c2 = st.columns([0.5, 0.5])
        with c1:
            f_from: date = st.date_input(
                "From",
                value=rpt_from_default,
                min_value=rpt_min,
                max_value=rpt_max,
                key="ofs_rpt_from",
            )
        with c2:
            f_to: date = st.date_input(
                "To",
                value=rpt_to_default,
                min_value=rpt_min,
                max_value=rpt_max,
                key="ofs_rpt_to",
            )

    display_cols = [
        "S.No",
        "Date",
        "Oguali Production",
        "Ukpichi Production",
        "Other Locations",
        "Evacuation",
        "Tankers - Oguali",
        "Tankers - Ukpichi",
        "Other Tankers",
    ]

    if not df.empty:
        # Normalize Date
        df["Date"] = pd.to_datetime(df["Date"]).dt.date

        # Apply date filters
        if f_from:
            df = df[df["Date"] >= f_from]
        if f_to:
            df = df[df["Date"] <= f_to]

    st.caption(f"{len(df)} record(s) found")

    if df.empty:
        st.info("No records found for the selected date range.")
        return

    # Show table
    st.dataframe(df[display_cols], use_container_width=True, hide_index=True)

    # ---------- PDF builder (conventional OTMS style, A4 portrait, 0.5 cm margins) ----------
    def build_pdf(dataframe: pd.DataFrame) -> bytes:
        # Work on a copy to avoid mutating original df
        _df = dataframe.copy()

        # Convert numeric columns safely
        for col in _df.columns:
            if col not in ("S.No", "Date"):
                _df[col] = pd.to_numeric(_df[col], errors="coerce").fillna(0.0)

        buffer = BytesIO()

        # A4 portrait, 0.5 cm margins on all sides
        page_w, _page_h = A4
        lm = rm = tm = bm = 0.5 * cm

        doc = SimpleDocTemplate(
            buffer,
            pagesize=A4,
            leftMargin=lm,
            rightMargin=rm,
            topMargin=tm,
            bottomMargin=bm,
        )

        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            "OFS_TITLE",
            parent=styles["Heading1"],
            fontSize=15,
            alignment=TA_CENTER,
            textColor=colors.HexColor("#1f4788"),
        )
        sub_style = ParagraphStyle(
            "OFS_SUBTITLE",
            parent=styles["Normal"],
            fontSize=10,
            alignment=TA_CENTER,
            textColor=colors.HexColor("#666666"),
        )

        elements = []
        # Title & subtitle (same convention as other reports)
        elements.append(Paragraph("<b>OFS PRODUCTION & EVACUATION</b>", title_style))
        elements.append(
            Paragraph(
                f"{loc.name} ({loc.code}) � Period: <b>{str(f_from)}</b> to <b>{str(f_to)}</b>",
                sub_style,
            )
        )
        elements.append(Spacer(1, 0.3 * cm))

        # Table headers & rows
        headers = display_cols
        table_data = [headers]

        for _, row in _df.iterrows():
            d = row["Date"]
            if hasattr(d, "strftime"):
                d_str = d.strftime("%Y-%m-%d")
            else:
                d_str = str(d)

            table_data.append(
                [
                    int(row["S.No"]) if pd.notna(row["S.No"]) else "",
                    d_str,
                    f"{float(row['Oguali Production']):,.2f}",
                    f"{float(row['Ukpichi Production']):,.2f}",
                    f"{float(row['Other Locations']):,.2f}",
                    f"{float(row['Evacuation']):,.2f}",
                    f"{float(row['Tankers - Oguali']):,.2f}",
                    f"{float(row['Tankers - Ukpichi']):,.2f}",
                    f"{float(row['Other Tankers']):,.2f}",
                ]
            )

        # Column widths scaled to perfectly fit A4 width within margins
        available_width = doc.width
        # S.No + Date slightly smaller, production/evac slightly wider
        weights = [0.6, 1.0, 1.2, 1.2, 1.2, 1.2, 1.0, 1.0, 1.0]
        scale = available_width / sum(weights)
        col_widths = [w * scale for w in weights]

        table = Table(table_data, colWidths=col_widths, repeatRows=1)
        table.setStyle(
            TableStyle(
                [
                    # Header row
                    ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#1f4788")),
                    ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
                    ("ALIGN", (0, 0), (-1, 0), "CENTER"),
                    ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
                    ("FONTSIZE", (0, 0), (-1, 0), 8),
                    ("BOTTOMPADDING", (0, 0), (-1, 0), 5),
                    ("TOPPADDING", (0, 0), (-1, 0), 5),
                    # Body rows
                    ("ALIGN", (0, 1), (-1, -1), "CENTER"),
                    ("FONTNAME", (0, 1), (-1, -1), "Helvetica"),
                    ("FONTSIZE", (0, 1), (-1, -1), 7),
                    ("ROWBACKGROUNDS", (0, 1), (-1, -1), [colors.whitesmoke, colors.HexColor("#f8f9fa")]),
                    # Grid & border
                    ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
                ]
            )
        )

        elements.append(table)
        doc.build(elements)
        pdf_data = buffer.getvalue()
        buffer.close()
        return pdf_data

    # Build PDF bytes once (for download + view)
    pdf_bytes = build_pdf(df[display_cols]) if not df.empty else b""

    # ---- Export buttons (single row: CSV, XLSX, PDF, View PDF) ----
    st.markdown("---")
    col_csv, col_xlsx, col_pdf, col_view = st.columns(4)

    # CSV
    csv_data = df[display_cols].to_csv(index=False).encode("utf-8")
    with col_csv:
        st.download_button(
            "📥 CSV",
            data=csv_data,
            file_name="ofs_production_evacuation.csv",
            mime="text/csv",
            use_container_width=True,
        )

    # XLSX
    xlsx_buffer = BytesIO()
    with pd.ExcelWriter(xlsx_buffer, engine="xlsxwriter") as writer:
        df[display_cols].to_excel(writer, index=False, sheet_name="OFS_Report")
    xlsx_bytes = xlsx_buffer.getvalue()
    with col_xlsx:
        st.download_button(
            "📥 XLSX",
            data=xlsx_bytes,
            file_name="ofs_production_evacuation.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    # PDF Download
    with col_pdf:
        st.download_button(
            "📥 PDF",
            data=pdf_bytes,
            file_name="ofs_production_evacuation.pdf",
            mime="application/pdf",
            use_container_width=True,
            disabled=(not pdf_bytes),
        )

    # View PDF in new tab (same JS pattern as other reports)
    with col_view:
        if st.button("👁️ View PDF", use_container_width=True, disabled=(not pdf_bytes)):
            if pdf_bytes:
                b64 = base64.b64encode(pdf_bytes).decode("utf-8")
                components.html(
                    f"""
                    <script>
                        const pdfData = "{b64}";
                        const byteCharacters = atob(pdfData);
                        const byteNumbers = new Array(byteCharacters.length);
                        for (let i = 0; i < byteCharacters.length; i++) {{
                            byteNumbers[i] = byteCharacters.charCodeAt(i);
                        }}
                        const byteArray = new Uint8Array(byteNumbers);
                        const file = new Blob([byteArray], {{ type: "application/pdf" }});
                        const fileURL = URL.createObjectURL(file);
                        window.open(fileURL, "_blank");
                    </script>
                    """,
                    height=0,
                )


def _render_remote_delete_request_ui(
    resource_type: str,
    resource_id: str,
    resource_label: str,
    page_name: str,
    metadata: Optional[Dict[str, Any]] = None,
):
    """Display helper UI for operators to request remote delete approvals."""
    user = st.session_state.get("auth_user") or {}
    if user.get("role") != "operator":
        return None

    approved = TaskManager.get_task_for_resource(
        resource_type,
        resource_id,
        statuses=[TaskStatus.APPROVED.value],
    )
    pending = TaskManager.get_task_for_resource(
        resource_type,
        resource_id,
        statuses=[TaskStatus.PENDING.value],
    )

    if approved:
        approved_by = approved.get("approved_by") or "Supervisor"
        approved_at = _format_task_timestamp(approved.get("approved_at"))
        st.success(
            f"Remote approval granted by {approved_by} on {approved_at}. "
            "You may proceed with deletion."
        )
        return approved

    if pending:
        st.info(
            f"Remote approval requested on "
            f"{_format_task_timestamp(pending.get('raised_at'))}. "
            "Awaiting supervisor action."
        )
        return None

    key = f"remote_delete_req_{resource_type}_{resource_id}"
    if st.button("📤 Request remote approval", key=key):
        merged_meta = metadata.copy() if metadata else {}
        merged_meta.setdefault("page", page_name)
        TaskManager.create_delete_request(
            resource_type=resource_type,
            resource_id=resource_id,
            resource_label=resource_label,
            raised_by=user.get("username", "operator"),
            raised_by_role=user.get("role"),
            location_id=st.session_state.get("active_location_id"),
            metadata=merged_meta,
        )
        st.success("Request sent to the supervisors for this location.")
        import time

        time.sleep(1)
        _st_safe_rerun()
    return None

def _normalized_temp_unit(unit: str | None) -> str:
    """
    Collapse messy unit labels (e.g., '°C', '°F') into a simple token.
    """
    if unit is None:
        return ""
    try:
        raw = str(unit).strip().upper()
    except Exception:
        raw = ""
    if not raw:
        return ""
    letters = "".join(ch for ch in raw if ch.isalpha())
    if not letters:
        return ""
    if "C" in letters and "F" not in letters:
        return "C"
    if "F" in letters and "C" not in letters:
        return "F"
    if letters.endswith("C"):
        return "C"
    if letters.endswith("F"):
        return "F"
    return letters


def _temp_to_f(val: float | None, unit: str | None) -> float:
    """Normalize arbitrary input into degrees Fahrenheit."""
    try:
        num = float(val if val is not None else 0.0)
    except Exception:
        num = 0.0
    unit_norm = _normalized_temp_unit(unit)
    if unit_norm == "C":
        return (num * 1.8) + 32.0
    return num


def _temp_to_c(val: float | None, unit: str | None) -> float:
    """Normalize arbitrary input into degrees Celsius."""
    try:
        num = float(val if val is not None else 0.0)
    except Exception:
        num = 0.0
    unit_norm = _normalized_temp_unit(unit)
    if unit_norm == "F":
        return (num - 32.0) / 1.8
    return num


def convert_api_to_60_from_api(api_obs: float, sample_temp_val: float, temp_unit: str = "°F") -> float:
    """Iterative API@60 calculator using observed API + sample temperature."""
    if not api_obs or api_obs <= 0:
        return 0.0
    tf = _temp_to_f(sample_temp_val, temp_unit)
    temp_diff = tf - 60.0
    rho_obs = (141.5 * WAT60_CONST / (131.5 + float(api_obs))) * (
        (1.0 - 0.00001278 * temp_diff) - (0.0000000062 * temp_diff * temp_diff)
    )
    rho = rho_obs
    for _ in range(10):
        alfa = 341.0957 / (rho * rho)
        vcf = math.exp(-alfa * temp_diff - 0.8 * alfa * alfa * temp_diff * temp_diff)
        rho = rho_obs / vcf
    api60 = 141.5 * WAT60_CONST / rho - 131.5
    return round(api60, 2)


def convert_api_to_60_from_density(dens_obs_kgm3: float, sample_temp_val: float, temp_unit: str = "°C") -> float:
    """Iterative API@60 calculator using observed density + sample temperature."""
    if not dens_obs_kgm3 or dens_obs_kgm3 <= 0:
        return 0.0
    tc = _temp_to_c(sample_temp_val, temp_unit)
    temp_diff = tc - 15.0
    hyc = 1.0 - 0.000023 * temp_diff - 0.00000002 * temp_diff * temp_diff
    rho_obs_corrected = float(dens_obs_kgm3) * hyc
    rho15 = rho_obs_corrected
    for _ in range(17):
        K = 613.9723 / (rho15 * rho15)
        vcf = math.exp(-K * temp_diff * (1.0 + 0.8 * K * temp_diff))
        rho15 = rho_obs_corrected / vcf
    sg60 = rho15 / WAT60_CONST
    if sg60 <= 0:
        return 0.0
    api60 = 141.5 / sg60 - 131.5
    return round(api60, 2)


def vcf_from_api60_and_temp(api60: float, tank_temp: float, tank_temp_unit: str = "°F", input_mode: str = "api") -> float:
    """VCF helper shared across tabs (input_mode kept for API parity with legacy helpers)."""
    if not api60 or api60 <= 0:
        return 1.0
    tank_temp_f = _temp_to_f(tank_temp, tank_temp_unit)
    delta_t = tank_temp_f - 60.0
    if abs(delta_t) < 0.01:
        return 1.0
    sg60 = 141.5 / (api60 + 131.5)
    rho60 = sg60 * WAT60_CONST
    K0 = 341.0957
    alpha = K0 / (rho60 * rho60)
    vcf = math.exp(-alpha * delta_t * (1.0 + 0.8 * alpha * delta_t))
    return round(float(vcf), 5)

def ensure_reportlab():
    """
    Import reportlab modules lazily. Returns (ok, err, mods_dict_or_None).
    This lets the app pick up a freshly installed package without restarting Streamlit.
    """
    # Force reportlab to be detected as installed
    return True, None, {
        "canvas": importlib.import_module("reportlab.pdfgen").canvas,
        "A4": importlib.import_module("reportlab.lib.pagesizes").A4,
        "ImageReader": importlib.import_module("reportlab.lib.utils").ImageReader,
    }
def clear_2fa_session_states():
    """Clear all 2FA-related session states"""
    keys_to_clear = [
        "pending_2fa_user",
        "backup_codes_visible",
        "new_backup_codes",
        "2fa_setup",
        "2fa_backup_codes_ready",
        "show_backup_codes"
    ]
    
    for key in keys_to_clear:
        st.session_state.pop(key, None)

# ---- OTR operation helpers ---------------------------------------------------
def _normalize_operation(loc_code: str, op_label: str) -> str | None:
    """Return canonical operation label for DB, per location."""
    if not op_label:
        return None
    label = " ".join(str(op_label).strip().lower().split())
    loc = (loc_code or "").strip().upper()

    jetty_map = {
        "okw receipt": "OKW Receipt",
        "anz receipt": "ANZ Receipt",
        "other receipts": "Other Receipts",
        "dispatch to barge": "Dispatch to barge",
        "other dispatch": "Other dispatch",
    }
    bfs_map = {
        "receipt - commingled": "Receipt - Commingled",
        "receipt commingled": "Receipt - Commingled",
        # legacy aliases
        "receipt - crude": "Receipt - Commingled",
        "receipt crude": "Receipt - Commingled",
        "receipt - condensate": "Receipt - Condensate",
        "receipt condensate": "Receipt - Condensate",
        "dispatch to jetty": "Dispatch to Jetty",
    }
    ndoni_map = {
        "receipt from agu": "Receipt from Agu",
        "receipt from ofs": "Receipt from OFS",
        "other receipts": "Other Receipts",
        "dispatch to barge": "Dispatch to barge",
    }
    generic_map = {
        "receipt": "Receipt",
        "dispatch": "Dispatch",
        "closing stock": "Closing Stock",
    }

    if loc in {"JETTY", "ASEMOKU"}:
        m = jetty_map
    elif loc in {"BFS", "BENEKU"}:
        m = bfs_map
    elif loc in {"NDONI"}:
        m = ndoni_map
    else:
        m = generic_map

    if label in m:
        return m[label]
    for k, v in m.items():
        if k in label:
            return v
    return op_label.strip() or None


def _coerce_operation_for_db(op_canonical: str):
    """
    Convert canonical human label (e.g., 'Opening Stock') to models.Operation enum.
    Returning the Enum instance makes SAEnum persist the enum NAME (OPENING_STOCK),
    which is what your column expects.
    """
    from models import Operation  # this Enum is defined in models.py

    if not op_canonical:
        return None

    # 1) try by value (labels like "Opening Stock")
    try:
        return Operation(op_canonical)
    except Exception:
        pass

    # 2) try by name (e.g., "OPENING_STOCK")
    key = (
        op_canonical.upper()
        .replace("-", "_")
        .replace(" ", "_")
    )
    try:
        return Operation[key]
    except Exception:
        return None  # force the caller to handle unsupported ops

def _is_condensate_tx(tx) -> bool:
    if tx is None:
        return False
    op_obj = getattr(tx, "operation", None)
    if hasattr(op_obj, "value"):
        label = str(op_obj.value or "")
    else:
        label = str(op_obj or "")
    tank_name = str(getattr(tx, "tank_name", "") or "")
    has_meter = (
        getattr(tx, "opening_meter_reading", None) is not None
        and getattr(tx, "closing_meter_reading", None) is not None
    )
    return (
        "condensate" in label.lower()
        or "condensate" in tank_name.lower()
        or has_meter
    )

def load_condensate_transactions(location_id: int | None, limit: int = 1000):
    """Return (records, meta_map) for condensate tank transactions (most recent first)."""
    if not location_id:
        return [], {}
    from models import TankTransaction, Table11

    with get_session() as s:
        rows = (
            s.query(TankTransaction)
            .filter(TankTransaction.location_id == int(location_id))
            .order_by(TankTransaction.date.desc(), TankTransaction.time.desc())
            .limit(limit)
            .all()
        )

    try:
        with get_session() as s_lt:
            lt_rows = s_lt.query(Table11).order_by(Table11.api60).all()
    except Exception:
        lt_rows = []
    lt_xs = [float(getattr(r, "api60", 0.0) or 0.0) for r in lt_rows]
    lt_ys = [float(getattr(r, "lt_factor", 0.0) or 0.0) for r in lt_rows]

    def _lt_lookup(api60: float) -> float:
        if not lt_xs or api60 <= 0:
            return 0.0
        if api60 <= lt_xs[0]:
            return lt_ys[0]
        if api60 >= lt_xs[-1]:
            return lt_ys[-1]
        import bisect
        idx = bisect.bisect_left(lt_xs, api60)
        x1, y1 = lt_xs[idx - 1], lt_ys[idx - 1]
        x2, y2 = lt_xs[idx], lt_ys[idx]
        if x2 == x1:
            return y1
        frac = (api60 - x1) / (x2 - x1)
        return y1 + frac * (y2 - y1)

    records = []
    meta_map: dict[str, tuple[str | None, str | None, datetime | None]] = {}
    for row in rows:
        if not _is_condensate_tx(row):
            continue

        opening_val = float(row.opening_meter_reading or 0.0)
        closing_val = float(row.closing_meter_reading or opening_val)
        qty_m3 = (
            float(row.condensate_qty_m3)
            if row.condensate_qty_m3 is not None
            else max(closing_val - opening_val, 0.0)
        )
        gov_bbl = float(row.qty_bbls or (qty_m3 * CONDENSATE_M3_TO_BBL))

        api_obs = float(getattr(row, "api_observed", 0.0) or 0.0)
        dens_obs = float(getattr(row, "density_observed", 0.0) or 0.0)
        sample_temp_c_val = float(getattr(row, "sample_temp_c", 0.0) or 0.0)
        sample_temp_f_val = float(getattr(row, "sample_temp_f", 0.0) or 0.0)
        tank_temp_c_val = float(getattr(row, "tank_temp_c", 0.0) or 0.0)
        tank_temp_f_val = float(getattr(row, "tank_temp_f", 0.0) or 0.0)

        if not sample_temp_f_val and sample_temp_c_val:
            sample_temp_f_val = (sample_temp_c_val * 1.8) + 32.0
        if not sample_temp_c_val and sample_temp_f_val:
            sample_temp_c_val = (sample_temp_f_val - 32.0) / 1.8

        if api_obs > 0:
            sample_unit = "°F" if sample_temp_f_val else "°C"
            sample_temp_for_api = sample_temp_f_val if sample_unit == "°F" else sample_temp_c_val
            api60_val = convert_api_to_60_from_api(api_obs, sample_temp_for_api or 0.0, sample_unit)
        elif dens_obs > 0:
            sample_temp_for_density = sample_temp_c_val or ((sample_temp_f_val - 32.0) / 1.8 if sample_temp_f_val else 15.0)
            api60_val = convert_api_to_60_from_density(dens_obs, sample_temp_for_density or 0.0, "°C")
        else:
            api60_val = 0.0

        tank_temp_c_for_vcf = tank_temp_c_val or ((tank_temp_f_val - 32.0) / 1.8 if tank_temp_f_val else 0.0)
        input_mode = "api" if api_obs > 0 else ("density" if dens_obs > 0 else "api")
        vcf_val = vcf_from_api60_and_temp(api60_val, tank_temp_c_for_vcf, "°C", input_mode)
        gsv_val = round(gov_bbl * vcf_val, 2)
        lt_factor = _lt_lookup(api60_val)
        lt_val = round(gsv_val * lt_factor, 2)
        mt_val = round(lt_val * 1.01605, 2)

        records.append({
            "Ticket ID": row.ticket_id,
            "Date": row.date,
            "Opening (m3)": opening_val,
            "Closing (m3)": closing_val,
            "Net Receipt (m3)": qty_m3,
            "GOV (bbls)": gov_bbl,
            "API @ 60": api60_val,
            "VCF": vcf_val,
            "GSV (bbls)": gsv_val,
            "LT": lt_val,
            "MT": mt_val,
            "Created By": getattr(row, "created_by", None),
            "Updated By": getattr(row, "updated_by", None),
            "Updated At": getattr(row, "updated_at", None),
        })
        meta_map[row.ticket_id] = (
            getattr(row, "created_by", None),
            getattr(row, "updated_by", None),
            getattr(row, "updated_at", None),
        )
    return records, meta_map


def _ensure_okw_column_exists():
    """Add okw_production column to gpp_production_records if missing (idempotent)."""
    if st.session_state.get("_okw_column_checked"):
        return
    try:
        with engine.begin() as conn:
            cols = {row[1] for row in conn.execute(text("PRAGMA table_info('gpp_production_records')"))}
            if "okw_production" not in cols:
                conn.execute(
                    text(
                        "ALTER TABLE gpp_production_records "
                        "ADD COLUMN okw_production REAL NOT NULL DEFAULT 0.0"
                    )
                )
    except Exception as exc:
        st.warning(f"Could not extend gpp_production_records: {exc}")
    finally:
        st.session_state["_okw_column_checked"] = True


def _ensure_gpp_closing_column_exists():
    if st.session_state.get("_gpp_closing_column_checked"):
        return
    try:
        with engine.begin() as conn:
            cols = {row[1] for row in conn.execute(text("PRAGMA table_info('gpp_production_records')"))}
            if "gpp_closing_stock" not in cols:
                conn.execute(
                    text(
                        "ALTER TABLE gpp_production_records "
                        "ADD COLUMN gpp_closing_stock REAL NOT NULL DEFAULT 0.0"
                    )
                )
    except Exception as exc:
        st.warning(f"Could not extend gpp_production_records (closing): {exc}")
    finally:
        st.session_state["_gpp_closing_column_checked"] = True


def load_gpp_production_records(location_id: int | None, limit: int = 1000) -> list[dict[str, Any]]:
    """Fetch latest GPP production entries for a location."""
    _ensure_okw_column_exists()
    _ensure_gpp_closing_column_exists()
    if not location_id:
        return []

    with get_session() as s:
        rows = (
            s.query(GPPProductionRecord)
            .filter(GPPProductionRecord.location_id == int(location_id))
            .order_by(GPPProductionRecord.date.desc(), GPPProductionRecord.id.desc())
            .limit(limit)
            .all()
        )

    records: list[dict[str, Any]] = []
    import re
    for row in rows:
        # ? Just use the dedicated GPP closing stock field; don't touch remarks.
        try:
            closing_stock_val = float(getattr(row, "gpp_closing_stock", 0.0) or 0.0)
        except Exception:
            closing_stock_val = 0.0

        # ? Remarks are whatever you typed. If empty, they remain empty.
        remarks_str = row.remarks or ""

        records.append(
            {
                "id": row.id,
                "Date": row.date,
                "OKW Production": round(float(row.okw_production or 0.0), 2),
                "GPP1 Production": round(float(row.gpp1_production or 0.0), 2),
                "GPP2 Production": round(float(row.gpp2_production or 0.0), 2),
                "GPP Closing Stock": round(float(closing_stock_val or 0.0), 2),
                "Total GPP Production": round(float(row.total_production or 0.0), 2),
                "Remarks": remarks_str or "",
                "Created By": row.created_by or "-",
                "Updated By": row.updated_by or "",
                "Updated At": row.updated_at,
            }
        )
    return records

def load_river_draft_records(location_id: int | None, limit: int = 1000) -> list[dict[str, Any]]:
    """Load recent river draft entries for convenience functions."""
    if not location_id:
        return []

    with get_session() as s:
        rows = (
            s.query(RiverDraftRecord)
            .filter(RiverDraftRecord.location_id == int(location_id))
            .order_by(RiverDraftRecord.date.desc(), RiverDraftRecord.id.desc())
            .limit(limit)
            .all()
        )

    records: list[dict[str, Any]] = []
    for row in rows:
        records.append(
            {
                "id": row.id,
                "Date": row.date,
                "River Draft (m)": round(float(row.river_draft_m or 0.0), 2),
                "Rainfall (cm)": round(float(row.rainfall_cm or 0.0), 2),
                "Created By": row.created_by or "-",
                "Updated By": row.updated_by or "",
                "Updated At": row.updated_at,
            }
        )
    return records


def load_produced_water_records(location_id: int | None, limit: int = 1000) -> list[dict[str, Any]]:
    """Load recent produced water entries for convenience functions."""
    if not location_id:
        return []

    with get_session() as s:
        rows = (
            s.query(ProducedWaterRecord)
            .filter(ProducedWaterRecord.location_id == int(location_id))
            .order_by(ProducedWaterRecord.date.desc(), ProducedWaterRecord.id.desc())
            .limit(limit)
            .all()
        )

    records: list[dict[str, Any]] = []
    for row in rows:
        records.append(
            {
                "id": row.id,
                "Date": row.date,
                "Produced Water (bbls)": round(float(row.produced_water_bbl or 0.0), 2),
                "Created By": row.created_by or "-",
                "Updated By": row.updated_by or "",
                "Updated At": row.updated_at,
            }
        )
    return records

def _fix_legacy_operation_enums():
    """
    One-time data repair:
    Convert legacy human-readable strings in tank_transactions.operation
    to the enum NAMES expected by SAEnum(Operation).
    Safe to run multiple times (idempotent).
    """
    from sqlalchemy import text
    from models import Operation
    from db import get_session

    label_to_name = {m.value: m.name for m in Operation}  # "Opening Stock" -> "OPENING_STOCK"
    if not label_to_name:
        return

    with get_session() as s:
        # use raw SQL so we don't trip over enum hydration
        rows = s.execute(text("SELECT DISTINCT operation FROM tank_transactions")).fetchall()
        for (op_val,) in rows:
            if op_val in label_to_name:  # legacy label stored
                s.execute(
                    text("UPDATE tank_transactions SET operation = :new WHERE operation = :old"),
                    {"new": label_to_name[op_val], "old": op_val},
                )
        s.commit()


def _ensure_ops_enum_fixed_once():
    """Run the legacy enum repair only once per Streamlit session."""
    if st.session_state.get("_ops_enum_fixed"):
        return
    try:
        _fix_legacy_operation_enums()
        st.session_state["_ops_enum_fixed"] = True
    except Exception:
        # stay non-blocking � if there is no table yet, etc.
        pass


_ensure_ops_enum_fixed_once()
def _get_selected_operation_from_state() -> str | None:
    """Try common widget keys so we don�t depend on one exact name."""
    for k in ("otr_form_operation", "otr_operation", "operation", "otr_op"):
        v = st.session_state.get(k)
        if v not in (None, "", "(Select)", "(All)"):
            return v
    return None

def user_with_caution(created_by: str | None, updated_by: str | None, updated_at) -> str:
    """
    Returns a small HTML badge:
      - shows creator
      - if edited, shows ✏️ with hover tooltip "Edited by X on YYYY-MM-DD HH:MM"
    """
    creator = (created_by or "").strip()
    if updated_by and updated_at:
        try:
            ts = pd.to_datetime(updated_at).strftime("%Y-%m-%d %H:%M")
        except Exception:
            ts = str(updated_at)
        tip = f"Edited by {updated_by} on {ts}"
        return f"<span title='{tip}'>✏️ {creator}</span>"
    return creator or "-"


# -----------------------------------------------------------------------------

import os
import re
# ---------------- Reporting Page (Asemoku Jetty ? BENEKU DISPATCH VS JETTY RECEIPT) ----------------
import json
from pathlib import Path
from datetime import date, timedelta
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.enums import TA_CENTER
from reportlab.lib import colors

REPORT_NOTES_PATH = OUTPUT / "reporting_notes.json"
REPORT_NOTES_PATH.parent.mkdir(exist_ok=True)
if not REPORT_NOTES_PATH.exists():
    REPORT_NOTES_PATH.write_text("{}", encoding="utf-8")

def _load_reporting_notes():
    try:
        return json.loads(REPORT_NOTES_PATH.read_text(encoding="utf-8"))
    except Exception:
        return {}

def _save_reporting_notes(notes: dict):
    REPORT_NOTES_PATH.write_text(json.dumps(notes, indent=2), encoding="utf-8")

def _date_str(d: date) -> str:
    return d.strftime("%Y-%m-%d")

def _generate_bfs_vs_jetty_pdf(df: pd.DataFrame, loc_name: str, loc_code: str, dfrom: date, dto: date) -> bytes:
    bio = BytesIO()
    doc = SimpleDocTemplate(bio, pagesize=landscape(A4), leftMargin=0.5*cm, rightMargin=0.5*cm, topMargin=0.6*cm, bottomMargin=0.6*cm)

    styles = getSampleStyleSheet()
    title_style = ParagraphStyle("T", parent=styles["Heading1"], fontSize=15, alignment=TA_CENTER, textColor=colors.HexColor("#1f4788"))
    sub_style   = ParagraphStyle("S", parent=styles["Normal"],   fontSize=10, alignment=TA_CENTER, textColor=colors.HexColor("#666666"))

    elements = []
    elements.append(Paragraph("<b>BENEKU DISPATCH VS JETTY RECEIPT</b>", title_style))
    elements.append(Paragraph(f"{loc_name} ({loc_code}) &nbsp;�&nbsp; Period: <b>{_date_str(dfrom)}</b> to <b>{_date_str(dto)}</b>", sub_style))
    elements.append(Spacer(1, 0.3*cm))

    # Table
    headers = ["Date","BFS Dispatch","Jetty Receipt","Water Received","Loss/Gain","Loss/Gain %","Remarks"]
    data = [headers]
    for _, r in df.iterrows():
        data.append([
            r["Date"],
            f"{r['BFS Dispatch']:,.2f}",
            f"{r['Jetty Receipt']:,.2f}",
            f"{r['Water Received']:,.2f}",
            f"{r['Loss/Gain']:,.2f}",
            f"{r['Loss/Gain %']:,.4f}",
            (r.get("Remarks") or "")[:70]
        ])

    table = Table(data, repeatRows=1)
    table.setStyle(TableStyle([
        ("BACKGROUND",(0,0),(-1,0), colors.HexColor("#1f4788")),
        ("TEXTCOLOR",(0,0),(-1,0), colors.white),
        ("ALIGN",(0,0),(-1,-1), "CENTER"),
        ("FONTNAME",(0,0),(-1,0), "Helvetica-Bold"),
        ("FONTSIZE",(0,0),(-1,0), 8),
        ("GRID",(0,0),(-1,-1), 0.25, colors.grey),
        ("ROWBACKGROUNDS",(0,1),(-1,-1), [colors.whitesmoke, colors.HexColor("#f8f9fa")]),
        ("FONTSIZE",(0,1),(-1,-1), 8)
    ]))
    elements.append(table)
    doc.build(elements)
    return bio.getvalue()


def _generate_production_pdf(df: pd.DataFrame, loc_name: str, loc_code: str, dfrom: date, dto: date) -> bytes:
    bio = BytesIO()
    doc = SimpleDocTemplate(
        bio,
        pagesize=landscape(A4),
        leftMargin=0.5 * cm,
        rightMargin=0.5 * cm,
        topMargin=0.6 * cm,
        bottomMargin=0.6 * cm,
    )

    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        "GPPTitle",
        parent=styles["Heading1"],
        fontSize=15,
        alignment=TA_CENTER,
        textColor=colors.HexColor("#1f4788"),
    )
    sub_style = ParagraphStyle(
        "GPPSub",
        parent=styles["Normal"],
        fontSize=10,
        alignment=TA_CENTER,
        textColor=colors.HexColor("#666666"),
    )

    df_sorted = df.sort_values(by="Date")
    headers = [
        "Date",
        "OKW Production",
        "GPP1 Production",
        "GPP2 Production",
        "GPP Closing Stock",
        "Total GPP Production",
        "Remarks",
    ]
    data = [headers]
    for _, row in df_sorted.iterrows():
        date_val = row["Date"]
        if isinstance(date_val, pd.Timestamp):
            date_val = date_val.date()
        data.append(
            [
                str(date_val),
                f"{row['OKW Production']:,.2f}",
                f"{row['GPP1 Production']:,.2f}",
                f"{row['GPP2 Production']:,.2f}",
                f"{row.get('GPP Closing Stock', 0.0):,.2f}",
                f"{row['Total GPP Production']:,.2f}",
                (row.get('Remarks') or '')[:80],
            ]
        )

    totals = df_sorted[
        [
            "OKW Production",
            "GPP1 Production",
            "GPP2 Production",
            "Total GPP Production",
        ]
    ].sum(numeric_only=True)
    data.append(
        [
            "TOTAL",
            f"{totals.get('OKW Production', 0.0):,.2f}",
            f"{totals.get('GPP1 Production', 0.0):,.2f}",
            f"{totals.get('GPP2 Production', 0.0):,.2f}",
            "",
            f"{totals.get('Total GPP Production', 0.0):,.2f}",
            "",
        ]
    )

    # Adjust column widths for the additional 'GPP Closing Stock' column
    table = Table(
        data,
        repeatRows=1,
        colWidths=[
            4.0 * cm,
            3.5 * cm,
            3.5 * cm,
            3.5 * cm,
            3.5 * cm,
            4.0 * cm,
            7.0 * cm,
        ],
    )
    table.setStyle(
        TableStyle(
            [
                ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#1f4788")),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
                ("ALIGN", (1, 1), (-2, -2), "RIGHT"),
                ("BACKGROUND", (0, 1), (-1, -1), colors.whitesmoke),
                ("ROWBACKGROUNDS", (0, 1), (-1, -2), [colors.whitesmoke, colors.HexColor("#f8f9fa")]),
                ("FONTSIZE", (0, 0), (-1, -1), 9),
                ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
                ("BACKGROUND", (0, -1), (-1, -1), colors.HexColor("#dfe6f1")),
                ("TEXTCOLOR", (0, -1), (-1, -1), colors.HexColor("#1f4788")),
            ]
        )
    )

    elements = [
        Paragraph("<b>PRODUCTION SUMMARY</b>", title_style),
        Paragraph(
            f"{loc_name} ({loc_code}) &nbsp;�&nbsp; Period: <b>{_date_str(dfrom)}</b> to <b>{_date_str(dto)}</b>",
            sub_style,
        ),
        Paragraph(
            f"Totals � OKW: <b>{totals.get('OKW Production', 0.0):,.2f}</b> bbls | GPP: <b>{totals.get('Total GPP Production', 0.0):,.2f}</b> bbls",
            sub_style,
        ),
        Spacer(1, 0.3 * cm),
        table,
    ]

    doc.build(elements)
    return bio.getvalue()

# --------------------------------------------------------------------
# PDF generator for tanker details (Aggu Dispatched & Ndoni Receipt)
def _generate_tanker_details_pdf(
    df: pd.DataFrame,
    title: str,
    dfrom: date,
    dto: date,
    summary_row: Optional[list[Any]] = None,
    summary_pairs: Optional[list[tuple[str, Any]]] = None,
) -> bytes:
    """
    Build a simple PDF summarizing tanker details for Aggu or Ndoni.

    The DataFrame columns should already be ordered as desired for the report.
    The title parameter will be used as the main heading (e.g. "Aggu Dispatched" or "Ndoni Receipt").
    dfrom and dto are used for the date range subtitle.
    """
    from reportlab.lib.pagesizes import A4, landscape
    from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.enums import TA_CENTER
    from reportlab.lib import colors
    from reportlab.lib.units import cm
    # Create buffer for PDF data
    buffer = BytesIO()
    doc = SimpleDocTemplate(
        buffer,
        pagesize=landscape(A4),
        leftMargin=0.5 * cm,
        rightMargin=0.5 * cm,
        topMargin=0.6 * cm,
        bottomMargin=0.6 * cm,
    )
    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        "TankerTitle",
        parent=styles["Heading1"],
        fontSize=15,
        alignment=TA_CENTER,
        textColor=colors.HexColor("#1f4788"),
    )
    sub_style = ParagraphStyle(
        "TankerSub",
        parent=styles["Normal"],
        fontSize=10,
        alignment=TA_CENTER,
        textColor=colors.HexColor("#666666"),
    )
    elements: list[Any] = []
    # Title
    elements.append(Paragraph(f"<b>{html.escape(title)}</b>", title_style))
    try:
        df_str = _date_str(dfrom) if dfrom else ""
        dt_str = _date_str(dto) if dto else ""
        subtitle = f"Period: <b>{df_str}</b> to <b>{dt_str}</b>"
    except Exception:
        subtitle = f"Period: {dfrom} to {dto}"
    elements.append(Paragraph(subtitle, sub_style))
    elements.append(Spacer(1, 0.3 * cm))
    # Build table data from DataFrame
    header_count = 0
    if df.empty:
        table_data = [["No records found"]]
        col_widths = [doc.width]
    else:
        headers = list(df.columns)
        header_count = len(headers)
        table_data = [headers]
        for _, r in df.iterrows():
            row = []
            for c in headers:
                v = r[c]
                if isinstance(v, float):
                    if float(v).is_integer():
                        row.append(f"{int(v):,}")
                    else:
                        row.append(f"{v:,.2f}")
                else:
                    if isinstance(v, (datetime, date)):
                        try:
                            row.append(v.strftime("%d-%b-%Y"))
                        except Exception:
                            row.append(str(v))
                    else:
                        row.append(str(v))
            table_data.append(row)
        # Determine column widths: small for serial/date, large for remarks, medium for others
        weights = []
        for h in headers:
            h_lower = h.lower()
            if "s.no" in h_lower or "serial" in h_lower:
                weights.append(0.6)
            elif "date" in h_lower:
                weights.append(1.3)
            elif "remark" in h_lower:
                weights.append(3.0)
            else:
                weights.append(1.3)
        if summary_row:
            padded_row = list(summary_row)
            if len(padded_row) < header_count:
                padded_row.extend([""] * (header_count - len(padded_row)))
            table_data.append(padded_row[:header_count])
        available_width = doc.width
        scale = available_width / sum(weights)
        col_widths = [w * scale for w in weights]
    tbl = Table(table_data, colWidths=col_widths, repeatRows=1)
    tbl_style_cmds = [
        ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#1f4788")),
        ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
        ("ALIGN", (0, 0), (-1, 0), "CENTER"),
        ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
        ("FONTSIZE", (0, 0), (-1, 0), 8),
        ("ALIGN", (0, 1), (-1, -1), "CENTER"),
        ("FONTNAME", (0, 1), (-1, -1), "Helvetica"),
        ("FONTSIZE", (0, 1), (-1, -1), 8),
        ("ROWBACKGROUNDS", (0, 1), (-1, -1), [colors.whitesmoke, colors.HexColor("#f8f9fa")]),
        ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
    ]
    if summary_row and header_count:
        tbl_style_cmds.append(
            ("BACKGROUND", (0, -1), (-1, -1), colors.HexColor("#dfe6f1"))
        )
        tbl_style_cmds.append(
            ("TEXTCOLOR", (0, -1), (-1, -1), colors.HexColor("#1f4788"))
        )
        tbl_style_cmds.append(
            ("FONTNAME", (0, -1), (-1, -1), "Helvetica-Bold")
        )
    tbl.setStyle(TableStyle(tbl_style_cmds))
    elements.append(tbl)
    if summary_pairs:
        elements.append(Spacer(1, 0.3 * cm))
        grid_items = summary_pairs[:]
        target_cells = 10  # 2 rows x 5 columns
        while len(grid_items) < target_cells:
            grid_items.append(("", ""))
        cell_paragraphs: list[list[Any]] = []
        cols = 5
        col_width = doc.width / cols
        for row_idx in range(2):
            row_cells: list[Any] = []
            for col_idx in range(cols):
                name, val = grid_items[row_idx * cols + col_idx]
                if name:
                    if isinstance(val, (int, float)):
                        val_str = f"{float(val):,.2f}"
                    else:
                        val_str = str(val)
                    cell_html = (
                        f"<font size=9 color='#0f172a'>{html.escape(str(name))}:</font><br/>"
                        f"<font size=10 color='#0f172a'><b>{html.escape(val_str)}</b></font>"
                    )
                else:
                    cell_html = ""
                row_cells.append(Paragraph(cell_html, styles["Normal"]))
            cell_paragraphs.append(row_cells)
        summary_table = Table(cell_paragraphs, colWidths=[col_width] * cols)
        summary_table.setStyle(
            TableStyle(
                [
                    ("BOX", (0, 0), (-1, -1), 1.2, colors.HexColor("#1f4788")),
                    ("INNERGRID", (0, 0), (-1, -1), 0, colors.white),
                    ("ALIGN", (0, 0), (-1, -1), "CENTER"),
                    ("VALIGN", (0, 0), (-1, -1), "MIDDLE"),
                    ("FONTNAME", (0, 0), (-1, -1), "Helvetica"),
                    ("FONTSIZE", (0, 0), (-1, -1), 9),
                    ("LEFTPADDING", (0, 0), (-1, -1), 4),
                    ("RIGHTPADDING", (0, 0), (-1, -1), 4),
                    ("TOPPADDING", (0, 0), (-1, -1), 6),
                    ("BOTTOMPADDING", (0, 0), (-1, -1), 6),
                ]
            )
        )
        elements.append(Spacer(1, 0.3 * cm))
        elements.append(Paragraph("<b>Summary Totals</b>", styles["Heading4"]))
        elements.append(summary_table)
    doc.build(elements)
    pdf_bytes = buffer.getvalue()
    buffer.close()
    return pdf_bytes

def render_tanker_details_tab() -> None:
    """
    Render the 'Tankers Details' tab on the Reporting page.

    This tab displays two tables: one for Aggu dispatches and another for Ndoni receipts.
    Each table provides date range filters and download/export options (CSV, XLSX, PDF)
    along with a 'View PDF' button that opens the PDF in a new browser tab.
    """
    import pandas as pd  # local import to avoid polluting global namespace
    import streamlit as st
    import base64
    from io import BytesIO
    from datetime import date, timedelta
    from sqlalchemy import or_
    from models import Location, LocationTankerEntry
    from db import get_session
    # Fetch Aggu and Ndoni locations
    with get_session() as _sess:
        aggu_loc = (
            _sess.query(Location)
            .filter(or_(Location.code.ilike("%AGGU%"), Location.name.ilike("%AGGU%")))
            .first()
        )
        ndoni_loc = (
            _sess.query(Location)
            .filter(or_(Location.code.ilike("%NDONI%"), Location.name.ilike("%NDONI%")))
            .first()
        )

    col_aggu, col_ndoni = st.columns(2)

    # Render Aggu table
    with col_aggu:
        if aggu_loc:
            st.markdown("#### Aggu Dispatched")
            aggu_cols = st.columns(2)
            today = date.today()
            with aggu_cols[0]:
                aggu_from = st.date_input(
                    "From (Aggu)",
                    value=today - timedelta(days=14),
                    key="tanker_rpt_aggu_from",
                )
            with aggu_cols[1]:
                aggu_to = st.date_input(
                    "To (Aggu)",
                    value=today,
                    key="tanker_rpt_aggu_to",
                )
            with get_session() as _sess:
                aggu_rows = (
                    _sess.query(LocationTankerEntry)
                    .filter(LocationTankerEntry.location_id == aggu_loc.id)
                    .order_by(LocationTankerEntry.date.asc(), LocationTankerEntry.serial_no.asc())
                    .all()
                )
            aggu_filtered = []
            for rec in aggu_rows:
                if aggu_from and rec.date < aggu_from:
                    continue
                if aggu_to and rec.date > aggu_to:
                    continue
                aggu_filtered.append(rec)
            aggu_data = []
            for rec in aggu_filtered:
                aggu_data.append(
                    {
                        "S.No": rec.serial_no,
                        "Date": rec.date.strftime("%d-%b-%Y") if rec.date else "",
                        "Tankers Dispatched": float(rec.tankers_dispatched or 0.0),
                        "Remarks": rec.remarks or "",
                    }
                )
            aggu_df = pd.DataFrame(aggu_data)
            st.dataframe(aggu_df, use_container_width=True, hide_index=True)
            # Export buttons
            st.markdown("---")
            col_csv, col_xlsx, col_pdf, col_view = st.columns(4)
            # CSV
            aggu_csv = aggu_df.to_csv(index=False).encode("utf-8")
            col_csv.download_button(
                "📥 CSV",
                data=aggu_csv,
                file_name=f"aggu_tankers_{aggu_from}_{aggu_to}.csv",
                mime="text/csv",
                use_container_width=True,
            )
            # XLSX
            aggu_xbio = BytesIO()
            with pd.ExcelWriter(aggu_xbio, engine="xlsxwriter") as writer:
                aggu_df.to_excel(writer, index=False, sheet_name="Aggu")
            col_xlsx.download_button(
                "📥 XLSX",
                data=aggu_xbio.getvalue(),
                file_name=f"aggu_tankers_{aggu_from}_{aggu_to}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
            # PDF
            aggu_pdf = b""
            if not aggu_df.empty:
                try:
                    aggu_pdf = _generate_tanker_details_pdf(
                        aggu_df, "Aggu Dispatched", aggu_from, aggu_to
                    )
                except Exception:
                    aggu_pdf = b""
            col_pdf.download_button(
                "📥 PDF",
                data=aggu_pdf,
                file_name=f"aggu_tankers_{aggu_from}_{aggu_to}.pdf",
                mime="application/pdf",
                use_container_width=True,
                disabled=(len(aggu_data) == 0),
            )
            # View PDF
            if col_view.button(
                "👁️ View PDF",
                key="aggu_pdf_view_btn",
                use_container_width=True,
                disabled=(len(aggu_data) == 0),
            ):
                if aggu_pdf:
                    b64 = base64.b64encode(aggu_pdf).decode("utf-8")
                    import streamlit.components.v1 as components

                    components.html(
                        f"""
                                <script>
                                    const pdfData = "{b64}";
                                    const byteCharacters = atob(pdfData);
                                    const byteNumbers = new Array(byteCharacters.length);
                                    for (let i = 0; i < byteCharacters.length; i++) {{
                                        byteNumbers[i] = byteCharacters.charCodeAt(i);
                                    }}
                                    const byteArray = new Uint8Array(byteNumbers);
                                    const file = new Blob([byteArray], {{ type: "application/pdf" }});
                                    const fileURL = URL.createObjectURL(file);
                                    window.open(fileURL, "_blank");
                                </script>
                            """,
                        height=0,
                    )
        else:
            st.info("Aggu location not configured.")

    # Render Ndoni table
    with col_ndoni:
        if ndoni_loc:
            st.markdown("#### Ndoni Receipt")
            nd_cols = st.columns(2)
            today = date.today()
            with nd_cols[0]:
                nd_from = st.date_input(
                    "From (Ndoni)",
                    value=today - timedelta(days=14),
                    key="tanker_rpt_ndoni_from",
                )
            with nd_cols[1]:
                nd_to = st.date_input(
                    "To (Ndoni)",
                    value=today,
                    key="tanker_rpt_ndoni_to",
                )
            with get_session() as _sess:
                nd_rows = (
                    _sess.query(LocationTankerEntry)
                    .filter(LocationTankerEntry.location_id == ndoni_loc.id)
                    .order_by(LocationTankerEntry.date.asc(), LocationTankerEntry.serial_no.asc())
                    .all()
                )
            nd_filtered: list[Any] = []
            for rec in nd_rows:
                if nd_from and rec.date < nd_from:
                    continue
                if nd_to and rec.date > nd_to:
                    continue
                nd_filtered.append(rec)
            nd_data = []
            for rec in nd_filtered:
                nd_data.append(
                    {
                        "S.No": rec.serial_no,
                        "Date": rec.date.strftime("%d-%b-%Y") if rec.date else "",
                        "Tankers from Aggu": float(rec.tankers_from_aggu or 0.0),
                        "Tankers from OFS": float(rec.tankers_from_ofs or 0.0),
                        "Other Tankers": float(rec.other_tankers or 0.0),
                        "Remarks": rec.remarks or "",
                    }
                )
            nd_df = pd.DataFrame(nd_data)
            st.dataframe(nd_df, use_container_width=True, hide_index=True)
            st.markdown("---")
            d_csv, d_xlsx, d_pdf, d_view = st.columns(4)
            # Ndoni CSV
            nd_csv = nd_df.to_csv(index=False).encode("utf-8")
            d_csv.download_button(
                "📥 CSV",
                data=nd_csv,
                file_name=f"ndoni_tankers_{nd_from}_{nd_to}.csv",
                mime="text/csv",
                use_container_width=True,
            )
            # Ndoni XLSX
            nd_xbio = BytesIO()
            with pd.ExcelWriter(nd_xbio, engine="xlsxwriter") as writer:
                nd_df.to_excel(writer, index=False, sheet_name="Ndoni")
            d_xlsx.download_button(
                "📥 XLSX",
                data=nd_xbio.getvalue(),
                file_name=f"ndoni_tankers_{nd_from}_{nd_to}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
            nd_pdf = b""
            if not nd_df.empty:
                try:
                    nd_pdf = _generate_tanker_details_pdf(
                        nd_df, "Ndoni Receipt", nd_from, nd_to
                    )
                except Exception:
                    nd_pdf = b""
            d_pdf.download_button(
                "📥 PDF",
                data=nd_pdf,
                file_name=f"ndoni_tankers_{nd_from}_{nd_to}.pdf",
                mime="application/pdf",
                use_container_width=True,
                disabled=(len(nd_data) == 0),
            )
            if d_view.button(
                "👁️ View PDF",
                key="ndoni_pdf_view_btn",
                use_container_width=True,
                disabled=(len(nd_data) == 0),
            ):
                if nd_pdf:
                    b64 = base64.b64encode(nd_pdf).decode("utf-8")
                    import streamlit.components.v1 as components

                    components.html(
                        f"""
                                <script>
                                    const pdfData = "{b64}";
                                    const byteCharacters = atob(pdfData);
                                    const byteNumbers = new Array(byteCharacters.length);
                                    for (let i = 0; i < byteCharacters.length; i++) {{
                                        byteNumbers[i] = byteCharacters.charCodeAt(i);
                                    }}
                                    const byteArray = new Uint8Array(byteNumbers);
                                    const file = new Blob([byteArray], {{ type: "application/pdf" }});
                                    const fileURL = URL.createObjectURL(file);
                                    window.open(fileURL, "_blank");
                                </script>
                            """,
                        height=0,
                    )
        else:
            st.info("Ndoni location not configured.")

def render_reports_page():
    """
    Reporting page � Location-aware.

    Tab 1: BENEKU DISPATCH VS JETTY RECEIPT (Asemoku Jetty)
      - Live filters (date + remark search)
      - Inline editable Remarks (double-click)
      - CSV/XLSX/PDF exports + View PDF in new tab
      - Portrait PDF, 0.5 cm margins, full-width table, dynamic TOTAL row

    Tab 2: JETTY METER READING (Asemoku Jetty)
      - Live date filter
      - Columns: Date, Opening (M1), Closing (M1), Opening (M2), Closing (M2), Net Receipt/Dispatch, Remarks
      - CSV/XLSX/PDF + View PDF in new tab
      - PDF: A4 portrait, 0.5 cm margins, same colours as other reports
    """
    import json, base64
    from io import BytesIO
    from datetime import date, timedelta, datetime, time
    from pathlib import Path

    import pandas as pd
    import streamlit as st
    import streamlit.components.v1 as components

    from db import get_session
    from models import Location
    from material_balance_calculator import MaterialBalanceCalculator as MBC

    # PDF libs (kept inside the function)
    from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.enums import TA_CENTER
    from reportlab.lib import colors
    from reportlab.lib.pagesizes import A4  # portrait
    from reportlab.lib.units import cm

    st.title("Reporting")

    # -------- Ensure active location / show context --------
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("⚠️ No active location selected. Please select a location first.")
        st.stop()

    with get_session() as s:
        loc = s.query(Location).filter(Location.id == active_location_id).first()
    if not loc:
        st.error("? Location not found.")
        st.stop()

    st.caption(f"📍 **Active Location:** {loc.name} ({loc.code})")

    try:
        from sqlalchemy import or_
        from models import ReportDefinition
        with get_session() as s:
            custom_reports = (
                s.query(ReportDefinition)
                .filter(
                    ReportDefinition.is_active == True,
                    or_(ReportDefinition.location_id == active_location_id, ReportDefinition.location_id.is_(None)),
                )
                .order_by(ReportDefinition.name)
                .all()
            )
        if custom_reports:
            st.markdown("### Custom Reports")
            cr_tabs = st.tabs([r.name for r in custom_reports])
            for i, r in enumerate(custom_reports):
                with cr_tabs[i]:
                    try:
                        cfg = json.loads(r.config_json or "{}")
                    except Exception:
                        cfg = {}
                    mode = str(cfg.get("mode") or "").strip()
                    src = str(cfg.get("primary_source") or "").strip()
                    columns = cfg.get("columns") or []
                    filter_cols = st.columns(2)
                    d_from = filter_cols[0].date_input("From date", value=date.today() - timedelta(days=30), key=f"cr_from_{r.id}")
                    d_to = filter_cols[1].date_input("To date", value=date.today(), key=f"cr_to_{r.id}")
                    loc_id_for_src = cfg.get("source_location_id") or active_location_id
                    # Date-Merge mode: build per-date columns from multiple sources/locations
                    if mode == "date_merge":
                        mappings = cfg.get("mappings") or []
                        cur = d_from
                        date_list = []
                        while cur <= d_to:
                            date_list.append(cur)
                            cur = cur + timedelta(days=1)
                        df = pd.DataFrame({"Date": [d.strftime("%Y-%m-%d") for d in date_list]})
                        def _load_rows_for_mapping(s2, mapping):
                            src_name = mapping.get("source")
                            loc_id = mapping.get("location_id") or active_location_id
                            rows, resolved_key = _load_rows_for_any_source(src_name, s2, loc_id, d_from, d_to)
                            op_filter = (mapping.get("operation_filter") or "").strip()
                            if op_filter:
                                rows = [row for row in rows if _matches_operation_filter(row, op_filter)]
                            return rows, resolved_key

                        with get_session() as s2:
                            for m in mappings:
                                label = m.get("label")
                                field = m.get("field")
                                dt_field = m.get("date_field") or "date"
                                agg = (m.get("aggregate") or "sum").lower()
                                rows, resolved_key = _load_rows_for_mapping(s2, m)
                                meta = _get_source_meta(resolved_key) if resolved_key else None
                                time_field = meta.get("time_field") if meta else None
                                grouped = defaultdict(list)
                                for r_obj in rows:
                                    d_val = _pluck_value(r_obj, dt_field)
                                    base_date = None
                                    t_val = None
                                    if isinstance(d_val, datetime):
                                        base_date = d_val.date()
                                        t_val = d_val.time()
                                    else:
                                        base_date = d_val
                                        if time_field:
                                            t_val = _pluck_value(r_obj, time_field)
                                        else:
                                            t_val = _pluck_value(r_obj, "time") or _pluck_value(r_obj, "transaction_time")
                                    report_date = _derive_report_date(base_date, t_val)
                                    if report_date is None or report_date < d_from or report_date > d_to:
                                        continue
                                    grouped[report_date].append(r_obj)
                                values = []
                                for d_cur in date_list:
                                    bucket_rows = grouped.get(d_cur, [])
                                    if not bucket_rows:
                                        values.append(None)
                                        continue
                                    agg_val = None
                                    if agg == "sum":
                                        total = 0.0
                                        for r_obj in bucket_rows:
                                            v_raw = _pluck_value(r_obj, field)
                                            try:
                                                total += float(v_raw or 0.0)
                                            except Exception:
                                                try:
                                                    total += float(str(v_raw)) if v_raw is not None else 0.0
                                                except Exception:
                                                    pass
                                        agg_val = total
                                    elif agg == "last":
                                        agg_val = _pluck_value(bucket_rows[-1], field)
                                    elif agg == "first":
                                        agg_val = _pluck_value(bucket_rows[0], field)
                                    else:
                                        agg_val = _pluck_value(bucket_rows[-1], field)
                                    values.append(agg_val)
                                df[label] = values
                        calcs = cfg.get("calculations") or []
                        if calcs:
                            for c in calcs:
                                lbl = str(c.get("label") or "").strip()
                                expr = str(c.get("expression") or "").strip()
                                if lbl and expr:
                                    try:
                                        normalized_expr = _normalize_calc_expression(expr, df.columns.tolist())
                                        df[lbl] = df.eval(normalized_expr)
                                    except Exception:
                                        df[lbl] = None
                        st.dataframe(df, use_container_width=True, hide_index=True)
                        col_dl, col_pdf = st.columns(2)
                        with col_dl:
                            xbio = BytesIO()
                            with pd.ExcelWriter(xbio, engine="xlsxwriter") as writer:
                                df.to_excel(writer, sheet_name=(r.slug or "Report")[:31], index=False)
                            st.download_button(
                                "Download",
                                data=xbio.getvalue(),
                                file_name=f"{r.slug or 'report'}_{d_from}_{d_to}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True,
                                key=f"cr_xlsx_{r.id}",
                            )
                        with col_pdf:
                            from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
                            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
                            from reportlab.lib.enums import TA_CENTER
                            from reportlab.lib.pagesizes import A4
                            from reportlab.lib import colors
                            pdf_buf = BytesIO()
                            doc = SimpleDocTemplate(pdf_buf, pagesize=A4)
                            styles = getSampleStyleSheet()
                            title_style = ParagraphStyle('CRT', parent=styles['Heading1'], alignment=TA_CENTER)
                            elems = [Paragraph(r.name, title_style), Paragraph(f"{d_from} to {d_to}", styles['Normal']), Spacer(1, 8)]
                            tbl = Table([list(df.columns)] + df.astype(str).values.tolist(), repeatRows=1)
                            tbl.setStyle(TableStyle([
                                ('BACKGROUND',(0,0),(-1,0),colors.lightgrey),
                                ('GRID',(0,0),(-1,-1),0.25,colors.grey),
                                ('ALIGN',(0,0),(-1,-1),'CENTER')
                            ]))
                            elems.append(tbl)
                            doc.build(elems)
                            st.download_button(
                                "View PDF",
                                data=pdf_buf.getvalue(),
                                file_name=f"{r.slug or 'report'}_{d_from}_{d_to}.pdf",
                                mime="application/pdf",
                                use_container_width=True,
                                key=f"cr_pdf_{r.id}",
                            )
                        continue
                    # Single-source mode: build row-wise payload
                    objs = []
                    with get_session() as s2:
                        if src_key == "fso_material_balance":
                            from models import FSOOperation
                            vessels = [row[0] for row in s2.query(FSOOperation.fso_vessel).filter(FSOOperation.location_id == loc_id_for_src).distinct().all()]
                            sel_vessel = st.selectbox("FSO Vessel", options=vessels or ["(none)"] , key=f"cr_vessel_{r.id}")
                            if vessels and sel_vessel:
                                q = s2.query(FSOOperation).filter(FSOOperation.location_id == loc_id_for_src, FSOOperation.fso_vessel == sel_vessel)
                                q = q.filter(FSOOperation.date >= d_from, FSOOperation.date <= d_to)
                                items = q.order_by(FSOOperation.date.asc(), FSOOperation.time.asc()).all()
                                mb_rows = []
                                cur = d_from
                                to = d_to
                                from datetime import time as dt_time
                                while cur <= to:
                                    ps = datetime.combine(cur, dt_time(6,1))
                                    pe = datetime.combine(cur + timedelta(days=1), dt_time(6,0))
                                    period = [e for e in items if ps <= datetime.combine(e.date, e.time if isinstance(e.time, dt_time) else convert_to_time_object(e.time)) <= pe]
                                    if period:
                                        first = period[0]; last = period[-1]
                                        opening_stock = float(getattr(first, 'opening_stock', 0.0) or 0.0)
                                        opening_water = float(getattr(first, 'opening_water', 0.0) or 0.0)
                                        receipts = sum(float(getattr(e, 'net_receipt_dispatch', 0.0) or 0.0) for e in period if getattr(e, 'operation', '') == 'Receipt' and float(getattr(e, 'net_receipt_dispatch', 0.0) or 0.0) > 0)
                                        exports = sum(abs(float(getattr(e, 'net_receipt_dispatch', 0.0) or 0.0)) for e in period if getattr(e, 'operation', '') == 'Export' and float(getattr(e, 'net_receipt_dispatch', 0.0) or 0.0) < 0)
                                        closing_stock = float(getattr(last, 'closing_stock', 0.0) or 0.0)
                                        closing_water = float(getattr(last, 'closing_water', 0.0) or 0.0)
                                        loss_gain = closing_stock - (opening_stock + receipts - exports)
                                        mb_rows.append({
                                            "Date": cur.strftime("%Y-%m-%d"),
                                            "Opening Stock": opening_stock,
                                            "Opening Water": opening_water,
                                            "Receipts": receipts,
                                            "Exports": exports,
                                            "Closing Stock": closing_stock,
                                            "Closing Water": closing_water,
                                            "Loss/Gain": loss_gain,
                                        })
                                    cur = cur + timedelta(days=1)
                                objs = mb_rows
                        else:
                            rows, resolved_key = _load_rows_for_any_source(src, s2, loc_id_for_src, d_from, d_to)
                            meta = _get_source_meta(resolved_key) if resolved_key else None
                            if meta:
                                filtered = []
                                for obj in rows:
                                    d_val = _pluck_value(obj, meta["date_field"])
                                    base_date = None
                                    t_val = None
                                    if isinstance(d_val, datetime):
                                        base_date = d_val.date()
                                        t_val = d_val.time()
                                    else:
                                        base_date = d_val
                                        t_val = _pluck_value(obj, meta.get("time_field"))
                                    report_date = _derive_report_date(base_date, t_val)
                                    if report_date is None or report_date < d_from or report_date > d_to:
                                        continue
                                    filtered.append(obj)
                                objs = filtered
                            else:
                                objs = rows
                    payload = []
                    for obj in objs:
                        row = {}
                        for c in columns:
                            label = str(c.get("label") or "")
                            field = str(c.get("field") or "")
                            if (src_key == "otr_records" or src == "OTRRecord") and field in ("Net Rece/Disp (bbls)", "Net Water Rece/Disp (bbls)"):
                                try:
                                    op = getattr(obj, "operation")
                                    t = str(op or "").lower()
                                    sign = 1.0 if ("rece" in t) else (-1.0 if ("disp" in t or "export" in t) else 0.0)
                                    base = getattr(obj, "nsv_bbl") if field == "Net Rece/Disp (bbls)" else getattr(obj, "free_water_bbl")
                                    val = sign * float(base or 0.0)
                                except Exception:
                                    val = None
                            else:
                                try:
                                    val = getattr(obj, field)
                                except Exception:
                                    try:
                                        val = obj.get(field) if isinstance(obj, dict) else None
                                    except Exception:
                                        val = None
                            if isinstance(val, (datetime, date)):
                                try:
                                    val = val.strftime("%Y-%m-%d")
                                except Exception:
                                    val = str(val)
                            row[label or field] = val
                        payload.append(row)
                    df = pd.DataFrame(payload)
                    st.dataframe(df, use_container_width=True, hide_index=True)
                    col_dl, col_pdf = st.columns(2)
                    with col_dl:
                        xbio = BytesIO()
                        with pd.ExcelWriter(xbio, engine="xlsxwriter") as writer:
                            df.to_excel(writer, sheet_name=(r.slug or "Report")[:31], index=False)
                        st.download_button(
                            "Download",
                            data=xbio.getvalue(),
                            file_name=f"{r.slug or 'report'}_{d_from}_{d_to}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True,
                            key=f"cr_xlsx_{r.id}",
                        )
                    with col_pdf:
                        from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
                        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
                        from reportlab.lib.enums import TA_CENTER
                        from reportlab.lib.pagesizes import A4
                        from reportlab.lib import colors
                        pdf_buf = BytesIO()
                        doc = SimpleDocTemplate(pdf_buf, pagesize=A4)
                        styles = getSampleStyleSheet()
                        title_style = ParagraphStyle('CRT', parent=styles['Heading1'], alignment=TA_CENTER)
                        elems = [Paragraph(r.name, title_style), Paragraph(f"{d_from} to {d_to}", styles['Normal']), Spacer(1, 8)]
                        tbl = Table([list(df.columns)] + df.astype(str).values.tolist(), repeatRows=1)
                        tbl.setStyle(TableStyle([
                            ('BACKGROUND',(0,0),(-1,0),colors.lightgrey),
                            ('GRID',(0,0),(-1,-1),0.25,colors.grey),
                            ('ALIGN',(0,0),(-1,-1),'CENTER')
                        ]))
                        elems.append(tbl)
                        doc.build(elems)
                        st.download_button(
                            "View PDF",
                            data=pdf_buf.getvalue(),
                            file_name=f"{r.slug or 'report'}_{d_from}_{d_to}.pdf",
                            mime="application/pdf",
                            use_container_width=True,
                            key=f"cr_pdf_{r.id}",
                        )
    except Exception:
        pass

    # Special handling: if this location is OML-157, show OFS reports and skip other tabs
    try:
        loc_code_norm = (loc.code or "").replace(" ", "").replace("-", "").upper()
    except Exception:
        loc_code_norm = ""
    if loc_code_norm == "OML157":
        # Render OFS report tab only
        user = st.session_state.get("auth_user") or {}
        render_ofs_reports_tab(active_location_id, loc, user)
        return
    loc_name_upper = (loc.name or "").upper()
    loc_name_norm = (loc.name or "").strip().lower()
    loc_code_upper = (loc.code or "").upper()
    is_beneku_location = (
        "BFS" in loc_code_upper
        or "BFS" in loc_name_upper
        or "BENEKU" in loc_name_upper
    )
    is_asemoku_location = loc_name_norm == "asemoku jetty" or "ASEMOKU" in loc_code_upper
    is_ndoni_location = "NDONI" in loc_name_upper or "NDONI" in loc_code_upper
    show_river_reports = is_asemoku_location or is_ndoni_location

    def _canon_token(value: str | None) -> str:
        return "".join(ch for ch in str(value or "").upper() if ch.isalnum())

    loc_token_set = {
        _canon_token(loc.code),
        _canon_token(loc.name),
        _canon_token(f"{loc.name}{loc.code}"),
    }
    lagos_tokens = {"LAGOSHO", "HO", "LAGOS"}
    is_lagos_ho = bool(loc_token_set & lagos_tokens)

    # -------- Tabs --------
    # Added "TANKER DETAILS" as a fifth tab for tanker movement comparisons (Aggu & Ndoni)
    tab_labels = [
        "BFS VS JETTY",
        "JETTY METER RECORDS",
        "CONDENSATE RECEIPT",
        "BFS PRODUCTION",
        "TANKER DETAILS",
    ]
    river_tab = None
    produced_tab = None
    daily_tab = None
    river_index = produced_index = daily_index = None
    if show_river_reports:
        river_index = len(tab_labels)
        tab_labels.append("River Draft")
        produced_index = len(tab_labels)
        tab_labels.append("Produced Water")
    if is_lagos_ho:
        daily_index = len(tab_labels)
        tab_labels.append("DAILY PRODUCTION & EVACUATION")
    tabs = st.tabs(tab_labels)
    tab1, tab2, tab3, tab4, tab5 = tabs[:5]
    if river_index is not None:
        river_tab = tabs[river_index]
    if produced_index is not None:
        produced_tab = tabs[produced_index]
    if daily_index is not None:
        daily_tab = tabs[daily_index]

    # Immediately render tanker details tab (tab5) content.  This ensures that the Tanker Details
    # tab is properly registered and can be displayed alongside other report tabs.
    with tab5:
        try:
            render_tanker_details_tab()
        except Exception as ex:
            st.error(f"Failed to render tanker details: {ex}")

    if river_tab is not None:
        with river_tab:
            st.subheader("River Draft Records")
            river_df = pd.DataFrame(load_river_draft_records(active_location_id, limit=3000))
            if not river_df.empty:
                river_df["Date"] = pd.to_datetime(river_df["Date"]).dt.date
            river_dates = river_df["Date"].tolist() if not river_df.empty else []
            rpt_river_min, rpt_river_max = _derive_filter_bounds(river_dates)
            rpt_river_from_default = _ensure_date_key_in_bounds(
                f"report_river_from_{active_location_id}",
                rpt_river_min,
                rpt_river_max,
                rpt_river_min,
            )
            rpt_river_to_default = _ensure_date_key_in_bounds(
                f"report_river_to_{active_location_id}",
                rpt_river_min,
                rpt_river_max,
                rpt_river_max,
            )

            filters = st.columns(2)
            with filters[0]:
                river_from = st.date_input(
                    "From date",
                    value=rpt_river_from_default,
                    min_value=rpt_river_min,
                    max_value=rpt_river_max,
                    key=f"report_river_from_{active_location_id}",
                )
            with filters[1]:
                river_to = st.date_input(
                    "To date",
                    value=rpt_river_to_default,
                    min_value=rpt_river_min,
                    max_value=rpt_river_max,
                    key=f"report_river_to_{active_location_id}",
                )

            if not river_df.empty:
                if river_from:
                    river_df = river_df[river_df["Date"] >= river_from]
                if river_to:
                    river_df = river_df[river_df["Date"] <= river_to]

            display_cols = ["Date", "River Draft (m)", "Rainfall (cm)"]
            river_display_df = (
                river_df[display_cols].copy()
                if not river_df.empty
                else pd.DataFrame(columns=display_cols)
            )
            st.caption(f"{len(river_display_df)} record(s) shown")

            if river_display_df.empty:
                st.info("No river draft entries for the selected range.")
            else:
                st.dataframe(river_display_df, use_container_width=True, hide_index=True)

                river_csv = river_display_df.to_csv(index=False).encode("utf-8")
                river_xlsx = BytesIO()
                with pd.ExcelWriter(river_xlsx, engine="xlsxwriter") as writer:
                    river_display_df.to_excel(writer, index=False, sheet_name="RiverDraft")
                river_pdf = _generate_tanker_details_pdf(
                    river_display_df,
                    "River Draft Report",
                    river_from,
                    river_to,
                )
                file_stub = f"river_draft_{loc.code}_{river_from}_{river_to}".replace(" ", "_")
                downloads = st.columns(4)
                downloads[0].download_button(
                    "Download CSV",
                    data=river_csv,
                    file_name=f"{file_stub}.csv",
                    mime="text/csv",
                    use_container_width=True,
                )
                downloads[1].download_button(
                    "Download XLSX",
                    data=river_xlsx.getvalue(),
                    file_name=f"{file_stub}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )
                downloads[2].download_button(
                    "Download PDF",
                    data=river_pdf,
                    file_name=f"{file_stub}.pdf",
                    mime="application/pdf",
                    use_container_width=True,
                )
                if downloads[3].button(
                    "View PDF",
                    key=f"river_pdf_view_report_{active_location_id}",
                    use_container_width=True,
                ):
                    _open_pdf_blob(river_pdf)

    if produced_tab is not None:
        with produced_tab:
            st.subheader("Produced Water Records")
            pw_df = pd.DataFrame(load_produced_water_records(active_location_id, limit=3000))
            if not pw_df.empty:
                pw_df["Date"] = pd.to_datetime(pw_df["Date"]).dt.date
            report_pw_dates = pw_df["Date"].tolist() if not pw_df.empty else []
            rpt_pw_min, rpt_pw_max = _derive_filter_bounds(report_pw_dates)
            rpt_pw_from_default = _ensure_date_key_in_bounds(
                f"report_pw_from_{active_location_id}",
                rpt_pw_min,
                rpt_pw_max,
                rpt_pw_min,
            )
            rpt_pw_to_default = _ensure_date_key_in_bounds(
                f"report_pw_to_{active_location_id}",
                rpt_pw_min,
                rpt_pw_max,
                rpt_pw_max,
            )

            filters = st.columns(2)
            with filters[0]:
                pw_from = st.date_input(
                    "From date",
                    value=rpt_pw_from_default,
                    min_value=rpt_pw_min,
                    max_value=rpt_pw_max,
                    key=f"report_pw_from_{active_location_id}",
                )
            with filters[1]:
                pw_to = st.date_input(
                    "To date",
                    value=rpt_pw_to_default,
                    min_value=rpt_pw_min,
                    max_value=rpt_pw_max,
                    key=f"report_pw_to_{active_location_id}",
                )

            if not pw_df.empty:
                if pw_from:
                    pw_df = pw_df[pw_df["Date"] >= pw_from]
                if pw_to:
                    pw_df = pw_df[pw_df["Date"] <= pw_to]

            pw_display_cols = ["Date", "Produced Water (bbls)"]
            pw_display_df = (
                pw_df[pw_display_cols].copy()
                if not pw_df.empty
                else pd.DataFrame(columns=pw_display_cols)
            )
            st.caption(f"{len(pw_display_df)} record(s) shown")

            if pw_display_df.empty:
                st.info("No produced water entries for the selected range.")
            else:
                st.dataframe(pw_display_df, use_container_width=True, hide_index=True)

                pw_csv = pw_display_df.to_csv(index=False).encode("utf-8")
                pw_xlsx = BytesIO()
                with pd.ExcelWriter(pw_xlsx, engine="xlsxwriter") as writer:
                    pw_display_df.to_excel(writer, index=False, sheet_name="ProducedWater")
                pw_pdf = _generate_tanker_details_pdf(
                    pw_display_df,
                    "Produced Water Report",
                    pw_from,
                    pw_to,
                )
                file_stub = f"produced_water_{loc.code}_{pw_from}_{pw_to}".replace(" ", "_")
                downloads = st.columns(4)
                downloads[0].download_button(
                    "Download CSV",
                    data=pw_csv,
                    file_name=f"{file_stub}.csv",
                    mime="text/csv",
                    use_container_width=True,
                )
                downloads[1].download_button(
                    "Download XLSX",
                    data=pw_xlsx.getvalue(),
                    file_name=f"{file_stub}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )
                downloads[2].download_button(
                    "Download PDF",
                    data=pw_pdf,
                    file_name=f"{file_stub}.pdf",
                    mime="application/pdf",
                    use_container_width=True,
                )
                if downloads[3].button(
                    "View PDF",
                    key=f"pw_pdf_view_report_{active_location_id}",
                    use_container_width=True,
                ):
                    _open_pdf_blob(pw_pdf)

    if daily_tab is not None:
        with daily_tab:
            st.subheader("DAILY PRODUCTION & EVACUATION")
            st.caption("Date-wise production, evacuation, and FSO receipt snapshot (Lagos HO view).")

            default_daily_to = date.today()
            default_daily_from = default_daily_to - timedelta(days=14)
            filter_cols = st.columns(2)
            daily_from = filter_cols[0].date_input(
                "From date",
                value=default_daily_from,
                key="lagos_daily_from",
            )
            daily_to = filter_cols[1].date_input(
                "To date",
                value=default_daily_to,
                key="lagos_daily_to",
            )

            if daily_from > daily_to:
                st.error("From date cannot be after To date.")
            else:
                with get_session() as s_locations:
                    location_entries = [
                        {"id": entry.id, "code": entry.code or "", "name": entry.name or ""}
                        for entry in s_locations.query(Location).all()
                    ]

                def _resolve_location(token_set: set[str]) -> dict | None:
                    canon_targets = {_canon_token(tok) for tok in token_set}
                    for entry in location_entries:
                        entry_tokens = {_canon_token(entry["code"]), _canon_token(entry["name"])}
                        if entry_tokens & canon_targets:
                            return entry
                    return None

                loc_aggu = _resolve_location({"AGGU"})
                loc_asemoku = _resolve_location({"JETTY", "ASEMOKU", "ASEMOKUJETTY"})
                loc_bfs = _resolve_location({"BFS", "BENEKU"})
                loc_oguali = _resolve_location({"OGUALI", "OML157", "OGUALIOML157"})
                loc_utapate = _resolve_location({"UTAPATE", "OML13", "OML-13"})
                loc_agge = _resolve_location({"AGGE"})

                missing_locations = []
                if not loc_aggu:
                    missing_locations.append("Aggu")
                if not loc_asemoku:
                    missing_locations.append("Asemoku Jetty")
                if not loc_bfs:
                    missing_locations.append("Beneku (BFS)")
                if not loc_oguali:
                    missing_locations.append("Oguali (OML-157)")
                if not loc_utapate:
                    missing_locations.append("Utapate (OML-13)")
                if not loc_agge:
                    missing_locations.append("Agge (FSO)")
                if missing_locations:
                    st.warning("Location mapping missing for: " + ", ".join(missing_locations))

                def _find_col_case(df: pd.DataFrame, candidates: list[str]) -> str | None:
                    if df is None or df.empty:
                        return None
                    for cand in candidates:
                        if cand in df.columns:
                            return cand
                    lower_map = {str(col).strip().lower(): col for col in df.columns}
                    for cand in candidates:
                        key = cand.strip().lower()
                        if key in lower_map:
                            return lower_map[key]
                    return None

                def _mb_series(loc_entry: dict | None, candidates: list[str], label: str) -> dict[date, float]:
                    if not loc_entry:
                        return {}
                    try:
                        rows = MBC.calculate_material_balance(
                            None,
                            (loc_entry["code"] or "").upper(),
                            daily_from,
                            daily_to,
                            location_id=loc_entry["id"],
                            debug=False,
                        ) or []
                    except Exception as ex:
                        st.warning(f"Unable to load {label}: {ex}")
                        return {}
                    if not rows:
                        return {}
                    df = pd.DataFrame(rows)
                    if df.empty or "Date" not in df.columns:
                        return {}
                    df["Date"] = pd.to_datetime(df["Date"], errors="coerce").dt.date
                    column = _find_col_case(df, candidates)
                    if not column:
                        return {}
                    df[column] = pd.to_numeric(df[column], errors="coerce").fillna(0.0)
                    return {
                        row["Date"]: float(row[column])
                        for _, row in df.iterrows()
                        if isinstance(row["Date"], date)
                    }

                def _gpp_series(loc_entry: dict | None, column_name: str, label: str) -> dict[date, float]:
                    if not loc_entry:
                        return {}
                    try:
                        records = load_gpp_production_records(loc_entry["id"], limit=2000)
                    except Exception as ex:
                        st.warning(f"Unable to load {label}: {ex}")
                        return {}
                    if not records:
                        return {}
                    df = pd.DataFrame(records)
                    if df.empty or column_name not in df.columns:
                        return {}
                    df["Date"] = pd.to_datetime(df["Date"], errors="coerce").dt.date
                    df[column_name] = pd.to_numeric(df[column_name], errors="coerce").fillna(0.0)
                    df = df[(df["Date"] >= daily_from) & (df["Date"] <= daily_to)]
                    return {
                        row["Date"]: float(row[column_name])
                        for _, row in df.iterrows()
                        if isinstance(row["Date"], date)
                    }

                def _ofs_series(loc_entry: dict | None, label: str) -> tuple[dict[date, float], dict[date, float]]:
                    oguali_map: dict[date, float] = {}
                    ukpichi_map: dict[date, float] = {}
                    if not loc_entry:
                        return oguali_map, ukpichi_map
                    try:
                        with get_session() as s_ofs:
                            rows = (
                                s_ofs.query(OFSProductionEvacuationRecord)
                                .filter(
                                    OFSProductionEvacuationRecord.location_id == loc_entry["id"],
                                    OFSProductionEvacuationRecord.date >= daily_from,
                                    OFSProductionEvacuationRecord.date <= daily_to,
                                )
                                .all()
                            )
                    except Exception as ex:
                        st.warning(f"Unable to load {label}: {ex}")
                        return oguali_map, ukpichi_map
                    for row in rows:
                        oguali_map[row.date] = float(row.oguali_production or 0.0)
                        uk_val = float(row.ukpichi_production or 0.0)
                        other_val = float(row.other_locations or 0.0)
                        ukpichi_map[row.date] = uk_val + other_val
                    return oguali_map, ukpichi_map

                def _fso_receipt_series(loc_entry: dict | None, vessel_name: str, label: str) -> dict[date, float]:
                    if not loc_entry:
                        return {}
                    try:
                        from models import FSOOperation
                        with get_session() as s_fso:
                            rows = (
                                s_fso.query(FSOOperation.date, FSOOperation.operation, FSOOperation.net_receipt_dispatch)
                                .filter(
                                    FSOOperation.location_id == loc_entry["id"],
                                    FSOOperation.fso_vessel == vessel_name,
                                    FSOOperation.date >= daily_from,
                                    FSOOperation.date <= daily_to,
                                )
                                .all()
                            )
                    except Exception as ex:
                        st.warning(f"Unable to load {label}: {ex}")
                        return {}
                    result: dict[date, float] = defaultdict(float)
                    for dt_val, op_val, qty_val in rows:
                        op_text = str(op_val or "").strip().lower()
                        if op_text.startswith("receipt"):
                            result[dt_val] += float(qty_val or 0.0)
                    return dict(result)

                aggu_series = _mb_series(loc_aggu, ["Receipt", "Receipts"], "Aggu receipt")
                anz_series = _mb_series(loc_asemoku, ["ANZ Receipt"], "ANZ receipt")
                gpp_series = _gpp_series(loc_bfs, "Total GPP Production", "Total GPP production")
                okw_series = _gpp_series(loc_bfs, "OKW Production", "OKW production")
                oguali_series, ukpichi_series = _ofs_series(loc_oguali, "OFS production")
                utapate_series = _mb_series(loc_utapate, ["Receipt", "Receipts"], "Utapate receipt")
                tanvi_series = _fso_receipt_series(loc_agge, "MT TULJA TANVI", "Tanvi receipts")
                kalyani_series = _fso_receipt_series(loc_utapate, "MT TULJA KALYANI", "Kalyani receipts")

                date_range = pd.date_range(daily_from, daily_to)
                rows: list[dict[str, Any]] = []
                for dt_val in date_range:
                    day = dt_val.date()
                    aggu_val = aggu_series.get(day, 0.0)
                    anz_val = anz_series.get(day, 0.0)
                    gpp_val = gpp_series.get(day, 0.0)
                    oguali_val = oguali_series.get(day, 0.0)
                    okw_val = okw_series.get(day, 0.0)
                    ukpichi_val = ukpichi_series.get(day, 0.0)
                    total_psc = aggu_val + anz_val + gpp_val + oguali_val + okw_val + ukpichi_val
                    row = {
                        "Date": day,
                        "AGGU": aggu_val,
                        "ANIEZE & ENYIE": anz_val,
                        "GPP": gpp_val,
                        "OGUALI": oguali_val,
                        "OKW": okw_val,
                        "UKPICHI": ukpichi_val,
                        "TOTAL PSC PRODUCTION": total_psc,
                        "TANVI RECEIPT": tanvi_series.get(day, 0.0),
                        "UTAPATE": utapate_series.get(day, 0.0),
                        "KALYANI RECEIPT": kalyani_series.get(day, 0.0),
                    }
                    rows.append(row)

                daily_df = pd.DataFrame(rows)
                if daily_df.empty:
                    st.info("No production/evacuation data found for the selected period.")
                else:
                    daily_df["Date"] = pd.to_datetime(daily_df["Date"])
                    numeric_columns = [col for col in daily_df.columns if col != "Date"]
                    totals = {col: float(daily_df[col].sum()) for col in numeric_columns}
                    st.markdown("##### Totals (Selected Range)")
                    totals_df = pd.DataFrame([totals])
                    st.dataframe(
                        totals_df.style.format({col: "{:,.2f}" for col in totals_df.columns}),
                        use_container_width=True,
                        hide_index=True,
                    )
                    display_df = daily_df.copy()
                    display_df["Date"] = display_df["Date"].dt.strftime("%d-%b-%Y")
                    st.dataframe(
                        display_df.style.format({col: "{:,.2f}" for col in numeric_columns}),
                        use_container_width=True,
                        hide_index=True,
                    )

                    export_df = daily_df.copy()
                    export_df["Date"] = export_df["Date"].dt.strftime("%Y-%m-%d")
                    csv_bytes = export_df.to_csv(index=False).encode("utf-8")
                    xlsx_buffer = BytesIO()
                    with pd.ExcelWriter(xlsx_buffer, engine="xlsxwriter") as writer:
                        export_df.to_excel(writer, index=False, sheet_name="DailyProduction")
                    xlsx_bytes = xlsx_buffer.getvalue()
                    pdf_title = "DATE-WISE PRODUCTION, EVACUATION & FSO RECEIPT"
                    pdf_df = export_df.copy()
                    pdf_columns = list(export_df.columns)
                    pdf_summary_row: list[Any] = []
                    for col in pdf_columns:
                        if col == "Date":
                            pdf_summary_row.append("TOTAL")
                        else:
                            pdf_summary_row.append(totals.get(col, 0.0))
                    pdf_summary_pairs = [(col, totals.get(col, 0.0)) for col in numeric_columns]
                    pdf_bytes = _generate_tanker_details_pdf(
                        pdf_df,
                        pdf_title,
                        daily_from,
                        daily_to,
                        summary_row=pdf_summary_row,
                        summary_pairs=pdf_summary_pairs,
                    )

                    file_stub = f"daily_production_{daily_from}_{daily_to}".replace(" ", "_")
                    btn_cols = st.columns(4)
                    btn_cols[0].download_button(
                        "📥 CSV",
                        data=csv_bytes,
                        file_name=f"{file_stub}.csv",
                        mime="text/csv",
                        use_container_width=True,
                    )
                    btn_cols[1].download_button(
                        "📥 XLSX",
                        data=xlsx_bytes,
                        file_name=f"{file_stub}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True,
                    )
                    btn_cols[2].download_button(
                        "📥 PDF",
                        data=pdf_bytes,
                        file_name=f"{file_stub}.pdf",
                        mime="application/pdf",
                        use_container_width=True,
                    )
                    if btn_cols[3].button("👁️ View PDF", key="daily_production_pdf_view", use_container_width=True):
                        _open_pdf_blob(pdf_bytes, filename=f"{file_stub}.pdf")


    # ======================================================================
    # TAB 1: BENEKU DISPATCH VS JETTY RECEIPT
    # ======================================================================
    with tab1:
        st.subheader("BENEKU DISPATCH VS JETTY RECEIPT")

        # ----- Live filters -----
        with st.container(border=True):
            c1, c2, c3 = st.columns([0.33, 0.33, 0.34])
            with c1:
                f_from = st.date_input("From", value=date.today() - timedelta(days=14), key="rpt_bj_from")
            with c2:
                f_to = st.date_input("To", value=date.today(), key="rpt_bj_to")
            with c3:
                search_remark = st.text_input("Search in remarks", key="rpt_bj_search")

        # ----- Resolve BFS & JETTY locations -----
        with get_session() as s:
            bfs = s.query(Location).filter(Location.code.in_(["BFS", "Beneku", "BENEKU"])).first()
            jet = s.query(Location).filter(Location.code.in_(["JETTY", "Asemoku", "ASEMOKU"])).first()

        if not bfs or not jet:
            st.error("Could not find BFS or JETTY locations. Ensure Location.code contains 'BFS' and 'JETTY'.")
            st.stop()

        # ----- Pull daily MB rows via calculator -----
        bfs_rows = MBC.calculate_material_balance(None, "BFS", f_from, f_to, location_id=bfs.id, debug=False)
        jet_rows = MBC.calculate_material_balance(None, "JETTY", f_from, f_to, location_id=jet.id, debug=False)

        bfs_df = pd.DataFrame(bfs_rows)
        jet_df = pd.DataFrame(jet_rows)

        if "Dispatch to Jetty" not in bfs_df.columns:
            bfs_df["Dispatch to Jetty"] = 0.0
        if "OKW Receipt" not in jet_df.columns:
            jet_df["OKW Receipt"] = 0.0

        bfs_df = bfs_df[["Date", "Dispatch to Jetty"]].rename(columns={"Dispatch to Jetty": "BFS Dispatch"})
        jet_df = jet_df[["Date", "OKW Receipt"]].rename(columns={"OKW Receipt": "Jetty Receipt"})

        # Join by Date and compute metrics
        df = pd.merge(jet_df, bfs_df, on="Date", how="outer").sort_values("Date")

        # Optional: derive Jetty free-water received from OTR-like model when available
        from sqlalchemy import and_, or_

        with get_session() as s:
            try:
                from models import OTR  # your preferred model name
                OTRModel = OTR
            except Exception:
                try:
                    from models import OTRTransaction as OTRModel
                except Exception:
                    OTRModel = None

        water_by_report_date = {}

        if OTRModel is not None:
            # time window [f_from 06:01, f_to+1 06:00] to map early morning to previous day
            fetch_start = datetime.combine(f_from, time(hour=6, minute=1))
            fetch_end   = datetime.combine(f_to + timedelta(days=1), time(hour=6, minute=0))

            def col(obj, *names):
                for n in names:
                    if hasattr(obj, n):
                        return getattr(obj, n)
                raise AttributeError(f"Missing column candidates {names} on {obj}")

            try:
                q = s.query(OTRModel).filter(
                    and_(
                        col(OTRModel, "location_id", "LocationId") == jet.id,
                        or_(
                            col(OTRModel, "operation", "operation_name", "Operation").ilike("%OKW Receipt%"),
                            col(OTRModel, "operation", "operation_name", "Operation") == "OKW Receipt",
                        ),
                        col(OTRModel, "timestamp", "dt", "created_at", "TxnDateTime").between(fetch_start, fetch_end),
                    )
                ).order_by(col(OTRModel, "timestamp", "dt", "created_at", "TxnDateTime").asc())
                rows = q.all()
            except Exception:
                rows = []

            prev_fw = None
            for r in rows:
                ts = None
                for nm in ("timestamp", "dt", "created_at", "TxnDateTime"):
                    if hasattr(r, nm):
                        ts = getattr(r, nm)
                        break
                if ts is None:
                    continue

                fw = None
                for nm in ("free_water_bbl", "FreeWater_bbl", "Free_Water_bbl", "free_water", "Free_Water"):
                    if hasattr(r, nm):
                        fw = getattr(r, nm)
                        break
                if fw is None:
                    continue

                try:
                    fw = float(fw or 0.0)
                except Exception:
                    fw = 0.0

                if prev_fw is None:
                    net_water = 0.0
                else:
                    net_water = fw - prev_fw
                prev_fw = fw

                # map to OTMS "report date"
                cutoff = time(hour=6, minute=0)
                report_date = (ts.date() - timedelta(days=1)) if ts.time() <= cutoff else ts.date()

                if report_date < f_from or report_date > f_to:
                    continue

                water_by_report_date[report_date] = water_by_report_date.get(report_date, 0.0) + float(net_water or 0.0)

        df["Water Received"] = df["Date"].map(lambda d: float(water_by_report_date.get(pd.to_datetime(d).date(), 0.0)))

        # Loss/Gain and Loss/Gain %
        df["Loss/Gain"] = (df["Jetty Receipt"].fillna(0) + df["Water Received"].fillna(0)) - df["BFS Dispatch"].fillna(0)
        denom = (df["Jetty Receipt"].fillna(0) + df["Water Received"].fillna(0))
        df["Loss/Gain %"] = df["Loss/Gain"].where(denom == 0, df["Loss/Gain"] / denom) * 100.0

        # ----- Inline Remarks persisted to OUTPUT/reporting_notes.json -----
        OUTPUT = Path("OUTPUT"); OUTPUT.mkdir(exist_ok=True)
        REPORT_NOTES_PATH = OUTPUT / "reporting_notes.json"
        if not REPORT_NOTES_PATH.exists():
            REPORT_NOTES_PATH.write_text("{}", encoding="utf-8")
        try:
            notes = json.loads(REPORT_NOTES_PATH.read_text(encoding="utf-8"))
        except Exception:
            notes = {}

        key_space = f"BFS_JETTY::{loc.code}"
        remarks_map = notes.get(key_space, {})
        df["Remarks"] = df["Date"].map(lambda d: remarks_map.get(str(d), ""))

        if search_remark.strip():
            df = df[df["Remarks"].str.contains(search_remark.strip(), case=False, na=False)]

        # ----- Table (Remarks editable only) -----
        st.caption("Double-click �Remarks� to edit, then click **Save Remarks**.")
        cfg = {
            "Date": st.column_config.TextColumn("Date", width="small"),
            "BFS Dispatch": st.column_config.NumberColumn("BFS Dispatch (bbls)", format="%.2f"),
            "Jetty Receipt": st.column_config.NumberColumn("Jetty Receipt (bbls)", format="%.2f"),
            "Water Received": st.column_config.NumberColumn("Water Received (bbls)", format="%.2f"),
            "Loss/Gain": st.column_config.NumberColumn("Loss/Gain (bbls)", format="%.2f"),
            "Loss/Gain %": st.column_config.NumberColumn("Loss/Gain %", format="%.4f"),
            "Remarks": st.column_config.TextColumn("Remarks", width="large"),
        }
        edited = st.data_editor(
            df,
            use_container_width=True,
            hide_index=True,
            column_config=cfg,
            disabled=["Date", "BFS Dispatch", "Jetty Receipt", "Water Received", "Loss/Gain", "Loss/Gain %"],
        )

        # Normalize dtypes
        num_cols = ["BFS Dispatch", "Jetty Receipt", "Water Received", "Loss/Gain", "Loss/Gain %"]
        for c in num_cols:
            edited[c] = pd.to_numeric(edited[c], errors="coerce").fillna(0.0)
        edited["Date"] = edited["Date"].astype(str)

        # Save Remarks
        if st.button("💾 Save Remarks", type="primary", key="bj_save_remarks_btn"):
            new_map = {}
            for _, r in edited.iterrows():
                if str(r["Date"]).upper() == "TOTAL":
                    continue
                new_map[str(r["Date"])] = r.get("Remarks", "") or ""
            notes[key_space] = new_map
            REPORT_NOTES_PATH.write_text(json.dumps(notes, indent=2), encoding="utf-8")
            st.success("Remarks saved.")
            try:
                import streamlit as _stmod
                _stmod.rerun()
            except Exception:
                import streamlit as _stmod
                _stmod.experimental_rerun()

        # Totals
        sum_cols = ["BFS Dispatch", "Jetty Receipt", "Water Received", "Loss/Gain"]
        totals = {c: float(edited[c].sum()) for c in sum_cols}
        denom_total = totals["Jetty Receipt"] + totals["Water Received"]
        totals_pct = 0.0 if denom_total == 0 else (totals["Loss/Gain"] / denom_total) * 100.0

        totals_row = {
            "Date": "TOTAL",
            "BFS Dispatch": totals["BFS Dispatch"],
            "Jetty Receipt": totals["Jetty Receipt"],
            "Water Received": totals["Water Received"],
            "Loss/Gain": totals["Loss/Gain"],
            "Loss/Gain %": totals_pct,
            "Remarks": "",
        }

        st.markdown("**Totals (filtered):**")
        totals_df = pd.DataFrame([totals_row])
        st.dataframe(
            totals_df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "BFS Dispatch": st.column_config.NumberColumn(format="%.2f"),
                "Jetty Receipt": st.column_config.NumberColumn(format="%.2f"),
                "Water Received": st.column_config.NumberColumn(format="%.2f"),
                "Loss/Gain": st.column_config.NumberColumn(format="%.2f"),
                "Loss/Gain %": st.column_config.NumberColumn(format="%.4f"),
            },
        )

        edited_with_total = pd.concat([edited, totals_df], ignore_index=True)

        # Exports
        st.markdown("---")
        col_a, col_b, col_c, col_d = st.columns(4)

        # CSV
        col_a.download_button(
            "📥 Download CSV",
            data=edited_with_total.to_csv(index=False).encode("utf-8"),
            file_name=f"bfs_vs_jetty_{loc.code}_{str(f_from)}_{str(f_to)}.csv",
            mime="text/csv",
            key="bj_csv_dl",
        )

        # XLSX
        xbio = BytesIO()
        with pd.ExcelWriter(xbio, engine="xlsxwriter") as writer:
            edited_with_total.to_excel(writer, index=False, sheet_name="BFS_vs_Jetty")
        col_b.download_button(
            "📥 Download XLSX",
            data=xbio.getvalue(),
            file_name=f"bfs_vs_jetty_{loc.code}_{str(f_from)}_{str(f_to)}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="bj_xlsx_dl",
        )

        # PDF generator for BFS vs JETTY
        def _pdf_bytes(_df: pd.DataFrame) -> bytes:
            for c in ["BFS Dispatch", "Jetty Receipt", "Water Received", "Loss/Gain", "Loss/Gain %"]:
                _df[c] = pd.to_numeric(_df[c], errors="coerce").fillna(0.0)

            if len(_df) == 0 or str(_df.iloc[-1]["Date"]).upper() != "TOTAL":
                _sum_cols = ["BFS Dispatch", "Jetty Receipt", "Water Received", "Loss/Gain"]
                _totals = {c: float(_df[c].sum()) for c in _sum_cols} if len(_df) else {c: 0.0 for c in _sum_cols}
                _denom_total = _totals["Jetty Receipt"] + _totals["Water Received"]
                _totals_pct = 0.0 if _denom_total == 0 else (_totals["Loss/Gain"] / _denom_total) * 100.0
                _total_row = {
                    "Date": "TOTAL",
                    "BFS Dispatch": _totals["BFS Dispatch"],
                    "Jetty Receipt": _totals["Jetty Receipt"],
                    "Water Received": _totals["Water Received"],
                    "Loss/Gain": _totals["Loss/Gain"],
                    "Loss/Gain %": _totals_pct,
                    "Remarks": "",
                }
                _df = pd.concat([_df, pd.DataFrame([_total_row])], ignore_index=True)

            bio = BytesIO()

            page_w, _page_h = A4
            lm = rm = tm = bm = 0.5 * cm
            avail_w = page_w - lm - rm

            doc = SimpleDocTemplate(
                bio, pagesize=A4,
                leftMargin=lm, rightMargin=rm, topMargin=tm, bottomMargin=bm
            )

            styles = getSampleStyleSheet()
            title_style = ParagraphStyle("T", parent=styles["Heading1"], fontSize=15,
                                         alignment=TA_CENTER, textColor=colors.HexColor("#1f4788"))
            sub_style = ParagraphStyle("S", parent=styles["Normal"], fontSize=10,
                                       alignment=TA_CENTER, textColor=colors.HexColor("#666666"))

            elements = []
            elements.append(Paragraph("<b>BENEKU DISPATCH VS JETTY RECEIPT</b>", title_style))
            elements.append(Paragraph(f"{loc.name} ({loc.code}) � Period: <b>{str(f_from)}</b> to <b>{str(f_to)}</b>", sub_style))
            elements.append(Spacer(1, 0.3 * cm))

            headers = ["Date", "BFS Dispatch", "Jetty Receipt", "Water Received", "Loss/Gain", "Loss/Gain %", "Remarks"]
            data = [headers]
            for _, r in _df.iterrows():
                is_total = str(r["Date"]).upper() == "TOTAL"
                data.append([
                    r["Date"],
                    f"{float(r['BFS Dispatch']):,.2f}",
                    f"{float(r['Jetty Receipt']):,.2f}",
                    f"{float(r['Water Received']):,.2f}",
                    f"{float(r['Loss/Gain']):,.2f}",
                    f"{float(r['Loss/Gain %']):,.4f}",
                    ("TOTAL" if is_total else (str(r.get("Remarks") or "")[:90])),
                ])

            weights = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.2]
            scale = avail_w / sum(weights)
            col_widths = [w * scale for w in weights]

            table = Table(data, repeatRows=1, colWidths=col_widths)
            table.setStyle(TableStyle([
                ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#1f4788")),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
                ("ALIGN", (0, 0), (-1, -1), "CENTER"),
                ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
                ("FONTSIZE", (0, 0), (-1, 0), 8),
                ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
                ("ROWBACKGROUNDS", (0, 1), (-1, -2), [colors.whitesmoke, colors.HexColor("#f8f9fa")]),
                ("FONTSIZE", (0, 1), (-1, -1), 8),
                ("BACKGROUND", (0, -1), (-1, -1), colors.HexColor("#e8eefc")),
                ("FONTNAME", (0, -1), (-1, -1), "Helvetica-Bold"),
            ]))

            elements.append(table)
            doc.build(elements)
            return bio.getvalue()

        pdf_bytes = _pdf_bytes(edited_with_total)

        col_c.download_button(
            "📥 Download PDF",
            data=pdf_bytes,
            file_name=f"bfs_vs_jetty_{loc.code}_{str(f_from)}_{str(f_to)}.pdf",
            mime="application/pdf",
            key="bj_pdf_dl",
        )

        if col_d.button("👁️ View PDF", key=f"view_bfs_pdf_{loc.code}"):
            b64 = base64.b64encode(pdf_bytes).decode("utf-8")
            components.html(
                f"""
                <script>
                (function(){{
                const b64="{b64}";
                const byteChars=atob(b64);
                const byteNums=new Array(byteChars.length);
                for (let i=0;i<byteChars.length;i++) byteNums[i]=byteChars.charCodeAt(i);
                const blob=new Blob([new Uint8Array(byteNums)],{{type:'application/pdf'}});
                const url=URL.createObjectURL(blob);
                window.open(url,'_blank');
                setTimeout(()=>URL.revokeObjectURL(url),60000);
                }})();
                </script>
                """,
                height=0
            )

    # ======================================================================
    # TAB 2: JETTY METER READING
    # ======================================================================
    with tab2:
        st.subheader("JETTY METER RECORDS")

        with st.container(border=True):
            f_col1, f_col2 = st.columns(2)
            with f_col1:
                jmr_from = st.date_input("From (Jetty Meter)", value=date.today() - timedelta(days=14), key="jmr_from")
            with f_col2:
                jmr_to = st.date_input("To (Jetty Meter)", value=date.today(), key="jmr_to")

        # Fetch meter transactions for active Jetty location within the range
        with get_session() as s:
            try:
                from models import MeterTransaction  # added Meter-2 fields earlier
            except Exception:
                MeterTransaction = None

            entries = []
            if MeterTransaction is not None:
                entries = (
                    s.query(MeterTransaction)
                    .filter(
                        MeterTransaction.location_id == active_location_id,
                        MeterTransaction.date >= jmr_from,
                        MeterTransaction.date <= jmr_to,
                    )
                    .order_by(MeterTransaction.date.asc())
                    .all()
                )

        # Build DataFrame with SHORT column names expected by the PDF
        jmr_cols = [
            "Date",
            "Opening (M1)", "Closing (M1)",
            "Opening (M2)", "Closing (M2)",
            "Net Receipt/Dispatch",
            "Net Tank dispatch",   # NEW
            "Variance",            # NEW
            "Remarks",
        ]

        data_rows = []
        for e in entries:
            try:
                dte = e.date.strftime("%Y-%m-%d") if isinstance(e.date, date) else str(e.date)
            except Exception:
                dte = str(e.date)

            om1 = float(e.opening_meter_reading or 0.0)
            cm1 = float(e.closing_meter_reading or 0.0)
            om2 = float(getattr(e, "opening_meter2_reading", 0.0) or 0.0)
            cm2 = float(getattr(e, "closing_meter2_reading", 0.0) or 0.0)
            net = (cm1 - om1) + (cm2 - om2)

            data_rows.append({
                "Date": dte,
                "Opening (M1)": om1,
                "Closing (M1)": cm1,
                "Opening (M2)": om2,
                "Closing (M2)": cm2,
                "Net Receipt/Dispatch": net,
                "Net Tank dispatch": 0.0,  # will be filled from MB
                "Variance": 0.0,            # will be computed
                "Remarks": e.remarks or "",
            })

        # Ensure columns exist even if no entries
        jmr_df = pd.DataFrame(data_rows, columns=jmr_cols)

        # --- Bring Net Tank dispatch from Material Balance (JETTY) and compute Variance ---
        # Normalize JMR dates and ensure target cols exist
        if not jmr_df.empty:
            jmr_df["Date"] = pd.to_datetime(jmr_df["Date"]).dt.strftime("%Y-%m-%d")
        else:
            jmr_df["Date"] = pd.Series(dtype=str)

        for col in ["Net Tank dispatch", "Variance"]:
            if col not in jmr_df.columns:
                jmr_df[col] = 0.0

        # Pull MB and compute Net Tank dispatch (case-insensitive, robust)
        try:
            mb_rows = MBC.calculate_material_balance(
                None, "JETTY", jmr_from, jmr_to, location_id=loc.id, debug=False
            )
            mb_df = pd.DataFrame(mb_rows)
        except Exception:
            mb_df = pd.DataFrame()

        if not mb_df.empty:
            # Lowercase and trim all MB column names for flexible matching
            mb_df = mb_df.rename(columns=lambda x: str(x).strip().lower())

            # Date normalization
            if "date" in mb_df.columns:
                mb_df["date"] = pd.to_datetime(mb_df["date"]).dt.strftime("%Y-%m-%d")
            else:
                mb_df["date"] = ""  # ensures no matches if MB lacks date

            # Accept variants like "Other Dispatches" vs "Other dispatch"
            if "dispatch to barge" not in mb_df.columns:
                mb_df["dispatch to barge"] = 0.0

            if "other dispatch" not in mb_df.columns:
                if "other dispatches" in mb_df.columns:
                    mb_df["other dispatch"] = mb_df["other dispatches"]
                else:
                    mb_df["other dispatch"] = 0.0

            mb_df["net tank dispatch"] = (
                pd.to_numeric(mb_df["dispatch to barge"], errors="coerce").fillna(0.0) +
                pd.to_numeric(mb_df["other dispatch"], errors="coerce").fillna(0.0)
            )

            # Map by date instead of merge to avoid _x/_y suffixes
            tank_map = mb_df.set_index("date")["net tank dispatch"].to_dict()
            if not jmr_df.empty:
                jmr_df["Net Tank dispatch"] = jmr_df["Date"].map(tank_map).fillna(0.0)

        # Compute Variance safely
        jmr_df["Variance"] = (
            pd.to_numeric(jmr_df["Net Receipt/Dispatch"], errors="coerce").fillna(0.0) -
            pd.to_numeric(jmr_df["Net Tank dispatch"], errors="coerce").fillna(0.0)
        )

        # View table
        if not jmr_df.empty:
            st.dataframe(
                jmr_df,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "Date": st.column_config.TextColumn("Date", width="small"),
                    "Opening (M1)": st.column_config.NumberColumn("Opening (M1)", format="%.2f"),
                    "Closing (M1)": st.column_config.NumberColumn("Closing (M1)", format="%.2f"),
                    "Opening (M2)": st.column_config.NumberColumn("Opening (M2)", format="%.2f"),
                    "Closing (M2)": st.column_config.NumberColumn("Closing (M2)", format="%.2f"),
                    "Net Receipt/Dispatch": st.column_config.NumberColumn("Net Receipt/Dispatch", format="%.2f"),
                    "Net Tank dispatch": st.column_config.NumberColumn("Net Tank dispatch", format="%.2f"),
                    "Variance": st.column_config.NumberColumn("Variance", format="%.2f"),
                    "Remarks": st.column_config.TextColumn("Remarks", width="large"),
                },
            )
        else:
            st.info("No meter transactions found for the selected date range.")

        # ----- Exports -----
        st.markdown("---")
        d_col_a, d_col_b, d_col_c, d_col_d = st.columns(4)

        # CSV
        d_col_a.download_button(
            "📥 Download CSV",
            data=jmr_df.to_csv(index=False).encode("utf-8"),
            file_name=f"jetty_meter_reading_{loc.code}_{str(jmr_from)}_{str(jmr_to)}.csv",
            mime="text/csv",
            key="jmr_csv_dl",
        )

        # XLSX
        _xlsx_io = BytesIO()
        with pd.ExcelWriter(_xlsx_io, engine="xlsxwriter") as writer:
            jmr_df.to_excel(writer, index=False, sheet_name="JettyMeterReading")
        d_col_b.download_button(
            "📥 Download XLSX",
            data=_xlsx_io.getvalue(),
            file_name=f"jetty_meter_reading_{loc.code}_{str(jmr_from)}_{str(jmr_to)}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="jmr_xlsx_dl",
        )

        # PDF helper for Jetty Meter Reading (LANDSCAPE A4)
        def _jmr_pdf_bytes(df: pd.DataFrame) -> bytes:
            # local import to ensure landscape is available even if not imported globally
            from reportlab.lib.pagesizes import A4, landscape

            df = df.copy()

            # numeric safety (works even when df is empty because columns exist)
            for col_name in [
                "Opening (M1)", "Closing (M1)",
                "Opening (M2)", "Closing (M2)",
                "Net Receipt/Dispatch",
                "Net Tank dispatch",  # NEW
                "Variance",           # NEW
            ]:
                if col_name in df.columns:
                    df[col_name] = pd.to_numeric(df[col_name], errors="coerce").fillna(0.0)

            bio = BytesIO()

            # LANDSCAPE sizing
            page_w, _page_h = landscape(A4)
            lm = rm = tm = bm = 0.5 * cm
            avail_w = page_w - lm - rm

            doc = SimpleDocTemplate(
                bio,
                pagesize=landscape(A4),  # <<< LANDSCAPE
                leftMargin=lm,
                rightMargin=rm,
                topMargin=tm,
                bottomMargin=bm,
            )

            styles = getSampleStyleSheet()
            title_style = ParagraphStyle(
                "JMRTitle", parent=styles["Heading1"], fontSize=15,
                alignment=TA_CENTER, textColor=colors.HexColor("#1f4788"),
            )
            sub_style = ParagraphStyle(
                "JMRSub", parent=styles["Normal"], fontSize=10,
                alignment=TA_CENTER, textColor=colors.HexColor("#666666"),
            )

            elements = []
            elements.append(Paragraph("<b>JETTY METER RECORDS</b>", title_style))
            elements.append(
                Paragraph(
                    f"{loc.name} ({loc.code}) � Period: <b>{str(jmr_from)}</b> to <b>{str(jmr_to)}</b>",
                    sub_style,
                )
            )
            elements.append(Spacer(1, 0.3 * cm))

            # Headers including the two new columns
            headers = [
                "Date",
                "Opening (M1)", "Closing (M1)",
                "Opening (M2)", "Closing (M2)",
                "Net Receipt/Dispatch",
                "Net Tank dispatch",   # NEW
                "Variance",            # NEW
                "Remarks",
            ]
            data = [headers]

            for _, row in df.iterrows():
                data.append([
                    str(row.get("Date", "")),
                    f"{float(row.get('Opening (M1)', 0.0)):,.2f}",
                    f"{float(row.get('Closing (M1)', 0.0)):,.2f}",
                    f"{float(row.get('Opening (M2)', 0.0)):,.2f}",
                    f"{float(row.get('Closing (M2)', 0.0)):,.2f}",
                    f"{float(row.get('Net Receipt/Dispatch', 0.0)):,.2f}",
                    f"{float(row.get('Net Tank dispatch', 0.0)):,.2f}",
                    f"{float(row.get('Variance', 0.0)):,.2f}",
                    (str(row.get("Remarks", ""))[:90] if row.get("Remarks") else "-"),
                ])

            # Column widths (remarks wider) - 9 columns total; landscape gives us more room
            weights = [1.0, 0.9, 0.9, 0.9, 0.9, 1.1, 1.1, 1.1, 2.0]
            scale = avail_w / sum(weights)
            col_widths = [w * scale for w in weights]

            table = Table(data, repeatRows=1, colWidths=col_widths)
            table.setStyle(TableStyle([
                ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#1f4788")),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
                ("ALIGN", (0, 0), (-1, -1), "CENTER"),
                ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
                ("FONTSIZE", (0, 0), (-1, 0), 8),
                ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
                ("ROWBACKGROUNDS", (0, 1), (-1, -1), [colors.whitesmoke, colors.HexColor("#f8f9fa")]),
                ("FONTSIZE", (0, 1), (-1, -1), 8),
            ]))

            elements.append(table)
            doc.build(elements)
            return bio.getvalue()

        jmr_pdf_bytes = _jmr_pdf_bytes(jmr_df)

        # PDF Download
        d_col_c.download_button(
            "📥 Download PDF",
            data=jmr_pdf_bytes,
            file_name=f"jetty_meter_reading_{loc.code}_{str(jmr_from)}_{str(jmr_to)}.pdf",
            mime="application/pdf",
            key="jmr_pdf_dl_btn",
        )

        # View PDF
        if d_col_d.button("👁️ View PDF", key="jmr_pdf_view_btn"):
            _b64 = base64.b64encode(jmr_pdf_bytes).decode("utf-8")
            components.html(
                f"""
                <script>
                (function(){{
                const b64="{_b64}";
                const byteChars=atob(b64);
                const byteNums=new Array(byteChars.length);
                for (let i=0;i<byteChars.length;i++) byteNums[i]=byteChars.charCodeAt(i);
                const blob=new Blob([new Uint8Array(byteNums)],{{type:'application/pdf'}});
                const url=URL.createObjectURL(blob);
                window.open(url,'_blank');
                setTimeout(()=>URL.revokeObjectURL(url),60000);
                }})();
                </script>
                """,
                height=0,
            )
    # ======================================================================
    # TAB 3: CONDENSATE RECEIPT
    # ======================================================================
    with tab3:
        st.subheader("CONDENSATE RECEIPT")

        from datetime import date, timedelta
        import pandas as pd
        import io, base64

        display_df = None

        # --- Filters (last 14 days default) ---
        with st.container(border=True):
            c1, c2, c3 = st.columns([1,1,1])
            with c1:
                cr_from = st.date_input("From", value=date.today() - timedelta(days=14), key="cr_from")
            with c2:
                cr_to = st.date_input("To", value=date.today(), key="cr_to")
            with c3:
                search_tid = st.text_input("Ticket Id (optional)", placeholder="e.g. BFS-TIC-...")

        # --- Load saved condensate receipts using shared helper to keep math identical ---
        raw_records, _ = load_condensate_transactions(active_location_id, limit=2000)
        df_raw = pd.DataFrame(raw_records)

        if df_raw.empty:
            st.info("No condensate receipts captured yet for this location.")
        else:
            df_raw["Date"] = pd.to_datetime(df_raw["Date"], errors="coerce")
            filtered = df_raw.dropna(subset=["Date"]).copy()
            filtered_dates = filtered["Date"].dt.date
            date_mask = (filtered_dates >= cr_from) & (filtered_dates <= cr_to)
            filtered = filtered[date_mask]

            if search_tid:
                search_term = search_tid.strip()
                if search_term:
                    filtered = filtered[
                        filtered["Ticket ID"].astype(str).str.contains(search_term, case=False, na=False)
                    ]

            if filtered.empty:
                st.info("No condensate receipts found for the selected range.")
            else:
                filtered = filtered.sort_values("Date", ascending=False)
                filtered["Date"] = filtered["Date"].dt.strftime("%Y-%m-%d")

                rename_map = {
                    "Ticket ID": "Ticket Id",
                    "Opening (m3)": "Opening meter reading",
                    "Closing (m3)": "Closing meter reading",
                    "Net Receipt (m3)": "Qty (m�)",
                    "API @ 60": "API @60°F",
                    "Created By": "Entered By",
                    "Updated By": "Edited By",
                    "Updated At": "Edited At",
                }
                display_df = filtered.rename(columns=rename_map)

                column_order = [
                    "Ticket Id",
                    "Date",
                    "Opening meter reading",
                    "Closing meter reading",
                    "Qty (m�)",
                    "GOV (bbls)",
                    "API @60°F",
                    "VCF",
                    "GSV (bbls)",
                    "LT",
                    "MT",
                ]
                # Ensure all expected columns exist before reordering
                for col in column_order:
                    if col not in display_df.columns:
                        display_df[col] = ""
                display_df = display_df[column_order].reset_index(drop=True)

                # Nice wide table (values already match View Transactions output)
                st.dataframe(display_df, hide_index=True, use_container_width=True)

        # --- Export buttons ---
        exp1, exp2, exp3, exp4 = st.columns([1,1,1,1])

        # CSV
        if display_df is not None and not display_df.empty:
            csv_bytes = display_df.to_csv(index=False).encode("utf-8")
            with exp1:
                st.download_button("Download CSV", data=csv_bytes, file_name="condensate_receipts.csv", mime="text/csv")

            # XLSX
            xbuf = io.BytesIO()
            with pd.ExcelWriter(xbuf, engine="xlsxwriter") as writer:
                display_df.to_excel(writer, index=False, sheet_name="Condensate")
            with exp2:
                st.download_button(
                    "Download XLSX",
                    data=xbuf.getvalue(),
                    file_name="condensate_receipts.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                )

            # PDF (A4 landscape, styled like other reporting tabs)
            def _build_cond_pdf(pdf_df: pd.DataFrame, title_text: str) -> bytes:
                from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
                from reportlab.lib.pagesizes import A4, landscape
                from reportlab.lib.units import cm
                from reportlab.lib import colors
                from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
                from reportlab.lib.enums import TA_CENTER

                df = pdf_df.copy()
                numeric_cols = ["Opening meter reading", "Closing meter reading", "Qty (m�)", "GOV (bbls)", "GSV (bbls)", "LT", "MT", "VCF", "API @60°F"]
                for col in numeric_cols:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0.0)

                totals = {
                    "Qty (m�)": float(df.get("Qty (m�)", pd.Series(dtype=float)).sum()),
                    "GOV (bbls)": float(df.get("GOV (bbls)", pd.Series(dtype=float)).sum()),
                    "GSV (bbls)": float(df.get("GSV (bbls)", pd.Series(dtype=float)).sum()),
                    "LT": float(df.get("LT", pd.Series(dtype=float)).sum()),
                    "MT": float(df.get("MT", pd.Series(dtype=float)).sum()),
                }
                total_row = {
                    "Ticket Id": "",
                    "Date": "TOTAL",
                    "Opening meter reading": "",
                    "Closing meter reading": "",
                    "Qty (m�)": totals["Qty (m�)"],
                    "GOV (bbls)": totals["GOV (bbls)"],
                    "GSV (bbls)": totals["GSV (bbls)"],
                    "API @60°F": "",
                    "VCF": "",
                    "LT": totals["LT"],
                    "MT": totals["MT"],
                }
                df = pd.concat([df, pd.DataFrame([total_row])], ignore_index=True)

                buf = io.BytesIO()
                doc = SimpleDocTemplate(
                    buf,
                    pagesize=landscape(A4),
                    leftMargin=0.5 * cm,
                    rightMargin=0.5 * cm,
                    topMargin=0.5 * cm,
                    bottomMargin=0.5 * cm,
                )
                styles = getSampleStyleSheet()
                title_style = ParagraphStyle(
                    "cond_title",
                    parent=styles["Heading1"],
                    fontSize=15,
                    alignment=TA_CENTER,
                    textColor=colors.HexColor("#1f4788"),
                )
                sub_style = ParagraphStyle(
                    "cond_sub",
                    parent=styles["Normal"],
                    fontSize=10,
                    alignment=TA_CENTER,
                    textColor=colors.HexColor("#666666"),
                )

                story = [
                    Paragraph(f"<b>{title_text}</b>", title_style),
                    Paragraph(
                        f"{loc.name} ({loc.code}) � Period: <b>{cr_from.strftime('%d-%b-%Y')}</b> to <b>{cr_to.strftime('%d-%b-%Y')}</b>",
                        sub_style,
                    ),
                    Paragraph(
                        f"Total GSV (bbls): <b>{totals['GSV (bbls)']:,.2f}</b> � Receipts: <b>{len(pdf_df):,}</b>",
                        sub_style,
                    ),
                        Spacer(1, 0.25 * cm),
                ]

                headers = [
                    "Date",
                    "Ticket Id",
                    "Opening meter reading",
                    "Closing meter reading",
                    "Qty (m�)",
                    "GOV (bbls)",
                    "GSV (bbls)",
                    "API @60°F",
                    "VCF",
                    "LT",
                    "MT",
                ]
                data = [headers]
                for _, row in df.iterrows():
                    is_total = str(row.get("Date", "")).upper() == "TOTAL"
                    data.append([
                        row.get("Date", ""),
                        row.get("Ticket Id", "") if not is_total else "TOTAL",
                        "" if is_total else f"{float(row.get('Opening meter reading') or 0.0):,.3f}",
                        "" if is_total else f"{float(row.get('Closing meter reading') or 0.0):,.3f}",
                        f"{float(row.get('Qty (m�)') or 0.0):,.3f}",
                        f"{float(row.get('GOV (bbls)') or 0.0):,.2f}",
                        f"{float(row.get('GSV (bbls)') or 0.0):,.2f}",
                        "" if is_total else f"{float(row.get('API @60°F') or 0.0):,.2f}",
                        "" if is_total else f"{float(row.get('VCF') or 0.0):,.5f}",
                        f"{float(row.get('LT') or 0.0):,.2f}",
                        f"{float(row.get('MT') or 0.0):,.2f}",
                    ])

                weights = [1.1, 1.4, 1.0, 1.0, 1.0, 0.95, 0.95, 0.8, 0.7, 0.85, 0.85]
                available_width = doc.width
                scale = available_width / sum(weights)
                col_widths = [w * scale for w in weights]

                table = Table(data, colWidths=col_widths, repeatRows=1)
                table.setStyle(TableStyle([
                    ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#1f4788")),
                    ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
                    ("ALIGN", (0, 0), (-1, -1), "CENTER"),
                    ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
                    ("FONTSIZE", (0, 0), (-1, 0), 8),
                    ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
                    ("ROWBACKGROUNDS", (0, 1), (-1, -2), [colors.whitesmoke, colors.HexColor("#f8f9fa")]),
                    ("FONTSIZE", (0, 1), (-1, -1), 8),
                    ("BACKGROUND", (0, -1), (-1, -1), colors.HexColor("#e8eefc")),
                    ("FONTNAME", (0, -1), (-1, -1), "Helvetica-Bold"),
                ]))

                story.append(table)
                doc.build(story)
                return buf.getvalue()

            pdf_source = display_df[[
                "Ticket Id","Date","Opening meter reading","Closing meter reading",
                "Qty (m�)","GOV (bbls)","API @60°F","VCF","GSV (bbls)","LT","MT"
            ]].copy()

            pdf_bytes = _build_cond_pdf(pdf_source, "Condensate Receipts")

            with exp3:
                st.download_button("Download PDF", data=pdf_bytes, file_name="condensate_receipts.pdf", mime="application/pdf")

            # Open PDF in new tab
            with exp4:
                if st.button("👁️ View PDF", key="cond_pdf_view_btn"):
                    b64 = base64.b64encode(pdf_bytes).decode("utf-8")
                    components.html(
                        f"""
                        <script>
                        (function(){{
                            const b64="{b64}";
                            const byteChars=atob(b64);
                            const byteNums=new Array(byteChars.length);
                            for (let i=0;i<byteChars.length;i++) byteNums[i]=byteChars.charCodeAt(i);
                            const blob=new Blob([new Uint8Array(byteNums)],{{type:'application/pdf'}});
                            const url=URL.createObjectURL(blob);
                            window.open(url,'_blank');
                            setTimeout(()=>URL.revokeObjectURL(url),60000);
                        }})();
                        </script>
                        """,
                        height=0,
                    )


    # ======================================================================
    # TAB 4: PRODUCTION
    # ======================================================================
    with tab4:
        st.subheader("Production")
        if not is_beneku_location:
            st.info("Production reporting is only available for Beneku/BFS locations.")
        else:
            default_from = date.today() - timedelta(days=14)
            default_to = date.today()
            with st.container(border=True):
                c1, c2, c3, c4 = st.columns([0.2, 0.2, 0.2, 0.4])
                with c1:
                    gpp_from = st.date_input("From", value=default_from, key="rpt_gpp_from")
                with c2:
                    gpp_to = st.date_input("To", value=default_to, key="rpt_gpp_to")
                with c3:
                    gpp_min_total = st.number_input("Min GPP Total (bbls)", min_value=0.0, step=100.0, key="rpt_gpp_min_total")
                with c4:
                    gpp_search = st.text_input(
                        "Search remarks / user",
                        key="rpt_gpp_search",
                        placeholder="Type any keyword",
                    ).strip().lower()

            gpp_records = load_gpp_production_records(active_location_id, limit=2000)
            gpp_df = pd.DataFrame(gpp_records)
            if not gpp_df.empty:
                gpp_df["Date"] = pd.to_datetime(gpp_df["Date"]).dt.date
                gpp_df["Updated At"] = (
                    pd.to_datetime(gpp_df["Updated At"], errors="coerce")
                    .dt.strftime("%Y-%m-%d %H:%M:%S")
                    .fillna("")
                )

                if gpp_from:
                    gpp_df = gpp_df[gpp_df["Date"] >= gpp_from]
                if gpp_to:
                    gpp_df = gpp_df[gpp_df["Date"] <= gpp_to]
                if gpp_min_total and gpp_min_total > 0:
                    gpp_df = gpp_df[gpp_df["Total GPP Production"] >= gpp_min_total]
                if gpp_search:
                    gpp_df = gpp_df[
                        gpp_df.apply(
                            lambda r: gpp_search in str(r["Remarks"]).lower()
                            or gpp_search in str(r["Created By"]).lower()
                            or gpp_search in str(r["Updated By"]).lower(),
                            axis=1,
                        )
                    ]

            st.caption(f"{len(gpp_df)} record(s) found")
            gpp_display_cols = [
                "Date",
                "OKW Production",
                "GPP1 Production",
                "GPP2 Production",
                "GPP Closing Stock",
                "Total GPP Production",
                "Remarks",
                "Created By",
                "Updated By",
                "Updated At",
            ]

            if gpp_df.empty:
                st.info("No production records match the selected filters.")
            else:
                gpp_display_df = gpp_df[gpp_display_cols].sort_values(by="Date", ascending=False)
                st.dataframe(gpp_display_df, use_container_width=True, hide_index=True)

                total_okw = gpp_display_df["OKW Production"].sum()
                total_gpp = gpp_display_df["Total GPP Production"].sum()
                met_okw, met_gpp = st.columns(2)
                met_okw.metric("Total OKW Production", f"{total_okw:,.2f} bbls")
                met_gpp.metric("Total GPP Production", f"{total_gpp:,.2f} bbls")

                csv_bytes = gpp_display_df.to_csv(index=False).encode("utf-8")
                xlsx_buffer = BytesIO()
                with pd.ExcelWriter(xlsx_buffer, engine="xlsxwriter") as writer:
                    gpp_display_df.to_excel(writer, sheet_name="Production", index=False)
                pdf_bytes = _generate_production_pdf(
                    gpp_display_df,
                    loc.name,
                    loc.code,
                    gpp_from or gpp_display_df["Date"].min(),
                    gpp_to or gpp_display_df["Date"].max(),
                )

                exp_csv, exp_xlsx, exp_pdf, exp_view = st.columns(4)
                exp_csv.download_button(
                    "Download CSV",
                    data=csv_bytes,
                    file_name="production.csv",
                    mime="text/csv",
                )
                exp_xlsx.download_button(
                    "Download XLSX",
                    data=xlsx_buffer.getvalue(),
                    file_name="production.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                )
                exp_pdf.download_button(
                    "Download PDF",
                    data=pdf_bytes,
                    file_name="production.pdf",
                    mime="application/pdf",
                )
                if exp_view.button("View PDF"):
                    try:
                        base64_pdf = base64.b64encode(pdf_bytes).decode("utf-8")
                        pdf_html = f"""
                            <script>
                                var pdfWindow = window.open("");
                                pdfWindow.document.write(
                                    '<html><head><title>Production Report</title></head>' +
                                    '<body style="margin:0"><iframe width="100%" height="100%" src="data:application/pdf;base64,{base64_pdf}"></iframe></body></html>'
                                );
                            </script>
                        """
                        components.html(pdf_html, height=0)
                        st.success("PDF opened in new tab!")
                    except Exception as ex:
                        st.error(f"Unable to open PDF: {ex}")


    # Simple demo supervisor code (replace with env/real auth later)
# -------------------- STEP 2: Compute TOA for a YADE Voyage --------------------
from typing import Dict, Tuple, Optional

def _nearest_table11_lt(api60: float, s) -> float:
    """Return the lt_factor from Table11 for nearest api60 (simple nearest-neighbor)."""
    from models import Table11
    rows = s.query(Table11).all()
    if not rows:
        return 0.0
    # choose the row with minimum |api - api60|
    best = min(rows, key=lambda r: abs((r.api60 or 0.0) - (api60 or 0.0)))
    return float(best.lt_factor or 0.0)

def _yade_vol_from_mm(yade_name: str, tank_id: str, dip_mm: float, s) -> float:
    """
    Resolve volume (bbl) from YADE calibration table for a (possibly fractional) dip in mm.
    Your table stores rows at integer dip_mm with per-mm increments (mm1..mm9) from that base.
    We assume base rows are every 10 mm (0,10,20,...) but function works even if every 1 mm exists.

    Algorithm:
      1) base = floor(dip_mm)
      2) Find the row with dip_mm == (base - base % 10)  (i.e., decade base like 530 -> 530)
      3) Add mm1..mmK for the integer remainder (K = base % 10)
      4) If fractional remains (e.g., 0.6 mm), add K+1 increment * 0.6
    """
    from models import YadeCalibration
    if dip_mm is None or dip_mm < 0:
        return 0.0

    # if exact integer row exists (and you want the exact value), we still use the decade system
    # to utilize per-mm increments consistently.
    base_decade = int(dip_mm) - (int(dip_mm) % 10)
    rem_int = int(dip_mm) - base_decade                  # 0..9
    rem_frac = float(dip_mm) - int(dip_mm)               # 0..<1

    row = (s.query(YadeCalibration)
             .filter(YadeCalibration.yade_name == yade_name,
                     YadeCalibration.tank_id == tank_id,
                     YadeCalibration.dip_mm == base_decade)
             .one_or_none())
    if not row:
        # Linear interpolation between closest two points
        rows = (s.query(YadeCalibration)
                .filter(YadeCalibration.yade_name == yade_name,
                        YadeCalibration.tank_id == tank_id)
                .order_by(YadeCalibration.dip_mm.asc())
                .all())
        if not rows:
            return 0.0
        xs = [float(r.dip_mm or 0.0) for r in rows]
        ys = [float(r.vol_bbl or 0.0) for r in rows]
        x = float(dip_mm)
        if x <= xs[0]:
            return ys[0]
        if x >= xs[-1]:
            return ys[-1]
        import bisect
        i = bisect.bisect_left(xs, x)
        x1, y1 = xs[i-1], ys[i-1]
        x2, y2 = xs[i], ys[i]
        if x2 == x1:
            return y1
        t = (x - x1) / (x2 - x1)
        return y1 + t * (y2 - y1)

    vol = float(row.vol_bbl or 0.0)

    # Add whole-mm increments (mm1..mmK)
    def inc_of(row, k: int) -> float:
        if k == 0: return 0.0
        return float(getattr(row, f"mm{k}", 0.0) or 0.0)

    for k in range(1, rem_int + 1):
        vol += inc_of(row, k)

    # Add fractional part using next mm increment (mmK+1)
    if rem_frac > 0:
        next_k = min(rem_int + 1, 9)  # mm9 is last available
        vol += inc_of(row, next_k) * rem_frac

    return vol

def _tank_stage_volumes(yade_name: str, tank_id: str, total_cm: float, water_cm: float, s) -> tuple[float, float, float]:
    """
    Return (TOV, FW, GOV) using the unified YADE interpolator.
    """
    tov = _yade_cal_vol_bbl(s, yade_name, tank_id, float(total_cm or 0.0))
    fw  = _yade_cal_vol_bbl(s, yade_name, tank_id, float(water_cm or 0.0)) if float(water_cm or 0.0) > 0 else 0.0
    gov = max(tov - fw, 0.0)
    return (tov, fw, gov)

def _read_sample_params(voyage_id: int, s) -> Dict[str, Dict[str, float]]:
    """
    Read YadeSampleParam rows into a dict:
      {"before": {"api60", "bsw_pct", "vcf", "lt", "ccf"}, "after": {...}}

    Baby-step (for now):
      - api60 from observed API (or derived from density) without full temp correction.
      - vcf  = 1.0000 (placeholder; you can wire your real VCF later).
      - lt   = nearest Table 11 LT factor by api60.
      - ccf  = stored correction factor (default 1.0).
    """
    from models import YadeSampleParam
    out = {"before": {}, "after": {}}
    for stage in ("before", "after"):
        rec = (s.query(YadeSampleParam)
                 .filter(YadeSampleParam.voyage_id == voyage_id,
                         YadeSampleParam.stage == stage)
                 .one_or_none())
        if not rec:
            out[stage] = {"api60": 0.0, "bsw_pct": 0.0, "vcf": 1.0, "lt": 0.0, "ccf": 1.0}
            continue

        # Observed ? API60 (baby step)
        if (rec.obs_mode or "").lower().startswith("observed api"):
            api60 = float(rec.obs_val or 0.0)
        else:
            # observed density to API60 (baby step without temp correction)
            wat60 = 999.012  # kg/m3
            den = float(rec.obs_val or 0.0)
            sg = den / wat60 if den > 0 else 0.0
            api60 = (141.5 / sg - 131.5) if sg > 0 else 0.0

        lt = _nearest_table11_lt(api60, s)
        out[stage] = {
            "api60": float(round(api60, 2)),
            "bsw_pct": float(rec.bsw_pct or 0.0),
            "vcf": 1.0,                         # placeholder (wire real VCF later)
            "lt": float(lt or 0.0),
            "ccf": max(float(rec.ccf or 1.0), 0.000001),  # never zero
        }
    return out


def compute_toa_for_voyage(voyage_id: int) -> Dict[str, float]:
    """
    Compute & persist TOA numbers (Before/After + Loaded/Unloaded) for a voyage.
    Returns a small dict summary you can show in the UI.
    """
    from models import (
        YadeVoyage, YadeDip,
        TOAYadeStage, TOAYadeSummary
    )

    with get_session() as s:
        v = s.query(YadeVoyage).filter(YadeVoyage.id == voyage_id).one_or_none()
        if not v:
            return {"error": "Voyage not found."}

        dips = s.query(YadeDip).filter(YadeDip.voyage_id == voyage_id).all()
        sp = _read_sample_params(voyage_id, s)

        # Aggregate per stage
        agg = {
            "before": {"tov": 0.0, "fw": 0.0, "gov": 0.0},
            "after":  {"tov": 0.0, "fw": 0.0, "gov": 0.0},
        }
        for d in dips:
            (tov, fw, gov) = _tank_stage_volumes(v.yade_name, d.tank_id, d.total_cm, d.water_cm, s)
            stage = (d.stage or "").lower()
            if stage in agg:
                agg[stage]["tov"] += tov
                agg[stage]["fw"]  += fw
                agg[stage]["gov"] += gov

        # Stage calcs with sample params (apply CCF before VCF)
        stage_rows = {}
        for stage in ("before", "after"):
            # Raw aggregates (sum of tanks)
            raw_tov = agg[stage]["tov"]
            raw_fw  = agg[stage]["fw"]

            # Sample parameters (api60, vcf placeholder, lt, bsw, ccf)
            api60    = sp[stage]["api60"]
            vcf      = sp[stage]["vcf"]          # 1.0 for now (wire your real VCF later)
            lt       = sp[stage]["lt"]
            bsw_pct  = sp[stage]["bsw_pct"]
            ccf      = sp[stage]["ccf"]

            # Apply correction factor to volumes BEFORE VCF
            adj_tov = raw_tov * ccf
            adj_fw  = raw_fw  * ccf
            gov     = max(adj_tov - adj_fw, 0.0)

            # Then apply VCF to get GSV
            gsv = gov * vcf

            # BS&W and NSV
            bsw_bbl = gov * (bsw_pct / 100.0)
            nsv     = gsv - bsw_bbl

            # Metric tons (using LT from Table 11)
            mt = nsv * lt

            stage_rows[stage] = {
                "gov_bbl": round(gov, 2),
                "gsv_bbl": round(gsv, 2),
                "bsw_pct": round(bsw_pct, 3),
                "bsw_bbl": round(bsw_bbl, 2),
                "nsv_bbl": round(nsv, 2),
                "lt": round(lt, 6),
                "mt": round(mt, 3),
                "fw_bbl": round(adj_fw, 2),  # store the CCF-adjusted FW
            }


        # Persist TOAYadeStage (upsert)
        for stage in ("before", "after"):
            row = (s.query(TOAYadeStage)
                    .filter(TOAYadeStage.voyage_id == voyage_id,
                            TOAYadeStage.stage == stage)
                    .one_or_none())
            vals = stage_rows[stage]
            if row is None:
                row = TOAYadeStage(voyage_id=voyage_id, stage=stage)
                s.add(row)
            row.gov_bbl = vals["gov_bbl"]
            row.gsv_bbl = vals["gsv_bbl"]
            row.bsw_pct = vals["bsw_pct"]
            row.bsw_bbl = vals["bsw_bbl"]
            row.nsv_bbl = vals["nsv_bbl"]
            row.lt      = vals["lt"]
            row.mt      = vals["mt"]
            row.fw_bbl  = vals["fw_bbl"]

        # Summary (for viewer header)
        gsv_before = stage_rows["before"]["gsv_bbl"]
        gsv_after  = stage_rows["after"]["gsv_bbl"]
        gsv_loaded = round(gsv_after - gsv_before, 2)

        summ = (s.query(TOAYadeSummary)
                 .filter(TOAYadeSummary.voyage_id == voyage_id)
                 .one_or_none())
        if summ is None:
            summ = TOAYadeSummary(voyage_id=voyage_id)
            s.add(summ)

        summ.date          = v.date
        summ.time          = v.time
        summ.yade_name     = v.yade_name
        summ.convoy_no     = v.convoy_no
        summ.destination   = getattr(v.destination, "value", str(v.destination))
        summ.loading_berth = getattr(v.loading_berth, "value", str(v.loading_berth))
        summ.gsv_before_bbl = gsv_before
        summ.gsv_after_bbl  = gsv_after
        summ.gsv_loaded_bbl = gsv_loaded

        s.commit()

        return {
            "gov_before": stage_rows["before"]["gov_bbl"],
            "gov_after":  stage_rows["after"]["gov_bbl"],
            "gsv_before": gsv_before,
            "gsv_after":  gsv_after,
            "gsv_loaded": gsv_loaded,
            "nsv_before": stage_rows["before"]["nsv_bbl"],
            "nsv_after":  stage_rows["after"]["nsv_bbl"],
            "mt_before":  stage_rows["before"]["mt"],
            "mt_after":   stage_rows["after"]["mt"],
        }
    
# ========================= YADE / TOA COMPUTE HELPERS =========================
from typing import Dict, Tuple, List, Optional
import math
import bisect

WAT60_YADE = 999.012  # keep consistent with your Excel

def _yade_cal_vol_bbl(sess, yade_name: str, tank_id: str, dip_cm: float) -> float:
    """
    UNIFIED: Resolve volume (bbl) from YADE calibration for any cm (with mm + fractional mm).
    Uses decade base rows (�0 mm) plus per-mm increments mm1..mm9.
    Falls back to linear interpolation across all dip_mm points if the exact decade base is missing.
    """
    from models import YadeCalibration
    if dip_cm is None or dip_cm < 0:
        return 0.0

    # Convert cm -> mm with fractional precision, then split into:
    # base_decade (�0), remainder integer mm (0..9), and fractional remainder (<1 mm)
    dip_mm = float(dip_cm) * 10.0
    base_decade = int(dip_mm) - (int(dip_mm) % 10)             # e.g., 123.6 -> 120
    rem_total   = dip_mm - base_decade                          # e.g., 3.6
    rem_int     = int(rem_total)                                # 0..9 (e.g., 3)
    rem_frac    = float(rem_total - rem_int)                    # 0..<1 (e.g., 0.6)

    # Try the decade row first
    base = (sess.query(YadeCalibration)
            .filter(YadeCalibration.yade_name == yade_name,
                    YadeCalibration.tank_id   == tank_id,
                    YadeCalibration.dip_mm    == base_decade)
            .one_or_none())

    if base is not None:
        vol = float(base.vol_bbl or 0.0)

        # Add whole-mm increments mm1..mm(rem_int)
        for k in range(1, rem_int + 1):
            inc = getattr(base, f"mm{k}", None)
            vol += float(inc or 0.0)

        # Add the fractional part using the next increment (mm(rem_int+1)), capped at mm9
        if rem_frac > 0:
            next_k = min(rem_int + 1, 9)
            inc = getattr(base, f"mm{next_k}", None)
            vol += float(inc or 0.0) * rem_frac

        return vol

    # Fallback: linear interpolation across all available dip_mm rows for this tank
    rows = (sess.query(YadeCalibration)
            .filter(YadeCalibration.yade_name == yade_name,
                    YadeCalibration.tank_id   == tank_id)
            .order_by(YadeCalibration.dip_mm.asc())
            .all())
    if not rows:
        return 0.0

    xs = [float(r.dip_mm or 0.0) for r in rows]  # in mm
    ys = [float(r.vol_bbl or 0.0) for r in rows]
    x  = float(dip_mm)

    if x <= xs[0]:
        return ys[0]
    if x >= xs[-1]:
        return ys[-1]

    import bisect
    i = bisect.bisect_left(xs, x)
    x1, y1 = xs[i-1], ys[i-1]
    x2, y2 = xs[i],   ys[i]
    if x2 == x1:
        return y1
    t = (x - x1) / (x2 - x1)
    return y1 + t * (y2 - y1)


def _api60_from_obs(api_or_dens_mode: str, obs_val: float, sample_temp: float, sample_unit: str) -> float:
    """
    Convert observed API or Density (@ sample temp) to API@60.
    - API path operates in °F
    - Density path operates in °C
    """
    import math
    WAT60_YADE = 999.012
    
    try:
        if (api_or_dens_mode or "").lower().startswith("observed api"):
            # API path (unchanged - already correct)
            tf = sample_temp if sample_unit == "°F" else round((sample_temp * 1.8) + 32.0, 1)
            temp_diff = tf - 60.0
            rho_obs = (141.5 * WAT60_YADE / (131.5 + obs_val)) * \
                      ((1 - 0.00001278 * temp_diff) - (0.0000000062 * temp_diff * temp_diff))
            rho = rho_obs
            for _ in range(10):
                alfa = 341.0957 / (rho * rho)
                vcf  = math.exp(-alfa * temp_diff - 0.8 * alfa * alfa * temp_diff * temp_diff)
                rho  = rho_obs / vcf
            api60 = 141.5 * WAT60_YADE / rho - 131.5
            return round(api60, 2)
        else:
            # Density path (CORRECTED)
            tc = sample_temp if sample_unit == "°C" else round((sample_temp - 32.0) / 1.8, 1)
            temp_diff = tc - 15.0
            
            # Hydrometer correction
            hyc = 1.0 - 0.000023 * temp_diff - 0.00000002 * temp_diff * temp_diff
            rho_obs_corrected = obs_val * hyc
            
            # Initial density at 15°C
            rho15 = rho_obs_corrected
            
            # Iterative VCF calculation (17 iterations)
            for _ in range(17):
                # Thermal expansion coefficient K
                K = 613.9723 / (rho15 * rho15)
                
                # VCF calculation (temperature-based)
                vcf = math.exp(-K * temp_diff * (1.0 + 0.8 * K * temp_diff))
                
                # Update density at 15°C
                rho15 = rho_obs_corrected / vcf
            
            # Convert density at 15°C to API@60°F
            sg60 = rho15 / WAT60_YADE
            if sg60 <= 0:
                return 0.0
            
            api60 = 141.5 / sg60 - 131.5
            return round(api60, 2)
            
    except Exception:
        return 0.0


def _vcf_from_api60_and_tank_temp(api60: float, tank_temp: float, tank_temp_unit: str, input_mode: str = "api") -> float:
    """
    Calculate VCF for YADE (supports both API and Density paths).
    Uses the unified vcf_from_api60_and_temp function.
    """
    return vcf_from_api60_and_temp(api60, tank_temp, tank_temp_unit, input_mode)


def _lt_from_table11(sess, api60: float) -> float:
    """Nearest/linear from ASTM Table 11 to LT factor."""
    from models import Table11
    if api60 <= 0:
        return 0.0
    rows = sess.query(Table11).order_by(Table11.api60.asc()).all()
    if not rows:
        return 0.0
    xs = [r.api60 for r in rows]
    ys = [r.lt_factor for r in rows]
    x  = api60
    if x <= xs[0]:  return float(ys[0] or 0.0)
    if x >= xs[-1]: return float(ys[-1] or 0.0)
    i  = bisect.bisect_left(xs, x)
    x1, y1 = xs[i-1], ys[i-1]
    x2, y2 = xs[i],   ys[i]
    if x2 == x1:
        return float(y1 or 0.0)
    t = (x - x1)/(x2 - x1)
    return float((y1 or 0.0) + t * ((y2 or 0.0) - (y1 or 0.0)))


def _compute_stage_totals(sess, yade_name: str, stage: str, tank_ids: List[str], dips_by_key: dict, sp: dict) -> Dict[str, float]:
    """
    For one stage ("before"/"after"):
      1) Interp per-tank TOV & FW from calibration
      2) Apply CCF to both: TOVc = TOV*CCF, FWc = FW*CCF
      3) GOV = TOVc - FWc
      4) API60 from observed, VCF from API60 & tank temp
      5) GSV = GOV * VCF
      6) BS&W% ? BS&W bbl; NSV = GSV - BS&W
      7) LT from Table 11; MT = NSV * LT
    """
    # sum TOV/FW from all tanks
    TOV, FW = 0.0, 0.0
    for tid in tank_ids:
        tot_cm = float(dips_by_key.get(f"{stage}_total_{tid}", 0.0) or 0.0)
        wat_cm = float(dips_by_key.get(f"{stage}_water_{tid}", 0.0) or 0.0)
        TOV += _yade_cal_vol_bbl(sess, yade_name, tid, tot_cm)
        if wat_cm > 0:
            FW  += _yade_cal_vol_bbl(sess, yade_name, tid, wat_cm)



    ccf     = max(float(sp.get("ccf") or 1.0), 0.000001)
    bsw_pct = float(sp.get("bsw_pct") or 0.0)

    # your rule: apply CCF to both before VCF
    TOV_c = TOV * ccf
    FW_c  = FW  * ccf
    GOV   = max(TOV_c - FW_c, 0.0)

    api60 = _api60_from_obs(
        sp.get("obs_mode") or "Observed API",
        float(sp.get("obs_val") or 0.0),
        float(sp.get("sample_temp") or 0.0),
        str(sp.get("sample_unit") or "°F"),
    )
    # Determine input mode from sample params
    # Calculate VCF (determine input mode based on obs_mode)
    input_mode = "density" if obs_mode == "Observed Density" else "api"
    vcf_val = vcf_from_api60_and_temp(api60, tank_temp_val, tank_temp_unit, input_mode)

    GSV     = GOV * vcf
    bsw_bbl = GSV * (bsw_pct / 100.0)
    NSV     = max(GSV - bsw_bbl, 0.0)
    LT      = _lt_from_table11(sess, api60)
    MT      = NSV * LT

    return dict(
        gov_bbl=GOV, gsv_bbl=GSV, bsw_pct=bsw_pct, bsw_bbl=bsw_bbl,
        nsv_bbl=NSV, lt=LT, mt=MT, fw_bbl=FW_c
    )
def _kind_text(x: object) -> str:
    """
    Normalize enums/enum-like strings to plain human text.
    Works for real enums, or strings like 'CargoKind.OKWUIBOME_CRUDE'.
    """
    if x is None:
        return ""
    # if it's a real Enum
    val = getattr(x, "value", None)
    if isinstance(val, str):
        return val
    # if it's already a plain string or an 'EnumClass.MEMBER' string
    s = str(x)
    if "." in s:  # e.g. 'CargoKind.OKWUIBOME_CRUDE'
        s = s.split(".", 1)[1]
    s = s.replace("_", " ").title()
    # fix casing for proper names you care about
    s = s.replace("Okwuibome", "Okwuibome")
    s = s.replace("Asemoku", "Asemoku")
    s = s.replace("Ndoni", "Ndoni")
    return s


def compute_and_upsert_toa_for_voyage(sess, voyage_id: int, yade_name: str, tank_ids: List[str]) -> None:
    """
    Load dips + sample params, compute stage totals, and upsert:
      - TOAYadeStage rows for 'before' + 'after'
      - TOAYadeSummary row (gsv_before, gsv_after, loaded)
    """
    from models import (YadeDip, YadeSampleParam, TOAYadeStage, TOAYadeSummary, YadeVoyage)

    v = sess.query(YadeVoyage).filter(YadeVoyage.id == voyage_id).one_or_none()
    if not v:
        return

    # dips ? quick lookup
    dips = sess.query(YadeDip).filter(YadeDip.voyage_id == voyage_id).all()
    dips_by_key = {}
    for d in dips:
        k1 = f"{(d.stage or '').lower()}_total_{d.tank_id}"
        k2 = f"{(d.stage or '').lower()}_water_{d.tank_id}"
        dips_by_key[k1] = float(d.total_cm or 0.0)
        dips_by_key[k2] = float(d.water_cm or 0.0)

    # sample params ? dicts
    sp_before = sess.query(YadeSampleParam).filter(
        YadeSampleParam.voyage_id == voyage_id, YadeSampleParam.stage == "before"
    ).one_or_none()
    sp_after = sess.query(YadeSampleParam).filter(
        YadeSampleParam.voyage_id == voyage_id, YadeSampleParam.stage == "after"
    ).one_or_none()

    def _spdict(sp):
        if not sp:
            return dict(obs_mode="Observed API", obs_val=0.0, sample_unit="°F",
                        sample_temp=0.0, tank_temp=0.0, ccf=1.0, bsw_pct=0.0)
        return dict(
            obs_mode=sp.obs_mode, obs_val=sp.obs_val, sample_unit=sp.sample_unit,
            sample_temp=sp.sample_temp, tank_temp=sp.tank_temp, ccf=sp.ccf, bsw_pct=sp.bsw_pct
        )

    before_vals = _compute_stage_totals(sess, yade_name, "before", tank_ids, dips_by_key, _spdict(sp_before))
    after_vals  = _compute_stage_totals(sess, yade_name, "after",  tank_ids, dips_by_key, _spdict(sp_after))

    # upsert stage rows
    def _upsert_stage(stage: str, vals: dict):
        row = (sess.query(TOAYadeStage)
               .filter(TOAYadeStage.voyage_id == voyage_id, TOAYadeStage.stage == stage)
               .one_or_none())
        if row is None:
            row = TOAYadeStage(voyage_id=voyage_id, stage=stage)
            sess.add(row)
        row.gov_bbl = round(vals["gov_bbl"], 2)
        row.gsv_bbl = round(vals["gsv_bbl"], 2)
        row.bsw_pct = round(vals["bsw_pct"], 3)
        row.bsw_bbl = round(vals["bsw_bbl"], 2)
        row.nsv_bbl = round(vals["nsv_bbl"], 2)
        row.lt      = round(vals["lt"], 6)
        row.mt      = round(vals["mt"], 3)
        row.fw_bbl  = round(vals["fw_bbl"], 2)

    _upsert_stage("before", before_vals)
    _upsert_stage("after",  after_vals)

    # upsert summary (IMPORTANT: store strings, not enums)
    summ = sess.query(TOAYadeSummary).filter(TOAYadeSummary.voyage_id == voyage_id).one_or_none()
    if summ is None:
        summ = TOAYadeSummary(voyage_id=voyage_id)
        sess.add(summ)

    # If these are enums in your YadeVoyage, coerce to .value; if already str, this still works.
    dest_val  = getattr(v.destination, "value", str(v.destination))
    berth_val = getattr(v.loading_berth, "value", str(v.loading_berth))

    summ.date            = v.date
    summ.time            = v.time
    summ.yade_name       = v.yade_name
    summ.convoy_no       = v.convoy_no
    summ.destination   = _kind_text(v.destination)
    summ.loading_berth = _kind_text(v.loading_berth)
    summ.gsv_before_bbl  = round(before_vals["gsv_bbl"], 2)
    summ.gsv_after_bbl   = round(after_vals["gsv_bbl"],  2)
    summ.gsv_loaded_bbl  = round(after_vals["gsv_bbl"] - before_vals["gsv_bbl"], 2)
# ====================== END YADE / TOA COMPUTE HELPERS ======================

# -------- YADE Tracking helpers --------
_YADE_TRACKING_TARGETS = {
    "ASEMOKU": {
        "label": "Asemoku Jetty",
        "tokens": {"ASEMOKU", "ASEMOKUJETTY", "JETTY"},
    },
    "NDONI": {
        "label": "Ndoni",
        "tokens": {"NDONI"},
    },
    "AGGE": {
        "label": "Agge",
        "tokens": {"AGGE"},
    },
}


def _canonical_location_tokens(value: str | None) -> set[str]:
    """Normalize a location name/code into comparable tokens."""
    tokens: set[str] = set()
    if value is None:
        return tokens
    try:
        raw = str(value).strip().upper()
    except Exception:
        return tokens
    if not raw:
        return tokens
    cleaned = raw.replace(".", "")
    variants = {
        cleaned,
        cleaned.replace(" ", ""),
        cleaned.replace("-", ""),
        cleaned.replace("_", ""),
    }
    variants.add(cleaned.replace("JETTY", "").strip())
    tokens.update({v for v in variants if v})
    return tokens


def _resolve_yade_tracking_locations(session) -> Dict[str, Optional[Dict[str, Any]]]:
    """Return database metadata for the locations we need to stitch together."""
    from models import Location

    matches: Dict[str, Optional[Dict[str, Any]]] = {k: None for k in _YADE_TRACKING_TARGETS}
    try:
        all_locations = session.query(Location).all()
    except Exception:
        return matches

    for loc in all_locations:
        loc_tokens = _canonical_location_tokens(loc.code)
        loc_tokens.update(_canonical_location_tokens(loc.name))
        if not loc_tokens:
            continue
        for key, meta in _YADE_TRACKING_TARGETS.items():
            if matches[key]:
                continue
            if loc_tokens & meta["tokens"]:
                matches[key] = {"id": loc.id, "name": loc.name, "code": loc.code}
    return matches


def _load_yade_tracking_rows(session, location_ids: List[int]) -> List[Dict[str, Any]]:
    """Load voyage rows + NSV quantities for the supplied locations."""
    if not location_ids:
        return []
    voyages = (
        session.query(YadeVoyage)
        .filter(YadeVoyage.location_id.in_(location_ids))
        .order_by(YadeVoyage.date.desc(), YadeVoyage.time.desc())
        .all()
    )
    if not voyages:
        return []
    voyage_ids = [v.id for v in voyages]
    stage_rows = session.query(TOAYadeStage).filter(TOAYadeStage.voyage_id.in_(voyage_ids)).all()
    stage_map: Dict[int, Dict[str, TOAYadeStage]] = {}
    for stage_row in stage_rows:
        stage_key = (stage_row.stage or "").strip().lower()
        stage_map.setdefault(stage_row.voyage_id, {})[stage_key] = stage_row

    def _stage_nsv(stage_obj: Optional[TOAYadeStage]) -> Optional[float]:
        if not stage_obj:
            return None
        try:
            return round(float(getattr(stage_obj, "nsv_bbl", 0.0) or 0.0), 2)
        except Exception:
            return None

    rows: List[Dict[str, Any]] = []
    for voyage in voyages:
        per_stage = stage_map.get(voyage.id, {})
        loading_berth = voyage.loading_berth
        if hasattr(loading_berth, "value"):
            loading_berth = loading_berth.value
        rows.append(
            {
                "Date": voyage.date,
                "Convoy No": voyage.convoy_no or "",
                "Yade No": voyage.yade_name or "",
                "ROB qty": _stage_nsv(per_stage.get("before")),
                "TOB qty": _stage_nsv(per_stage.get("after")),
                "Loading berth": loading_berth or "",
                "_location_id": voyage.location_id,
                "_voyage_id": voyage.id,
            }
        )
    return rows


# -------- App setup --------
st.set_page_config(page_title="OTMS", page_icon="🛢️", layout="wide")

# ==== Brand UI (visual-only) ====
BRAND_CSS = """
<style>
/* Page */
.block-container { padding-top: 1.2rem; }
header[data-testid="stHeader"] { background: transparent; }

/* Buttons � global polish */
.stButton > button {
  border-radius: 14px !important;
  padding: .6rem 1.0rem !important;
  font-weight: 600 !important;
  box-shadow: 0 6px 16px rgba(0,0,0,.08) !important;
  border: 1px solid rgba(0,0,0,.08) !important;
  transition: transform .06s ease, box-shadow .2s ease, background .2s ease !important;
}
.stButton > button:hover { transform: translateY(-1px); box-shadow: 0 10px 24px rgba(0,0,0,.12) !important; }
.stButton > button:active { transform: translateY(0); }

/* Primary buttons look */
div[data-testid="stButton"] button[kind="primary"],
.stButton > button[kind="primary"] {
  background: linear-gradient(180deg, #2563eb 0%, #1d4ed8 100%) !important;
  color: #fff !important;
  border: 0 !important;
}

/* Secondary buttons */
.stButton > button:not([kind="primary"]) {
  background: #ffffff !important;
}

/* �Danger� flavor when the label includes specific glyphs */
.stButton:has(button:contains("✏️")) > button,
.stButton:has(button:contains("🗑️")) > button {
  background: linear-gradient(180deg, #ef4444 0%, #dc2626 100%) !important;
  color: #fff !important;
  border: 0 !important;
}

/* Sidebar active button (disabled used as active) */
section[data-testid="stSidebar"] .stButton > button[disabled] {
  background: linear-gradient(180deg, #0ea5e9 0%, #0284c7 100%) !important;
  color: #ffffff !important;
  opacity: 1 !important;
}

/* Inputs */
input, textarea, select, .stNumberInput input, .stTextInput input {
  border-radius: 12px !important;
}

/* Alerts */
div[data-testid="stAlert"] { border-radius: 16px !important; }

/* Images */
img { border-radius: 14px; }
</style>
"""
try:
    import streamlit as st  # ensure st exists in this scope
    st.markdown(BRAND_CSS, unsafe_allow_html=True)
    st.markdown("<style>body{--brand:#2563eb}</style>", unsafe_allow_html=True)
except Exception:
    pass
# ==== /Brand UI ====

# ==== Optional Glass Card CSS (visual only) ====
GLASS = """
<style>
.card-glass {
  background: rgba(255,255,255,.65);
  backdrop-filter: blur(10px);
  border: 1px solid rgba(255,255,255,.5);
  border-radius: 18px;
  padding: 1rem 1.25rem;
  box-shadow: 0 10px 30px rgba(0,0,0,.08);
}
@media (prefers-color-scheme: dark) {
  .card-glass { background: rgba(17,25,40,.45); border-color: rgba(255,255,255,.08); }
}
</style>
"""
try:
    st.markdown(GLASS, unsafe_allow_html=True)
except Exception:
    pass
# ==== /Glass Card CSS ====



init_db()

# -------- Session defaults --------
if "auth_user" not in st.session_state:
    st.session_state.auth_user = None  # {"username": "...", "role": "admin"|"user"}

if "calib_preview" not in st.session_state:
    st.session_state.calib_preview = None

# -------- Unified Sidebar (logo + icon buttons) --------
from pathlib import Path

# Resolve logo gracefully
LOGOS_DIR = Path("assets") / "logos"
_logo_candidates = [
    LOGOS_DIR / "company_logo.png",
    LOGOS_DIR / "company.png",
    LOGOS_DIR / "logo.png",
    Path("assets") / "logo.png",
]
_sidebar_logo = next((p for p in _logo_candidates if p.exists()), None)

user = st.session_state.get("auth_user")
location_id = st.session_state.get("active_location_id")

# ========== DYNAMIC PAGES BASED ON PERMISSIONS ==========
if user is None:
    pages = ["Home"]
else:
    # Get available pages based on role and location permissions
    from permission_manager import PermissionManager
    
    base_pages = ["Home"]
    
    # Get user role early for page visibility checks
    user_role = (user.get("role") or "").lower()
    
    # ========== TRANSACTION PAGES - ALWAYS SHOW IN SIDEBAR ==========
    # Permission check happens when user CLICKS the page, not in sidebar
    # Admin-IT cannot access operational pages
    if user_role != "admin-it":
        base_pages.extend([
            "Tank Transactions",
            "Yade Transactions",
            "Tanker Transactions",
            "View Transactions",
            "Yade Tracking",
            ])
        
    # Conditionally expose special pages
    allowed_mapping_page = False
    allowed_convoy_page = False
    _active_loc_name_norm = ""
    if location_id:
        try:
            from location_manager import LocationManager

            with get_session() as _s:
                _loc = LocationManager.get_location_by_id(_s, location_id)
                if _loc:
                    _active_loc_name_norm = (_loc.name or "").strip().lower()
        except Exception:
            log_warning("Failed to evaluate active location for sidebar permissions", exc_info=True)
    if user_role in ["admin-operations", "manager"]:
        allowed_mapping_page = True
        allowed_convoy_page = True
    else:
        if _active_loc_name_norm in {"agge", "lagos (ho)"}:
            allowed_mapping_page = True
        if _active_loc_name_norm in CONVOY_STATUS_ALLOWED_LOCATIONS:
            allowed_convoy_page = True
    if allowed_mapping_page:
        base_pages.append("Yade-Vessel Mapping")
    if allowed_convoy_page:
        base_pages.append("Convoy Status")
    
    # ========== REPORTS - AVAILABLE TO ALL EXCEPT ADMIN-IT ==========
    if user_role != "admin-it":
        base_pages.extend([
            "OTR-Vessel",
            "FSO-Operations",
            "TOA-Yade",
            "OTR",
            "BCCR",
            "Material Balance",
            "Reporting"
        ])
    
    # ========== MANAGEMENT PAGES - ONLY ADMIN ==========
    # Lagos (HO) supervisors/operators CANNOT access these
    if PermissionManager.can_access_management_pages(user):
        base_pages.extend([
            "Add Asset",
            "Manage Locations",
            "Manage Users",
            "Audit Log",
            "Recycle Bin",
            "Backup & Recovery",
            "Location Settings"
        ])
    
    # ========== USER SETTINGS - AVAILABLE TO ALL ==========
    base_pages.extend([
        "My Tasks",
        "2FA Settings",
        "Login History"
    ])

    # ---------- APPLY LOCATION-BASED PAGE VISIBILITY ----------
    # Use the page_visibility settings stored in location configuration to determine
    # which transactional/report pages should appear in the sidebar for non-admin users.
    if location_id and user_role not in ["admin-operations", "manager"]:
        try:
            from location_config import LocationConfig
            with get_session() as _s:
                cfg = LocationConfig.get_config(_s, location_id)
            page_vis = cfg.get("page_visibility", {})
            page_access = cfg.get("page_access", {})
            # Hide Tank Transactions page if disabled
            if not page_vis.get("show_tank_transactions", True) and "Tank Transactions" in base_pages:
                base_pages.remove("Tank Transactions")
            # Hide Tanker Transactions page if disabled
            if not page_vis.get("show_tanker_transactions", False) and "Tanker Transactions" in base_pages:
                base_pages.remove("Tanker Transactions")
            # Hide YADE-related pages if disabled
            if not page_vis.get("show_yade_transactions", False):
                for _p in ["Yade Transactions", "Yade Tracking"]:
                    if _p in base_pages:
                        base_pages.remove(_p)
            # Hide TOA-Yade page if disabled
            if not page_vis.get("show_toa_yade", False) and "TOA-Yade" in base_pages:
                base_pages.remove("TOA-Yade")
            for _p in list(base_pages):
                if _p in {"Home", "Add Asset", "Manage Locations", "Manage Users", "Audit Log", "Recycle Bin", "Backup & Recovery", "Location Settings", "My Tasks", "2FA Settings", "Login History", "View Transactions"}:
                    continue
                if page_access.get(_p) is False and _p in base_pages:
                    base_pages.remove(_p)
        except Exception:
            log_warning("Failed to apply page visibility settings", exc_info=True)

    pages = base_pages

# Icons to show in the sidebar
ICONS = {
    "Home": "🏠",
    "Tank Transactions": "🛢️",
    "Yade Transactions": "⛴️",
    "Yade Tracking": "📍",
    "Yade-Vessel Mapping": "🗺️",
    "Tanker Transactions": "🚢",
    "TOA-Yade": "📋",
    "View Transactions": "👁️",
    "Convoy Status": "🚦",
    "OTR": "📊",
    "OTR-Vessel": "🛳️",
    "FSO-Operations": "⚓",
    "BCCR": "📈",
    "Material Balance": "⚖️",
    "Reporting": "📄",
    "Add Asset": "➕",
    "Manage Locations": "🌍",
    "Manage Users": "👥",
    "Audit Log": "📜",
    "Recycle Bin": "🗑️",
    "Backup & Recovery": "💾",
    "Location Settings": "⚙️",
    "2FA Settings": "🔐",
    "My Tasks": "✅",
    "Login History": "🕒",
}

# Read current page from session (fallback Home)
_current = st.session_state.get("page", "Home")

# -------- Unified Sidebar (logo + icon buttons) --------
pending_tasks_count = st.session_state.get("my_tasks_pending_count", 0)
with st.sidebar:
    if _sidebar_logo:
        st.image(str(_sidebar_logo), width=180)
    st.markdown("### OTMS")

    # FIX: Safely get user from session state
    user = st.session_state.get("auth_user")
    
    if user:
        st.caption(f"👤 **{user.get('full_name') or user.get('username', 'User')}**")
        st.caption(f"🎭 Role: {user.get('role', 'Unknown').title()}")
        
        # Show active location for ALL users
        if st.session_state.get("active_location_id"):
            with get_session() as s:
                from location_manager import LocationManager
                from permission_manager import PermissionManager
                
                loc = LocationManager.get_location_by_id(s, st.session_state.active_location_id)
                if loc:
                    # Check if Head Office
                    is_ho = PermissionManager.is_head_office(s, st.session_state.active_location_id)
                    
                    # Different styling for admin vs regular users
                    if user.get('role') in ["admin-operations", "manager"]:
                        st.caption(f"📍 Viewing: **{loc.code}**")
                    else:
                        st.caption(f"📍 Location: **{loc.code}**")
                    
                    # Show HO badge if applicable
                    if is_ho:
                        st.info("🏢 **Head Office**\nView-only access")
        
        try:
            pending_tasks_count = TaskManager.count_pending_tasks_for_user(user)
        except Exception:
            pending_tasks_count = st.session_state.get("my_tasks_pending_count", 0)
        st.session_state["my_tasks_pending_count"] = pending_tasks_count
        if pending_tasks_count:
            st.success(f"📬 {pending_tasks_count} pending task(s)")

        if st.button("🚪 Sign out", key="sidebar_signout_btn"):
            # Log logout
            try:
                from security import SecurityManager
                with get_session() as s:
                    SecurityManager.log_audit(
                        s, user.get('username', 'unknown'), "LOGOUT",
                        user_id=user.get('id'),
                        location_id=st.session_state.get("active_location_id")
                    )
            except Exception:
                pass  # Don't break logout if logging fails
            clear_2fa_session_states()  # Clear 2FA states
            st.session_state.auth_user = None
            st.session_state.active_location_id = None
            st.session_state["page"] = "Home"
            _st_safe_rerun()
    else:
        st.caption("Not signed in")

    st.markdown("---")

    # Render navigation as nice icon buttons
    for p in pages:
        label = f"{ICONS.get(p, '📄')} {p}"
        if p == "My Tasks" and pending_tasks_count:
            label = f"{label} ({pending_tasks_count})"
        if st.button(label, key=f"nav_{p}", disabled=(p == _current)):
            st.session_state["page"] = p
            _st_safe_rerun()

# Allow Home tiles to navigate (kept from your design)
if st.session_state.get("nav_to"):
    st.session_state["page"] = st.session_state.pop("nav_to")

# Export a single 'page' variable used by all the page-render code below
page = st.session_state.get("page", "Home")


# --------------------- TOA-YADE DATA ACCESS (materialize-safe) ---------------------
def load_toa_view_data(limit: int = 200):
    """
    Returns a list of plain dict rows you can bind directly in Streamlit,
    with enums converted to strings and quantities filled from TOAYadeSummary/Stage.
    """
    from models import YadeVoyage, TOAYadeSummary, TOAYadeStage

    rows = []
    with get_session() as s:
        vrows = (
            s.query(YadeVoyage)
             .order_by(YadeVoyage.date.desc(), YadeVoyage.time.desc())
             .limit(limit)
             .all()
        )
        if not vrows:
            return rows

        v_ids = [v.id for v in vrows]

        # summaries (GSV before/after/loaded for table header values)
        sums = {
            r.voyage_id: r
            for r in s.query(TOAYadeSummary).filter(TOAYadeSummary.voyage_id.in_(v_ids)).all()
        }

        # compute missing ones on the fly (older data)
        for v in vrows:
            if v.id not in sums:
                tids = (["C1", "C2", "P1", "P2", "S1", "S2"] if str(v.design) == "6"
                        else ["P1", "P2", "S1", "S2"])
                compute_and_upsert_toa_for_voyage(s, v.id, v.yade_name, tids)
        s.commit()

        # reload after compute
        sums = {
            r.voyage_id: r
            for r in s.query(TOAYadeSummary).filter(TOAYadeSummary.voyage_id.in_(v_ids)).all()
        }

        # stages (Before/After breakdown for the middle table)
        stages = {
            (r.voyage_id, (r.stage or "").lower()): r
            for r in s.query(TOAYadeStage).filter(TOAYadeStage.voyage_id.in_(v_ids)).all()
        }

        # materialize plain dicts (avoid DetachedInstanceError)
        def _text(x):
            return x.value if hasattr(x, "value") else str(x)

        for v in vrows:
            ssum = sums.get(v.id)
            b = stages.get((v.id, "before"))
            a = stages.get((v.id, "after"))

            rows.append({
                "id": v.id,
                "yade_no": v.yade_name,
                "voyage_no": v.voyage_no,
                "convoy_no": v.convoy_no,
                "date": v.date,
                "time": v.time,
                "destination": _text(v.destination),
                "loading_berth": _text(v.loading_berth),
                # summary numbers for header table
                "gsv_before": float(getattr(ssum, "gsv_before_bbl", 0.0) or 0.0),
                "gsv_after":  float(getattr(ssum, "gsv_after_bbl",  0.0) or 0.0),
                "gsv_loaded": float(getattr(ssum, "gsv_loaded_bbl", 0.0) or 0.0),
                # stage totals for middle table (none means 0)
                "stage_before": {
                    "gov_bbl": float(getattr(b, "gov_bbl", 0.0) or 0.0),
                    "gsv_bbl": float(getattr(b, "gsv_bbl", 0.0) or 0.0),
                    "bsw_pct": float(getattr(b, "bsw_pct", 0.0) or 0.0),
                    "bsw_bbl": float(getattr(b, "bsw_bbl", 0.0) or 0.0),
                    "nsv_bbl": float(getattr(b, "nsv_bbl", 0.0) or 0.0),
                    "lt":      float(getattr(b, "lt", 0.0) or 0.0),
                    "mt":      float(getattr(b, "mt", 0.0) or 0.0),
                    "fw_bbl":  float(getattr(b, "fw_bbl", 0.0) or 0.0),
                },
                "stage_after": {
                    "gov_bbl": float(getattr(a, "gov_bbl", 0.0) or 0.0),
                    "gsv_bbl": float(getattr(a, "gsv_bbl", 0.0) or 0.0),
                    "bsw_pct": float(getattr(a, "bsw_pct", 0.0) or 0.0),
                    "bsw_bbl": float(getattr(a, "bsw_bbl", 0.0) or 0.0),
                    "nsv_bbl": float(getattr(a, "nsv_bbl", 0.0) or 0.0),
                    "lt":      float(getattr(a, "lt", 0.0) or 0.0),
                    "mt":      float(getattr(a, "mt", 0.0) or 0.0),
                    "fw_bbl":  float(getattr(a, "fw_bbl", 0.0) or 0.0),
                },
            })
    return rows

# ============ SESSION TIMEOUT CHECK WITH WARNING ============
if st.session_state.get("auth_user"):
    from security import SecurityManager
    from datetime import datetime, timedelta
    
    user = st.session_state.auth_user
    
    # Check session timeout
    if SecurityManager.is_session_expired(user):
        st.error("⏰ Your session has expired due to inactivity. Please login again.")
        st.session_state.auth_user = None
        st.session_state.active_location_id = None
        st.session_state.pop("page", None)
        _st_safe_rerun()
    
    # Warning: 5 minutes before timeout
    else:
        last_activity = user.get("last_activity")
        if last_activity:
            if isinstance(last_activity, str):
                last_activity = datetime.fromisoformat(last_activity)
            
            timeout_at = last_activity + timedelta(minutes=SecurityManager.SESSION_TIMEOUT_MINUTES)
            time_remaining = timeout_at - datetime.utcnow()
            
            # Show warning if less than 5 minutes remaining
            if time_remaining.total_seconds() < 300 and time_remaining.total_seconds() > 0:
                minutes_left = int(time_remaining.total_seconds() / 60)
                st.sidebar.warning(f"⏰ Session expires in {minutes_left} min")
    
    # Update last activity
    try:
        with get_session() as s:
            SecurityManager.update_last_activity(s, user["id"])
            # Update session state
            user["last_activity"] = datetime.utcnow().isoformat()
            st.session_state.auth_user = user
    except Exception:
        pass  # Don't break the app if this fails

# =================== PAGES ===================
# ========================= HOME PAGE =========================
if page == "Home":
    header("Home")

    if st.session_state.auth_user is None:
        # ---- Login card ----
        c1, c2, c3 = st.columns([0.2, 0.6, 0.2])
        with c2:
            st.markdown("### 🛢️ Oil Terminal Management System")
            st.caption("Multi-Location Operations Management")

            with st.container(border=True):
                st.markdown("#### Login")
                username = st.text_input("Username", key="home_username")
                password = st.text_input("Password", type="password", key="home_password")

                login_btn = st.button("🔐 Login", key="home_login_btn", type="primary")

                st.markdown(
                    "<div style='margin-top:6px'><a href='#' onclick='return false;'>Forgot password?</a> "
                    "<span style='opacity:0.7'>(Contact your administrator)</span></div>",
                    unsafe_allow_html=True,
                )

                if login_btn:
                    if not username.strip():
                        st.error("Please enter a username.")
                    elif not password.strip():
                        st.error("Please enter a password.")
                    else:
                        try:
                            from auth import AuthManager
                            from twofa import TwoFactorAuth
                            from ip_service import IPService
                            import platform
                            
                            # ========== GET CLIENT INFO ==========
                            client_ip = IPService.get_client_ip()
                            
                            # Build detailed user agent with system info
                            system_info = platform.system()  # Windows, Linux, Darwin (Mac)
                            python_version = platform.python_version()
                            
                            # Try to get Streamlit version
                            try:
                                import streamlit as st_module
                                st_version = st_module.__version__
                            except:
                                st_version = "unknown"
                            
                            # More detailed user agent
                            user_agent = f"Streamlit/{st_version} ({system_info}; Python {python_version})"
                            
                            with get_session() as s:
                                # ========== AUTHENTICATE WITH IP AND USER AGENT ==========
                                authenticated_user = AuthManager.authenticate(
                                    s, 
                                    username.strip(), 
                                    password,
                                    ip_address=client_ip,
                                    user_agent=user_agent  # ? PASSING USER AGENT!
                                )
                                
                                if authenticated_user:
                                    # ========== AUTHENTICATION SUCCESSFUL ==========
                                    
                                    # Check if 2FA is enabled for this user
                                    is_2fa_enabled = TwoFactorAuth.is_enabled(s, authenticated_user["id"])
                                    
                                    if is_2fa_enabled:
                                        # ========== 2FA ENABLED - REQUIRE VERIFICATION ==========
                                        st.info("🔐 Two-Factor Authentication required")
                                        
                                        # Store user in session temporarily (pending 2FA)
                                        st.session_state["pending_2fa_user"] = authenticated_user
                                        
                                        # Also store IP and user_agent for 2FA logging
                                        st.session_state["pending_2fa_ip"] = client_ip
                                        st.session_state["pending_2fa_useragent"] = user_agent
                                        
                                        # Redirect to 2FA verification page
                                        st.session_state["page"] = "2FA Verify"
                                        _st_safe_rerun()
                                    else:
                                        # ========== NO 2FA - COMPLETE LOGIN ==========
                                        st.session_state.auth_user = authenticated_user
                                        
                                        # Set default active location
                                        if authenticated_user["role"] in ["admin-operations", "admin-it", "manager"]:
                                            from location_manager import LocationManager
                                            locations = LocationManager.get_all_locations(s, active_only=True)
                                            if locations:
                                                st.session_state.active_location_id = locations[0].id
                                        else:
                                            st.session_state.active_location_id = authenticated_user.get("location_id")
                                        
                                        # Check if password change required
                                        if authenticated_user.get("must_change_password"):
                                            st.warning("🔑 You must change your password before continuing.")
                                            st.session_state["force_password_change"] = True
                                        else:
                                            st.success(f"? Welcome, {authenticated_user.get('full_name') or authenticated_user['username']}!")
                                        
                                        _st_safe_rerun()
                                else:
                                    # ========== AUTHENTICATION FAILED ==========
                                    st.error("? Invalid username or password.")
                        
                        except ValueError as ve:
                            # Handle specific errors (account locked, etc.)
                            st.error(f"? {str(ve)}")
                        
                        except Exception as ex:
                            # Handle unexpected errors
                            from logger import log_error
                            log_error(f"Login failed: {ex}", exc_info=True)
                            st.error(f"? Login failed: {ex}")
                            
                            # Show detailed error for debugging (remove in production)
                            import traceback
                            with st.expander("⚠️ Error Details (Debug Info)"):
                                st.code(traceback.format_exc())

    else:
        # ---- User is logged in - show enhanced dashboard ----
        user = st.session_state.get("auth_user")
        
        if user is None:
            st.error("Session error. Please login again.")
            st.session_state.auth_user = None
            _st_safe_rerun()
            st.stop()
        
        # Check for forced password change
        if st.session_state.get("force_password_change") or user.get("must_change_password"):
            st.markdown("### 🔑 Password Change Required")
            st.warning("For security reasons, you must change your password before continuing.")
            
            with st.form("force_password_change_form"):
                current_pwd = st.text_input("Current Password", type="password", key="force_current_pwd")
                new_pwd = st.text_input("New Password", type="password", key="force_new_pwd")
                confirm_pwd = st.text_input("Confirm New Password", type="password", key="force_confirm_pwd")
                
                st.caption("Password must contain:")
                st.caption("• At least 8 characters")
                st.caption("• Uppercase and lowercase letters")
                st.caption("• At least one number")
                st.caption("• At least one special character (!@#$%^&*...)")
                
                submit = st.form_submit_button("Change Password", type="primary")
                
                if submit:
                    if not current_pwd or not new_pwd or not confirm_pwd:
                        st.error("All fields are required.")
                    elif new_pwd != confirm_pwd:
                        st.error("New passwords do not match.")
                    else:
                        try:
                            from auth import AuthManager
                            with get_session() as s:
                                result = AuthManager.change_password(
                                    s, user["id"], current_pwd, new_pwd
                                )
                            
                            st.success("? Password changed successfully! You can now use the system.")
                            st.session_state["force_password_change"] = False
                            st.session_state.auth_user["must_change_password"] = False
                            _st_safe_rerun()
                            
                        except Exception as ex:
                            log_error(f"Failed to change password: {ex}", exc_info=True)
                            st.error(f"Failed to change password: {ex}")
            
            st.stop()
        
        # Location selector - for Admin AND Lagos (HO) users
        from permission_manager import PermissionManager

        is_lagos_ho = PermissionManager.is_lagos_ho_user(user)
        global_view = user.get("role") in ["admin-operations", "manager"]

        if global_view or is_lagos_ho:
            from location_manager import LocationManager
            with get_session() as s:
                accessible_locs = PermissionManager.get_accessible_locations_for_user(s, user)
                
            if accessible_locs:
                loc_options = {f"{loc['name']} ({loc['code']})": loc['id'] for loc in accessible_locs}
                
                current_loc_id = st.session_state.get("active_location_id")
                current_idx = 0
                if current_loc_id:
                    loc_ids = list(loc_options.values())
                    if current_loc_id in loc_ids:
                        current_idx = loc_ids.index(current_loc_id)
                
                if global_view:
                    label = "📍 Active Location (Admin/Manager View)"
                else:
                    label = f"📍 Active Location ({user.get('full_name')} - Lagos HO)"
                
                selected = st.selectbox(
                    label,
                    options=list(loc_options.keys()),
                    index=current_idx,
                    key="location_selector"
                )
                
                st.session_state.active_location_id = loc_options[selected]
                
                # Show info about access level
                if is_lagos_ho:
                    if user.get("role") == "supervisor":
                        st.info("📍 **Lagos (HO) Supervisor:** Full access to all locations (create, view, delete)")
                    else:
                        st.info("📍 **Lagos (HO) Operator:** Can create and view entries at all locations (cannot delete)")
            else:
                st.warning("No active locations found. Please add a location in Manage Locations.")
        else:
            # Non-admin, non-HO users: auto-set to their assigned location
            if user.get("location_id"):
                st.session_state.active_location_id = user["location_id"]
                
                with get_session() as s:
                    from location_manager import LocationManager
                    loc = LocationManager.get_location_by_id(s, user["location_id"])
                    if loc:
                        st.info(f"📍 **Your Location:** {loc.name} ({loc.code})")
            else:
                st.error("⚠️ Your account is not assigned to any location. Please contact your administrator.")
                st.stop()
        
# ========================= HOME DASHBOARD =========================
if page == "Home":
    # ============ CUSTOM CSS ============
    st.markdown("""
        <style>
        .main-header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 2rem;
            border-radius: 10px;
            color: white;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .main-header h1 {
            margin: 0;
            font-size: 2.5rem;
            font-weight: 700;
        }
        .main-header p {
            margin: 0.5rem 0 0 0;
            font-size: 1.2rem;
            opacity: 0.9;
        }
        .stat-card {
            background: white;
            padding: 1rem;                 
            border-radius: 10px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            border-left: 4px solid #667eea;
            transition: transform 0.2s;
            margin-bottom: 0.75rem;
        }
        .stat-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        }
        .stat-card.stat-card--compact { padding: 0.75rem; border-left-width: 3px; }
        .stat-card.stat-card--compact .stat-value { font-size: 1.2rem; }
        .stat-card.stat-card--compact .stat-label { font-size: 0.75rem; }
        .psc-card {
            min-height: 90px;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
        }
        .stat-label--nowrap { white-space: nowrap; }
        .stat-label--wrap { white-space: normal; word-break: break-word; }
        .mb-note { font-size: 0.7rem; color: #888; }
        .stat-card.stat-card--mini { padding: 0.6rem; border-left-width: 3px; }
        .mb-note.mb-note--avg { font-size: 0.85rem; font-weight: 700; }
        .stat-value {
            font-size: 1.6rem;             
            font-weight: bold;
            color: #667eea;
            margin: 0.5rem 0;
        }
        .stat-label {
            color: #666;
            font-size: 0.8rem;
            font-weight: bold;             
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        .stat-card--brown { border-left-color: #8b5a2b; }
        .stat-card--brown .stat-value,
        .stat-card--brown .stat-label { color: #8b5a2b; }
        .stat-card--orange { border-left-color: #d97706; }
        .stat-card--orange .stat-value,
        .stat-card--orange .stat-label { color: #d97706; }
        .stat-card--jv { border-left-color: #064e3b; }
        .stat-card--jv .stat-value,
        .stat-card--jv .stat-label { color: #064e3b; }
        .total-card { min-height: 230px; }
        .total-title {
            font-size: 1.2rem;
            font-weight: 700;
            letter-spacing: 2px;
        }

        .tank-card {
            background: linear-gradient(to bottom, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 15px;
            padding: 1.5rem;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
            margin-bottom: 1.5rem;
            transition: all 0.3s;
        }
        .tank-card:hover {
            transform: scale(1.02);
            box-shadow: 0 6px 20px rgba(0,0,0,0.15);
        }
        .tank-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #dee2e6;
        }
        .tank-name {
            font-size: 1.3rem;
            font-weight: bold;
            color: #2c3e50;
        }
        .tank-status {
            padding: 0.3rem 0.8rem;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 600;
        }
        .tank-info-row {
            display: flex;
            justify-content: space-between;
            margin-bottom: 0.5rem;
        }
        .tank-info-label {
            color: #6c757d;
            font-size: 0.9rem;
        }
        .tank-info-value {
            font-weight: bold;
        }
        .tank-visual {
            position: relative;
            width: 100%;
            height: 200px;
            background: linear-gradient(to bottom, #e9ecef 0%, #dee2e6 100%);
            border-radius: 10px;
            overflow: hidden;
            border: 3px solid #adb5bd;
            margin: 1rem 0;
        }
        .tank-fill {
            position: absolute;
            bottom: 0;
            width: 100%;
            transition: height 0.5s ease;
        }
        .tank-percentage {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: white;
            font-weight: bold;
            font-size: 1.5rem;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        .tank-stock-badge {
            position: absolute;
            top: 10px;
            right: 10px;
            background: rgba(255,255,255,0.9);
            padding: 0.3rem 0.6rem;
            border-radius: 5px;
            font-size: 0.8rem;
            font-weight: bold;
        }
        .tank-footer {
            margin-top: 1rem;
            padding-top: 1rem;
            border-top: 1px solid #dee2e6;
            display: flex;
            justify-content: space-between;
            font-size: 0.85rem;
            color: #6c757d;
        }
        .activity-item {
            padding: 1rem;
            border-left: 3px solid #667eea;
            margin-bottom: 1rem;
            background: #f8f9fa;
            border-radius: 5px;
        }
        </style>
    """, unsafe_allow_html=True)
    
    def _coerce_time(value) -> dt_time | None:
        """Normalize stored time inputs (strings/datetime) into datetime.time."""
        if isinstance(value, dt_time):
            return value
        if isinstance(value, datetime):
            return value.time()
        if isinstance(value, str):
            txt = value.strip()
            if not txt:
                return None
            parts = txt.split(":")
            try:
                hour = int(parts[0])
                minute = int(parts[1]) if len(parts) > 1 else 0
                second = int(parts[2]) if len(parts) > 2 else 0
                return dt_time(hour, minute, second)
            except Exception:
                return None
        return None

    # ============ GET LOCATION AND USER ============
    active_location_id = st.session_state.get("active_location_id")
    user = st.session_state.get("auth_user")
    
    if not user:
        st.error("🚫 User not authenticated")
        st.stop()
    
    # ============ ADMIN-IT SPECIAL HOME PAGE ============
    if user.get("role") == "admin-it":
        st.markdown("""
        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem;'>
            <h1 style='color: white; margin: 0;'>🔧 System Administration</h1>
            <p style='color: rgba(255,255,255,0.9); margin: 0.5rem 0 0 0;'>Admin-IT Dashboard</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"### Welcome, {user.get('full_name') or user.get('username')}!")
        st.caption("You have system administration access")
        
        st.markdown("---")
        st.markdown("### 🔐 Your Access")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **? You Can Access:**
            - 👥 Manage Users
            - 📜 Audit Log
            - 🕒 Login History
            - 💾 Backup & Recovery
            - ✅ My Tasks (Password Reset Requests)
            - 🔐 2FA Settings
            """)
        
        with col2:
            st.markdown("""
            **? Restricted Access:**
            - All Operational Pages (Tank, Yade, Tanker Transactions)
            - All Reports (OTR, BCCR, Material Balance)
            - Location-specific Operations
            
            *Admin-IT is for system administration only*
            """)
        
        st.markdown("---")
        st.markdown("### 📌 Quick Links")
        
        quick_col1, quick_col2, quick_col3 = st.columns(3)
        
        with quick_col1:
            if st.button("👥 Manage Users", use_container_width=True):
                st.session_state.page = "Manage Users"
                st.rerun()
        
        with quick_col2:
            if st.button("📜 View Audit Log", use_container_width=True):
                st.session_state.page = "Audit Log"
                st.rerun()
        
        with quick_col3:
            if st.button("✅ My Tasks", use_container_width=True):
                st.session_state.page = "My Tasks"
                st.rerun()
        
        st.stop()
    
    # ============ NORMAL OPERATIONAL DASHBOARD FOR OTHER ROLES ============
    if not active_location_id:
        st.warning("⚠️ Please select a location after login")
        st.stop()
    
    # ============ GET LOCATION DETAILS ============
    is_agge_location = False
    with get_session() as s:
        from location_manager import LocationManager
        from permission_manager import PermissionManager
        
        loc = LocationManager.get_location_by_id(s, active_location_id)
        if not loc:
            st.error("? Location not found.")
            st.stop()
        
        def _dash_canon(txt: str) -> str:
            return str(txt or "").upper().replace(" ", "").replace("-", "")
        
        loc_code_value = getattr(loc, "code", "") or ""
        loc_name_value = getattr(loc, "name", "") or ""
        dash_tokens = {_dash_canon(loc_code_value), _dash_canon(loc_name_value)}
        is_agge_location = bool(dash_tokens & {"AGGE"})
        
        # Check permissions
        can_view_tanks = PermissionManager.can_access_feature(s, active_location_id, "tank_transactions", user["role"])
        can_view_yade = PermissionManager.can_access_feature(s, active_location_id, "yade_transactions", user["role"])
        can_view_tanker = PermissionManager.can_access_feature(s, active_location_id, "tanker_transactions", user["role"])
    
    # ============ HEADER ============

    # Decide dashboard title based on location
    def _canon_loc(text: str) -> str:
        return str(text or "").upper().replace(" ", "").replace("-", "")

    loc_name_safe = getattr(loc, "name", "") or ""
    loc_code_safe = getattr(loc, "code", "") or ""

    _name_c = _canon_loc(loc_name_safe)
    _code_c = _canon_loc(loc_code_safe)

    # Lagos ? special title, others ? "<Location> Dashboard"
    is_lagos_location = ("LAGOS" in _name_c) or ("LAGOS" in _code_c)
    header_title = (
        "CRUDE OPERATIONS DASHBOARD"
        if is_lagos_location
        else f"{loc_name_safe or loc_code_safe or 'Location'} Dashboard"
    )

    st.markdown(
        f"""
        <div class="main-header">
            <h1>{header_title}</h1>
            <p>MANAGEMENT INFORMATION SYSTEM</p>
            <p>Welcome back, <strong>{user['username']}</strong> | {datetime.now().strftime('%A, %B %d, %Y - %I:%M %p')}</p>
        </div>
        """,
        unsafe_allow_html=True,
    )
    if is_lagos_location:
        from models import Location, OFSProductionEvacuationRecord
        from material_balance_calculator import MaterialBalanceCalculator as MBC
        from datetime import date as _date

        # Reuse the global dashboard date instead of creating a new widget
        dp_date = st.session_state.get("dash_date_all_sites", _date.today())
        tabs = st.tabs(["Production & Evacuation Summary", "Stock Positions"])

        # ---------- Helper functions (PSC labels, MB helpers, FSO helper) ----------
        def _psc_label_html(text: str) -> str:
            tokens = [t for t in str(text).split() if t]
            wrap_cls = "stat-label--nowrap" if len(tokens) <= 1 else "stat-label--wrap"
            return f'<div class="stat-label {wrap_cls}">{html.escape(text)}</div>'

        def _psc_card_class(text: str) -> str:
            canon = str(text or "").strip().upper()
            if canon in {"AGGU", "NDONI RECEIPT", "NDONI EVACUATION"}:
                return "stat-card--brown"
            if canon in {"OGUALI", "UKPICHI"}:
                return "stat-card--orange"
            return ""

        def _mb_sum_range(loc_entry: dict | None, start_date, end_date, candidates: list[str]) -> float:
            if not loc_entry:
                return 0.0
            try:
                rows = MBC.calculate_material_balance(
                    None,
                    (loc_entry["code"] or "").upper(),
                    start_date,
                    end_date,
                    location_id=loc_entry["id"],
                    debug=False,
                ) or []
                df = pd.DataFrame(rows)
                if df.empty:
                    return 0.0
                lower_map = {str(col).strip().lower(): col for col in df.columns}
                target_col = None
                for cand in candidates:
                    if cand in df.columns:
                        target_col = cand
                        break
                    cand_lower = str(cand).strip().lower()
                    if cand_lower in lower_map:
                        target_col = lower_map[cand_lower]
                        break
                if not target_col:
                    return 0.0
                return float(pd.to_numeric(df[target_col], errors="coerce").fillna(0.0).sum())
            except Exception:
                return 0.0

        def _fso_receipt_sum(loc_entry: dict | None, start_date, end_date, vessel_name: str) -> float:
            if not loc_entry:
                return 0.0
            total = 0.0
            try:
                from models import FSOOperation
                with get_session() as s_fso:
                    rows = (
                        s_fso.query(FSOOperation)
                        .filter(
                            FSOOperation.location_id == loc_entry["id"],
                            FSOOperation.fso_vessel == vessel_name,
                            FSOOperation.date >= start_date,
                            FSOOperation.date <= end_date,
                        )
                        .all()
                    )
                for r in rows:
                    op_text = str(getattr(r, "operation", "") or "").strip().lower()
                    if op_text.startswith("receipt"):
                        total += float(getattr(r, "net_receipt_dispatch", 0.0) or 0.0)
            except Exception:
                pass
            return total

        # ---------- Resolve locations & compute DAILY PSC volumes ----------
        with get_session() as s:
            locations = s.query(Location).order_by(Location.name).all()

            def _canon_token(v):
                return str(v or "").upper().replace(" ", "").replace("-", "")

            def _resolve(token_set):
                targets = {_canon_token(t) for t in token_set}
                for L in locations:
                    if {_canon_token(L.code), _canon_token(L.name)} & targets:
                        return {"id": L.id, "code": L.code or "", "name": L.name or ""}
                return None

            loc_aggu = _resolve({"AGGU"})
            loc_asemoku = _resolve({"JETTY", "ASEMOKU", "ASEMOKUJETTY"})
            loc_bfs = _resolve({"BFS", "BENEKU"})
            loc_oguali = _resolve({"OGUALI", "OML157", "OGUALIOML157"})
            loc_utapate = _resolve({"UTAPATE", "OML13", "OML-13"})
            loc_ogini = _resolve({"OGINI", "UMUOGINI", "OML26", "OML-26"})
            loc_ndoni = _resolve({"NDONI"})

            # Aggu (receipt) via MB
            aggu_val = 0.0
            try:
                if loc_aggu:
                    rows = MBC.calculate_material_balance(
                        None,
                        (loc_aggu["code"] or "").upper(),
                        dp_date,
                        dp_date,
                        location_id=loc_aggu["id"],
                        debug=False,
                    ) or []
                    df = pd.DataFrame(rows)
                    col = "Receipt" if "Receipt" in df.columns else ("Receipts" if "Receipts" in df.columns else None)
                    if col and not df.empty:
                        aggu_val = float(pd.to_numeric(df[col], errors="coerce").fillna(0.0).sum())
            except Exception:
                pass

            # ANZ via MB
            anz_val = 0.0
            try:
                if loc_asemoku:
                    rows = MBC.calculate_material_balance(
                        None,
                        (loc_asemoku["code"] or "").upper(),
                        dp_date,
                        dp_date,
                        location_id=loc_asemoku["id"],
                        debug=False,
                    ) or []
                    df = pd.DataFrame(rows)
                    col = "ANZ Receipt" if "ANZ Receipt" in df.columns else None
                    if col and not df.empty:
                        anz_val = float(pd.to_numeric(df[col], errors="coerce").fillna(0.0).sum())
            except Exception:
                pass

            # GPP & OKW via GPPProductionRecord loader
            gpp_val = 0.0
            okw_val = 0.0
            try:
                if loc_bfs:
                    recs = load_gpp_production_records(loc_bfs["id"], limit=2000)
                    df = pd.DataFrame(recs)
                    df["Date"] = pd.to_datetime(df["Date"], errors="coerce").dt.date
                    df = df[df["Date"] == dp_date]
                    if not df.empty:
                        gpp_val = float(pd.to_numeric(df["Total GPP Production"], errors="coerce").fillna(0.0).sum())
                        okw_val = float(pd.to_numeric(df["OKW Production"], errors="coerce").fillna(0.0).sum())
            except Exception:
                pass

            # Oguali & Ukpichi via OFSProductionEvacuationRecord
            oguali_val = 0.0
            ukpichi_val = 0.0
            try:
                if loc_oguali:
                    rows = (
                        s.query(OFSProductionEvacuationRecord)
                        .filter(
                            OFSProductionEvacuationRecord.location_id == loc_oguali["id"],
                            OFSProductionEvacuationRecord.date == dp_date,
                        )
                        .all()
                    )
                    oguali_val = float(
                        sum([float(getattr(r, "oguali_production", 0.0) or 0.0) for r in rows])
                    )
                    ukpichi_val = float(
                        sum(
                            [
                                float(getattr(r, "ukpichi_production", 0.0) or 0.0)
                                + float(getattr(r, "other_locations", 0.0) or 0.0)
                                for r in rows
                            ]
                        )
                    )
            except Exception:
                pass

        # ---------- Helper for Stock Positions tab ----------
        def _mb_value_for_column(loc_entry: dict | None, the_date, candidates: list[str]) -> float:
            if not loc_entry:
                return 0.0
            try:
                rows = MBC.calculate_material_balance(
                    None,
                    (loc_entry["code"] or "").upper(),
                    the_date,
                    the_date,
                    location_id=loc_entry["id"],
                    debug=False,
                ) or []
                df = pd.DataFrame(rows)
                if df.empty:
                    return 0.0
                lower_map = {str(col).strip().lower(): col for col in df.columns}
                target_col = None
                for cand in candidates:
                    if cand in df.columns:
                        target_col = cand
                        break
                    cand_lower = str(cand).strip().lower()
                    if cand_lower in lower_map:
                        target_col = lower_map[cand_lower]
                        break
                if not target_col:
                    return 0.0
                return float(pd.to_numeric(df[target_col], errors="coerce").fillna(0.0).sum())
            except Exception:
                return 0.0

        # =====================================================================
        # TAB 0: PRODUCTION & EVACUATION SUMMARY (ALL CARDS STAY HERE)
        # =====================================================================
        with tabs[0]:
            st.subheader("Summary Statistics")

            labels = [
                ("Aggu", aggu_val),
                ("Anieze & Enyie", anz_val),
                ("GPP", gpp_val),
                ("Oguali", oguali_val),
                ("Okwuibome", okw_val),
                ("Ukpichi", ukpichi_val),
            ]

            total_psc = float(
                (aggu_val or 0.0)
                + (anz_val or 0.0)
                + (gpp_val or 0.0)
                + (oguali_val or 0.0)
                + (okw_val or 0.0)
                + (ukpichi_val or 0.0)
            )

            st.markdown("### DAILY PRODUCTION & EVACUATION")
            st.markdown("#### PSC Block")

            grid_left, total_right = st.columns([0.8, 0.2])
            dp_items = [
                ("Anieze & Enyie", anz_val),
                ("Okwuibome", okw_val),
                ("GPP", gpp_val),
                ("Aggu", aggu_val),
                ("Oguali", oguali_val),
                ("Ukpichi", ukpichi_val),
            ]
            dp_cols_all = grid_left.columns(6)
            for i, (lbl, val) in enumerate(dp_items):
                try:
                    vtxt = f"{float(val or 0.0):,.0f} bbls"
                except Exception:
                    vtxt = "-"
                label_html = _psc_label_html(lbl)
                extra_cls = _psc_card_class(lbl)
                html_card = f"""
                <div class="stat-card stat-card--compact psc-card {extra_cls}">
                    {label_html}
                    <div class="stat-value">{html.escape(vtxt)}</div>
                    <div class="mb-note">{pd.to_datetime(dp_date).strftime('%d-%b-%Y')}</div>
                </div>
                """
                dp_cols_all[i].markdown(html_card, unsafe_allow_html=True)

            # ---------- Pre-compute Ndoni / Jetty / Tanvi for DAILY cards ----------
            with get_session() as s2:
                locations = s2.query(Location).order_by(Location.name).all()

                def _canon_token(v):
                    return str(v or "").upper().replace(" ", "").replace("-", "")

                def _resolve(token_set):
                    targets = {_canon_token(t) for t in token_set}
                    for L in locations:
                        if {_canon_token(L.code), _canon_token(L.name)} & targets:
                            return {"id": L.id, "code": L.code or "", "name": L.name or ""}
                    return None

                loc_ndoni2 = _resolve({"NDONI"})
                loc_jetty2 = _resolve({"JETTY", "ASEMOKU", "ASEMOKUJETTY"})
                loc_agge = _resolve({"AGGE"})

                ndoni_receipt = 0.0
                try:
                    if loc_ndoni2:
                        rows = MBC.calculate_material_balance(
                            None,
                            (loc_ndoni2["code"] or "").upper(),
                            dp_date,
                            dp_date,
                            location_id=loc_ndoni2["id"],
                            debug=False,
                        ) or []
                        df = pd.DataFrame(rows)
                        cands = ["Receipt from Agu", "Receipt from OFS", "Other Receipts"]
                        for c in cands:
                            if c in df.columns:
                                ndoni_receipt += float(
                                    pd.to_numeric(df[c], errors="coerce").fillna(0.0).sum()
                                )
                            else:
                                lower_map = {str(col).strip().lower(): col for col in df.columns}
                                key = c.strip().lower()
                                if key in lower_map:
                                    col = lower_map[key]
                                    ndoni_receipt += float(
                                        pd.to_numeric(df[col], errors="coerce").fillna(0.0).sum()
                                    )
                except Exception:
                    pass

                ndoni_evac = 0.0
                try:
                    if loc_ndoni2:
                        rows = MBC.calculate_material_balance(
                            None,
                            (loc_ndoni2["code"] or "").upper(),
                            dp_date,
                            dp_date,
                            location_id=loc_ndoni2["id"],
                            debug=False,
                        ) or []
                        df = pd.DataFrame(rows)
                        cand = "Dispatch to barge"
                        col = cand if cand in df.columns else None
                        if not col:
                            lower_map = {str(col2).strip().lower(): col2 for col2 in df.columns}
                            if cand.lower() in lower_map:
                                col = lower_map[cand.lower()]
                        if col and not df.empty:
                            ndoni_evac = float(
                                pd.to_numeric(df[col], errors="coerce").fillna(0.0).sum()
                            )
                except Exception:
                    pass

                jetty_evac = 0.0
                try:
                    if loc_jetty2:
                        rows = MBC.calculate_material_balance(
                            None,
                            (loc_jetty2["code"] or "").upper(),
                            dp_date,
                            dp_date,
                            location_id=loc_jetty2["id"],
                            debug=False,
                        ) or []
                        df = pd.DataFrame(rows)
                        cand = "Dispatch to barge"
                        col = cand if cand in df.columns else None
                        if not col:
                            lower_map = {str(col2).strip().lower(): col2 for col2 in df.columns}
                            if cand.lower() in lower_map:
                                col = lower_map[cand.lower()]
                        if col and not df.empty:
                            jetty_evac = float(
                                pd.to_numeric(df[col], errors="coerce").fillna(0.0).sum()
                            )
                except Exception:
                    pass

                tanvi_receipt = 0.0
                try:
                    from models import FSOOperation

                    if loc_agge:
                        rows = (
                            s2.query(FSOOperation)
                            .filter(
                                FSOOperation.location_id == loc_agge["id"],
                                FSOOperation.fso_vessel == "MT TULJA TANVI",
                                FSOOperation.date == dp_date,
                            )
                            .all()
                        )
                        for r in rows:
                            op_text = str(getattr(r, "operation", "") or "").strip().lower()
                            if op_text.startswith("receipt"):
                                try:
                                    tanvi_receipt += float(
                                        getattr(r, "net_receipt_dispatch", 0.0) or 0.0
                                    )
                                except Exception:
                                    pass
                except Exception:
                    pass

            # ---------- DAILY Ndoni / Jetty / Tanvi cards + TOTAL ----------
            rec_cols = grid_left.columns(4)
            rec_items = [
                ("NDONI RECEIPT", ndoni_receipt),
                ("NDONI EVACUATION", ndoni_evac),
                ("JETTY EVACUATION", jetty_evac),
                ("FSO TANVI RECEIPT", tanvi_receipt),
            ]
            for i, (lbl, val) in enumerate(rec_items):
                try:
                    vtxt = f"{float(val or 0.0):,.0f} bbls"
                except Exception:
                    vtxt = "-"
                label_html = _psc_label_html(lbl)
                extra_cls = _psc_card_class(lbl)
                html_card = f"""
                <div class="stat-card stat-card--compact psc-card {extra_cls}">
                    {label_html}
                    <div class="stat-value">{html.escape(vtxt)}</div>
                    <div class="mb-note">{pd.to_datetime(dp_date).strftime('%d-%b-%Y')}</div>
                </div>
                """
                rec_cols[i].markdown(html_card, unsafe_allow_html=True)

            # TOTAL card adjacent, spanning two rows: PSC Production + PSC Evacuation
            psc_prod = total_psc
            psc_evac = float((ndoni_evac or 0.0) + (jetty_evac or 0.0))
            total_html = f"""
            <div class="stat-card stat-card--compact total-card">
                <div class="total-title">TOTAL</div>
                <div>
                    {_psc_label_html("PSC Production")}
                    <div class="stat-value">{psc_prod:,.0f} bbls</div>
                </div>
                <div style="margin-top:0.75rem">
                    {_psc_label_html("PSC Evacuation")}
                    <div class="stat-value">{psc_evac:,.0f} bbls</div>
                </div>
            </div>
            """
            total_right.markdown(total_html, unsafe_allow_html=True)

            # ---------- DAILY JV Block ----------
            oml13_prod = _mb_sum_range(loc_utapate, dp_date, dp_date, ["Receipt", "Receipts"])
            oml13_evac = _mb_sum_range(
                loc_utapate,
                dp_date,
                dp_date,
                ["Dispatch", "Dispatch to barge", "Dispatch to Barge"],
            )
            oml26_prod = _mb_sum_range(loc_ogini, dp_date, dp_date, ["Receipt", "Receipts"])
            oml26_evac = _mb_sum_range(
                loc_ogini,
                dp_date,
                dp_date,
                ["Dispatch", "Dispatch to barge", "Dispatch to Barge"],
            )
            kalyani_receipt = _fso_receipt_sum(
                loc_utapate, dp_date, dp_date, "MT TULJA KALYANI"
            )
            total_jv_volume = float(
                (oml13_prod or 0.0) + (oml26_prod or 0.0) + (kalyani_receipt or 0.0)
            )

            st.markdown("#### JV Block")
            jv_cols = st.columns(6)
            jv_items = [
                ("OML-13 PRODUCTION", oml13_prod),
                ("OML-13 EVACUATION", oml13_evac),
                ("OML-26 PRODUCTION", oml26_prod),
                ("OML-26 EVACUATION", oml26_evac),
                ("FSO KALYANI RECEIPT", kalyani_receipt),
                ("TOTAL JV THROUGHPUT", total_jv_volume),
            ]
            jv_note = pd.to_datetime(dp_date).strftime("%d-%b-%Y")
            for idx, (lbl, val) in enumerate(jv_items):
                try:
                    vtxt = f"{float(val or 0.0):,.0f} bbls"
                except Exception:
                    vtxt = "-"
                label_html = _psc_label_html(lbl)
                card_html = f"""
                <div class="stat-card stat-card--compact psc-card stat-card--jv">
                    {label_html}
                    <div class="stat-value">{html.escape(vtxt)}</div>
                    <div class="mb-note">{html.escape(jv_note)}</div>
                </div>
                """
                jv_cols[idx].markdown(card_html, unsafe_allow_html=True)

            # ---------- MONTHLY DATA ----------
            st.markdown("##### MONTHLY DATA")
            my_cols = st.columns(2)
            my_from = my_cols[0].date_input(
                "From",
                value=date.today().replace(day=1),
                key=f"lagos_my_from_{active_location_id}",
            )
            my_to = my_cols[1].date_input(
                "To",
                value=date.today(),
                key=f"lagos_my_to_{active_location_id}",
            )

            if my_from > my_to:
                st.error("From date cannot be after To date.")
            else:
                st.markdown("#### PSC Block")
                my_grid_left, my_total_right = st.columns([0.8, 0.2])

                with get_session() as s3:
                    locations = s3.query(Location).order_by(Location.name).all()

                    def _canon_token(v):
                        return str(v or "").upper().replace(" ", "").replace("-", "")

                    def _resolve(token_set):
                        targets = {_canon_token(t) for t in token_set}
                        for L in locations:
                            if {_canon_token(L.code), _canon_token(L.name)} & targets:
                                return {
                                    "id": L.id,
                                    "code": L.code or "",
                                    "name": L.name or "",
                                }
                        return None

                    loc_aggu_m = _resolve({"AGGU"})
                    loc_asemoku_m = _resolve({"JETTY", "ASEMOKU", "ASEMOKUJETTY"})
                    loc_bfs_m = _resolve({"BFS", "BENEKU"})
                    loc_oguali_m = _resolve({"OGUALI", "OML157", "OGUALIOML157"})
                    loc_ndoni_m = _resolve({"NDONI"})
                    loc_utapate_m = _resolve({"UTAPATE", "OML13", "OML-13"})
                    loc_ogini_m = _resolve({"OGINI", "UMUOGINI", "OML26", "OML-26"})

                    n_days = (my_to - my_from).days + 1

                    aggu_total = 0.0
                    try:
                        if loc_aggu_m:
                            rows = MBC.calculate_material_balance(
                                None,
                                (loc_aggu_m["code"] or "").upper(),
                                my_from,
                                my_to,
                                location_id=loc_aggu_m["id"],
                                debug=False,
                            ) or []
                            df = pd.DataFrame(rows)
                            col = (
                                "Receipt"
                                if "Receipt" in df.columns
                                else ("Receipts" if "Receipts" in df.columns else None)
                            )
                            if col and not df.empty:
                                aggu_total = float(
                                    pd.to_numeric(df[col], errors="coerce")
                                    .fillna(0.0)
                                    .sum()
                                )
                    except Exception:
                        pass

                    anz_total = 0.0
                    try:
                        if loc_asemoku_m:
                            rows = MBC.calculate_material_balance(
                                None,
                                (loc_asemoku_m["code"] or "").upper(),
                                my_from,
                                my_to,
                                location_id=loc_asemoku_m["id"],
                                debug=False,
                            ) or []
                            df = pd.DataFrame(rows)
                            col = "ANZ Receipt" if "ANZ Receipt" in df.columns else None
                            if col and not df.empty:
                                anz_total = float(
                                    pd.to_numeric(df[col], errors="coerce")
                                    .fillna(0.0)
                                    .sum()
                                )
                    except Exception:
                        pass

                    gpp_total = 0.0
                    okw_total = 0.0
                    try:
                        if loc_bfs_m:
                            recs = load_gpp_production_records(loc_bfs_m["id"], limit=5000)
                            df = pd.DataFrame(recs)
                            df["Date"] = pd.to_datetime(df["Date"], errors="coerce").dt.date
                            df = df[(df["Date"] >= my_from) & (df["Date"] <= my_to)]
                            if not df.empty:
                                gpp_total = float(
                                    pd.to_numeric(
                                        df["Total GPP Production"], errors="coerce"
                                    )
                                    .fillna(0.0)
                                    .sum()
                                )
                                okw_total = float(
                                    pd.to_numeric(df["OKW Production"], errors="coerce")
                                    .fillna(0.0)
                                    .sum()
                                )
                    except Exception:
                        pass

                    oguali_total = 0.0
                    ukpichi_total = 0.0
                    jetty_evac_total = 0.0
                    ndoni_evac_total = 0.0
                    tanvi_total = 0.0
                    try:
                        if loc_oguali_m:
                            rows = (
                                s3.query(OFSProductionEvacuationRecord)
                                .filter(
                                    OFSProductionEvacuationRecord.location_id
                                    == loc_oguali_m["id"],
                                    OFSProductionEvacuationRecord.date >= my_from,
                                    OFSProductionEvacuationRecord.date <= my_to,
                                )
                                .all()
                            )
                            oguali_total = float(
                                sum(
                                    [
                                        float(getattr(r, "oguali_production", 0.0) or 0.0)
                                        for r in rows
                                    ]
                                )
                            )
                            ukpichi_total = float(
                                sum(
                                    [
                                        float(getattr(r, "ukpichi_production", 0.0) or 0.0)
                                        + float(getattr(r, "other_locations", 0.0) or 0.0)
                                        for r in rows
                                    ]
                                )
                            )
                        if loc_asemoku_m:
                            rows = MBC.calculate_material_balance(
                                None,
                                (loc_asemoku_m["code"] or "").upper(),
                                my_from,
                                my_to,
                                location_id=loc_asemoku_m["id"],
                                debug=False,
                            ) or []
                            df = pd.DataFrame(rows)
                            cand = "Dispatch to barge"
                            col = cand if cand in df.columns else None
                            if not col:
                                lower_map = {
                                    str(col2).strip().lower(): col2 for col2 in df.columns
                                }
                                if cand.lower() in lower_map:
                                    col = lower_map[cand.lower()]
                            if col and not df.empty:
                                jetty_evac_total = float(
                                    pd.to_numeric(df[col], errors="coerce")
                                    .fillna(0.0)
                                    .sum()
                                )
                        if loc_ndoni_m:
                            rows = MBC.calculate_material_balance(
                                None,
                                (loc_ndoni_m["code"] or "").upper(),
                                my_from,
                                my_to,
                                location_id=loc_ndoni_m["id"],
                                debug=False,
                            ) or []
                            df = pd.DataFrame(rows)
                            cand = "Dispatch to barge"
                            col = cand if cand in df.columns else None
                            if not col:
                                lower_map = {
                                    str(col2).strip().lower(): col2 for col2 in df.columns
                                }
                                if cand.lower() in lower_map:
                                    col = lower_map[cand.lower()]
                            if col and not df.empty:
                                ndoni_evac_total = float(
                                    pd.to_numeric(df[col], errors="coerce")
                                    .fillna(0.0)
                                    .sum()
                                )
                        from models import FSOOperation

                        loc_agge_m = _resolve({"AGGE"})
                        if loc_agge_m:
                            rows = (
                                s3.query(FSOOperation)
                                .filter(
                                    FSOOperation.location_id == loc_agge_m["id"],
                                    FSOOperation.fso_vessel == "MT TULJA TANVI",
                                    FSOOperation.date >= my_from,
                                    FSOOperation.date <= my_to,
                                )
                                .all()
                            )
                            for r in rows:
                                op_text = str(getattr(r, "operation", "") or "").strip().lower()
                                if op_text.startswith("receipt"):
                                    try:
                                        tanvi_total += float(
                                            getattr(r, "net_receipt_dispatch", 0.0) or 0.0
                                        )
                                    except Exception:
                                        pass
                    except Exception:
                        pass

                jv_oml13_prod = _mb_sum_range(
                    loc_utapate_m, my_from, my_to, ["Receipt", "Receipts"]
                )
                jv_oml13_evac = _mb_sum_range(
                    loc_utapate_m,
                    my_from,
                    my_to,
                    ["Dispatch", "Dispatch to barge", "Dispatch to Barge"],
                )
                jv_oml26_prod = _mb_sum_range(
                    loc_ogini_m, my_from, my_to, ["Receipt", "Receipts"]
                )
                jv_oml26_evac = _mb_sum_range(
                    loc_ogini_m,
                    my_from,
                    my_to,
                    ["Dispatch", "Dispatch to barge", "Dispatch to Barge"],
                )
                jv_kalyani_receipt = _fso_receipt_sum(
                    loc_utapate_m, my_from, my_to, "MT TULJA KALYANI"
                )
                jv_total_volume = float(
                    (jv_oml13_prod or 0.0)
                    + (jv_oml26_prod or 0.0)
                    + (jv_kalyani_receipt or 0.0)
                )
                psc_total = float(
                    sum(
                        [
                            aggu_total,
                            anz_total,
                            gpp_total,
                            oguali_total,
                            okw_total,
                            ukpichi_total,
                        ]
                    )
                )

                row2 = [
                    (
                        "JETTY EVACUATION",
                        jetty_evac_total,
                        jetty_evac_total / max(n_days, 1),
                    ),
                    (
                        "NDONI EVACUATION",
                        ndoni_evac_total,
                        ndoni_evac_total / max(n_days, 1),
                    ),
                    (
                        "FSO TANVI RECEIPT",
                        tanvi_total,
                        tanvi_total / max(n_days, 1),
                    ),
                ]

                # Arrange monthly 6 cards + adjacent TOTAL
                row1_labels = [
                    ("Anieze & Enyie", anz_total, anz_total / max(n_days, 1)),
                    ("Okwuibome", okw_total, okw_total / max(n_days, 1)),
                    ("GPP", gpp_total, gpp_total / max(n_days, 1)),
                    ("Aggu", aggu_total, aggu_total / max(n_days, 1)),
                    ("Oguali", oguali_total, oguali_total / max(n_days, 1)),
                    ("Ukpichi", ukpichi_total, ukpichi_total / max(n_days, 1)),
                ]
                my_row1_cols = my_grid_left.columns(6)
                for i, (lbl, total_v, avg_v) in enumerate(row1_labels):
                    try:
                        vtxt = f"{float(total_v or 0.0):,.0f} bbls"
                        atxt = f"Avg: {float(avg_v or 0.0):,.0f} bbls/day"
                    except Exception:
                        vtxt = "-"
                        atxt = ""
                    label_html = _psc_label_html(lbl)
                    extra_cls = _psc_card_class(lbl)
                    html_card = f"""
                    <div class="stat-card stat-card--mini {extra_cls}">
                        {label_html}
                        <div class="stat-value">{html.escape(vtxt)}</div>
                        <div class="mb-note mb-note--avg">{html.escape(atxt)}</div>
                    </div>
                    """
                    my_row1_cols[i].markdown(html_card, unsafe_allow_html=True)

                my_row2_cols = my_grid_left.columns(3)
                for i, (lbl, total_v, avg_v) in enumerate(row2):
                    try:
                        vtxt = f"{float(total_v or 0.0):,.0f} bbls"
                        atxt = f"Avg: {float(avg_v or 0.0):,.0f} bbls/day"
                    except Exception:
                        vtxt = "-"
                        atxt = ""
                    label_html = _psc_label_html(lbl)
                    extra_cls = _psc_card_class(lbl)
                    html_card = f"""
                    <div class="stat-card stat-card--mini {extra_cls}">
                        {label_html}
                        <div class="stat-value">{html.escape(vtxt)}</div>
                        <div class="mb-note mb-note--avg">{html.escape(atxt)}</div>
                    </div>
                    """
                    my_row2_cols[i].markdown(html_card, unsafe_allow_html=True)

                # Monthly TOTAL card
                psc_total = float(
                    sum([aggu_total, anz_total, gpp_total, oguali_total, okw_total, ukpichi_total])
                )
                psc_evac_total = float(
                    (jetty_evac_total or 0.0) + (ndoni_evac_total or 0.0)
                )
                total_month_html = f"""
                <div class="stat-card stat-card--mini" style="height: 100%;">
                    {_psc_label_html("TOTAL")}
                    <div>
                        {_psc_label_html("PSC Production")}
                        <div class="stat-value">{psc_total:,.0f} bbls</div>
                        <div class="mb-note mb-note--avg">Avg: {(psc_total/max(n_days,1)):,.0f} bbls/day</div>
                    </div>
                    <div style="margin-top:0.75rem">
                        {_psc_label_html("PSC Evacuation")}
                        <div class="stat-value">{psc_evac_total:,.0f} bbls</div>
                        <div class="mb-note mb-note--avg">Avg: {(psc_evac_total/max(n_days,1)):,.0f} bbls/day</div>
                    </div>
                </div>
                """
                my_total_right.markdown(total_month_html, unsafe_allow_html=True)

                st.markdown("#### JV Block")
                jv_month_cols = st.columns(6)
                jv_month_items = [
                    ("OML-13 PRODUCTION", jv_oml13_prod),
                    ("OML-13 EVACUATION", jv_oml13_evac),
                    ("OML-26 PRODUCTION", jv_oml26_prod),
                    ("OML-26 EVACUATION", jv_oml26_evac),
                    ("FSO KALYANI RECEIPT", jv_kalyani_receipt),
                    ("TOTAL JV THROUGHPUT", jv_total_volume),
                ]
                for i, (lbl, total_v) in enumerate(jv_month_items):
                    try:
                        vtxt = f"{float(total_v or 0.0):,.0f} bbls"
                        atxt = f"Avg: {float((total_v or 0.0) / max(n_days, 1)):,.0f} bbls/day"
                    except Exception:
                        vtxt = "-"
                        atxt = ""
                    label_html = _psc_label_html(lbl)
                    html_card = f"""
                    <div class="stat-card stat-card--mini stat-card--jv">
                        {label_html}
                        <div class="stat-value">{html.escape(vtxt)}</div>
                        <div class="mb-note mb-note--avg">{html.escape(atxt)}</div>
                    </div>
                    """
                    jv_month_cols[i].markdown(html_card, unsafe_allow_html=True)

        # =====================================================================
        # TAB 1: STOCK POSITIONS (DONUT + SIDE DETAILS + FSO CYLINDERS)
        # =====================================================================
        with tabs[1]:
            st.markdown("### Stock Positions")

            stock_date = st.date_input(
                "Select date",
                value=st.session_state.get("lagos_stock_date", dp_date),
                key="lagos_stock_date",
            )

            aggu_cs = (
                _mb_value_for_column(
                    loc_aggu, stock_date, ["Closing Stock", "Book Closing Stock"]
                )
                if loc_aggu
                else 0.0
            )
            jetty_cs = (
                _mb_value_for_column(
                    loc_asemoku, stock_date, ["Closing Stock", "Book Closing Stock"]
                )
                if loc_asemoku
                else 0.0
            )
            beneku_cs = (
                _mb_value_for_column(
                    loc_bfs, stock_date, ["Closing Stock", "Book Closing Stock"]
                )
                if loc_bfs
                else 0.0
            )
            ndoni_cs = (
                _mb_value_for_column(
                    loc_ndoni, stock_date, ["Closing Stock", "Book Closing Stock"]
                )
                if loc_ndoni
                else 0.0
            )
            ogini_cs = (
                _mb_value_for_column(
                    loc_ogini, stock_date, ["Closing Stock", "Book Closing Stock"]
                )
                if loc_ogini
                else 0.0
            )
            utapate_cs = (
                _mb_value_for_column(
                    loc_utapate, stock_date, ["Closing Stock", "Book Closing Stock"]
                )
                if loc_utapate
                else 0.0
            )

            # GPP closing stock from GPP records
            gpp_cs = 0.0
            try:
                if loc_bfs:
                    recs = load_gpp_production_records(loc_bfs["id"], limit=2000)
                    df_gpp = pd.DataFrame(recs)
                    df_gpp["Date"] = pd.to_datetime(
                        df_gpp["Date"], errors="coerce"
                    ).dt.date
                    df_gpp = df_gpp[df_gpp["Date"] == stock_date]
                    if not df_gpp.empty:
                        gpp_cs = float(
                            pd.to_numeric(
                                df_gpp["GPP Closing Stock"], errors="coerce"
                            )
                            .fillna(0.0)
                            .sum()
                        )
            except Exception:
                gpp_cs = 0.0

            labels = [
                "Aggu",
                "Asemoku Jetty",
                "Beneku",
                "GPP",
                "Ndoni",
                "Ogini",
                "Utapate",
            ]
            values = [
                aggu_cs,
                jetty_cs,
                beneku_cs,
                gpp_cs,
                ndoni_cs,
                ogini_cs,
                utapate_cs,
            ]
            colors = [
                "#1f77b4",
                "#ff7f0e",
                "#2ca02c",
                "#d62728",
                "#9467bd",
                "#8c564b",
                "#e377c2",
            ]

            total_val = float(sum(values)) or 0.0

            # ---------- Helper: get FSO closing stock for a vessel on a date ----------
            from datetime import datetime as _dt, time as _t, timedelta as _td
            from db import get_session
            from models import FSOOperation

            def _get_fso_closing_stock_for_date(
                vessel_name: str, the_date
            ) -> float | None:
                try:
                    with get_session() as s_fso:
                        ext_from = the_date - _td(days=1)
                        ext_to = the_date + _td(days=1)

                        entries = (
                            s_fso.query(FSOOperation)
                            .filter(
                                FSOOperation.fso_vessel == vessel_name,
                                FSOOperation.date >= ext_from,
                                FSOOperation.date <= ext_to,
                            )
                            .order_by(FSOOperation.date, FSOOperation.time)
                            .all()
                        )
                    if not entries:
                        return None

                    win_start = _dt.combine(the_date, _t(6, 1))
                    win_end = _dt.combine(the_date + _td(days=1), _t(6, 0))

                    def _to_time(t):
                        if isinstance(t, _t):
                            return t
                        for fmt in ("%H:%M", "%H:%M:%S"):
                            try:
                                return _dt.strptime(str(t), fmt).time()
                            except Exception:
                                continue
                        return _t(0, 0)

                    period = []
                    for e in entries:
                        try:
                            edt = _dt.combine(e.date, _to_time(e.time))
                            if win_start <= edt <= win_end:
                                period.append(e)
                        except Exception:
                            continue

                    if not period:
                        return None

                    period.sort(key=lambda e: _dt.combine(e.date, _to_time(e.time)))

                    def _num(val):
                        try:
                            return float(val or 0.0)
                        except Exception:
                            return 0.0

                    last_entry = period[-1]
                    closing_stock = _num(getattr(last_entry, "closing_stock", None))

                    # Stock opening adjustment (same logic pattern as MB)
                    stock_opening_entries = [
                        e
                        for e in period
                        if (getattr(e, "operation", "") or "")
                        .strip()
                        .lower()
                        == "stock opening"
                    ]
                    if stock_opening_entries:
                        stock_opening_entry = stock_opening_entries[0]
                        stock_opening_closing = _num(
                            getattr(stock_opening_entry, "closing_stock", None)
                        )
                        try:
                            stock_opening_dt = _dt.combine(
                                stock_opening_entry.date,
                                _to_time(stock_opening_entry.time),
                            )
                            entries_before_opening = [
                                e
                                for e in period
                                if _dt.combine(e.date, _to_time(e.time))
                                < stock_opening_dt
                            ]
                            if entries_before_opening:
                                closing_stock = _num(
                                    getattr(
                                        entries_before_opening[-1],
                                        "closing_stock",
                                        None,
                                    )
                                )
                            else:
                                closing_stock = (
                                    stock_opening_closing
                                    if stock_opening_closing
                                    else closing_stock
                                )
                        except Exception:
                            pass

                    return closing_stock
                except Exception:
                    return None

            # ---------- Helper: FSO tank card (same cylindrical style as tank visuals) ----------
            import html as _html_mod

            def _fso_tank_card_html(
                title: str,
                stock_value: float | None,
                element_id: str,
                capacity: float = 1_880_000.0,
            ) -> tuple[str, int]:
                if stock_value is None:
                    return (
                        f"""
<div style="border:1px solid #dee2e6;border-radius:10px;padding:0.8rem;background:#fff;
            box-shadow:0 3px 8px rgba(0,0,0,0.06);margin-top:0.4rem;">
  <div style="text-align:center;font-weight:600;font-size:1rem;margin-bottom:0.3rem;">
    {_html_mod.escape(title)}
  </div>
  <div style="font-size:0.85rem;color:#666;text-align:center;padding:0.4rem 0;">
    No data for selected date
  </div>
</div>
""",
                        150,
                    )

                try:
                    current_stock = float(stock_value or 0.0)
                except Exception:
                    current_stock = 0.0

                cap = capacity if capacity > 0 else 1.0
                fill_percentage = max(0.0, min(current_stock / cap * 100.0, 100.0))

                # Same colour logic as tank visual
                if fill_percentage >= 80:
                    liquid_color = "#28a745"
                    liquid_dark = "#1e7e34"
                    status_emoji = "🟢"
                elif fill_percentage >= 50:
                    liquid_color = "#ffc107"
                    liquid_dark = "#d39e00"
                    status_emoji = "🟡"
                elif fill_percentage >= 20:
                    liquid_color = "#fd7e14"
                    liquid_dark = "#dc3545"
                    status_emoji = "🟠"
                else:
                    liquid_color = "#dc3545"
                    liquid_dark = "#bd2130"
                    status_emoji = "🔴"

                tank_height = 175.0
                liquid_height = (fill_percentage / 100.0) * tank_height
                liquid_y = tank_height - liquid_height

                svg_code = f"""
<svg width="100%" height="230" viewBox="0 0 150 220" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <linearGradient id="tankGrad_{element_id}" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#c0c0c0;stop-opacity:1" />
      <stop offset="50%" style="stop-color:#e8e8e8;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#c0c0c0;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="liquidGrad_{element_id}" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:{liquid_dark};stop-opacity:0.9" />
      <stop offset="50%" style="stop-color:{liquid_color};stop-opacity:1" />
      <stop offset="100%" style="stop-color:{liquid_dark};stop-opacity:0.9" />
    </linearGradient>
    <radialGradient id="topGrad_{element_id}" cx="50%" cy="50%" r="50%">
      <stop offset="0%" style="stop-color:#ffffff;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#d0d0d0;stop-opacity:1" />
    </radialGradient>
    <radialGradient id="bottomGrad_{element_id}" cx="50%" cy="50%" r="50%">
      <stop offset="0%" style="stop-color:#a0a0a0;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#707070;stop-opacity:1" />
    </radialGradient>
  </defs>

  <!-- Stock badge (smaller) -->
  <rect x="92" y="8" width="52" height="20" rx="10" fill="{liquid_color}" opacity="0.95"/>
  <text x="118" y="22" text-anchor="middle" fill="white" font-size="11" font-weight="bold">
    {current_stock/1000.0:.1f}K
  </text>

  <!-- Tank top ellipse -->
  <ellipse cx="75" cy="35" rx="42" ry="13"
           fill="url(#topGrad_{element_id})" stroke="#999" stroke-width="1.5"/>

  <!-- Tank body -->
  <rect x="33" y="35" width="84" height="{tank_height}"
        fill="url(#tankGrad_{element_id})" stroke="#999" stroke-width="1.5"/>

  <!-- Liquid fill -->
  <rect x="33" y="{35 + liquid_y}" width="84" height="{liquid_height}"
        fill="url(#liquidGrad_{element_id})"/>

  <!-- Liquid top surface -->
  <ellipse cx="75" cy="{35 + liquid_y}" rx="42" ry="13"
           fill="{liquid_color}" opacity="0.8"/>

  <!-- Percentage text -->
  <text x="75" y="{35 + tank_height/2:.1f}" text-anchor="middle"
        fill="white" font-size="26" font-weight="bold"
        style="text-shadow:2px 2px 4px rgba(0,0,0,0.7);">
    {fill_percentage:.0f}%
  </text>

  <!-- Tank bottom ellipse -->
  <ellipse cx="75" cy="{35 + tank_height}" rx="42" ry="13"
           fill="url(#bottomGrad_{element_id})" stroke="#666" stroke-width="1.5"/>

  <!-- Shadow -->
  <ellipse cx="75" cy="{38 + tank_height}" rx="44" ry="6"
           fill="black" opacity="0.2"/>
</svg>
"""

                available = max(cap - current_stock, 0.0)

                return (
                    f"""
<div style="border:1px solid #dee2e6;border-radius:12px;padding:1rem;background:#fff;
            box-shadow:0 4px 10px rgba(0,0,0,0.08);margin-top:0.5rem;">
  <div style="text-align:center;font-weight:600;font-size:1rem;margin-bottom:0.4rem;">
    {_html_mod.escape(title)}
  </div>
  {svg_code}
  <div style="margin-top:0.6rem;font-size:0.82rem;color:#333;">
    <div style="display:flex;justify-content:space-between;margin-bottom:0.35rem;border-bottom:1px solid #f1f1f1;padding-bottom:0.2rem;">
      <span style="color:#666;">Stock (bbls)</span>
      <strong style="color:{liquid_color};font-size:0.9rem;">{current_stock:,.0f}</strong>
    </div>
    <div style="display:flex;justify-content:space-between;margin-bottom:0.35rem;border-bottom:1px solid #f1f1f1;padding-bottom:0.2rem;">
      <span style="color:#666;">Capacity (bbls)</span>
      <strong style="font-size:0.9rem;">{cap:,.0f}</strong>
    </div>
    <div style="display:flex;justify-content:space-between;margin-bottom:0.35rem;border-bottom:1px solid #f1f1f1;padding-bottom:0.2rem;">
      <span style="color:#666;">Available (bbls)</span>
      <strong style="font-size:0.9rem;">{available:,.0f}</strong>
    </div>
    <div style="display:flex;justify-content:space-between;margin-bottom:0.1rem;">
      <span style="color:#666;">Level</span>
      <strong style="color:{liquid_color};font-size:0.9rem;">{status_emoji} {fill_percentage:.1f}%</strong>
    </div>
  </div>
</div>
""",
                    420,
                )

            # Layout: donut + FSO cylinders on the left, custom details list on the right
            col_chart, col_legend = st.columns([2, 1])

            # ------------------ LEFT: DONUT + FSO CYLINDERS ------------------
            with col_chart:
                # Donut chart with values inside (bold)
                fig = go.Figure(
                    data=[
                        go.Pie(
                            labels=labels,
                            values=values,
                            hole=0.5,
                            marker=dict(colors=colors),
                            textinfo="value",          # only values
                            textposition="inside",     # inside the donut
                            texttemplate="<b>%{value:,.0f}</b>",
                            hoverinfo="label+value",   # no %
                            showlegend=False,
                        )
                    ]
                )
                fig.update_traces(textfont=dict(size=12, color="#000000"))
                fig.update_layout(
                    title_text=f"Stock Positions as of {stock_date.strftime('%d-%b-%Y')}",
                    margin=dict(t=40, b=20, l=0, r=0),
                )
                st.plotly_chart(fig, use_container_width=True)

                # FSO cylindrical visuals � same look & feel as tank cards
                st.markdown("#### FSO Stock Position")

                fso_cols = st.columns(2)

                tanvi_stock = _get_fso_closing_stock_for_date(
                    "MT TULJA TANVI", stock_date
                )
                kalyani_stock = _get_fso_closing_stock_for_date(
                    "MT TULJA KALYANI", stock_date
                )

                with fso_cols[0]:
                    tanvi_html, tanvi_height = _fso_tank_card_html(
                        "MT TULJA TANVI", tanvi_stock, "tanvi"
                    )
                    components.html(tanvi_html, height=tanvi_height)

                with fso_cols[1]:
                    kalyani_html, kalyani_height = _fso_tank_card_html(
                        "MT TULJA KALYANI", kalyani_stock, "kalyani"
                    )
                    components.html(kalyani_html, height=kalyani_height)

            # ------------------ RIGHT: DETAILS LIST ------------------
            with col_legend:
                st.markdown("#### Details")
                if total_val <= 0:
                    st.markdown(
                        "<p>No stock data available for the selected date.</p>",
                        unsafe_allow_html=True,
                    )
                else:
                    legend_lines = []
                    for lbl, val, col in zip(labels, values, colors):
                        try:
                            vtxt = f"{float(val or 0.0):,.0f} bbls"
                        except Exception:
                            vtxt = "-"

                        legend_lines.append(
                            f"""
                            <div style="display:flex;align-items:center;margin-bottom:4px;">
                                <span style="
                                    display:inline-block;
                                    width:10px;
                                    height:10px;
                                    border-radius:50%;
                                    background:{col};
                                    margin-right:8px;
                                "></span>
                                <span>
                                    <strong>{html.escape(lbl)}</strong><br/>
                                    <strong>{html.escape(vtxt)}</strong>
                                </span>
                            </div>
                            """
                        )

                    st.markdown("".join(legend_lines), unsafe_allow_html=True)

            # =====================================================================
            # CONVOY & VESSEL STATUS SECTION
            # =====================================================================
            st.markdown("---")
            st.markdown("### 🚦 Convoy & Vessel Status")
            st.caption(f"Saved entries from Convoy Status page for {stock_date.strftime('%d-%b-%Y')}")
            
            convoy_col, vessel_col = st.columns(2)
            yade_entries_all: list[dict[str, str]] = []
            vessel_entries_all: list[dict[str, str]] = []
            fetch_error = None
            
            try:
                from models import ConvoyStatusYade, ConvoyStatusVessel
                
                # Get location IDs for Agge and Utapate
                with get_session() as s_loc:
                    locations = s_loc.query(Location).all()
                    
                    def _canon_token(v):
                        return str(v or "").upper().replace(" ", "").replace("-", "")
                    
                    agge_loc = None
                    utapate_loc = None
                    
                    for L in locations:
                        loc_tokens = {_canon_token(L.code), _canon_token(L.name)}
                        if loc_tokens & {"AGGE"}:
                            agge_loc = L
                        if loc_tokens & {"UTAPATE", "OML13", "OML-13"}:
                            utapate_loc = L
                
                # Fetch convoy status entries for both locations
                with get_session() as s_convoy:
                    # Query YADE entries from both Agge and Utapate
                    for loc in [agge_loc, utapate_loc]:
                        if not loc:
                            continue
                        
                        yade_rows = (
                            s_convoy.query(ConvoyStatusYade, YadeBarge.name)
                            .join(YadeBarge, ConvoyStatusYade.yade_barge_id == YadeBarge.id)
                            .filter(
                                ConvoyStatusYade.location_id == loc.id,
                                ConvoyStatusYade.date == stock_date,
                            )
                            .order_by(ConvoyStatusYade.status.asc(), YadeBarge.name.asc())
                            .all()
                        )
                        
                        for rec, yade_name in yade_rows:
                            yade_entries_all.append(
                                {
                                    "Location": loc.name or "N/A",
                                    "Status": (rec.status or "N/A").strip(),
                                    "YADE": yade_name or "N/A",
                                    "Convoy": rec.convoy_no or "N/A",
                                    "Stock": rec.stock_display or "N/A",
                                    "Notes": rec.notes or "",
                                }
                            )
                    
                    # Query Vessel entries from both Agge and Utapate
                    for loc in [agge_loc, utapate_loc]:
                        if not loc:
                            continue
                        
                        vessel_rows = (
                            s_convoy.query(ConvoyStatusVessel)
                            .filter(
                                ConvoyStatusVessel.location_id == loc.id,
                                ConvoyStatusVessel.date == stock_date,
                            )
                            .order_by(ConvoyStatusVessel.vessel_name.asc())
                            .all()
                        )
                        
                        for rec in vessel_rows:
                            vessel_entries_all.append(
                                {
                                    "Location": loc.name or "N/A",
                                    "Vessel": (rec.vessel_name or "N/A").strip(),
                                    "Status": (rec.status or "N/A").strip(),
                                    "Shuttle": rec.shuttle_no or "N/A",
                                    "Stock": rec.stock_display or "N/A",
                                    "Notes": rec.notes or "",
                                }
                            )
                            
            except Exception as exc:
                fetch_error = str(exc)
                log_error("Convoy/vessel snapshot load failed in Lagos Dashboard", exc_info=True)
            
            if fetch_error:
                st.error(f"Unable to load convoy status snapshots: {fetch_error}")
            
            # Sort entries
            yade_entries_all.sort(key=lambda item: (item["Location"], item["Status"], item["YADE"]))
            vessel_entries_all.sort(key=lambda item: (item["Location"], item["Vessel"]))
            
            # Display YADE convoy status
            with convoy_col:
                st.markdown("#### Convoy Status (YADE)")
                if not yade_entries_all:
                    st.info("No YADE convoy statuses saved for this date.")
                else:
                    # Group by location
                    location_groups = defaultdict(list)
                    for entry in yade_entries_all:
                        location_groups[entry["Location"]].append(entry)
                    
                    for location in sorted(location_groups):
                        st.markdown(f"**{location}**")
                        entries = location_groups[location]
                        
                        # Group by status within location
                        status_groups = defaultdict(list)
                        for entry in entries:
                            status_groups[entry["Status"]].append(entry)
                        
                        for status in sorted(status_groups):
                            st.markdown(f"*{status}*")
                            for entry in status_groups[status]:
                                notes_text = f" � {entry['Notes']}" if entry['Notes'] else ""
                                st.markdown(
                                    f"- {entry['YADE']} | Convoy: {entry['Convoy']} | Stock: {entry['Stock']}{notes_text}"
                                )
                        st.markdown("")  # Add spacing between locations
            
            # Display Vessel status
            with vessel_col:
                st.markdown("#### Vessel Status")
                if not vessel_entries_all:
                    st.info("No vessel statuses saved for this date.")
                else:
                    # Group by location
                    location_groups = defaultdict(list)
                    for entry in vessel_entries_all:
                        location_groups[entry["Location"]].append(entry)
                    
                    for location in sorted(location_groups):
                        st.markdown(f"**{location}**")
                        for entry in location_groups[location]:
                            notes_text = f" � {entry['Notes']}" if entry['Notes'] else ""
                            st.markdown(
                                f"- **{entry['Vessel']}** � {entry['Status']} (Shuttle: {entry['Shuttle']}, Stock: {entry['Stock']}){notes_text}"
                            )
                        st.markdown("")  # Add spacing between locations

        st.stop()

    # ======================= VIEW PDF (visual � exact dashboard look) =======================
    # Put this near the top of the dashboard page (above Summary Statistics).
    import json
    import math
    import pandas as pd
    import streamlit as st
    import streamlit.components.v1 as components
    from datetime import date as _date, datetime, timedelta, time as dt_time
    from db import get_session

    # Fallbacks if your helpers aren't defined above in your file (keep or remove if you already have them).
    try:
        _build_tank_svg_card_html
    except NameError:
        def _build_tank_svg_card_html(
            *,
            tank: str,
            stock_bbl: float,
            capacity_bbl: float,
            product_name: str,
            status_text: str,
            tank_code: str,
        ) -> str:
            cap = max(float(capacity_bbl or 0.0), 0.0)
            stock = max(float(stock_bbl or 0.0), 0.0)
            cap_safe = cap if cap > 0 else 1.0
            fill_pct = max(0.0, min((stock / cap_safe) * 100.0, 100.0))
            available = max(cap - stock, 0.0)
            status = (status_text or "UNKNOWN").strip()
            status_class = "ok"
            if status.upper() in {"CRITICAL", "FAULT", "DOWN"}:
                status_class = "bad"
            elif status.upper() in {"ALERT", "MAINTENANCE"}:
                status_class = "warn"

            return f"""
            <div class="tank-card">
                <div class="tank-card__header">
                    <span class="tank-card__name">{html.escape(tank or tank_code)}</span>
                    <span class="tank-card__code">{html.escape(tank_code)}</span>
                </div>
                <div class="tank-card__product">{html.escape(product_name or "N/A")}</div>
                <div class="tank-gauge">
                    <div class="tank-gauge__fill" style="height:{fill_pct:.1f}%"></div>
                    <div class="tank-gauge__overlay">
                        <span>{fill_pct:.0f}%</span>
                    </div>
                </div>
                <div class="tank-card__stats">
                    <div><label>Stock</label><strong>{stock:,.0f}</strong></div>
                    <div><label>Capacity</label><strong>{cap:,.0f}</strong></div>
                    <div><label>Available</label><strong>{available:,.0f}</strong></div>
                </div>
                <div class="tank-card__status tank-card__status--{status_class}">
                    {html.escape(status or "UNKNOWN")}
                </div>
            </div>
            """
    def _norm_status(val):
        """Return UPPERCASED string status safely from str/Enum/None."""
        try:
            if val is None:
                return ""
            if isinstance(val, str):
                return val.strip().upper()
            # Enum-like object support
            if hasattr(val, "value") and val.value is not None:
                return str(val.value).strip().upper()
            if hasattr(val, "name") and val.name is not None:
                return str(val.name).strip().upper()
            return str(val).strip().upper()
        except Exception:
            try:
                return str(val).strip().upper()
            except Exception:
                return ""

    def _canon(txt: str) -> str:
        return str(txt or "").upper().replace(" ", "").replace("-", "")

    def _fmt0(v):
        try:
            if v is None: return "-"
            if isinstance(v, (int, float)): return f"{v:,.0f}"
            return str(v)
        except Exception:
            return "-"

    def _find_col(df: pd.DataFrame, cands):
        if df is None or df.empty: return None
        for c in cands:
            if c in df.columns: return c
        lower = {str(c).strip().lower(): c for c in df.columns}
        for c in cands:
            lc = str(c).strip().lower()
            if lc in lower: return lower[lc]
        return None

    def _canonical_fso_code(code: str | None) -> str:
        if not code: return ""
        s2 = str(code).strip().upper()
        s_norm = s2.replace(" ", "").replace("-", "")
        aliases = {"UTAPATE":"OML-13","OML13":"OML-13","OML-13":"OML-13","OML 13":"OML-13","AGGE":"AGGE"}
        return aliases.get(s2, aliases.get(s_norm, s2))

    # ---------- Pull FSO �Exports (bbls)� from session caches over a range (used in Monthly Data) ----------
    def _sum_exports_from_session(md_from, md_to, canon_loc: str, vessel_name="MT TULJA KALYANI"):
        keys = [
            "fso_mb_df","fso_mb_table","fso_material_balance_df",
            "fso_mb_daily","fso_mb_cache","fso_mb_summary_df",
            "fso_mb_pivot","fso_mb_records"
        ]
        def _pick(df: pd.DataFrame):
            if df is None or df.empty: return None
            dcol = _find_col(df, ["Date","MB Date","As Of","Asof"])
            if not dcol: return None
            dfx = df.copy()
            dfx[dcol] = pd.to_datetime(dfx[dcol], errors="coerce").dt.date
            dfx = dfx[(dfx[dcol] >= md_from) & (dfx[dcol] <= md_to)]
            if dfx.empty: return None
            lcol = _find_col(dfx, ["Location","Loc","Site","Code"])
            if lcol is not None and canon_loc:
                norm = dfx[lcol].astype(str).str.upper().str.replace(" ","",regex=False).str.replace("-","",regex=False)
                dfx = dfx[norm == canon_loc.replace("-","").replace(" ","")]
                if dfx.empty: return None
            vcol = _find_col(dfx, ["Vessel","FSO Vessel","Vessel Name","fso_vessel"])
            if vcol is not None and vessel_name:
                dfx = dfx[dfx[vcol].astype(str).str.upper().str.contains(vessel_name.upper())]
                if dfx.empty: return None
            ecol = _find_col(dfx, ["Exports (bbls)","Export (bbls)","exports_bbls","export_bbls","Exports","Export"])
            if ecol is None: return None
            return float(pd.to_numeric(dfx[ecol], errors="coerce").fillna(0).sum())
        # Try known keys
        for k in keys:
            if k in st.session_state:
                try:
                    obj = st.session_state[k]
                    df = obj.copy() if isinstance(obj, pd.DataFrame) else pd.DataFrame(obj)
                    val = _pick(df)
                    if val is not None:
                        return val
                except Exception:
                    pass
        # Try all DataFrame-like objects in session as a last resort
        for k, obj in list(st.session_state.items()):
            try:
                if isinstance(obj, pd.DataFrame):
                    df = obj
                elif isinstance(obj, (list, tuple)) and obj and isinstance(obj[0], dict):
                    df = pd.DataFrame(obj)
                else:
                    continue
                if df is None or df.empty: 
                    continue
                val = _pick(df.copy())
                if val is not None:
                    return val
            except Exception:
                continue
        return None

    # ---------- Build an SVG trend (so PDF matches the dashboard visually) ----------
    def _build_trend_svg_for_pdf(s, loc_code: str, tr_from: _date, tr_to: _date, width=900, height=360):
        from material_balance_calculator import MaterialBalanceCalculator as MBCalc

        # Prepare date index
        dates = pd.date_range(tr_from, tr_to, freq="D").date.tolist()
        if not dates:
            return '<svg width="100%" height="1"></svg>'

        # Pull material balance rows for the range
        try:
            rows = MBCalc.calculate_material_balance(
                entries=None,
                location_code=(loc_code or "").upper(),
                date_from=tr_from,
                date_to=tr_to,
                location_id=active_location_id,
                debug=False
            )
            df = pd.DataFrame(rows) if rows else pd.DataFrame({"Date": dates})
        except Exception:
            df = pd.DataFrame({"Date": dates})

        # Find date column
        dcol = _find_col(df, ["Date","MB Date","As Of","Asof"]) or "Date"
        if dcol not in df.columns:
            df[dcol] = dates
        df[dcol] = pd.to_datetime(df[dcol], errors="coerce").dt.date

        # Determine location profile (Utapate vs Asemoku)
        is_asemoku = _canon(loc_code) in {"JETTY","ASEMOKU","ASEMOKUJETTY"}
        series_defs = []
        if is_asemoku:
            # 3 lines: ANZ Production, BFS Receipt, Evacuation
            series_defs = [
                ("ANZ Production", ["ANZ Receipt"], "#8B4513"),  # brown
                ("BFS Receipt",    ["OKW Receipt"], "#006400"),  # dark green
                ("Evacuation",     ["Dispatch to barge","Dispatch to Barge","Dispatch"], "#1f77b4"),  # blue
            ]
        else:
            # Utapate (and others like OML-13): 2 lines: Production, Evacuation
            series_defs = [
                ("Production", ["Receipt"], "#8B4513"),  # brown
                ("Evacuation", ["Dispatch"], "#006400"), # dark green
            ]

        # Build a merged daily frame
        base = pd.DataFrame({ "date": dates })
        for label, cand_cols, _color in series_defs:
            col = None
            for c in cand_cols:
                if c in df.columns: 
                    col = c; break
            if not col:
                # try case-insensitive
                lower_map = {str(c).lower(): c for c in df.columns}
                for c in cand_cols:
                    if c.lower() in lower_map:
                        col = lower_map[c.lower()]
                        break
            if col:
                sub = df[[dcol, col]].copy()
                sub.columns = ["date", label]
                base = base.merge(sub, on="date", how="left")
            else:
                base[label] = 0.0
        # Fill
        for label, _, _ in series_defs:
            base[label] = pd.to_numeric(base[label], errors="coerce").fillna(0.0)

        # Compute y scale
        y_max = max([base[l].max() for l,_,_ in series_defs] + [0.0])
        if y_max <= 0: y_max = 1.0
        y_max = float(y_max * 1.10)  # headroom

        # SVG layout
        W, H = width, height
        left, right, top, bottom = 60, 20, 20, 60
        plot_w, plot_h = W - left - right, H - top - bottom

        def x_pos(d):
            return left + (plot_w * (dates.index(d) / max(len(dates)-1, 1)))
        def y_pos(v):
            return top + plot_h - (plot_h * (float(v) / y_max))

        # Build paths & markers
        series_paths = []
        labels = []
        # For global highest/lowest highlight (single label per your requirement)
        all_points = []
        for label, _cands, color in series_defs:
            pts = [(x_pos(d), y_pos(base.loc[base['date']==d, label].values[0])) for d in dates]
            # path
            if pts:
                d_attr = "M " + " L ".join([f"{x:.1f},{y:.1f}" for x,y in pts])
            else:
                d_attr = ""
            series_paths.append(f'<path d="{d_attr}" fill="none" stroke="{color}" stroke-width="2"/>')
            # triangle markers
            tris = []
            for (x,y), d in zip(pts, dates):
                tris.append(f'<path d="M {x:.1f},{y-5:.1f} L {x-5:.1f},{y+5:.1f} L {x+5:.1f},{y+5:.1f} Z" fill="{color}" />')
                all_points.append((label, d, base.loc[base["date"]==d, label].values[0], x, y, color))
            series_paths.append("".join(tris))

        # Determine single highest & single lowest across all series
        if all_points:
            max_pt = max(all_points, key=lambda r: float(r[2] or 0.0))
            min_pt = min(all_points, key=lambda r: float(r[2] or 0.0))
            for (tag, pt, anchor) in [("MAX", max_pt, "start"), ("MIN", min_pt, "end")]:
                _lbl, _date, _val, _x, _y, _col = pt
                _txt = f"{_lbl}: {_fmt0(_val)}"
                _xo = 8 if tag=="MAX" else -8
                labels.append(
                    f'<text x="{_x+_xo:.1f}" y="{_y-8:.1f}" font-size="12" font-weight="bold" fill="#000" text-anchor="{anchor}">{_txt}</text>'
                )

        # Grid & axes
        # Y ticks (5)
        y_ticks = []
        for i in range(0,6):
            v = (y_max/5)*i
            y = y_pos(v)
            y_ticks.append(f'<line x1="{left}" y1="{y:.1f}" x2="{left+plot_w}" y2="{y:.1f}" stroke="#eaeaea"/>')
            y_ticks.append(f'<text x="{left-8}" y="{y+4:.1f}" font-size="11" fill="#555" text-anchor="end">{_fmt0(v)}</text>')

        # X ticks: one per day
        x_ticks = []
        for d in dates:
            x = x_pos(d)
            if len(dates) <= 31 or dates.index(d) % max(1, math.ceil(len(dates)/31)) == 0:
                x_ticks.append(f'<text x="{x:.1f}" y="{top+plot_h+18:.1f}" font-size="11" fill="#555" text-anchor="middle">{pd.to_datetime(d).strftime("%d-%b")}</text>')

        # Legend
        legend_items = []
        lx = left; ly = top - 5
        for label, _c, color in series_defs:
            legend_items.append(f'<rect x="{lx}" y="{ly}" width="10" height="10" fill="{color}" />')
            legend_items.append(f'<text x="{lx+14}" y="{ly+10}" font-size="12" fill="#222">{label}</text>')
            lx += 130

        # Axis titles
        axis_titles = [
            f'<text x="{left + plot_w/2:.1f}" y="{top+plot_h+40:.1f}" font-size="12" fill="#222" text-anchor="middle">Date</text>',
            f'<text transform="translate({left-45:.1f},{top+plot_h/2:.1f}) rotate(-90)" font-size="12" fill="#222" text-anchor="middle">Quantity in bbls</text>'
        ]

        svg = f'''
        <svg width="{W}" height="{H}" viewBox="0 0 {W} {H}" xmlns="http://www.w3.org/2000/svg">
        <rect x="0" y="0" width="{W}" height="{H}" fill="#fff"/>
        <!-- Legend -->
        {''.join(legend_items)}
        <!-- Plot area -->
        <rect x="{left}" y="{top}" width="{plot_w}" height="{plot_h}" fill="#fff" stroke="#ddd"/>
        <!-- Grid & Axes -->
        {''.join(y_ticks)}
        {''.join(x_ticks)}
        <!-- Series paths -->
        {''.join(series_paths)}
        <!-- Highlight labels -->
        {''.join(labels)}
        <!-- Axis titles -->
        {''.join(axis_titles)}
        <!-- In-plot totals card (top-right) -->
        <rect x="{left+plot_w-200}" y="{top+10}" width="190" height="52" rx="8" fill="rgba(255,255,255,0.95)" stroke="#ddd"/>
        <text x="{left+plot_w-105}" y="{top+30}" text-anchor="middle" font-size="12" fill="#222">
            Totals: {' / '.join([f'{name} '+_fmt0(base[name].sum()) for name,_,_ in series_defs])}
        </text>
        </svg>
        '''
        return svg

    # ---------- Build HTML snapshot for the 4 sections ----------
    def _build_dashboard_html_for_pdf():
        with get_session() as s:
            # Location & dates
            try:
                from location_manager import LocationManager
                loc_obj = LocationManager.get_location_by_id(s, active_location_id)
                loc_code = (getattr(loc_obj, "code", "") or "")
                loc_name = (getattr(loc_obj, "name", "") or "")
            except Exception:
                loc_code, loc_name = "", ""
            canon_loc = _canonical_fso_code(loc_code)
            is_asemoku = _canon(loc_code) in {"JETTY","ASEMOKU","ASEMOKUJETTY"}
            is_utapate = _canon(loc_code) in {"UTAPATE","OML13","OML-13"}

            sel_date = st.session_state.get("dash_date_all_sites", _date.today())
            md_from  = st.session_state.get("monthly_from", sel_date.replace(day=1))
            md_to    = st.session_state.get("monthly_to", sel_date)
            tr_from  = st.session_state.get("trend_from", sel_date.replace(day=1))
            tr_to    = st.session_state.get("trend_to", sel_date)

            # ===== Summary (same mapping you already use) =====
            prod_bbl = 0.0; evac_bbl = 0.0; fso_receipt_bbl = None; fso_stock_bbl = None
            try:
                from material_balance_calculator import MaterialBalanceCalculator as MBCalc
                rows = MBCalc.calculate_material_balance(
                    entries=None, location_code=(loc_code or "").upper(),
                    date_from=sel_date, date_to=sel_date,
                    location_id=active_location_id, debug=False
                )
                if rows:
                    r = pd.DataFrame(rows).iloc[0].to_dict()
                    prod_bbl = float(r.get("Receipt", 0) or 0)
                    evac_bbl = float(r.get("Dispatch", 0) or 0)
            except Exception:
                pass

            # FSO receipt & stock (same day)
            def _fso_from_cache(date_, code_):
                keys = ["fso_mb_df","fso_mb_table","fso_material_balance_df","fso_mb_daily","fso_mb_cache","fso_mb_summary_df","fso_mb_pivot","fso_mb_records"]
                canon = _canonical_fso_code(code_)
                for k in keys:
                    if k not in st.session_state: continue
                    obj = st.session_state[k]
                    try:
                        df = obj.copy() if isinstance(obj, pd.DataFrame) else pd.DataFrame(obj)
                    except Exception:
                        continue
                    if df is None or df.empty: continue
                    dcol = _find_col(df, ["Date","MB Date","As Of","Asof"])
                    if not dcol: continue
                    dfx = df.copy()
                    dfx[dcol] = pd.to_datetime(dfx[dcol], errors="coerce").dt.date
                    dfx = dfx[dfx[dcol] == date_]
                    if dfx.empty: continue
                    lcol = _find_col(dfx, ["Location","Loc","Site","Code"])
                    if lcol is not None and canon:
                        norm = dfx[lcol].astype(str).str.upper().str.replace(" ","",regex=False).str.replace("-","",regex=False)
                        dfx = dfx[norm == canon.replace("-","").replace(" ","")]
                        if dfx.empty: continue
                    c_rec = _find_col(dfx, ["Receipt (bbls)","Receipts (bbls)","receipt_bbls","receipts","receipt"])
                    c_cls = _find_col(dfx, ["Closing Stock (bbls)","Closing Stock","closing_stock","closing_stock_bbl"])
                    rec = float(pd.to_numeric(dfx[c_rec], errors="coerce").fillna(0).sum()) if c_rec else None
                    cls = None
                    if c_cls is not None:
                        srs = pd.to_numeric(dfx[c_cls], errors="coerce").dropna()
                        if not srs.empty: cls = float(srs.iloc[-1])
                    if rec is not None or cls is not None:
                        return rec, cls
                return None, None

            fso_receipt_bbl, fso_stock_bbl = _fso_from_cache(sel_date, loc_code)

            # ===== Ullage & Pumpable (status aware) =====
            try:
                from models import Tank, TankTransaction, OTRRecord
                tanks = s.query(Tank).filter(Tank.location_id == active_location_id).order_by(Tank.name).all()
            except Exception:
                tanks = []

            ullage_available_bbl = 0.0
            pumpable_stock_bbl   = 0.0
            for t in tanks:
                latest = (
                    s.query(TankTransaction.ticket_id, TankTransaction.date, TankTransaction.time)
                    .filter(TankTransaction.tank_id == t.id, TankTransaction.date <= sel_date)
                    .order_by(TankTransaction.date.desc(), TankTransaction.time.desc())
                    .first()
                )
                stock = 0.0
                if latest and latest.ticket_id:
                    otr = s.query(OTRRecord).filter(OTRRecord.ticket_id == latest.ticket_id).first()
                    stock = float(getattr(otr, "nsv_bbl", 0.0) or 0.0)
                cap = float(getattr(t, "capacity_bbl", 0.0) or 0.0)
                ullage_available_bbl += 0.90 * max(cap - stock, 0.0)

                # ---- FIXED: normalize Enum/string status safely ----
                status_norm = _norm_status(getattr(t, "status", None))
                if status_norm in {"IDLE","READY","DISPATCHING"}:
                    pumpable_stock_bbl += 0.85 * stock

            # ===== Tank visuals HTML (same card design you use) =====
            tank_html = ""
            if tanks:
                tank_html += '<div class="tanks-grid">'
                for t in tanks:
                    latest = (
                        s.query(TankTransaction.ticket_id, TankTransaction.date, TankTransaction.time)
                        .filter(TankTransaction.tank_id == t.id, TankTransaction.date <= sel_date)
                        .order_by(TankTransaction.date.desc(), TankTransaction.time.desc())
                        .first()
                    )
                    stock = 0.0
                    if latest and latest.ticket_id:
                        otr = s.query(OTRRecord).filter(OTRRecord.ticket_id == latest.ticket_id).first()
                        stock = float(getattr(otr, "nsv_bbl", 0.0) or 0.0)
                    cap  = float(getattr(t, "capacity_bbl", 0.0) or 0.0)
                    prod = getattr(t, "product_type", getattr(t, "product", "N/A"))
                    code = getattr(t, "code", f"T-{t.id}")

                    # ---- FIXED: friendly display for Enum/string status ----
                    status_norm = _norm_status(getattr(t, "status", None))
                    status_disp = status_norm.title() if status_norm else "-"

                    tank_html += _build_tank_svg_card_html(
                        tank=getattr(t, "name", code),
                        stock_bbl=stock, capacity_bbl=cap,
                        product_name=prod, status_text=status_disp, tank_code=code
                    )
                tank_html += "</div>"
            else:
                tank_html = '<div style="color:#6c757d;">No tanks configured.</div>'

            # ===== Monthly Data (reuse cached HTML if present) =====
            monthly_html = st.session_state.get('__monthly_html_for_pdf', '')
            if not monthly_html:
                # Calculate as in dashboard (Utapate & Asemoku mappings)
                from material_balance_calculator import MaterialBalanceCalculator as MBCalc
                mb_rows = MBCalc.calculate_material_balance(
                    entries=None,
                    location_code=(loc_code or "").upper(),
                    date_from=md_from,
                    date_to=md_to,
                    location_id=active_location_id,
                    debug=False
                )
                df_mb = pd.DataFrame(mb_rows) if mb_rows else pd.DataFrame({"Date":[]})
                def pick(df, cands):
                    if df.empty: return None
                    for c in cands:
                        if c in df.columns: return c
                    low = {str(c).lower(): c for c in df.columns}
                    for c in cands:
                        if c.lower() in low: return low[c.lower()]
                    return None

                if is_utapate:
                    c_rec = pick(df_mb, ["Receipt"])
                    c_dis = pick(df_mb, ["Dispatch"])
                    prod_total = float(pd.to_numeric(df_mb[c_rec], errors="coerce").fillna(0).sum()) if c_rec else 0.0
                    evac_total = float(pd.to_numeric(df_mb[c_dis], errors="coerce").fillna(0).sum()) if c_dis else 0.0
                    days_count = max(len(pd.date_range(md_from, md_to)), 1)
                    avg_prod = prod_total / days_count
                    avg_evac = evac_total / days_count
                    export_total = _sum_exports_from_session(md_from, md_to, canon_loc, "MT TULJA KALYANI")

                    monthly_html = f"""
                    <div class="section">
                    <h2>📊 Monthly Data</h2>
                    <div class="cards four">
                        <div class="stat-card">
                        <div class="stat-label">Production</div>
                        <div class="stat-value">{_fmt0(prod_total)}</div>
                        <div style="color:#6c757d;font-size:0.8rem;">Avg Production: {_fmt0(avg_prod)}</div>
                        </div>
                        <div class="stat-card">
                        <div class="stat-label">Evacuation</div>
                        <div class="stat-value">{_fmt0(evac_total)}</div>
                        <div style="color:#6c757d;font-size:0.8rem;">Avg Evacuation: {_fmt0(avg_evac)}</div>
                        </div>
                        <div class="stat-card">
                        <div class="stat-label">Export (MT TULJA KALYANI)</div>
                        <div class="stat-value">{_fmt0(export_total)}</div>
                        <div style="color:#6c757d;font-size:0.8rem;">{_fmt0(days_count)} days</div>
                        </div>
                        <div class="stat-card">
                        <div class="stat-label">Vessel Status &amp; Stock</div>
                        <div class="stat-value">-</div>
                        <div style="color:#6c757d;font-size:0.8rem;">(to be wired)</div>
                        </div>
                    </div>
                    </div>
                    """
                else:
                    c_anz = pick(df_mb, ["ANZ Receipt"])
                    c_okw = pick(df_mb, ["OKW Receipt"])
                    c_dis = pick(df_mb, ["Dispatch to barge","Dispatch"])
                    anz_total  = float(pd.to_numeric(df_mb[c_anz], errors="coerce").fillna(0).sum()) if c_anz else 0.0
                    bfs_total  = float(pd.to_numeric(df_mb[c_okw or c_dis], errors="coerce").fillna(0).sum()) if (c_okw or c_dis) else 0.0
                    evac_total = float(pd.to_numeric(df_mb[c_dis], errors="coerce").fillna(0).sum()) if c_dis else 0.0
                    days_count = max(len(pd.date_range(md_from, md_to)), 1)
                    avg_anz  = anz_total / days_count
                    avg_bfs  = bfs_total / days_count
                    avg_evac = evac_total / days_count

                    monthly_html = f"""
                    <div class="section">
                    <h2>📊 Monthly Data</h2>
                    <div class="cards four">
                        <div class="stat-card">
                        <div class="stat-label">ANZ Production</div>
                        <div class="stat-value">{_fmt0(anz_total)}</div>
                        <div style="color:#6c757d;font-size:0.8rem;">Avg: {_fmt0(avg_anz)}</div>
                        </div>
                        <div class="stat-card">
                        <div class="stat-label">BFS Receipt</div>
                        <div class="stat-value">{_fmt0(bfs_total)}</div>
                        <div style="color:#6c757d;font-size:0.8rem;">Avg: {_fmt0(avg_bfs)}</div>
                        </div>
                        <div class="stat-card">
                        <div class="stat-label">Evacuation</div>
                        <div class="stat-value">{_fmt0(evac_total)}</div>
                        <div style="color:#6c757d;font-size:0.8rem;">Avg: {_fmt0(avg_evac)}</div>
                        </div>
                        <div class="stat-card">
                        <div class="stat-label">BCCR</div>
                        <div class="stat-value">-</div>
                        <div style="color:#6c757d;font-size:0.8rem;">(to be wired)</div>
                        </div>
                    </div>
                    </div>
                    """

            # ===== Trend SVG (exactly for current location) =====
            trend_svg = _build_trend_svg_for_pdf(s, loc_code, tr_from, tr_to, width=980, height=380)

            # ===== Cards CSS & Final HTML =====
            css = """
            <style>
            body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Arial, sans-serif; color:#222; }
            .wrap { padding: 18px 22px; }
            h2 { margin: 6px 0 12px; }
            .cards { display: grid; grid-gap: 12px; }
            .cards.six  { grid-template-columns: repeat(6, 1fr); }
            .cards.four { grid-template-columns: repeat(4, 1fr); }
            .section { margin-top: 18px; }
            .stat-card {
                background: white; padding: 1.0rem; border-radius: 10px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.1); border-left: 4px solid #667eea;
                transition: transform 0.2s;
            }
            .stat-value { font-size: 1.4rem; font-weight: bold; color: #667eea; margin: 0.25rem 0; }
            .stat-label { color: #666; font-size: 0.8rem; text-transform: uppercase; letter-spacing: 1px; }
            .tanks-grid { display: grid; grid-template-columns: repeat(5, 1fr); grid-gap: 12px; }
            .tank-card { border: 1px solid #e5e7eb; border-radius: 10px; padding: 8px 10px; box-shadow: 0 2px 6px rgba(0,0,0,.06); }
            .tank-card__header { display:flex; justify-content:space-between; font-weight:600; color:#1f4788; font-size:0.9rem; }
            .tank-card__code { font-size:0.75rem; color:#6c757d; }
            .tank-card__product { font-size:0.78rem; color:#555; margin:4px 0 6px; }
            .tank-gauge { position:relative; height:120px; border:1px solid #d7dce3; border-radius:8px; overflow:hidden; background:linear-gradient(180deg,#eef3fb 0%,#fff 100%); }
            .tank-gauge__fill { position:absolute; bottom:0; left:0; right:0; background:linear-gradient(180deg,#00b4d8 0%,#0077b6 100%); transition:height 0.4s ease; }
            .tank-gauge__overlay { position:absolute; inset:0; display:flex; align-items:center; justify-content:center; font-size:1.15rem; font-weight:bold; color:#fff; text-shadow:0 1px 3px rgba(0,0,0,0.4); }
            .tank-card__stats { display:flex; justify-content:space-between; margin-top:8px; font-size:0.72rem; color:#6c757d; }
            .tank-card__stats div { text-align:center; flex:1; }
            .tank-card__stats strong { display:block; color:#212529; font-size:0.85rem; margin-top:2px; }
            .tank-card__status { margin-top:6px; text-align:center; font-size:0.78rem; font-weight:600; padding:4px 6px; border-radius:6px; }
            .tank-card__status--ok { color:#0f5132; background:#d1e7dd; }
            .tank-card__status--warn { color:#664d03; background:#fff3cd; }
            .tank-card__status--bad { color:#842029; background:#f8d7da; }
            .subtle { color:#6c757d; font-size: 0.78rem; }
            .mb-note { color:#6c757d; font-size:0.75rem; margin-top:2px; }
            </style>
            """

            sum_cards_html = f"""
            <div class="section">
            <h2>📊 Summary Statistics &nbsp; <span class="subtle">{sel_date.strftime('%d-%b-%Y')}</span></h2>
            <div class="cards six">
                <div class="stat-card"><div class="stat-label">Production</div><div class="stat-value">{_fmt0(prod_bbl)}</div><div class="mb-note">{sel_date.strftime('%d-%b-%Y')}</div></div>
                <div class="stat-card"><div class="stat-label">Evacuation</div><div class="stat-value">{_fmt0(evac_bbl)}</div><div class="mb-note">{sel_date.strftime('%d-%b-%Y')}</div></div>
                <div class="stat-card"><div class="stat-label">FSO receipt</div><div class="stat-value">{_fmt0(fso_receipt_bbl)}</div><div class="mb-note">{sel_date.strftime('%d-%b-%Y')}</div></div>
                <div class="stat-card"><div class="stat-label">FSO Stock</div><div class="stat-value">{_fmt0(fso_stock_bbl)}</div><div class="mb-note">{sel_date.strftime('%d-%b-%Y')}</div></div>
                <div class="stat-card"><div class="stat-label">Ullage available</div><div class="stat-value">{_fmt0(ullage_available_bbl)}</div><div class="mb-note">{sel_date.strftime('%d-%b-%Y')}</div></div>
                <div class="stat-card"><div class="stat-label">Pumpable Stock</div><div class="stat-value">{_fmt0(pumpable_stock_bbl)}</div><div class="mb-note">{sel_date.strftime('%d-%b-%Y')}</div></div>
            </div>
            </div>
            """

            _canon_name = str(loc_name or "").upper().replace(" ", "").replace("-", "")
            _canon_code = str(loc_code or "").upper().replace(" ", "").replace("-", "")
            _is_lagos_pdf = ("LAGOS" in _canon_name) or ("LAGOS" in _canon_code)
            _display_title = "CRUDE OPERATIONS DASHBOARD" if _is_lagos_pdf else f"{loc_name or loc_code or 'Location'} Dashboard"
            html = f"""
            <!doctype html>
            <html><head><meta charset="utf-8"/>{css}</head>
            <body>
            <div class="wrap">
                <h2>{_display_title}</h2>
                <div class="subtle">Generated: {datetime.now().strftime('%d-%b-%Y %H:%M')}</div>

                {sum_cards_html}

                <div class="section">
                <h2>🛢️ Tank Stock Levels</h2>
                {tank_html}
                </div>

                {monthly_html}

                <div class="section">
                <h2>📈 Production &amp; Evacuation Trend</h2>
                {trend_svg}
                </div>
            </div>
            </body></html>
            """
        return html

    def _find_local_chromium() -> str | None:
        """Attempt to locate a locally installed Chromium/Chrome/Edge executable."""
        env_paths = [
            os.environ.get("CHROME_PATH"),
            os.environ.get("GOOGLE_CHROME_PATH"),
            os.environ.get("EDGE_PATH"),
        ]
        known_paths = [
            r"C:\Program Files\Google\Chrome\Application\chrome.exe",
            r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe",
            r"C:\Program Files\Microsoft\Edge\Application\msedge.exe",
            r"C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe",
            r"C:\Program Files\Chromium\Application\chrome.exe",
        ]
        for candidate in env_paths + known_paths:
            if candidate and Path(candidate).exists():
                return candidate
        exe = shutil.which("chrome") or shutil.which("msedge") or shutil.which("chromium")
        return exe

    def _render_dashboard_pdf_bytes(html_payload: str, timeout: int = 30) -> bytes:
        """Render dashboard HTML to PDF using headless Chromium via pyppeteer."""
        import asyncio
        try:
            from pyppeteer import launch
        except ImportError as exc:
            raise RuntimeError(
                "pyppeteer is required to generate dashboard PDFs. "
                "Please install it with 'pip install pyppeteer'."
            ) from exc

        executable = _find_local_chromium()
        launch_kwargs = dict(
            headless=True,
            args=[
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-dev-shm-usage",
                "--disable-gpu",
            ],
            handleSIGINT=False,
            handleSIGTERM=False,
            handleSIGHUP=False,
        )
        if executable:
            launch_kwargs["executablePath"] = executable

        async def _convert() -> bytes:
            browser = await launch(**launch_kwargs)
            try:
                page = await browser.newPage()
                await page.setContent(html_payload)
                await asyncio.sleep(0.5)
                pdf_bytes = await page.pdf(
                    format="A4",
                    printBackground=True,
                    margin={"top": "10mm", "right": "10mm", "bottom": "10mm", "left": "10mm"},
                    landscape=True,
                )
                await page.close()
                return pdf_bytes
            finally:
                await browser.close()

        try:
            return asyncio.run(asyncio.wait_for(_convert(), timeout=timeout))
        except RuntimeError:
            loop = asyncio.new_event_loop()
            try:
                return loop.run_until_complete(asyncio.wait_for(_convert(), timeout=timeout))
            finally:
                loop.close()

    def _open_pdf_blob(pdf_bytes: bytes, filename: str = "OTMS_Dashboard.pdf"):
        b64 = base64.b64encode(pdf_bytes).decode("ascii")
        components.html(
            f"""
            <script>
            (function(){{
                const b64="{b64}";
                const bytes=atob(b64);
                const len=bytes.length;
                const out=new Uint8Array(len);
                for(let i=0;i<len;i++){{out[i]=bytes.charCodeAt(i);}}
                const blob=new Blob([out],{{type:"application/pdf"}});
                const url=URL.createObjectURL(blob);
                const win=window.open(url,"_blank");
                if(!win){{alert("Please allow pop-ups for OTMS to display the PDF.");}}
                setTimeout(()=>URL.revokeObjectURL(url),120000);
            }})();
            </script>
            """,
            height=0,
        )



    # ===== Header & Button =====
    with get_session() as s:
        try:
            from location_manager import LocationManager
            _loc = LocationManager.get_location_by_id(s, st.session_state.get("active_location_id"))
            _loc_code = (getattr(_loc, "code", "") or "")
            _loc_name = (getattr(_loc, "name", "") or "")
        except Exception:
            _loc_code, _loc_name = "", ""
    def _canon(txt: str) -> str:
        return str(txt or "").upper().replace(" ", "").replace("-", "")
    _keys = {_canon(_loc_code), _canon(_loc_name)}
    _is_lagos = any("LAGOS" in k for k in _keys)
    _dash_title = "CRUDE OPERATIONS DASHBOARD" if _is_lagos else f"{_loc_name or _loc_code or 'Location'} Dashboard"
    h1, h2 = st.columns([3,1])
    with h1:
        st.markdown(f"## {_dash_title}")
    with h2:
        view_pdf_clicked = st.button("👁️ View PDF", use_container_width=True, key="btn_view_pdf_visual_exact")

    if view_pdf_clicked:
        with st.spinner("Building dashboard PDF..."):
            try:
                html_str = _build_dashboard_html_for_pdf()
            except Exception as exc:
                log_error("Dashboard PDF generation failed", exc_info=True)
                st.error(f"? Unable to build dashboard PDF: {exc}")
            else:
                try:
                    pdf_bytes = _render_dashboard_pdf_bytes(html_str)
                except RuntimeError as exc:
                    st.error(str(exc))
                except Exception as exc:
                    log_error("Dashboard PDF rendering failed", exc_info=True)
                    st.error(f"? Unable to render dashboard PDF: {exc}")
                else:
                    _open_pdf_blob(pdf_bytes)
                    st.success("? Dashboard PDF opened in a new tab!")
    # =======================================================================
    # ======= SUMMARY STATISTICS (location-aware: Asemoku, Aggu, Beneku) ====
    from datetime import date as _date, datetime, time as dt_time, timedelta
    import pandas as pd

    st.markdown("### 📊 Summary Statistics")

    # --- Date selector (shared across dashboard) ---
    d1, d2 = st.columns([1, 3])
    with d1:
        _selected_date = st.date_input(
            "Date",
            value=st.session_state.get("dash_date_all_sites", _date.today()),
            key="dash_date_all_sites"
        )
    with d2:
        st.write(f"Showing **{_selected_date.strftime('%d-%b-%Y')}**")

    prev_summary_date = _selected_date - timedelta(days=1)

    # Defaults
    prod_bbl = 0.0
    evac_bbl = 0.0
    prev_prod_bbl = None
    prev_evac_bbl = None
    fso_receipt_bbl = None  # renders as "-" if None
    fso_stock_bbl = None    # renders as "-" if None

    # OFS (Oguali) specific placeholders (wired to OFS Production & Evacuation data)
    ofs_oguali_prod_bbl = 0.0
    ofs_ukpichi_prod_bbl = 0.0
    ofs_other_prod_bbl = 0.0
    prev_ofs_oguali_prod_bbl = None
    prev_ofs_ukpichi_prod_bbl = None
    prev_ofs_other_prod_bbl = None
    ofs_evacuation_bbl = 0.0
    ofs_tankers_oguali = 0.0
    ofs_tankers_ukpichi = 0.0
    ofs_tankers_other = 0.0

    # Asemoku-specific values
    anz_prod_bbl = None
    okw_receipt_bbl = None
    dispatch_barge_bbl = None
    produced_water_bbl = None
    prev_anz_prod_bbl = None
    prev_okw_receipt_bbl = None
    prev_produced_water_bbl = None
    river_draft_value = None
    rainfall_value = None
    prev_river_draft_value = None
    prev_rainfall_value = None
    river_display_date = None

    # Beneku (BFS)-specific values
    okw_prod_bbl = None
    gpp_prod_bbl = None
    prev_okw_prod_bbl = None
    prev_gpp_prod_bbl = None
    bfs_evac_bbl = None

    # Agge-specific dashboard cards
    agge_receipt_from_yade_bbl = None
    agge_evacuation_bbl = None
    agge_fso_receipt_bbl = None
    agge_fso_stock_bbl = None

    # Aggu dashboard metrics
    aggu_tankers_dispatched = None

    # Ndoni tanker detail metrics
    nd_tankers_from_aggu = None
    nd_tankers_from_ofs = None
    nd_other_tankers = None
    prev_nd_receipt_agu_bbl = None
    prev_nd_receipt_ofs_bbl = None
    prev_nd_other_rcpt_bbl = None

    # Location flags
    is_asemoku = False
    is_aggu = False
    is_agge = False
    is_bfs = False
    is_ndoni = False

    with get_session() as s:
        # -------- Resolve location code/name --------
        try:
            from location_manager import LocationManager
            loc_obj = LocationManager.get_location_by_id(s, active_location_id)
            loc_code = (getattr(loc_obj, "code", "") or "")
            loc_name = (getattr(loc_obj, "name", "") or "")
        except Exception:
            loc_code, loc_name = "", ""

        def _canon(txt: str) -> str:
            return str(txt or "").upper().replace(" ", "").replace("-", "")

        _loc_keys = {_canon(loc_code), _canon(loc_name)}
        is_asemoku = bool(_loc_keys & {"JETTY", "ASEMOKU", "ASEMOKUJETTY"})
        is_aggu    = bool(_loc_keys & {"AGGU"})
        is_agge    = bool(_loc_keys & {"AGGE"})
        is_ndoni   = bool(_loc_keys & {"NDONI"})
        # Beneku (BFS) - handle code or name
        is_bfs     = bool(_loc_keys & {"BFS", "BENEKU", "BENEKU(BFS)"})
        is_utapate = bool(_loc_keys & {"UTAPATE", "OML13", "OML-13"})
        # Oguali (OML-157) � OFS Production & Evacuation summary dashboard
        is_ofs_oguali = bool(
            _loc_keys
            & {
                "OML157",
                "OGUALI",
                "OGUALI(OML157)",
                "OGUALIOML157",
            }
        )

        if is_asemoku or is_ndoni:
            river_target_date = _selected_date + timedelta(days=1)
            river_display_date = river_target_date
            rd_row = (
                s.query(RiverDraftRecord)
                .filter(
                    RiverDraftRecord.location_id == active_location_id,
                    RiverDraftRecord.date == river_target_date,
                )
                .order_by(RiverDraftRecord.id.desc())
                .first()
            )
            if rd_row:
                try:
                    river_draft_value = float(getattr(rd_row, "river_draft_m", 0.0) or 0.0)
                except Exception:
                    river_draft_value = 0.0
                try:
                    rainfall_value = float(getattr(rd_row, "rainfall_cm", 0.0) or 0.0)
                except Exception:
                    rainfall_value = 0.0

            prev_date = river_target_date - timedelta(days=1)
            prev_row = (
                s.query(RiverDraftRecord)
                .filter(
                    RiverDraftRecord.location_id == active_location_id,
                    RiverDraftRecord.date == prev_date,
                )
                .order_by(RiverDraftRecord.id.desc())
                .first()
            )
            if prev_row:
                try:
                    prev_river_draft_value = float(getattr(prev_row, "river_draft_m", 0.0) or 0.0)
                except Exception:
                    prev_river_draft_value = 0.0
                try:
                    prev_rainfall_value = float(getattr(prev_row, "rainfall_cm", 0.0) or 0.0)
                except Exception:
                    prev_rainfall_value = 0.0

        if is_asemoku:
            pw_rows = (
                s.query(ProducedWaterRecord)
                .filter(
                    ProducedWaterRecord.location_id == active_location_id,
                    ProducedWaterRecord.date == _selected_date,
                )
                .all()
            )
            if pw_rows:
                produced_water_bbl = sum(float(getattr(row, "produced_water_bbl", 0.0) or 0.0) for row in pw_rows)
            pw_prev_rows = (
                s.query(ProducedWaterRecord)
                .filter(
                    ProducedWaterRecord.location_id == active_location_id,
                    ProducedWaterRecord.date == prev_summary_date,
                )
                .all()
            )
            if pw_prev_rows:
                prev_produced_water_bbl = sum(
                    float(getattr(row, "produced_water_bbl", 0.0) or 0.0) for row in pw_prev_rows
                )

        # -------- OFS (Oguali) values from production & evacuation records --------
        if is_ofs_oguali:
            ofs_rows = (
                s.query(OFSProductionEvacuationRecord)
                .filter(
                    OFSProductionEvacuationRecord.location_id == active_location_id,
                    OFSProductionEvacuationRecord.date == _selected_date,
                )
                .all()
            )
            ofs_prev_rows = (
                s.query(OFSProductionEvacuationRecord)
                .filter(
                    OFSProductionEvacuationRecord.location_id == active_location_id,
                    OFSProductionEvacuationRecord.date == prev_summary_date,
                )
                .all()
            )

            def _ofs_sum(rows, attr: str) -> float:
                return sum(float(getattr(row, attr) or 0.0) for row in rows or [])

            if ofs_rows:
                ofs_oguali_prod_bbl = _ofs_sum(ofs_rows, "oguali_production")
                ofs_ukpichi_prod_bbl = _ofs_sum(ofs_rows, "ukpichi_production")
                ofs_other_prod_bbl = _ofs_sum(ofs_rows, "other_locations")
                ofs_evacuation_bbl = _ofs_sum(ofs_rows, "evacuation")
                ofs_tankers_oguali = _ofs_sum(ofs_rows, "tankers_oguali")
                ofs_tankers_ukpichi = _ofs_sum(ofs_rows, "tankers_ukpichi")
                ofs_tankers_other = _ofs_sum(ofs_rows, "other_tankers")
            if ofs_prev_rows:
                prev_ofs_oguali_prod_bbl = _ofs_sum(ofs_prev_rows, "oguali_production")
                prev_ofs_ukpichi_prod_bbl = _ofs_sum(ofs_prev_rows, "ukpichi_production")
                prev_ofs_other_prod_bbl = _ofs_sum(ofs_prev_rows, "other_locations")

        # -------- Material Balance for selected date (generic) --------
        df_mb = None
        df_mb_prev = None
        try:
            from material_balance_calculator import MaterialBalanceCalculator as MBCalc
            mb_rows = MBCalc.calculate_material_balance(
                entries=None,
                location_code=(loc_code or "").upper(),
                date_from=_selected_date,
                date_to=_selected_date,
                location_id=active_location_id,
                debug=False
            )
            if mb_rows:
                df_mb = pd.DataFrame(mb_rows)
            prev_rows = MBCalc.calculate_material_balance(
                entries=None,
                location_code=(loc_code or "").upper(),
                date_from=prev_summary_date,
                date_to=prev_summary_date,
                location_id=active_location_id,
                debug=False,
            )
            if prev_rows:
                df_mb_prev = pd.DataFrame(prev_rows)
        except Exception:
            pass

        # Generic (for locations that use "Receipt"/"Dispatch" columns)
        if df_mb is not None:
            if "Receipt" in df_mb.columns:
                prod_bbl = float(pd.to_numeric(df_mb["Receipt"], errors="coerce").fillna(0).sum())
            if "Dispatch" in df_mb.columns:
                evac_bbl = float(pd.to_numeric(df_mb["Dispatch"], errors="coerce").fillna(0).sum())
        if df_mb_prev is not None:
            if "Receipt" in df_mb_prev.columns:
                prev_prod_bbl = float(pd.to_numeric(df_mb_prev["Receipt"], errors="coerce").fillna(0).sum())
            if "Dispatch" in df_mb_prev.columns:
                prev_evac_bbl = float(pd.to_numeric(df_mb_prev["Dispatch"], errors="coerce").fillna(0).sum())

        # Helper to find columns case/space insensitive
        def _find_col(df: pd.DataFrame, candidates):
            if df is None or df.empty:
                return None
            # exact first
            for c in candidates:
                if c in df.columns:
                    return c
            lower_map = {str(c).strip().lower(): c for c in df.columns}
            for c in candidates:
                lc = str(c).strip().lower()
                if lc in lower_map:
                    return lower_map[lc]
            return None

        def _sum_bbl(df: pd.DataFrame, col_name: str | None) -> float | None:
            if not col_name or col_name not in df.columns:
                return None
            ser = df[col_name]
            try:
                ser = ser.astype(str).str.replace(",", "", regex=False)
            except Exception:
                pass
            ser = pd.to_numeric(ser, errors="coerce")
            return float(ser.fillna(0.0).sum())

        # -------- Asemoku Jetty specific mapping --------
        # ANZ Production  -> "ANZ Receipt"
        # BFS Receipt     -> "OKW Receipt"
        # Evacuation      -> "Dispatch to barge"
        if is_asemoku and df_mb is not None:
            c_anz = _find_col(df_mb, ["ANZ Receipt"])
            c_okw = _find_col(df_mb, ["OKW Receipt"])
            c_disp_barge = _find_col(df_mb, ["Dispatch to barge"])

            if c_anz:
                val = _sum_bbl(df_mb, c_anz)
                if val is not None:
                    anz_prod_bbl = val
            if c_okw:
                val = _sum_bbl(df_mb, c_okw)
                if val is not None:
                    okw_receipt_bbl = val
            if c_disp_barge:
                val = _sum_bbl(df_mb, c_disp_barge)
                if val is not None:
                    dispatch_barge_bbl = val
        if is_asemoku and df_mb_prev is not None:
            c_prev_anz = _find_col(df_mb_prev, ["ANZ Receipt"])
            c_prev_okw = _find_col(df_mb_prev, ["OKW Receipt"])
            if c_prev_anz:
                val = _sum_bbl(df_mb_prev, c_prev_anz)
                if val is not None:
                    prev_anz_prod_bbl = val
            if c_prev_okw:
                val = _sum_bbl(df_mb_prev, c_prev_okw)
                if val is not None:
                    prev_okw_receipt_bbl = val

        # -------- Beneku (BFS) specific mapping (Production tab + Evacuation from MB) --------
        if is_bfs:
            try:
                from models import GPPProductionRecord
                def _calc_bfs_totals(rows):
                    if not rows:
                        return None, None
                    okw_total = sum(float(r.okw_production or 0.0) for r in rows)
                    gpp_total = sum(
                        float(
                            r.total_production
                            if r.total_production is not None
                            else (r.gpp1_production or 0.0) + (r.gpp2_production or 0.0)
                        )
                        for r in rows
                    )
                    return okw_total, gpp_total

                prod_rows = (
                    s.query(GPPProductionRecord)
                    .filter(
                        GPPProductionRecord.location_id == active_location_id,
                        GPPProductionRecord.date == _selected_date,
                    )
                    .all()
                )
                prev_prod_rows = (
                    s.query(GPPProductionRecord)
                    .filter(
                        GPPProductionRecord.location_id == active_location_id,
                        GPPProductionRecord.date == prev_summary_date,
                    )
                    .all()
                )
                if prod_rows:
                    okw_prod_bbl, gpp_prod_bbl = _calc_bfs_totals(prod_rows)
                if prev_prod_rows:
                    prev_okw_prod_bbl, prev_gpp_prod_bbl = _calc_bfs_totals(prev_prod_rows)
            except Exception:
                pass

        if is_bfs and df_mb is not None:
            c_disp_bfs = _find_col(df_mb, ["Dispatch to Jetty"])
            if c_disp_bfs:
                val = _sum_bbl(df_mb, c_disp_bfs)
                if val is not None:
                    bfs_evac_bbl = val

        # -------- Aggu tanker dispatched (from tanker entries) --------
        if is_aggu:
            try:
                agg_value = (
                    s.query(func.sum(LocationTankerEntry.tankers_dispatched))
                    .filter(
                        LocationTankerEntry.location_id == active_location_id,
                        LocationTankerEntry.date == _selected_date,
                    )
                    .scalar()
                )
                if agg_value is not None:
                    aggu_tankers_dispatched = float(agg_value or 0.0)
            except Exception:
                pass

        # -------- Agge specific wiring (YADE, OTR-Vessel, FSO MB) --------
        if is_agge:
            try:
                from models import TOAYadeSummary, YadeVoyage, OTRVessel, FSOOperation
                from fso_config import FSOConfig
            except Exception:
                pass
            else:
                yade_vals = (
                    s.query(TOAYadeSummary.gsv_loaded_bbl)
                    .join(YadeVoyage, TOAYadeSummary.voyage_id == YadeVoyage.id)
                    .filter(
                        YadeVoyage.location_id == active_location_id,
                        TOAYadeSummary.date == _selected_date,
                    )
                    .all()
                )
                if yade_vals:
                    agge_receipt_from_yade_bbl = sum(
                        abs(float(val or 0.0)) for (val,) in yade_vals
                    )

                otr_vals = (
                    s.query(OTRVessel.net_receipt_dispatch)
                    .filter(
                        OTRVessel.location_id == active_location_id,
                        OTRVessel.date == _selected_date,
                    )
                    .all()
                )
                if otr_vals:
                    agge_evacuation_bbl = sum(
                        abs(float(val or 0.0)) for (val,) in otr_vals
                    )

                fso_vessel = None
                loc_candidates = []
                if loc_code:
                    loc_candidates.append(loc_code.upper())
                if loc_name:
                    loc_candidates.append(loc_name.upper())
                canon_loc_code = _canon(loc_code)
                canon_loc_name = _canon(loc_name)
                if canon_loc_code == "AGGE" or canon_loc_name == "AGGE":
                    loc_candidates.append("AGGE")

                for candidate in loc_candidates:
                    if not candidate:
                        continue
                    vessels = FSOConfig.get_fso_for_location(candidate)
                    if vessels:
                        fso_vessel = vessels[0]
                        break

                if not fso_vessel:
                    fso_vessel = FSOConfig.get_default_fso("AGGE")

                if fso_vessel:
                    period_start = datetime.combine(_selected_date, dt_time(6, 1))
                    period_end = datetime.combine(_selected_date + timedelta(days=1), dt_time(6, 0))

                    fso_rows = (
                        s.query(FSOOperation)
                        .filter(
                            FSOOperation.location_id == active_location_id,
                            FSOOperation.fso_vessel == fso_vessel,
                            FSOOperation.date >= (_selected_date - timedelta(days=1)),
                            FSOOperation.date <= (_selected_date + timedelta(days=1)),
                        )
                        .order_by(FSOOperation.date, FSOOperation.time)
                        .all()
                    )

                    window_entries = []
                    for entry in fso_rows or []:
                        entry_time = _coerce_time(entry.time)
                        if not entry_time:
                            continue
                        entry_dt = datetime.combine(entry.date, entry_time)
                        if period_start <= entry_dt <= period_end:
                            window_entries.append((entry, entry_dt))

                    if window_entries:
                        window_entries.sort(key=lambda pair: pair[1])
                        agge_fso_receipt_bbl = sum(
                            abs(float(pair[0].net_receipt_dispatch or 0.0))
                            for pair in window_entries
                            if pair[0].operation == "Receipt" and pair[0].net_receipt_dispatch is not None
                        )
                        last_entry = window_entries[-1][0]
                        try:
                            agge_fso_stock_bbl = float(last_entry.closing_stock or 0.0)
                        except Exception:
                            agge_fso_stock_bbl = None

        # -------- Ndoni specific mapping --------
        def _ndoni_values_from_df(df: pd.DataFrame):
            if df is None or df.empty:
                return None, None, None, None

            cols_raw = list(df.columns)

            def _col_by_idx(i):
                try:
                    return cols_raw[i]
                except Exception:
                    return None

            agu_candidates = [
                "Receipt from Agu",
                "Receipt from agu",
                "Receipt from AGU",
                "Receipt Agu",
                "Receipt AGU",
                "Receipt From Agu",
                "Receipt from Agu (bbls)",
                "Receipt from AGU (bbls)",
                "Receipt Agu (bbls)",
                "Receipt AGU (bbls)",
            ]
            c_rcpt_agu = _find_col(df, agu_candidates) or _col_by_idx(2)
            c_rcpt_ofs = _find_col(df, ["Receipt from OFS", "Receipt from ofs"]) or _col_by_idx(3)
            c_rcpt_other = _find_col(df, ["Other Receipts", "Other receipts"]) or _col_by_idx(4)
            c_disp_barge_nd = _find_col(df, ["Dispatch to barge", "Dispatch to Barge"]) or _col_by_idx(5)

            first_row = df.iloc[0]

            def _value_from_row(col_name):
                if not col_name:
                    return None
                if col_name not in first_row.index:
                    return None
                raw = first_row[col_name]
                if raw is None:
                    return None
                try:
                    return float(str(raw).replace(",", ""))
                except Exception:
                    try:
                        return float(raw)
                    except Exception:
                        return None

            return (
                _value_from_row(c_rcpt_agu),
                _value_from_row(c_rcpt_ofs),
                _value_from_row(c_rcpt_other),
                _value_from_row(c_disp_barge_nd),
            )

        nd_receipt_agu_bbl = nd_receipt_ofs_bbl = nd_other_rcpt_bbl = nd_dispatch_barge_bbl = None
        if is_ndoni:
            (
                nd_receipt_agu_bbl,
                nd_receipt_ofs_bbl,
                nd_other_rcpt_bbl,
                nd_dispatch_barge_bbl,
            ) = _ndoni_values_from_df(df_mb)
            (
                prev_nd_receipt_agu_bbl,
                prev_nd_receipt_ofs_bbl,
                prev_nd_other_rcpt_bbl,
                _,
            ) = _ndoni_values_from_df(df_mb_prev)

        if is_ndoni:
            try:
                tanker_sums = (
                    s.query(
                        func.sum(LocationTankerEntry.tankers_from_aggu),
                        func.sum(LocationTankerEntry.tankers_from_ofs),
                        func.sum(LocationTankerEntry.other_tankers),
                    )
                    .filter(
                        LocationTankerEntry.location_id == active_location_id,
                        LocationTankerEntry.date == _selected_date,
                    )
                    .one_or_none()
                )
                if tanker_sums:
                    nd_tankers_from_aggu = float(tanker_sums[0] or 0.0)
                    nd_tankers_from_ofs = float(tanker_sums[1] or 0.0)
                    nd_other_tankers = float(tanker_sums[2] or 0.0)
            except Exception:
                pass

        # -------- FSO Material Balance (kept as before; not used for BFS/Aggu cards) --------
        try:
            from fso_config import FSOConfig
            from models import FSOOperation

            def _canonical_fso_code(code: str | None) -> str:
                if not code:
                    return ""
                s = str(code).strip().upper()
                s_norm = s.replace(" ", "").replace("-", "")
                aliases = {
                    "UTAPATE": "OML-13",
                    "OML13": "OML-13",
                    "OML-13": "OML-13",
                    "OML 13": "OML-13",
                    "AGGE": "AGGE",
                }
                return aliases.get(s, aliases.get(s_norm, s))

            loc_code_up = (loc_code or "").upper()

            def _fso_values_from_mb_page(selected_date, loc_code_inner):
                possible_keys = [
                    "fso_mb_df", "fso_mb_table", "fso_material_balance_df",
                    "fso_mb_daily", "fso_mb_cache", "fso_mb_summary_df",
                    "fso_mb_pivot", "fso_mb_records"
                ]
                canon_loc = _canonical_fso_code(loc_code_inner)
                for key in possible_keys:
                    if key not in st.session_state:
                        continue
                    obj = st.session_state[key]
                    try:
                        df = obj.copy() if isinstance(obj, pd.DataFrame) else pd.DataFrame(obj)
                    except Exception:
                        continue
                    if df is None or df.empty:
                        continue

                    # date column
                    date_col = None
                    for c in df.columns:
                        if str(c).strip().lower() in {"date", "mb date", "as of", "asof"}:
                            date_col = c
                            break
                    if date_col is None:
                        continue

                    dfx = df.copy()
                    dfx[date_col] = pd.to_datetime(dfx[date_col], errors="coerce").dt.date
                    dfx = dfx[dfx[date_col] == selected_date]
                    if dfx.empty:
                        continue

                    # optional loc filter
                    loc_col = None
                    for c in dfx.columns:
                        if str(c).strip().lower() in {"location", "loc", "site", "code"}:
                            loc_col = c
                            break
                    if loc_col is not None and canon_loc:
                        dfx["_fso_loc_norm"] = dfx[loc_col].astype(str).str.upper().str.replace(" ", "", regex=False).str.replace("-", "", regex=False)
                        dfx = dfx[dfx["_fso_loc_norm"] == canon_loc.replace("-", "").replace(" ", "")]
                        if dfx.empty:
                            continue

                    # receipt / closing stock columns
                    rec_cols = [
                        "Receipt (bbls)", "Receipts (bbls)", "receipt (bbls)", "receipts (bbls)",
                        "receipt_bbls", "receipts_bbls", "receipt", "receipts"
                    ]
                    close_cols = [
                        "Closing Stock (bbls)", "closing stock (bbls)", "Closing Stock",
                        "closing stock", "closing_stock", "closing_stock_bbl"
                    ]
                    rec_col = next((c for c in dfx.columns if str(c).strip() in rec_cols), None) \
                            or next((c for c in dfx.columns if str(c).strip().lower() in [x.lower() for x in rec_cols]), None)
                    close_col = next((c for c in dfx.columns if str(c).strip() in close_cols), None) \
                            or next((c for c in dfx.columns if str(c).strip().lower() in [x.lower() for x in close_cols]), None)

                    rec_val = float(pd.to_numeric(dfx[rec_col], errors="coerce").fillna(0).sum()) if rec_col else None
                    close_val = None
                    if close_col:
                        cs = pd.to_numeric(dfx[close_col], errors="coerce").dropna()
                        if not cs.empty:
                            close_val = float(cs.iloc[-1])
                    if rec_val is not None or close_val is not None:
                        return rec_val, close_val

                return None, None
            fso_receipt_bbl, fso_stock_bbl = _fso_values_from_mb_page(_selected_date, loc_code_up)

            if fso_receipt_bbl is None or fso_stock_bbl is None:
                # fallback compute
                fso_map = {k.upper(): v for k, v in FSOConfig.get_fso_locations().items()}
                fso_vessel = fso_map.get(_canonical_fso_code(loc_code_up))
                if fso_vessel:
                    ext_from = _selected_date - timedelta(days=1)
                    ext_to   = _selected_date + timedelta(days=1)
                    entries = (s.query(FSOOperation)
                                .filter(
                                    FSOOperation.location_id == active_location_id,
                                    FSOOperation.fso_vessel == fso_vessel,
                                    FSOOperation.date >= ext_from,
                                    FSOOperation.date <= ext_to,
                                )
                                .order_by(FSOOperation.date, FSOOperation.time)
                                .all())
                    if entries:
                        win_start = datetime.combine(_selected_date, dt_time(6, 1))
                        win_end   = datetime.combine(_selected_date + timedelta(days=1), dt_time(6, 0))

                        def _to_time(t):
                            if isinstance(t, dt_time):
                                return t
                            try:
                                return datetime.strptime(str(t), "%H:%M").time()
                            except Exception:
                                return dt_time(0, 0)

                        period = []
                        for e in entries:
                            try:
                                edt = datetime.combine(e.date, _to_time(e.time))
                                if win_start <= edt <= win_end:
                                    period.append(e)
                            except Exception:
                                continue

                        if period:
                            period.sort(key=lambda e: datetime.combine(e.date, _to_time(e.time)))
                            # receipts
                            rec_total = 0.0
                            for e in period:
                                op = (getattr(e, "operation", "") or "").strip().lower()
                                if op in {"receipt", "receipts"}:
                                    try:
                                        v = float(getattr(e, "net_receipt_dispatch", 0.0) or 0.0)
                                    except Exception:
                                        v = 0.0
                                    if v > 0:
                                        rec_total += v
                            if fso_receipt_bbl is None:
                                fso_receipt_bbl = rec_total

                            # closing stock
                            last_e = period[-1]
                            try:
                                if fso_stock_bbl is None:
                                    fso_stock_bbl = float(getattr(last_e, "closing_stock", 0.0) or 0.0)
                            except Exception:
                                pass
        except Exception:
            pass

        # === Ullage available & Pumpable Stock (status-dependent; unchanged logic) ===
        from sqlalchemy import and_, or_
        from models import OTRRecord, TankTransaction, Tank
        try:
            from models import TankDailyStatus, TankOpStatus
        except Exception:
            TankDailyStatus = None
            TankOpStatus = None

        ullage_available_bbl = 0.0
        pumpable_stock_bbl   = 0.0

        _mb_close_date = _selected_date + timedelta(days=1)
        _mb_close_time = dt_time(6, 0)
        _allowed_status = {"IDLE", "READY", "DISPATCHING"}

        tanks_ul = s.query(Tank).filter(Tank.location_id == active_location_id).all()

        for tnk in tanks_ul:
            # capacity
            try:
                cap = float(getattr(tnk, "capacity_bbl", 0.0) or 0.0)
            except Exception:
                cap = 0.0

            # stock @ MB close
            last_txn = (
                s.query(TankTransaction.ticket_id, TankTransaction.date, TankTransaction.time)
                .filter(TankTransaction.tank_id == tnk.id)
                .filter(
                    or_(
                        TankTransaction.date < _mb_close_date,
                        and_(TankTransaction.date == _mb_close_date, TankTransaction.time <= _mb_close_time)
                    )
                )
                .order_by(TankTransaction.date.desc(), TankTransaction.time.desc())
                .first()
            )

            stock = 0.0
            if last_txn and last_txn.ticket_id:
                _otr = s.query(OTRRecord).filter(OTRRecord.ticket_id == last_txn.ticket_id).first()
                try:
                    stock = float(getattr(_otr, "nsv_bbl", 0.0) or 0.0)
                except Exception:
                    stock = 0.0

            # ullage always counts
            ullage_available_bbl += max(cap - stock, 0.0)

            # status-gated pumpable
            status_name = "READY"
            try:
                if TankDailyStatus is not None:
                    _row = (s.query(TankDailyStatus)
                            .filter(TankDailyStatus.tank_id == tnk.id,
                                    TankDailyStatus.date == _selected_date)
                            .first())
                    if _row is not None:
                        status_name = getattr(_row.op_status, "name", str(_row.op_status) or "READY")
                elif hasattr(tnk, "status") and getattr(tnk, "status") is not None:
                    status_name = str(getattr(tnk, "status") or "READY")
            except Exception:
                pass

            if str(status_name).strip().upper() in _allowed_status:
                pumpable_stock_bbl += stock

        # percentages
        ullage_available_bbl = 0.90 * ullage_available_bbl
        pumpable_stock_bbl   = 0.85 * pumpable_stock_bbl

    # --------- Helper for formatting ---------
    def _fmt(v):
        return f"{v:,.0f}" if isinstance(v, (int, float)) else "-"

    def _value_with_delta(
        curr: Optional[float],
        prev: Optional[float],
        unit: str = "",
        fmt: str = "{:,.0f}",
    ) -> str:
        unit_suffix = f" {unit}" if unit else ""

        def _fmt_value(val: float | None) -> str:
            if val is None:
                return "-"
            try:
                return fmt.format(val)
            except Exception:
                return f"{val}"

        if curr is None:
            base = "-"
        else:
            base = f"{_fmt_value(curr)}{(' ' + unit) if unit else ''}"
        if curr is None or prev is None:
            return base
        diff = curr - prev
        if abs(diff) < 1e-6:
            return (
                f"{base} "
                f"<span style='color:#6c757d;margin-left:6px;font-size:0.95rem;'>&harr; 0"
                f"{unit_suffix}</span>"
            )
        arrow = "&uarr;" if diff > 0 else "&darr;"
        color = "#198754" if diff > 0 else "#dc3545"
        return (
            f"{base} "
            f"<span style='color:{color};margin-left:6px;font-size:0.95rem;'>"
            f"{arrow} {_fmt_value(abs(diff))}{unit_suffix}</span>"
        )

    # --------- Render cards (location-aware layout) ---------
    if is_asemoku:
        # 6 cards: Anz Prod, BFS Receipt, Evacuation, Produced Water, Ullage, Pumpable
        c1, c2, c3, c4, c5, c6 = st.columns(6)
        anz_html = _value_with_delta(anz_prod_bbl, prev_anz_prod_bbl, "", "{:,.0f}")
        bfs_html = _value_with_delta(okw_receipt_bbl, prev_okw_receipt_bbl, "", "{:,.0f}")
        produced_water_html = _value_with_delta(produced_water_bbl, prev_produced_water_bbl, "", "{:,.0f}")

        with c1:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Anz Production</div>
                    <div class="stat-value">{anz_html}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c2:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">BFS Receipt</div>
                    <div class="stat-value">{bfs_html}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c3:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Evacuation</div>
                    <div class="stat-value">{_fmt(dispatch_barge_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c4:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Produced Water</div>
                    <div class="stat-value">{produced_water_html}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c5:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Ullage available</div>
                    <div class="stat-value">{_fmt(ullage_available_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c6:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Pumpable Stock</div>
                    <div class="stat-value">{_fmt(pumpable_stock_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        rd_html = _value_with_delta(river_draft_value, prev_river_draft_value, "m", "{:.2f}")
        rain_html = _value_with_delta(rainfall_value, prev_rainfall_value, "cm", "{:.2f}")
        label = river_display_date.strftime("%d-%b-%Y @ 06:00 hrs") if river_display_date else _selected_date.strftime("%d-%b-%Y")
        st.markdown(
            f"<div style='margin-top:0.75rem;font-size:1.05rem;font-weight:600;'>"
            f"River Draft: {rd_html}<br/>Rainfall: {rain_html}<br/>"
            f"<span style='color:#6c757d;font-size:0.9rem;'>Data for {label}</span></div>",
            unsafe_allow_html=True,
        )

    elif is_agge:
        # AGGE: 4 cards - Receipt from Yade, Evacuation (OTR), FSO Receipt, FSO Stock
        c1, c2, c3, c4 = st.columns(4)

        with c1:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Receipt from Yade</div>
                    <div class="stat-value">{_fmt(agge_receipt_from_yade_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c2:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Evacuation</div>
                    <div class="stat-value">{_fmt(agge_evacuation_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c3:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">FSO Receipt</div>
                    <div class="stat-value">{_fmt(agge_fso_receipt_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c4:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">FSO Stock</div>
                    <div class="stat-value">{_fmt(agge_fso_stock_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

    elif is_ofs_oguali:
        # Oguali/OML-157 summary cards sourced from OFS Production & Evacuation tab
        c1, c2, c3, c4, c5 = st.columns(5)
        ofs_oguali_html = _value_with_delta(ofs_oguali_prod_bbl, prev_ofs_oguali_prod_bbl, "", "{:,.0f}")
        ofs_ukpichi_html = _value_with_delta(ofs_ukpichi_prod_bbl, prev_ofs_ukpichi_prod_bbl, "", "{:,.0f}")
        ofs_other_html = _value_with_delta(ofs_other_prod_bbl, prev_ofs_other_prod_bbl, "", "{:,.0f}")

        with c1:
            st.markdown(
                f"""
                <div class="stat-card">
                    <div class="stat-label">Oguali Production</div>
                    <div class="stat-value">{ofs_oguali_html}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
                """,
                unsafe_allow_html=True,
            )

        with c2:
            st.markdown(
                f"""
                <div class="stat-card">
                    <div class="stat-label">Ukpichi Production</div>
                    <div class="stat-value">{ofs_ukpichi_html}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
                """,
                unsafe_allow_html=True,
            )

        with c3:
            st.markdown(
                f"""
                <div class="stat-card">
                    <div class="stat-label">Other Locations Production</div>
                    <div class="stat-value">{ofs_other_html}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
                """,
                unsafe_allow_html=True,
            )

        with c4:
            st.markdown(
                f"""
                <div class="stat-card">
                    <div class="stat-label">Evacuation</div>
                    <div class="stat-value">{_fmt(ofs_evacuation_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
                """,
                unsafe_allow_html=True,
            )

        total_tankers = ofs_tankers_oguali + ofs_tankers_ukpichi + ofs_tankers_other
        with c5:
            st.markdown(
                f"""
                <div class="stat-card">
                    <div class="stat-label">Number of Tankers</div>
                    <div class="stat-value">{_fmt(total_tankers)}</div>
                    <div style="color:#6c757d;font-size:0.78rem; margin-top:0.5rem;">
                        <div style="display:flex; justify-content:space-between;">
                            <span>From Oguali</span><strong>{_fmt(ofs_tankers_oguali)}</strong>
                        </div>
                        <div style="display:flex; justify-content:space-between;">
                            <span>From Ukpichi</span><strong>{_fmt(ofs_tankers_ukpichi)}</strong>
                        </div>
                        <div style="display:flex; justify-content:space-between;">
                            <span>From Other Locations</span><strong>{_fmt(ofs_tankers_other)}</strong>
                        </div>
                    </div>
                </div>
                """,
                unsafe_allow_html=True,
            )

        # Oguali dashboard stops after summary cards (no monthly/trend sections required)
        st.stop()

    elif is_aggu:
        # AGGU: 5 cards - Production, Evacuation, Tankers Dispatched, Ullage, Pumpable
        c1, c2, c3, c4, c5 = st.columns(5)
        aggu_prod_html = _value_with_delta(prod_bbl, prev_prod_bbl, "", "{:,.0f}")

        with c1:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Production</div>
                    <div class="stat-value">{aggu_prod_html}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c2:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Evacuation</div>
                    <div class="stat-value">{_fmt(evac_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c3:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Tankers Dispatched</div>
                    <div class="stat-value">{_fmt(aggu_tankers_dispatched)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c4:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Ullage available</div>
                    <div class="stat-value">{_fmt(ullage_available_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c5:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Pumpable Stock</div>
                    <div class="stat-value">{_fmt(pumpable_stock_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

    elif is_bfs:
        # BENEKU (BFS): 5 cards - OKW Production, GPP Production, Evacuation, Ullage, Pumpable
        c1, c2, c3, c4, c5 = st.columns(5)
        okw_prod_html = _value_with_delta(okw_prod_bbl, prev_okw_prod_bbl, "", "{:,.0f}")
        gpp_prod_html = _value_with_delta(gpp_prod_bbl, prev_gpp_prod_bbl, "", "{:,.0f}")

        with c1:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">OKW Production</div>
                    <div class="stat-value">{okw_prod_html}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c2:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">GPP Production</div>
                    <div class="stat-value">{gpp_prod_html}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c3:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Evacuation</div>
                    <div class="stat-value">{_fmt(bfs_evac_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c4:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Ullage available</div>
                    <div class="stat-value">{_fmt(ullage_available_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c5:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Pumpable Stock</div>
                    <div class="stat-value">{_fmt(pumpable_stock_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

    elif is_ndoni:
        # Ndoni: 6 cards - Receipt Agu, Receipt OFS, Other Receipts, Evacuation, Ullage, Pumpable
        c1, c2, c3, c4, c5, c6 = st.columns(6)
        nd_receipt_agu_html = _value_with_delta(nd_receipt_agu_bbl, prev_nd_receipt_agu_bbl, "", "{:,.0f}")
        nd_receipt_ofs_html = _value_with_delta(nd_receipt_ofs_bbl, prev_nd_receipt_ofs_bbl, "", "{:,.0f}")
        nd_other_receipt_html = _value_with_delta(nd_other_rcpt_bbl, prev_nd_other_rcpt_bbl, "", "{:,.0f}")

        with c1:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Receipt from Agu</div>
                    <div class="stat-value">{nd_receipt_agu_html}</div>
                    <div style="color:#6c757d;font-size:0.78rem;">Tankers: {_fmt(nd_tankers_from_aggu)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c2:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Receipt from OFS</div>
                    <div class="stat-value">{nd_receipt_ofs_html}</div>
                    <div style="color:#6c757d;font-size:0.78rem;">Tankers: {_fmt(nd_tankers_from_ofs)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c3:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Other Receipts</div>
                    <div class="stat-value">{nd_other_receipt_html}</div>
                    <div style="color:#6c757d;font-size:0.78rem;">Tankers: {_fmt(nd_other_tankers)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c4:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Evacuation</div>
                    <div class="stat-value">{_fmt(nd_dispatch_barge_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c5:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Ullage available</div>
                    <div class="stat-value">{_fmt(ullage_available_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c6:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Pumpable Stock</div>
                    <div class="stat-value">{_fmt(pumpable_stock_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        rd_html = _value_with_delta(river_draft_value, prev_river_draft_value, "m", "{:.2f}")
        rain_html = _value_with_delta(rainfall_value, prev_rainfall_value, "cm", "{:.2f}")
        label = river_display_date.strftime("%d-%b-%Y @ 06:00 hrs") if river_display_date else _selected_date.strftime("%d-%b-%Y")
        st.markdown(
            f"<div style='margin-top:0.75rem;font-size:1.05rem;font-weight:600;'>"
            f"River Draft: {rd_html}<br/>Rainfall: {rain_html}<br/>"
            f"<span style='color:#6c757d;font-size:0.9rem;'>Data for {label}</span></div>",
            unsafe_allow_html=True,
        )

    else:
        # Other locations: keep original 6 cards (Production, Evac, FSO, Ullage, Pumpable)
        c1, c2, c3, c4, c5, c6 = st.columns(6)
        default_prod_html = (
            _value_with_delta(prod_bbl, prev_prod_bbl, "", "{:,.0f}")
            if is_utapate
            else _fmt(prod_bbl)
        )

        with c1:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Production</div>
                    <div class="stat-value">{default_prod_html}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c2:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Evacuation</div>
                    <div class="stat-value">{_fmt(evac_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c3:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">FSO receipt</div>
                    <div class="stat-value">{_fmt(fso_receipt_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c4:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">FSO Stock</div>
                    <div class="stat-value">{_fmt(fso_stock_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c5:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Ullage available</div>
                    <div class="stat-value">{_fmt(ullage_available_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

        with c6:
            st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-label">Pumpable Stock</div>
                    <div class="stat-value">{_fmt(pumpable_stock_bbl)}</div>
                    <div style="color:#6c757d;font-size:0.8rem;">{_selected_date.strftime('%d-%b-%Y')}</div>
                </div>
            """, unsafe_allow_html=True)

    # ============ TANK VISUALIZATIONS (3D CYLINDRICAL - COMPACT) ============
    if can_view_tanks and not is_agge_location:
        st.markdown("### 🛢️ Tank Stock Levels")
        
        # Use the same dashboard date if available; otherwise default to today
        from datetime import date as _date, timedelta
        selected_date = st.session_state.get("dash_date_all_sites", _date.today())

        # Models used in this section
        from sqlalchemy import func as sa_func
        from models import OTRRecord
        try:
            from models import TankDailyStatus, TankOpStatus
        except Exception:
            TankDailyStatus = None
            TankOpStatus = None

        # Auto-save callback for per-tank daily status (selector at bottom of each card)
        def _save_tank_status_cb(_key_name, _tank_id, _the_date):
            if TankDailyStatus is None or TankOpStatus is None:
                return
            new_val = st.session_state.get(_key_name)
            if not new_val:
                return
            with get_session() as _s:
                row = (_s.query(TankDailyStatus)
                    .filter(TankDailyStatus.tank_id == _tank_id,
                            TankDailyStatus.date == _the_date)
                    .first())
                if row is None:
                    row = TankDailyStatus(tank_id=_tank_id, date=_the_date, op_status=TankOpStatus[new_val])
                    _s.add(row)
                else:
                    row.op_status = TankOpStatus[new_val]
                # Commit the status change
                _s.commit()
                # ----------------------- Audit log for tank daily status save -----------------------
                try:
                    from security import SecurityManager  # type: ignore
                    # Fetch user context from session state
                    user_ctx = st.session_state.get("auth_user") or {}
                    username = user_ctx.get("username", "unknown")
                    user_id = user_ctx.get("id")
                    # Determine action type based on whether the row existed
                    action_type = "CREATE" if row is None else "UPDATE"
                    # Create a composite ID using tank and date for the record
                    rec_id = f"{_tank_id}-{_the_date.isoformat()}"
                    SecurityManager.log_audit(
                        None,
                        username,
                        action_type,
                        resource_type="TankDailyStatus",
                        resource_id=rec_id,
                        details=f"{action_type.title()} tank daily status to {new_val}",
                        user_id=user_id,
                        location_id=active_location_id,
                    )
                except Exception:
                    # Do not interrupt the user flow if audit logging fails
                    pass

        # ----------------------- TANK VISUALS (date-aware) -----------------------
        with get_session() as s:
            tanks = s.query(Tank).filter(
                Tank.location_id == active_location_id
            ).order_by(Tank.name).all()
            
            if not tanks:
                st.info("ℹ️ No tanks configured yet. Go to **Add Asset ? Add Tank** to create tanks.")
            else:
                # Get stock as-of the selected date for each tank (latest txn on or before selected_date)
                tank_stocks = {}
                for tank in tanks:
                    latest_txn = (
                        s.query(
                            TankTransaction.ticket_id,
                            TankTransaction.date,
                            TankTransaction.time,
                        )
                        .filter(
                            TankTransaction.tank_id == tank.id,
                            TankTransaction.date <= selected_date  # <-- date-aware
                        )
                        .order_by(TankTransaction.date.desc(), TankTransaction.time.desc())
                        .first()
                    )

                    if latest_txn and latest_txn.ticket_id:
                        otr = s.query(OTRRecord).filter(
                            OTRRecord.ticket_id == latest_txn.ticket_id
                        ).first()
                        current_stock = float(otr.nsv_bbl if otr else 0.0)
                    else:
                        current_stock = 0.0
                    
                    tank_stocks[tank.id] = current_stock
                
                # Display tanks in grid (5 columns)
                num_cols = 5
                tank_rows = [tanks[i:i+num_cols] for i in range(0, len(tanks), num_cols)]
                
                for tank_row in tank_rows:
                    cols = st.columns(num_cols)
                    
                    for idx, tank in enumerate(tank_row):
                        with cols[idx]:
                            current_stock = tank_stocks.get(tank.id, 0.0)
                            
                            # Get capacity safely
                            try:
                                capacity = float(tank.capacity_bbl or 100000)
                            except:
                                capacity = 100000.0
                            
                            fill_percentage = min((current_stock / capacity * 100), 100) if capacity > 0 else 0
                            
                            # Color based on fill level
                            if fill_percentage >= 80:
                                liquid_color = "#28a745"
                                liquid_dark = "#1e7e34"
                                status_emoji = "🟢"
                            elif fill_percentage >= 50:
                                liquid_color = "#ffc107"
                                liquid_dark = "#d39e00"
                                status_emoji = "🟡"
                            elif fill_percentage >= 20:
                                liquid_color = "#fd7e14"
                                liquid_dark = "#dc3545"
                                status_emoji = "🟠"
                            else:
                                liquid_color = "#dc3545"
                                liquid_dark = "#bd2130"
                                status_emoji = "🔴"
                            
                            status_icon = "❌" if getattr(tank, 'status', 'INACTIVE') == "INACTIVE" else "✓"
                            
                            # Get product name safely
                            product_name = (
                                getattr(tank, 'product_type', None) or 
                                getattr(tank, 'product', None) or 
                                'N/A'
                            )
                            
                            # Get tank code safely
                            tank_code = getattr(tank, 'code', f'T-{tank.id}')
                            
                            # Calculate SVG parameters (smaller dimensions)
                            tank_height = 140
                            liquid_height = (fill_percentage / 100) * tank_height
                            liquid_y = tank_height - liquid_height
                            
                            # Read current daily status for the selected date (fallback READY if not available)
                            status_text = "READY"
                            if TankDailyStatus is not None and TankOpStatus is not None:
                                row = (s.query(TankDailyStatus)
                                    .filter(TankDailyStatus.tank_id == tank.id,
                                            TankDailyStatus.date == selected_date)
                                    .first())
                                if row is not None:
                                    status_text = getattr(row.op_status, "name", "READY")

                            # Create compact 3D cylindrical tank using SVG
                            with st.container(border=True):
                                # Tank name (compact)
                                st.markdown(
                                    f"<div style='text-align: center; font-weight: bold; font-size: 0.9rem; margin-bottom: 0.2rem;'>{tank.name} {status_icon}</div>",
                                    unsafe_allow_html=True
                                )

                                # Status line immediately below the tank name (display only)
                                st.markdown(
                                    f"<div style='text-align: center; font-size: 0.75rem; color:#666; margin-bottom: 0.2rem;'>Status: <b>{status_text.title()}</b></div>",
                                    unsafe_allow_html=True
                                )

                                # 3D Tank SVG (compact) � unchanged design
                                svg_code = f'''
                                <svg width="100%" height="200" viewBox="0 0 140 200" xmlns="http://www.w3.org/2000/svg">
                                    <defs>
                                        <linearGradient id="tankGrad{tank.id}" x1="0%" y1="0%" x2="100%" y2="0%">
                                            <stop offset="0%" style="stop-color:#c0c0c0;stop-opacity:1" />
                                            <stop offset="50%" style="stop-color:#e8e8e8;stop-opacity:1" />
                                            <stop offset="100%" style="stop-color:#c0c0c0;stop-opacity:1" />
                                        </linearGradient>
                                        
                                        <linearGradient id="liquidGrad{tank.id}" x1="0%" y1="0%" x2="100%" y2="0%">
                                            <stop offset="0%" style="stop-color:{liquid_dark};stop-opacity:0.9" />
                                            <stop offset="50%" style="stop-color:{liquid_color};stop-opacity:1" />
                                            <stop offset="100%" style="stop-color:{liquid_dark};stop-opacity:0.9" />
                                        </linearGradient>
                                        
                                        <radialGradient id="topGrad{tank.id}" cx="50%" cy="50%" r="50%">
                                            <stop offset="0%" style="stop-color:#ffffff;stop-opacity:1" />
                                            <stop offset="100%" style="stop-color:#d0d0d0;stop-opacity:1" />
                                        </radialGradient>
                                        
                                        <radialGradient id="bottomGrad{tank.id}" cx="50%" cy="50%" r="50%">
                                            <stop offset="0%" style="stop-color:#a0a0a0;stop-opacity:1" />
                                            <stop offset="100%" style="stop-color:#707070;stop-opacity:1" />
                                        </radialGradient>
                                    </defs>
                                    
                                    <!-- Stock badge (smaller) -->
                                    <rect x="85" y="5" width="50" height="18" rx="9" fill="{liquid_color}" opacity="0.9"/>
                                    <text x="110" y="17" text-anchor="middle" fill="white" font-size="10" font-weight="bold">
                                        {current_stock/1000:.1f}K
                                    </text>
                                    
                                    <!-- Tank top ellipse -->
                                    <ellipse cx="70" cy="30" rx="40" ry="12" fill="url(#topGrad{tank.id})" stroke="#999" stroke-width="1.5"/>
                                    
                                    <!-- Tank body (cylinder) -->
                                    <rect x="30" y="30" width="80" height="{tank_height}" fill="url(#tankGrad{tank.id})" stroke="#999" stroke-width="1.5"/>
                                    
                                    <!-- Liquid fill -->
                                    <rect x="30" y="{30 + liquid_y}" width="80" height="{liquid_height}" fill="url(#liquidGrad{tank.id})"/>
                                    
                                    <!-- Liquid top surface (ellipse) -->
                                    <ellipse cx="70" cy="{30 + liquid_y}" rx="40" ry="12" fill="{liquid_color}" opacity="0.8"/>
                                    
                                    <!-- Percentage text (smaller) -->
                                    <text x="70" y="{30 + tank_height/2 + 6}" text-anchor="middle" fill="white" font-size="24" font-weight="bold" 
                                        style="text-shadow: 2px 2px 4px rgba(0,0,0,0.7);">
                                        {fill_percentage:.0f}%
                                    </text>
                                    
                                    <!-- Tank bottom ellipse -->
                                    <ellipse cx="70" cy="{30 + tank_height}" rx="40" ry="12" fill="url(#bottomGrad{tank.id})" stroke="#666" stroke-width="1.5"/>
                                    
                                    <!-- Bottom shadow -->
                                    <ellipse cx="70" cy="{33 + tank_height}" rx="42" ry="6" fill="black" opacity="0.2"/>
                                </svg>
                                '''
                                
                                # Use components.html to render SVG
                                import streamlit.components.v1 as components
                                components.html(svg_code, height=200)
                                
                                # Compact info display
                                st.markdown(f"""
                                    <div style='font-size: 0.75rem; line-height: 1.3; color: #666;'>
                                        <div style='display: flex; justify-content: space-between; margin-bottom: 0.2rem;'>
                                            <span>Stock:</span>
                                            <strong style='color: {liquid_color};'>{current_stock:,.0f}</strong>
                                        </div>
                                        <div style='display: flex; justify-content: space-between; margin-bottom: 0.2rem;'>
                                            <span>Capacity:</span>
                                            <strong>{capacity:,.0f}</strong>
                                        </div>
                                        <div style='display: flex; justify-content: space-between; margin-bottom: 0.2rem;'>
                                            <span>Available:</span>
                                            <strong>{(capacity - current_stock):,.0f}</strong>
                                        </div>
                                        <div style='display: flex; justify-content: space-between; margin-bottom: 0.2rem;'>
                                            <span>Level:</span>
                                            <strong style='color: {liquid_color};'>{status_emoji} {fill_percentage:.1f}%</strong>
                                        </div>
                                        <div style='text-align: center; padding-top: 0.3rem; border-top: 1px solid #dee2e6; margin-top: 0.3rem;'>
                                            <div style='font-size: 0.7rem;'>{product_name}</div>
                                            <div style='font-size: 0.65rem; color: #999;'>{tank_code}</div>
                                        </div>
                                    </div>
                                """, unsafe_allow_html=True)

                                # --- Selector at the bottom of the card (auto-saves on change) ---
                                if TankDailyStatus is not None and TankOpStatus is not None:
                                    status_options = [e.name for e in TankOpStatus]
                                    _key = f"tank_status_{tank.id}_{selected_date.isoformat()}"
                                    st.selectbox(
                                        "Status",
                                        status_options,
                                        index=status_options.index(status_text) if status_text in status_options else 0,
                                        key=_key,
                                        label_visibility="collapsed",
                                        on_change=_save_tank_status_cb,
                                        args=(_key, tank.id, selected_date),
                                    )
    # ===================== MONTHLY DATA (place between Tank Stock Levels and Trend) =====================
    st.markdown("### 📊 Monthly Data")

    from datetime import date as _date, datetime, timedelta, time as dt_time
    import pandas as pd

    # --- Date range selector (default: current month to dashboard date) ---
    _md_default_to = st.session_state.get("dash_date_all_sites", _date.today())
    _md_default_from = _md_default_to.replace(day=1)

    mcol1, mcol2 = st.columns(2)
    with mcol1:
        md_from = st.date_input("From (Monthly Data)", value=_md_default_from, key="monthly_from")
    with mcol2:
        md_to = st.date_input("To (Monthly Data)", value=_md_default_to, key="monthly_to")

    # Guard
    if md_from > md_to:
        st.warning("⚠️ 'From' date is after 'To' date. Please adjust the range.")
    else:
        # ---------- Helpers ----------
        def _fmt(v):
            return f"{v:,.0f}" if isinstance(v, (int, float)) else "-"

        days_range_count = max(1, (md_to - md_from).days + 1)

        agge_monthly_receipt_from_yade = None
        agge_monthly_evacuation_bbl = None
        agge_monthly_fso_receipt_bbl = None
        agge_avg_receipt_from_yade = None
        agge_avg_evacuation_bbl = None
        agge_avg_fso_receipt_bbl = None

        # Resolve location code (e.g., OML-13 for Utapate) and detect site
        with get_session() as s:
            try:
                from location_manager import LocationManager
                loc_obj = LocationManager.get_location_by_id(s, active_location_id)
                loc_code = (getattr(loc_obj, "code", "") or "").upper()
                loc_name = (getattr(loc_obj, "name", "") or "")
            except Exception:
                loc_code, loc_name = "", ""

            def _canon(txt: str) -> str:
                return str(txt or "").upper().replace(" ", "").replace("-", "")

            loc_fingerprint = {_canon(loc_code), _canon(loc_name)}
            is_asemoku = bool(loc_fingerprint & {"JETTY", "ASEMOKU", "ASEMOKUJETTY"})
            is_utapate = bool(loc_fingerprint & {"UTAPATE", "OML13"})
            is_aggu    = bool(loc_fingerprint & {"AGGU"})
            is_agge    = bool(loc_fingerprint & {"AGGE"})
            is_bfs     = bool(loc_fingerprint & {"BFS", "BENEKU", "BENEKU(BFS)"})
            # ℹ️ NEW: Ndoni flag
            is_ndoni  = bool(loc_fingerprint & {"NDONI"})

            if is_agge:
                try:
                    from models import TOAYadeSummary, YadeVoyage, OTRVessel, FSOOperation
                    from fso_config import FSOConfig
                except Exception:
                    pass
                else:
                    yade_rows = (
                        s.query(TOAYadeSummary.gsv_loaded_bbl)
                        .join(YadeVoyage, TOAYadeSummary.voyage_id == YadeVoyage.id)
                        .filter(
                            YadeVoyage.location_id == active_location_id,
                            TOAYadeSummary.date >= md_from,
                            TOAYadeSummary.date <= md_to,
                        )
                        .all()
                    )
                    if yade_rows:
                        agge_monthly_receipt_from_yade = sum(
                            abs(float(val or 0.0)) for (val,) in yade_rows
                        )

                    otr_rows = (
                        s.query(OTRVessel.net_receipt_dispatch)
                        .filter(
                            OTRVessel.location_id == active_location_id,
                            OTRVessel.date >= md_from,
                            OTRVessel.date <= md_to,
                        )
                        .all()
                    )
                    if otr_rows:
                        agge_monthly_evacuation_bbl = sum(
                            abs(float(val or 0.0)) for (val,) in otr_rows
                        )

                    fso_vessel = None
                    loc_candidates = []
                    if loc_code:
                        loc_candidates.append(loc_code.upper())
                    if loc_name:
                        loc_candidates.append(str(loc_name).upper())
                    if _canon(loc_code) == "AGGE" or _canon(loc_name) == "AGGE":
                        loc_candidates.append("AGGE")

                    for cand in loc_candidates:
                        vessels = FSOConfig.get_fso_for_location(cand)
                        if vessels:
                            fso_vessel = vessels[0]
                            break

                    if not fso_vessel:
                        fso_vessel = FSOConfig.get_default_fso("AGGE")

                    if fso_vessel:
                        extended_from = md_from - timedelta(days=1)
                        extended_to = md_to + timedelta(days=1)
                        fso_entries = (
                            s.query(FSOOperation)
                            .filter(
                                FSOOperation.location_id == active_location_id,
                                FSOOperation.fso_vessel == fso_vessel,
                                FSOOperation.date >= extended_from,
                                FSOOperation.date <= extended_to,
                            )
                            .order_by(FSOOperation.date, FSOOperation.time)
                            .all()
                        )

                        total_receipts = 0.0
                        for entry in fso_entries:
                            entry_time = _coerce_time(entry.time)
                            if not entry_time:
                                continue
                            entry_dt = datetime.combine(entry.date, entry_time)
                            day_key = entry_dt.date()
                            if entry_time < dt_time(6, 1):
                                day_key = day_key - timedelta(days=1)
                            if day_key < md_from or day_key > md_to:
                                continue
                            op_label = (entry.operation or "").strip().lower()
                            if op_label == "receipt" and entry.net_receipt_dispatch is not None:
                                try:
                                    total_receipts += abs(float(entry.net_receipt_dispatch or 0.0))
                                except Exception:
                                    continue

                        if total_receipts:
                            agge_monthly_fso_receipt_bbl = total_receipts

                    if agge_monthly_receipt_from_yade is not None:
                        agge_avg_receipt_from_yade = agge_monthly_receipt_from_yade / days_range_count
                    if agge_monthly_evacuation_bbl is not None:
                        agge_avg_evacuation_bbl = agge_monthly_evacuation_bbl / days_range_count
                    if agge_monthly_fso_receipt_bbl is not None:
                        agge_avg_fso_receipt_bbl = agge_monthly_fso_receipt_bbl / days_range_count

            # ===== 1) Production & Evacuation totals (sum over range) from Material Balance =====
            prod_total = 0.0
            evac_total = 0.0
            avg_prod = 0.0
            avg_evac = 0.0
            df_mb = None
            try:
                from material_balance_calculator import MaterialBalanceCalculator as MBCalc
                mb_rows = MBCalc.calculate_material_balance(
                    entries=None,
                    location_code=loc_code,
                    date_from=md_from,
                    date_to=md_to,
                    location_id=active_location_id,
                    debug=False
                )
                if mb_rows:
                    df_mb = pd.DataFrame(mb_rows)
                    # Be tolerant to column casing/spacing
                    def _col(df, candidates):
                        for c in candidates:
                            if c in df.columns:
                                return c
                        lower_map = {str(c).lower(): c for c in df.columns}
                        for c in candidates:
                            if c.lower() in lower_map:
                                return lower_map[c.lower()]
                        return None

                    c_receipt  = _col(df_mb, ["Receipt"])
                    c_dispatch = _col(df_mb, ["Dispatch"])

                    if c_receipt is not None:
                        prod_total = float(pd.to_numeric(df_mb[c_receipt], errors="coerce").fillna(0).sum())
                    if c_dispatch is not None:
                        evac_total = float(pd.to_numeric(df_mb[c_dispatch], errors="coerce").fillna(0).sum())

                    # Average per day within the selected range (uniform basis)
                    avg_prod = prod_total / days_range_count
                    avg_evac = evac_total / days_range_count
            except Exception:
                pass  # leave zeros

            # ===== Common case-insensitive column finder =====
            def _find_col(df: pd.DataFrame, candidates):
                if df is None or df.empty:
                    return None
                for c in candidates:
                    if c in df.columns:
                        return c
                lower_map = {str(c).strip().lower(): c for c in df.columns}
                for c in candidates:
                    lc = str(c).strip().lower()
                    if lc in lower_map:
                        return lower_map[lc]
                return None

            # ===== Asemoku Jetty specific monthly mapping (cards: ANZ Production, BFS Receipt, Evacuation, BCCR) =====
            # Anz Production -> "ANZ Receipt" (sum over range)
            # BFS Receipt    -> "OKW Receipt" (sum over range)
            # Evacuation     -> "Dispatch to barge" (sum over range)
            # BCCR           -> (leave empty for now)
            anz_total = None
            bfs_receipt_total = None
            evac_total_asemoku = None
            avg_anz = None
            avg_bfs_receipt = None
            avg_evac_asemoku = None
            bccr_total = None
            avg_bccr = None

            if is_asemoku and df_mb is not None:
                c_anz = _find_col(df_mb, ["ANZ Receipt"])
                c_okw = _find_col(df_mb, ["OKW Receipt"])
                c_disp_barge = _find_col(df_mb, ["Dispatch to barge"])

                if c_anz:
                    anz_total = float(pd.to_numeric(df_mb[c_anz], errors="coerce").fillna(0).sum())
                    avg_anz = anz_total / days_range_count
                if c_okw:
                    bfs_receipt_total = float(pd.to_numeric(df_mb[c_okw], errors="coerce").fillna(0).sum())
                    avg_bfs_receipt = bfs_receipt_total / days_range_count
                if c_disp_barge:
                    evac_total_asemoku = float(pd.to_numeric(df_mb[c_disp_barge], errors="coerce").fillna(0).sum())
                    avg_evac_asemoku = evac_total_asemoku / days_range_count

            # ===== Beneku (BFS) specific monthly mapping =====
            # OKW Production        -> GPPProductionRecord.okw_production (sum range)
            # GPP Production        -> GPPProductionRecord.total_production (sum range)
            # Evacuation            -> MB "Dispatch to Jetty"
            # BFS Condensate Receipt-> MB "Receipt-Condensate"/"Receipt - Condensate"
            okw_total = 0.0
            gpp_total = 0.0
            bfs_evac_total = 0.0
            bfs_cond_total = 0.0
            avg_okw = avg_gpp = avg_bfs_evac = avg_bfs_cond = 0.0

            if is_bfs:
                # From reporting page - GPPProductionRecord
                try:
                    from models import GPPProductionRecord
                except Exception:
                    GPPProductionRecord = None

                if GPPProductionRecord is not None:
                    try:
                        recs = (
                            s.query(GPPProductionRecord)
                            .filter(
                                GPPProductionRecord.location_id == active_location_id,
                                GPPProductionRecord.date >= md_from,
                                GPPProductionRecord.date <= md_to,
                            )
                            .all()
                        )
                        if recs:
                            okw_total = sum(float(getattr(r, "okw_production", 0.0) or 0.0) for r in recs)
                            gpp_total = sum(float(getattr(r, "total_production", 0.0) or 0.0) for r in recs)
                            avg_okw = okw_total / days_range_count
                            avg_gpp = gpp_total / days_range_count
                    except Exception:
                        pass

                # From Material Balance
                if df_mb is not None:
                    c_bfs_evac = _find_col(df_mb, ["Dispatch to Jetty"])
                    c_bfs_cond = _find_col(df_mb, ["Receipt-Condensate", "Receipt - Condensate"])

                    if c_bfs_evac:
                        bfs_evac_total = float(pd.to_numeric(df_mb[c_bfs_evac], errors="coerce").fillna(0).sum())
                        avg_bfs_evac = bfs_evac_total / days_range_count
                    if c_bfs_cond:
                        bfs_cond_total = float(pd.to_numeric(df_mb[c_bfs_cond], errors="coerce").fillna(0).sum())
                        avg_bfs_cond = bfs_cond_total / days_range_count

            # ===== Ndoni specific monthly mapping =====
            # Receipt from Agu   -> MB "Receipt from Agu"
            # Receipt from OFS   -> MB "Receipt from OFS"
            # Other Receipts     -> MB "Other Receipts"
            # Evacuation         -> MB "Dispatch to barge"
            agu_total = ofs_total = other_total = ndoni_evac_total = 0.0
            avg_agu = avg_ofs = avg_other = avg_ndoni_evac = 0.0

            if is_ndoni and df_mb is not None:
                c_agu = _find_col(df_mb, ["Receipt from Agu"])
                c_ofs = _find_col(df_mb, ["Receipt from OFS"])
                c_oth = _find_col(df_mb, ["Other Receipts"])
                c_disp_barge_nd = _find_col(df_mb, ["Dispatch to barge"])

                if c_agu:
                    agu_total = float(pd.to_numeric(df_mb[c_agu], errors="coerce").fillna(0).sum())
                    avg_agu = agu_total / days_range_count
                if c_ofs:
                    ofs_total = float(pd.to_numeric(df_mb[c_ofs], errors="coerce").fillna(0).sum())
                    avg_ofs = ofs_total / days_range_count
                if c_oth:
                    other_total = float(pd.to_numeric(df_mb[c_oth], errors="coerce").fillna(0).sum())
                    avg_other = other_total / days_range_count
                if c_disp_barge_nd:
                    ndoni_evac_total = float(pd.to_numeric(df_mb[c_disp_barge_nd], errors="coerce").fillna(0).sum())
                    avg_ndoni_evac = ndoni_evac_total / days_range_count

            # ===== 2) Export total (sum over range) from FSO Material Balance (MT TULJA KALYANI) =====
            export_total = None  # "-" if not available
            avg_export = None

            # Canonicalize FSO location code
            def _canonical_fso_code(code: str | None) -> str:
                if not code:
                    return ""
                s2 = str(code).strip().upper()
                # normalize spaces/hyphens so OML-13 / OML 13 / OML13 all match
                s_norm = s2.replace(" ", "").replace("-", "")
                aliases = {
                    "UTAPATE": "OML-13",
                    "OML13": "OML-13",
                    "OML-13": "OML-13",
                    "OML 13": "OML-13",
                    "AGGE": "AGGE",
                }
                # try direct first, then normalized
                return aliases.get(s2, aliases.get(s_norm, s2))

            canon_loc = _canonical_fso_code(loc_code)

            # Helpers to find columns & sum exports from a df like the FSO MB page emits
            def _find_col_generic(df: pd.DataFrame, candidates):
                # exact then case-insensitive
                for c in candidates:
                    if c in df.columns:
                        return c
                lower_map = {str(c).strip().lower(): c for c in df.columns}
                for c in candidates:
                    lc = str(c).strip().lower()
                    if lc in lower_map:
                        return lower_map[lc]
                return None

            def _sum_exports_from_df(df: pd.DataFrame, date_from, date_to, vessel_name="MT TULJA KALYANI"):
                if df is None or df.empty:
                    return None

                # Identify date column
                date_col = _find_col_generic(df, ["Date", "MB Date", "As Of", "Asof"])
                if date_col is None:
                    return None

                dfx = df.copy()
                dfx[date_col] = pd.to_datetime(dfx[date_col], errors="coerce").dt.date
                dfx = dfx[(dfx[date_col] >= date_from) & (dfx[date_col] <= date_to)]
                if dfx.empty:
                    return None

                # Optional location filter (when a location column exists)
                loc_col = _find_col_generic(dfx, ["Location", "Loc", "Site", "Code"])
                if loc_col is not None and canon_loc:
                    loc_norm = dfx[loc_col].astype(str).str.upper()
                    loc_norm = loc_norm.str.replace(" ", "", regex=False).str.replace("-", "", regex=False)
                    dfx = dfx[loc_norm == canon_loc.replace("-", "").replace(" ", "")]
                    if dfx.empty:
                        return None

                # Optional vessel filter (when a vessel column exists)
                vessel_col = _find_col_generic(dfx, ["Vessel", "FSO Vessel", "FSO", "Vessel Name", "fso_vessel"])
                if vessel_col is not None and vessel_name:
                    dfx = dfx[dfx[vessel_col].astype(str).str.upper().str.contains(vessel_name.upper())]
                    if dfx.empty:
                        return None

                # Exports column (must exist)
                exp_col = _find_col_generic(
                    dfx,
                    ["Exports (bbls)", "Export (bbls)", "exports (bbls)", "export (bbls)",
                    "exports_bbls", "export_bbls", "Exports", "Export"]
                )
                if exp_col is None:
                    return None

                return float(pd.to_numeric(dfx[exp_col], errors="coerce").fillna(0).sum())

            # 1) Try common FSO MB page cache keys first
            _possible_keys = [
                "fso_mb_df", "fso_mb_table", "fso_material_balance_df",
                "fso_mb_daily", "fso_mb_cache", "fso_mb_summary_df",
                "fso_mb_pivot", "fso_mb_records"
            ]
            for _k in _possible_keys:
                if _k in st.session_state and export_total is None:
                    try:
                        _obj = st.session_state[_k]
                        _df = _obj.copy() if isinstance(_obj, pd.DataFrame) else pd.DataFrame(_obj)
                        val = _sum_exports_from_df(_df, md_from, md_to, "MT TULJA KALYANI")
                        if val is not None:
                            export_total = val
                    except Exception:
                        pass

            # 2) If still not found, scan *every* DataFrame-like object in session_state
            if export_total is None:
                for _k, _obj in list(st.session_state.items()):
                    try:
                        if isinstance(_obj, pd.DataFrame):
                            _df = _obj
                        elif isinstance(_obj, (list, tuple)) and _obj and isinstance(_obj[0], dict):
                            _df = pd.DataFrame(_obj)
                        else:
                            continue
                        if _df is None or _df.empty:
                            continue
                        val = _sum_exports_from_df(_df.copy(), md_from, md_to, "MT TULJA KALYANI")
                        if val is not None:
                            export_total = val
                            break
                    except Exception:
                        continue

            # 3) Fallback: compute from raw FSOOperation by day windows (06:01?06:00) and summing "Export" ops
            if export_total is None:
                try:
                    from fso_config import FSOConfig
                    from models import FSOOperation

                    # Map location ? vessel
                    try:
                        fso_map = {k.upper(): v for k, v in FSOConfig.get_fso_locations().items()}
                        vessel_name = fso_map.get(canon_loc, "MT TULJA KALYANI")
                    except Exception:
                        vessel_name = "MT TULJA KALYANI"

                    # Pull slightly wider range so we can slice per-day windows
                    ext_from = md_from - timedelta(days=1)
                    ext_to   = md_to   + timedelta(days=1)

                    entries = (s.query(FSOOperation)
                                .filter(
                                    FSOOperation.location_id == active_location_id,
                                    FSOOperation.fso_vessel == vessel_name,
                                    FSOOperation.date >= ext_from,
                                    FSOOperation.date <= ext_to,
                                )
                                .order_by(FSOOperation.date, FSOOperation.time)
                                .all())

                    if entries:
                        def _to_time(t):
                            if isinstance(t, dt_time):
                                return t
                            try:
                                return datetime.strptime(str(t), "%H:%M").time()
                            except Exception:
                                return dt_time(0, 0)

                        total = 0.0
                        day_list = pd.date_range(md_from, md_to, freq="D").date
                        for D in day_list:
                            win_start = datetime.combine(D, dt_time(6, 1))
                            win_end   = datetime.combine(D + timedelta(days=1), dt_time(6, 0))
                            # Filter window
                            per = []
                            for e in entries:
                                try:
                                    edt = datetime.combine(e.date, _to_time(e.time))
                                    if win_start <= edt <= win_end:
                                        per.append(e)
                                except Exception:
                                    continue
                            if not per:
                                continue
                            # Sum exports: operations like "Export"/"Exports"/"Shipment"/"Ship Out"
                            day_exp = 0.0
                            for e in per:
                                op = (getattr(e, "operation", "") or "").strip().lower()
                                if any(tok in op for tok in ["export", "shipment", "ship out"]):
                                    try:
                                        v = float(getattr(e, "net_receipt_dispatch", 0.0) or 0.0)
                                    except Exception:
                                        v = 0.0
                                    if v != 0:
                                        day_exp += abs(v)
                            total += day_exp
                        export_total = total
                except Exception:
                    export_total = None

            # Average export (only used for non-Utapate cards)
            if export_total is not None:
                avg_export = export_total / days_range_count

            # ===== Render cards =====
            if is_asemoku:
                # Asemoku Jetty cards with averages (4 cards)
                c1, c2, c3, c4 = st.columns(4)

                with c1:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Anz Production</div>
                            <div class="stat-value">{_fmt(anz_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Anz Production: {_fmt(avg_anz)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c2:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">BFS Receipt</div>
                            <div class="stat-value">{_fmt(bfs_receipt_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg BFS Receipt: {_fmt(avg_bfs_receipt)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c3:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Evacuation</div>
                            <div class="stat-value">{_fmt(evac_total_asemoku)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Evacuation: {_fmt(avg_evac_asemoku)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c4:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">BCCR</div>
                            <div class="stat-value">{_fmt(bccr_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg BCCR: {_fmt(avg_bccr)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                (to be wired)
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

            elif is_bfs:
                # BENEKU (BFS): 4 cards � OKW Prod, GPP Prod, Evacuation, BFS Condensate Receipt (all with averages)
                c1, c2, c3, c4 = st.columns(4)

                with c1:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">OKW Production</div>
                            <div class="stat-value">{_fmt(okw_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg OKW Production: {_fmt(avg_okw)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c2:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">GPP Production</div>
                            <div class="stat-value">{_fmt(gpp_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg GPP Production: {_fmt(avg_gpp)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c3:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Evacuation</div>
                            <div class="stat-value">{_fmt(bfs_evac_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Evacuation: {_fmt(avg_bfs_evac)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c4:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">BFS Condensate Receipt</div>
                            <div class="stat-value">{_fmt(bfs_cond_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Condensate Receipt: {_fmt(avg_bfs_cond)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

            elif is_ndoni:
                # NDONI: 4 cards � Receipt from Agu, Receipt from OFS, Other Receipts, Evacuation (all with averages)
                c1, c2, c3, c4 = st.columns(4)

                with c1:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Receipt from Agu</div>
                            <div class="stat-value">{_fmt(agu_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Receipt from Agu: {_fmt(avg_agu)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c2:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Receipt from OFS</div>
                            <div class="stat-value">{_fmt(ofs_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Receipt from OFS: {_fmt(avg_ofs)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c3:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Other Receipts</div>
                            <div class="stat-value">{_fmt(other_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Other Receipts: {_fmt(avg_other)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c4:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Evacuation</div>
                            <div class="stat-value">{_fmt(ndoni_evac_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Evacuation: {_fmt(avg_ndoni_evac)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

            elif is_agge:
                # AGGE: 3 cards � Receipt from Yade, Evacuation (OTR), FSO Receipt
                c1, c2, c3 = st.columns(3)
                range_note = f"{md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}"

                with c1:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Receipt from Yade</div>
                            <div class="stat-value">{_fmt(agge_monthly_receipt_from_yade)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg: {_fmt(agge_avg_receipt_from_yade)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {range_note}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c2:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Evacuation</div>
                            <div class="stat-value">{_fmt(agge_monthly_evacuation_bbl)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg: {_fmt(agge_avg_evacuation_bbl)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {range_note}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c3:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">FSO Receipt</div>
                            <div class="stat-value">{_fmt(agge_monthly_fso_receipt_bbl)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg: {_fmt(agge_avg_fso_receipt_bbl)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {range_note}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

            elif is_aggu:
                # AGGU: 3 cards only (Production, Evacuation, Tankers Dispatched)
                c1, c2, c3 = st.columns(3)

                with c1:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Production</div>
                            <div class="stat-value">{_fmt(prod_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Production: {_fmt(avg_prod)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c2:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Evacuation</div>
                            <div class="stat-value">{_fmt(evac_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Evacuation: {_fmt(avg_evac)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c3:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Tankers Dispatched</div>
                            <div class="stat-value">-</div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

            else:
                # Non-Asemoku, non-AGGU, non-BFS, non-NDONI locations (incl. Utapate). Keep 4 cards with averages.
                c1, c2, c3, c4 = st.columns(4)

                with c1:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Production</div>
                            <div class="stat-value">{_fmt(prod_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Production: {_fmt(avg_prod)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c2:
                    st.markdown(f"""
                        <div class="stat-card">
                            <div class="stat-label">Evacuation</div>
                            <div class="stat-value">{_fmt(evac_total)}</div>
                            <div style="color:#6c757d;font-size:0.8rem;">
                                Avg Evacuation: {_fmt(avg_evac)}
                            </div>
                            <div style="color:#6c757d;font-size:0.75rem;">
                                {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                            </div>
                        </div>
                    """, unsafe_allow_html=True)

                with c3:
                    # For Utapate ONLY, hide the average line for Export
                    if is_utapate:
                        st.markdown(f"""
                            <div class="stat-card">
                                <div class="stat-label">Export (MT TULJA KALYANI)</div>
                                <div class="stat-value">{_fmt(export_total)}</div>
                                <div style="color:#6c757d;font-size:0.75rem;">
                                    {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                                </div>
                            </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                            <div class="stat-card">
                                <div class="stat-label">Export (MT TULJA KALYANI)</div>
                                <div class="stat-value">{_fmt(export_total)}</div>
                                <div style="color:#6c757d;font-size:0.8rem;">
                                    Avg Export: {_fmt(avg_export)}
                                </div>
                                <div style="color:#6c757d;font-size:0.75rem;">
                                    {md_from.strftime('%d-%b-%Y')} ? {md_to.strftime('%d-%b-%Y')}
                                </div>
                            </div>
                        """, unsafe_allow_html=True)

                with c4:
                    # For Utapate ONLY, hide the average line for Vessel Status & Stock
                    if is_utapate:
                        st.markdown(f"""
                            <div class="stat-card">
                                <div class="stat-label">Vessel Status & Stock</div>
                                <div class="stat-value">-</div>
                                <div style="color:#6c757d;font-size:0.75rem;">
                                    (to be wired)
                                </div>
                            </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                            <div class="stat-card">
                                <div class="stat-label">Vessel Status & Stock</div>
                                <div class="stat-value">-</div>
                                <div style="color:#6c757d;font-size:0.8rem;">
                                    Avg Vessel Status & Stock: -
                                </div>
                                <div style="color:#6c757d;font-size:0.75rem;">
                                    (to be wired)
                                </div>
                            </div>
                        """, unsafe_allow_html=True)


    if is_agge:
        st.markdown("### 🚦 Convoy & Vessel Status")
        st.caption(f"Snapshots for {_selected_date.strftime('%d-%b-%Y')} from Convoy Status page.")
        convoy_col, vessel_col = st.columns(2)
        yade_entries: list[dict[str, str]] = []
        vessel_entries: list[dict[str, str]] = []
        fetch_error = None
        try:
            from models import ConvoyStatusYade, ConvoyStatusVessel
            with get_session() as s_convoy:
                yade_rows = (
                    s_convoy.query(ConvoyStatusYade, YadeBarge.name)
                    .join(YadeBarge, ConvoyStatusYade.yade_barge_id == YadeBarge.id)
                    .filter(
                        ConvoyStatusYade.location_id == active_location_id,
                        ConvoyStatusYade.date == _selected_date,
                    )
                    .order_by(ConvoyStatusYade.status.asc(), YadeBarge.name.asc())
                    .all()
                )
                for rec, yade_name in yade_rows:
                    yade_entries.append(
                        {
                            "Status": (rec.status or "N/A").strip(),
                            "YADE": yade_name or "N/A",
                            "Convoy": rec.convoy_no or "N/A",
                            "Stock": rec.stock_display or "N/A",
                        }
                    )
                vessel_rows = (
                    s_convoy.query(ConvoyStatusVessel)
                    .filter(
                        ConvoyStatusVessel.location_id == active_location_id,
                        ConvoyStatusVessel.date == _selected_date,
                    )
                    .all()
                )
                for rec in vessel_rows:
                    vessel_entries.append(
                        {
                            "Vessel": (rec.vessel_name or "N/A").strip(),
                            "Status": (rec.status or "N/A").strip(),
                            "Shuttle": rec.shuttle_no or "N/A",
                            "Stock": rec.stock_display or "N/A",
                        }
                    )
        except Exception as exc:
            fetch_error = str(exc)
            log_error("Convoy/vessel snapshot load failed", exc_info=True)

        if fetch_error:
            st.error(f"Unable to load convoy status snapshots: {fetch_error}")

        yade_entries.sort(key=lambda item: (item["Status"], item["YADE"]))
        vessel_entries.sort(key=lambda item: item["Vessel"])

        with convoy_col:
            st.markdown("#### Convoy Status (YADE)")
            if not yade_entries:
                st.info("No YADE convoy statuses saved for this date.")
            else:
                status_groups = defaultdict(list)
                for entry in yade_entries:
                    status_groups[entry["Status"]].append(entry)
                for status in sorted(status_groups):
                    st.markdown(f"**{status}**")
                    for entry in status_groups[status]:
                        st.markdown(
                            f"- {entry['YADE']} | Convoy: {entry['Convoy']} | Stock: {entry['Stock']}"
                        )

        with vessel_col:
            st.markdown("#### Vessel Status")
            if not vessel_entries:
                st.info("No vessel statuses saved for this date.")
            else:
                for entry in vessel_entries:
                    st.markdown(
                        f"- **{entry['Vessel']}** � {entry['Status']} (Shuttle: {entry['Shuttle']}, Stock: {entry['Stock']})"
                    )

    else:
        # ====================================================================================================
       # ===================== PRODUCTION & EVACUATION TREND =====================
        st.markdown("### 📈 Production & Evacuation Trend")
    
        import pandas as pd
        import altair as alt
        from datetime import date as _date, datetime, timedelta
    
        # --- Separate date-range selector for Trend ---
        tcol1, tcol2 = st.columns(2)
        with tcol1:
            trend_from = st.date_input(
                "From (Trend)",
                value=st.session_state.get("dash_date_all_sites", _date.today()).replace(day=1),
                key="trend_from",
            )
        with tcol2:
            trend_to = st.date_input(
                "To (Trend)",
                value=st.session_state.get("dash_date_all_sites", _date.today()),
                key="trend_to",
            )
    
        if trend_from > trend_to:
            st.warning("⚠️ 'From (Trend)' is after 'To (Trend)'. Please adjust the range.")
        else:
            # Helper
            def _find_col(df: pd.DataFrame, candidates):
                if df is None or df.empty:
                    return None
                for c in candidates:
                    if c in df.columns:
                        return c
                lower_map = {str(c).strip().lower(): c for c in df.columns}
                for c in candidates:
                    lc = str(c).strip().lower()
                    if lc in lower_map:
                        return lower_map[lc]
                return None
    
            # Resolve location (to branch for Asemoku Jetty vs BFS vs others)
            with get_session() as s:
                try:
                    from location_manager import LocationManager
                    loc_obj = LocationManager.get_location_by_id(s, active_location_id)
                    loc_code = (getattr(loc_obj, "code", "") or "")
                    loc_name = (getattr(loc_obj, "name", "") or "")
                except Exception:
                    loc_code, loc_name = "", ""
    
            def _canon(txt: str) -> str:
                return str(txt or "").upper().replace(" ", "").replace("-", "")
    
            fp = {_canon(loc_code), _canon(loc_name)}
            is_asemoku = bool(fp & {"JETTY", "ASEMOKU", "ASEMOKUJETTY"})
            is_bfs     = bool(fp & {"BFS", "BENEKU", "BENEKU(BFS)"})
            is_ndoni   = bool(fp & {"NDONI"})  # ℹ️ Ndoni detection
    
            # Pull Material Balance rows for the selected range
            df_mb = None
            try:
                from material_balance_calculator import MaterialBalanceCalculator as MBCalc
                df_mb = pd.DataFrame(
                    MBCalc.calculate_material_balance(
                        entries=None,
                        location_code=(loc_code or "").upper(),
                        date_from=trend_from,
                        date_to=trend_to,
                        location_id=active_location_id,
                        debug=False,
                    )
                )
            except Exception:
                df_mb = None
    
            if df_mb is None or df_mb.empty:
                st.info("No material balance data available for the selected range.")
            else:
                # Ensure date column exists and is normalized
                dcol = _find_col(df_mb, ["Date"])
                if dcol is None:
                    st.info("Material balance result does not include a Date column.")
                else:
                    df_mb = df_mb.copy()
                    df_mb[dcol] = pd.to_datetime(df_mb[dcol], errors="coerce").dt.date
                    full_days = pd.DataFrame({"Date": pd.date_range(trend_from, trend_to, freq="D").date})
    
                    if is_asemoku:
                        # --- ASEMOKU JETTY: 3 lines (ANZ Production, BFS Receipt, Evacuation) ---
                        c_anz  = _find_col(df_mb, ["ANZ Receipt"])
                        c_okw  = _find_col(df_mb, ["OKW Receipt"])
                        c_disp = _find_col(df_mb, ["Dispatch to barge"])
    
                        agg = df_mb.groupby(dcol).agg({
                            (c_anz if c_anz else dcol): "sum",
                            (c_okw if c_okw else dcol): "sum",
                            (c_disp if c_disp else dcol): "sum",
                        }).reset_index()
    
                        # Rename to friendly labels
                        rename_map = {}
                        if c_anz:  rename_map[c_anz]  = "ANZ Production"
                        if c_okw:  rename_map[c_okw]  = "BFS Receipt"
                        if c_disp: rename_map[c_disp] = "Evacuation"
                        agg = agg.rename(columns=rename_map)
    
                        # Merge with full date skeleton
                        df_day = full_days.merge(agg.rename(columns={dcol: "Date"}), on="Date", how="left")
                        for col in ["ANZ Production", "BFS Receipt", "Evacuation"]:
                            if col not in df_day.columns:
                                df_day[col] = 0.0
                        df_day[["ANZ Production", "BFS Receipt", "Evacuation"]] = (
                            df_day[["ANZ Production", "BFS Receipt", "Evacuation"]]
                            .apply(pd.to_numeric, errors="coerce")
                            .fillna(0.0)
                        )
                        df_day["DateTS"] = pd.to_datetime(df_day["Date"])
    
                        # Totals for the small card
                        tot_anz  = float(df_day["ANZ Production"].sum())
                        tot_bfs  = float(df_day["BFS Receipt"].sum())
                        tot_evac = float(df_day["Evacuation"].sum())
    
                        # Extreme flags per series
                        def _extreme_flags(series):
                            s = series.fillna(0.0)
                            return (s == s.max()).astype(int), (s == s.min()).astype(int)
    
                        df_day["is_max_anz"],  df_day["is_min_anz"]  = _extreme_flags(df_day["ANZ Production"])
                        df_day["is_max_bfs"],  df_day["is_min_bfs"]  = _extreme_flags(df_day["BFS Receipt"])
                        df_day["is_max_evac"], df_day["is_min_evac"] = _extreme_flags(df_day["Evacuation"])
    
                        # Long-form for legend-friendly plotting (lines + points + labels)
                        df_anz = df_day[["Date", "DateTS", "ANZ Production", "is_max_anz", "is_min_anz"]].rename(
                            columns={"ANZ Production": "Value", "is_max_anz": "is_max", "is_min_anz": "is_min"}
                        )
                        df_anz["Series"] = "ANZ Production"
    
                        df_bfs = df_day[["Date", "DateTS", "BFS Receipt", "is_max_bfs", "is_min_bfs"]].rename(
                            columns={"BFS Receipt": "Value", "is_max_bfs": "is_max", "is_min_bfs": "is_min"}
                        )
                        df_bfs["Series"] = "BFS Receipt"
    
                        df_evac = df_day[["Date", "DateTS", "Evacuation", "is_max_evac", "is_min_evac"]].rename(
                            columns={"Evacuation": "Value", "is_max_evac": "is_max", "is_min_evac": "is_min"}
                        )
                        df_evac["Series"] = "Evacuation"
    
                        plot_df = pd.concat([df_anz, df_bfs, df_evac], ignore_index=True)
    
                        # Axis & scales
                        x_axis = alt.Axis(title="Date", format="%d-%b", labelAngle=0,
                                        tickCount={"interval": "day", "step": 1})
                        y_axis = alt.Axis(title="Quantity in bbls")
    
                        # Colors (Brown, Green, Blue for Asemoku)
                        domain = ["ANZ Production", "BFS Receipt", "Evacuation"]
                        range_  = ["#8B4513", "#006400", "#1E90FF"]
    
                        # Y domain padding for better fitting (room for labels + totals card)
                        y_domain_max = max(float(plot_df["Value"].max() or 1.0), 1.0) * 1.25
    
                        base = alt.Chart(plot_df).properties(height=360)
    
                        # Lines with legend
                        lines = base.mark_line(strokeWidth=2).encode(
                            x=alt.X("DateTS:T", axis=x_axis),
                            y=alt.Y("Value:Q", axis=y_axis, scale=alt.Scale(domain=[0, y_domain_max])),
                            color=alt.Color(
                                "Series:N",
                                scale=alt.Scale(domain=domain, range=range_),
                                legend=alt.Legend(title=None, orient="top", symbolStrokeWidth=6),
                            ),
                        )
    
                        # Triangular points
                        pts = base.mark_point(shape="triangle-up", filled=False, size=60).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        # One set of value labels (black)
                        labels = base.mark_text(dy=-12, color="black", fontSize=11).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            text=alt.Text("Value:Q", format=",.0f"),
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        # Bold labels for extremes (max & min)
                        max_labels = base.transform_filter(alt.datum.is_max == 1).mark_text(
                            dy=-12, color="black", fontWeight="bold", fontSize=12
                        ).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            text=alt.Text("Value:Q", format=",.0f"),
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        min_labels = base.transform_filter(alt.datum.is_min == 1).mark_text(
                            dy=-12, color="black", fontWeight="bold", fontSize=12
                        ).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            text=alt.Text("Value:Q", format=",.0f"),
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        # --- Totals card inside the chart ---
                        y_max_all = float(max(df_day[["ANZ Production", "BFS Receipt", "Evacuation"]].max()))
                        y_min_all = float(min(df_day[["ANZ Production", "BFS Receipt", "Evacuation"]].min()))
                        card_top = max(y_domain_max * 0.98, y_max_all)  # stay within domain
                        card_bottom = max(card_top * 0.70, y_min_all)
    
                        card_df = pd.DataFrame({
                            "x0": [pd.to_datetime(df_day["Date"].min())],
                            "x1": [pd.to_datetime(df_day["Date"].min()) +
                                pd.Timedelta(days=max(1, (trend_to - trend_from).days // 4))],
                            "y0": [card_bottom],
                            "y1": [card_top],
                            "t1": [f"ANZ: {tot_anz:,.0f} bbls"],
                            "t2": [f"BFS: {tot_bfs:,.0f} bbls"],
                            "t3": [f"Evac: {tot_evac:,.0f} bbls"],
                        })
    
                        card_rect = alt.Chart(card_df).mark_rect(
                            fill="#f8f9fa", stroke="#ccd1d6", opacity=0.9
                        ).encode(
                            x="x0:T", x2="x1:T", y="y0:Q", y2="y1:Q"
                        )
                        card_text1 = alt.Chart(card_df).mark_text(
                            align="left", dx=8, dy=8, fontSize=12
                        ).encode(
                            x="x0:T", y="y1:Q", text="t1"
                        )
                        card_text2 = alt.Chart(card_df).mark_text(
                            align="left", dx=8, dy=26, fontSize=12
                        ).encode(
                            x="x0:T", y="y1:Q", text="t2"
                        )
                        card_text3 = alt.Chart(card_df).mark_text(
                            align="left", dx=8, dy=44, fontSize=12
                        ).encode(
                            x="x0:T", y="y1:Q", text="t3"
                        )
    
                        chart_asemoku = (
                            card_rect + card_text1 + card_text2 + card_text3 +
                            lines + pts + labels + max_labels + min_labels
                        ).properties(
                            height=360,
                            padding={"left": 5, "right": 5, "top": 5, "bottom": 40}
                        ).configure_axis(
                            labelColor="#000",
                            titleColor="#000",
                            labelFontSize=11,
                            titleFontSize=12,
                        ).configure_legend(
                            labelFontSize=11,
                            titleFontSize=12,
                            orient="top",
                        ).configure_view(strokeOpacity=0)
    
                        st.altair_chart(chart_asemoku, use_container_width=True)
    
                    elif is_bfs:
                        # --- BENEKU (BFS): 3 lines (OKW Production, GPP Production, Evacuation) ---
                        # OKW & GPP from GPPProductionRecord (reporting page), Evacuation from MB ("Dispatch to Jetty")
                        try:
                            from models import GPPProductionRecord
                        except Exception:
                            GPPProductionRecord = None
    
                        gpp_agg = None
                        if GPPProductionRecord is not None:
                            try:
                                with get_session() as s2:
                                    recs = (
                                        s2.query(GPPProductionRecord)
                                        .filter(
                                            GPPProductionRecord.location_id == active_location_id,
                                            GPPProductionRecord.date >= trend_from,
                                            GPPProductionRecord.date <= trend_to,
                                        )
                                        .all()
                                    )
                                if recs:
                                    gpp_df = pd.DataFrame(
                                        [
                                            {
                                                "Date": r.date,
                                                "OKW Production": float(getattr(r, "okw_production", 0.0) or 0.0),
                                                "GPP Production": float(getattr(r, "total_production", 0.0) or 0.0),
                                            }
                                            for r in recs
                                        ]
                                    )
                                    gpp_agg = (
                                        gpp_df.groupby("Date", as_index=False)[
                                            ["OKW Production", "GPP Production"]
                                        ].sum()
                                    )
                            except Exception:
                                gpp_agg = None
    
                        # Evacuation from MB
                        evac_agg = None
                        c_evac = _find_col(df_mb, ["Dispatch to Jetty"])
                        if c_evac:
                            evac_agg = (
                                df_mb.groupby(dcol, as_index=False)[c_evac]
                                .sum()
                                .rename(columns={dcol: "Date", c_evac: "Evacuation"})
                            )
    
                        # Merge into daily skeleton
                        df_day = full_days.copy()  # has "Date"
    
                        if gpp_agg is not None:
                            df_day = df_day.merge(gpp_agg, on="Date", how="left")
                        else:
                            df_day["OKW Production"] = 0.0
                            df_day["GPP Production"] = 0.0
    
                        if evac_agg is not None:
                            df_day = df_day.merge(evac_agg, on="Date", how="left")
                        if "Evacuation" not in df_day.columns:
                            df_day["Evacuation"] = 0.0
    
                        for col in ["OKW Production", "GPP Production", "Evacuation"]:
                            if col not in df_day.columns:
                                df_day[col] = 0.0
    
                        df_day[["OKW Production", "GPP Production", "Evacuation"]] = (
                            df_day[["OKW Production", "GPP Production", "Evacuation"]]
                            .apply(pd.to_numeric, errors="coerce")
                            .fillna(0.0)
                        )
                        df_day["DateTS"] = pd.to_datetime(df_day["Date"])
    
                        # Totals for small card
                        tot_okw = float(df_day["OKW Production"].sum())
                        tot_gpp = float(df_day["GPP Production"].sum())
                        tot_evac = float(df_day["Evacuation"].sum())
    
                        # extremes
                        def _ext(series):
                            s = series.fillna(0.0)
                            return (s == s.max()).astype(int), (s == s.min()).astype(int)
    
                        df_day["is_max_okw"], df_day["is_min_okw"] = _ext(df_day["OKW Production"])
                        df_day["is_max_gpp"], df_day["is_min_gpp"] = _ext(df_day["GPP Production"])
                        df_day["is_max_evac"], df_day["is_min_evac"] = _ext(df_day["Evacuation"])
    
                        # Long-form for plotting
                        frames = []
                        for col, s_name, imax, imin in [
                            ("OKW Production", "OKW Production", "is_max_okw", "is_min_okw"),
                            ("GPP Production", "GPP Production", "is_max_gpp", "is_min_gpp"),
                            ("Evacuation", "Evacuation", "is_max_evac", "is_min_evac"),
                        ]:
                            sub = df_day[["Date", "DateTS", col, imax, imin]].rename(
                                columns={col: "Value", imax: "is_max", imin: "is_min"}
                            )
                            sub["Series"] = s_name
                            frames.append(sub)
                        plot_df = pd.concat(frames, ignore_index=True)
    
                        # Axis & scales
                        x_axis = alt.Axis(
                            title="Date", format="%d-%b", labelAngle=0,
                            tickCount={"interval": "day", "step": 1}
                        )
                        y_axis = alt.Axis(title="Quantity in bbls")
    
                        # Colors (Brown, Green, Blue) for BFS
                        domain = ["OKW Production", "GPP Production", "Evacuation"]
                        range_  = ["#8B4513", "#006400", "#1E90FF"]
    
                        y_domain_max = max(float(plot_df["Value"].max() or 1.0), 1.0) * 1.25
    
                        base = alt.Chart(plot_df).properties(height=360)
    
                        # Lines with legend
                        lines = base.mark_line(strokeWidth=2).encode(
                            x=alt.X("DateTS:T", axis=x_axis),
                            y=alt.Y("Value:Q", axis=y_axis, scale=alt.Scale(domain=[0, y_domain_max])),
                            color=alt.Color(
                                "Series:N",
                                scale=alt.Scale(domain=domain, range=range_),
                                legend=alt.Legend(title=None, orient="top", symbolStrokeWidth=6),
                            ),
                        )
    
                        # Triangular points
                        pts = base.mark_point(shape="triangle-up", filled=False, size=60).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        # Regular labels
                        labels = base.mark_text(dy=-12, color="black", fontSize=11).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            text=alt.Text("Value:Q", format=",.0f"),
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        # Bold labels for extremes
                        max_labels = base.transform_filter(alt.datum.is_max == 1).mark_text(
                            dy=-12, color="black", fontWeight="bold", fontSize=12
                        ).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            text=alt.Text("Value:Q", format=",.0f"),
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        min_labels = base.transform_filter(alt.datum.is_min == 1).mark_text(
                            dy=-12, color="black", fontWeight="bold", fontSize=12
                        ).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            text=alt.Text("Value:Q", format=",.0f"),
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        # Totals card
                        y_max_all = float(df_day[["OKW Production", "GPP Production", "Evacuation"]].max().max())
                        y_min_all = float(df_day[["OKW Production", "GPP Production", "Evacuation"]].min().min())
                        card_top = max(y_domain_max * 0.98, y_max_all)
                        card_bottom = max(card_top * 0.70, y_min_all)
    
                        card_df = pd.DataFrame({
                            "x0": [pd.to_datetime(df_day["Date"].min())],
                            "x1": [pd.to_datetime(df_day["Date"].min()) +
                                pd.Timedelta(days=max(1, (trend_to - trend_from).days // 4))],
                            "y0": [card_bottom],
                            "y1": [card_top],
                            "t1": [f"OKW: {tot_okw:,.0f} bbls"],
                            "t2": [f"GPP: {tot_gpp:,.0f} bbls"],
                            "t3": [f"Evac: {tot_evac:,.0f} bbls"],
                        })
    
                        card_rect = alt.Chart(card_df).mark_rect(
                            fill="#f8f9fa", stroke="#ccd1d6", opacity=0.9
                        ).encode(
                            x="x0:T", x2="x1:T", y="y0:Q", y2="y1:Q"
                        )
                        card_text1 = alt.Chart(card_df).mark_text(
                            align="left", dx=8, dy=8, fontSize=12
                        ).encode(
                            x="x0:T", y="y1:Q", text="t1"
                        )
                        card_text2 = alt.Chart(card_df).mark_text(
                            align="left", dx=8, dy=26, fontSize=12
                        ).encode(
                            x="x0:T", y="y1:Q", text="t2"
                        )
                        card_text3 = alt.Chart(card_df).mark_text(
                            align="left", dx=8, dy=44, fontSize=12
                        ).encode(
                            x="x0:T", y="y1:Q", text="t3"
                        )
    
                        chart_bfs = (
                            card_rect + card_text1 + card_text2 + card_text3 +
                            lines + pts + labels + max_labels + min_labels
                        ).properties(
                            height=360,
                            padding={"left": 5, "right": 5, "top": 5, "bottom": 40}
                        ).configure_axis(
                            labelColor="#000",
                            titleColor="#000",
                            labelFontSize=11,
                            titleFontSize=12,
                        ).configure_legend(
                            labelFontSize=11,
                            titleFontSize=12,
                            orient="top",
                        ).configure_view(strokeOpacity=0)
    
                        st.altair_chart(chart_bfs, use_container_width=True)
    
                    elif is_ndoni:
                        # --- NDONI: 2-line trend (Receipt, Evacuation) ---
                        # Receipt = Receipt from Agu + Receipt from OFS + Other Receipts
                        # Evacuation = Dispatch to barge
    
                        c_agu   = _find_col(df_mb, ["Receipt from Agu"])
                        c_ofs   = _find_col(df_mb, ["Receipt from OFS"])
                        c_other = _find_col(df_mb, ["Other Receipts"])
                        c_disp  = _find_col(df_mb, ["Dispatch to barge"])
    
                        df_nd = df_mb.copy()
    
                        def _num(col_name):
                            if not col_name:
                                return 0.0
                            return pd.to_numeric(df_nd[col_name], errors="coerce").fillna(0.0)
    
                        df_nd["rcpt_agu"]   = _num(c_agu)
                        df_nd["rcpt_ofs"]   = _num(c_ofs)
                        df_nd["rcpt_other"] = _num(c_other)
                        df_nd["evac"]       = _num(c_disp)
    
                        agg = (
                            df_nd.groupby(dcol, as_index=False)[["rcpt_agu", "rcpt_ofs", "rcpt_other", "evac"]]
                            .sum()
                        )
                        agg = agg.rename(columns={dcol: "Date"})
                        agg["Receipt"]    = agg["rcpt_agu"] + agg["rcpt_ofs"] + agg["rcpt_other"]
                        agg["Evacuation"] = agg["evac"]
    
                        df_day = full_days.merge(agg[["Date", "Receipt", "Evacuation"]], on="Date", how="left")
    
                        for col in ["Receipt", "Evacuation"]:
                            if col not in df_day.columns:
                                df_day[col] = 0.0
    
                        df_day[["Receipt", "Evacuation"]] = (
                            df_day[["Receipt", "Evacuation"]].apply(pd.to_numeric, errors="coerce").fillna(0.0)
                        )
                        df_day["DateTS"] = pd.to_datetime(df_day["Date"])
    
                        # Totals for card
                        tot_receipt = float(df_day["Receipt"].sum())
                        tot_evac    = float(df_day["Evacuation"].sum())
    
                        # extremes per series
                        def _ext(series):
                            s = series.fillna(0.0)
                            return (s == s.max()).astype(int), (s == s.min()).astype(int)
    
                        df_day["is_max_rcpt"], df_day["is_min_rcpt"] = _ext(df_day["Receipt"])
                        df_day["is_max_evac"], df_day["is_min_evac"] = _ext(df_day["Evacuation"])
    
                        # Long-form for plotting (2 series)
                        frames = []
                        for col, s_name, imax, imin in [
                            ("Receipt", "Receipt", "is_max_rcpt", "is_min_rcpt"),
                            ("Evacuation", "Evacuation", "is_max_evac", "is_min_evac"),
                        ]:
                            sub = df_day[["Date", "DateTS", col, imax, imin]].rename(
                                columns={col: "Value", imax: "is_max", imin: "is_min"}
                            )
                            sub["Series"] = s_name
                            frames.append(sub)
    
                        plot_df = pd.concat(frames, ignore_index=True)
    
                        x_axis = alt.Axis(
                            title="Date", format="%d-%b", labelAngle=0,
                            tickCount={"interval": "day", "step": 1}
                        )
                        y_axis = alt.Axis(title="Quantity in bbls")
    
                        # Colors: Brown (Receipt) & Green (Evacuation)
                        domain = ["Receipt", "Evacuation"]
                        range_ = ["#8B4513", "#006400"]
    
                        y_domain_max = max(float(plot_df["Value"].max() or 1.0), 1.0) * 1.25
                        base = alt.Chart(plot_df).properties(height=360)
    
                        # Lines
                        lines = base.mark_line(strokeWidth=2).encode(
                            x=alt.X("DateTS:T", axis=x_axis),
                            y=alt.Y("Value:Q", axis=y_axis, scale=alt.Scale(domain=[0, y_domain_max])),
                            color=alt.Color(
                                "Series:N",
                                scale=alt.Scale(domain=domain, range=range_),
                                legend=alt.Legend(title=None, orient="top", symbolStrokeWidth=6),
                            ),
                        )
    
                        # Points
                        pts = base.mark_point(shape="triangle-up", filled=False, size=60).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        # Normal labels
                        labels = base.mark_text(dy=-12, color="black", fontSize=11).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            text=alt.Text("Value:Q", format=",.0f"),
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        # Bold labels for highest/lowest
                        max_labels = base.transform_filter(alt.datum.is_max == 1).mark_text(
                            dy=-12, color="black", fontWeight="bold", fontSize=12
                        ).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            text=alt.Text("Value:Q", format=",.0f"),
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        min_labels = base.transform_filter(alt.datum.is_min == 1).mark_text(
                            dy=-12, color="black", fontWeight="bold", fontSize=12
                        ).encode(
                            x="DateTS:T",
                            y="Value:Q",
                            text=alt.Text("Value:Q", format=",.0f"),
                            color=alt.Color("Series:N", scale=alt.Scale(domain=domain, range=range_), legend=None),
                        )
    
                        # Card inside graph (totals for range)
                        y_max_all = float(df_day[["Receipt", "Evacuation"]].max().max())
                        y_min_all = float(df_day[["Receipt", "Evacuation"]].min().min())
                        card_top = max(y_domain_max * 0.98, y_max_all)
                        card_bottom = max(card_top * 0.70, y_min_all)
    
                        card_df = pd.DataFrame({
                            "x0": [pd.to_datetime(df_day["Date"].min())],
                            "x1": [pd.to_datetime(df_day["Date"].min()) +
                                pd.Timedelta(days=max(1, (trend_to - trend_from).days // 4))],
                            "y0": [card_bottom],
                            "y1": [card_top],
                            "t1": [f"Receipt: {tot_receipt:,.0f} bbls"],
                            "t2": [f"Evac: {tot_evac:,.0f} bbls"],
                        })
    
                        card_rect = alt.Chart(card_df).mark_rect(
                            fill="#f8f9fa", stroke="#ccd1d6", opacity=0.9
                        ).encode(
                            x="x0:T", x2="x1:T", y="y0:Q", y2="y1:Q"
                        )
                        card_text1 = alt.Chart(card_df).mark_text(
                            align="left", dx=8, dy=8, fontSize=12
                        ).encode(
                            x="x0:T", y="y1:Q", text="t1"
                        )
                        card_text2 = alt.Chart(card_df).mark_text(
                            align="left", dx=8, dy=26, fontSize=12
                        ).encode(
                            x="x0:T", y="y1:Q", text="t2"
                        )
    
                        chart_ndoni = (
                            card_rect + card_text1 + card_text2 +
                            lines + pts + labels + max_labels + min_labels
                        ).properties(
                            height=360,
                            padding={"left": 5, "right": 5, "top": 5, "bottom": 40}
                        ).configure_axis(
                            labelColor="#000",
                            titleColor="#000",
                            labelFontSize=11,
                            titleFontSize=12,
                        ).configure_legend(
                            labelFontSize=11,
                            titleFontSize=12,
                            orient="top",
                        ).configure_view(strokeOpacity=0)
    
                        st.altair_chart(chart_ndoni, use_container_width=True)
    
                    else:
                        # --- OTHER LOCATIONS (incl. AGGU): 2-line trend (Production=Receipt, Evacuation=Dispatch) ---
                        c_receipt  = _find_col(df_mb, ["Receipt"])
                        c_dispatch = _find_col(df_mb, ["Dispatch"])
    
                        agg = df_mb.groupby(dcol).agg({
                            c_receipt if c_receipt else dcol: "sum",
                            c_dispatch if c_dispatch else dcol: "sum",
                        }).reset_index()
    
                        rename_map = {}
                        if c_receipt:  rename_map[c_receipt]  = "Production"
                        if c_dispatch: rename_map[c_dispatch] = "Evacuation"
                        agg = agg.rename(columns=rename_map)
    
                        df_day = full_days.merge(agg.rename(columns={dcol: "Date"}), on="Date", how="left")
                        for col in ["Production", "Evacuation"]:
                            if col not in df_day.columns:
                                df_day[col] = 0.0
                        df_day[["Production", "Evacuation"]] = df_day[["Production", "Evacuation"]].apply(
                            pd.to_numeric, errors="coerce"
                        ).fillna(0.0)
                        df_day["DateTS"] = pd.to_datetime(df_day["Date"])
    
                        # extremes
                        def _ext(series):
                            s = series.fillna(0.0)
                            return (s == s.max()).astype(int), (s == s.min()).astype(int)
    
                        df_day["is_max_prod"], df_day["is_min_prod"] = _ext(df_day["Production"])
                        df_day["is_max_evac"], df_day["is_min_evac"] = _ext(df_day["Evacuation"])
    
                        x_axis = alt.Axis(
                            title="Date", format="%d-%b", labelAngle=0,
                            tickCount={"interval": "day", "step": 1}
                        )
                        y_axis = alt.Axis(title="Quantity in bbls")
    
                        # Colors for other locations: Brown (Production) and Green (Evacuation)
                        color_prod = "#8B4513"  # brown
                        color_evac = "#006400"  # dark green
    
                        y_domain_max = max(float(df_day[["Production", "Evacuation"]].max().max() or 1.0), 1.0) * 1.25
                        base = alt.Chart(df_day).properties(height=320)
    
                        # Production
                        p_line = base.mark_line().encode(
                            x=alt.X("DateTS:T", axis=x_axis),
                            y=alt.Y("Production:Q", axis=y_axis, scale=alt.Scale(domain=[0, y_domain_max])),
                            color=alt.value(color_prod),
                        )
                        p_pts  = base.mark_point(shape="triangle-up", color=color_prod).encode(
                            x="DateTS:T", y="Production:Q"
                        )
                        p_txt  = base.mark_text(dy=-12, color="black").encode(
                            x="DateTS:T",
                            y="Production:Q",
                            text=alt.Text("Production:Q", format=",.0f"),
                        )
                        e_line = base.mark_line(strokeDash=[4, 4]).encode(
                            x=alt.X("DateTS:T", axis=x_axis),
                            y=alt.Y("Evacuation:Q", axis=y_axis, scale=alt.Scale(domain=[0, y_domain_max])),
                            color=alt.value(color_evac),
                        )
                        e_pts = base.mark_point(shape="triangle-down", color=color_evac).encode(
                            x="DateTS:T", y="Evacuation:Q"
                        )
                        e_txt = base.mark_text(dy=-12, color="black").encode(
                            x="DateTS:T",
                            y="Evacuation:Q",
                            text=alt.Text("Evacuation:Q", format=",.0f"),
                        )
                        chart_other = (p_line + p_pts + p_txt + e_line + e_pts + e_txt).properties(width="container")
                        st.altair_chart(chart_other, use_container_width=True)
    
    
    
    # ============ QUICK ACTIONS ============
    st.markdown("### ? Quick Actions")
    
    action_cols = st.columns(4)
    
    with action_cols[0]:
        if can_view_tanks:
            if st.button("➕ New Tank Transaction", use_container_width=True, type="primary"):
                st.session_state["page"] = "Tank Transactions"
                _st_safe_rerun()
    
    with action_cols[1]:
        if can_view_yade:
            if st.button("➕ New YADE Voyage", use_container_width=True, type="primary"):
                st.session_state["page"] = "Yade Transactions"
                _st_safe_rerun()
    
    with action_cols[2]:
        if can_view_tanker:
            if st.button("➕ New Tanker Dispatch", use_container_width=True, type="primary"):
                st.session_state["page"] = "Tanker Transactions"
                _st_safe_rerun()
    
    with action_cols[3]:
        if st.button("👁️ View Transactions", use_container_width=True, type="primary"):
            st.session_state["page"] = "View Transactions"
            _st_safe_rerun()
    
    st.markdown("---")
    
    # ============ RECENT ACTIVITY ============
    st.markdown("### 📋 Recent Activity")
    
    with get_session() as s:
        recent_tank_txns = s.query(TankTransaction).filter(
            TankTransaction.location_id == active_location_id
        ).order_by(
            TankTransaction.date.desc(),
            TankTransaction.time.desc()
        ).limit(5).all()
        
        recent_yade_txns = s.query(YadeVoyage).filter(
            YadeVoyage.location_id == active_location_id
        ).order_by(
            YadeVoyage.date.desc(),
            YadeVoyage.time.desc()
        ).limit(5).all()
        
        try:
            recent_tanker_txns = s.query(TankerTransaction).filter(
                TankerTransaction.location_id == active_location_id
            ).order_by(
                TankerTransaction.transaction_date.desc(),
                TankerTransaction.transaction_time.desc()
            ).limit(5).all()
        except:
            recent_tanker_txns = []
    
    # Combine activities
    all_activities = []
    
    for txn in recent_tank_txns:
        all_activities.append({
            "icon": "🛢️",
            "datetime": datetime.combine(txn.date, txn.time),
            "description": f"Tank Transaction: {txn.tank_name} - {txn.operation.value if txn.operation else 'N/A'}",
            "user": txn.created_by or "Unknown",
            "details": f"Ticket: {txn.ticket_id}"
        })
    
    for txn in recent_yade_txns:
        # Get destination safely
        dest = txn.destination
        if hasattr(dest, 'value'):
            dest_str = dest.value
        elif dest:
            dest_str = str(dest)
        else:
            dest_str = 'N/A'
        
        all_activities.append({
            "icon": "⛴️",
            "datetime": datetime.combine(txn.date, txn.time),
            "description": f"YADE Voyage: {txn.yade_name} - Voyage {txn.voyage_no}",
            "user": txn.created_by or "Unknown",
            "details": f"Destination: {dest_str}"
        })
    
    for txn in recent_tanker_txns:
        all_activities.append({
            "icon": "⛴️",
            "datetime": datetime.combine(txn.transaction_date, txn.transaction_time),
            "description": f"Tanker Dispatch: {txn.tanker_name}",
            "user": "System",
            "details": f"Convoy: {txn.convoy_no}"
        })
    
    all_activities.sort(key=lambda x: x["datetime"], reverse=True)
    
    if not all_activities:
        st.info("ℹ️ No recent activity")
    else:
        for activity in all_activities[:10]:
            time_ago = datetime.now() - activity["datetime"]
            
            if time_ago.days > 0:
                time_str = f"{time_ago.days} day{'s' if time_ago.days > 1 else ''} ago"
            elif time_ago.seconds >= 3600:
                hours = time_ago.seconds // 3600
                time_str = f"{hours} hour{'s' if hours > 1 else ''} ago"
            elif time_ago.seconds >= 60:
                minutes = time_ago.seconds // 60
                time_str = f"{minutes} minute{'s' if minutes > 1 else ''} ago"
            else:
                time_str = "Just now"
            
            st.markdown(f"""
                <div class="activity-item">
                    <div style="display: flex; justify-content: space-between; align-items: start;">
                        <div style="flex: 1;">
                            <div style="font-weight: bold; color: #2c3e50; margin-bottom: 0.3rem;">
                                {activity['icon']} {activity['description']}
                            </div>
                            <div style="font-size: 0.9rem; color: #6c757d; margin-bottom: 0.3rem;">
                                {activity['details']}
                            </div>
                            <div style="font-size: 0.85rem; color: #adb5bd;">
                                By: {activity['user']}
                            </div>
                        </div>
                        <div style="white-space: nowrap; margin-left: 1rem; color: #6c757d; font-size: 0.85rem;">
                            {time_str}
                        </div>
                    </div>
                </div>
            """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # ============ SYSTEM INFO ============
    st.markdown("### ℹ️ System Information")
    
    info_cols = st.columns(3)
    
    with info_cols[0]:
        st.info(f"**Location:** {loc.name} ({loc.code})")
    
    with info_cols[1]:
        st.info(f"**Role:** {user['role'].title()}")
    
    with info_cols[2]:
        st.info(f"**Time:** {datetime.now().strftime('%I:%M %p')}")

# ========================= 2FA VERIFICATION PAGE =========================
elif page == "2FA Verify":
    header("Two-Factor Authentication")
    
    # ========== SAFELY CHECK FOR PENDING USER ==========
    pending_user = st.session_state.get("pending_2fa_user")
    
    if not pending_user:
        st.error("? No pending login found. Please login first.")
        st.info("↩️ Redirecting to Home page...")
        
        # Clear any stale 2FA states
        clear_2fa_session_states()
        
        # Redirect to home
        st.session_state["page"] = "Home"
        
        import time
        time.sleep(2)
        _st_safe_rerun()
        st.stop()
    
    # ========== PENDING USER EXISTS - SHOW 2FA VERIFICATION ==========
    st.markdown("### 🔐 Enter Verification Code")
    
    col1, col2, col3 = st.columns([0.3, 0.4, 0.3])
    
    with col2:
        st.info(f"**User:** {pending_user.get('username', 'Unknown')}")
        st.caption("Enter the 6-digit code from your authenticator app")
        
        with st.form("2fa_verify_form"):
            token = st.text_input(
                "Verification Code",
                max_chars=10,
                placeholder="000000 or XXXX-XXXX",
                key="2fa_token_input",
                help="Enter code from Microsoft Authenticator or your backup codes"
            )
            
            col_verify, col_cancel = st.columns(2)
            
            with col_verify:
                verify_btn = st.form_submit_button("? Verify", type="primary", use_container_width=True)
            
            with col_cancel:
                cancel_btn = st.form_submit_button("❌ Cancel", use_container_width=True)
            
            # ========== VERIFY BUTTON HANDLER ==========
            if verify_btn:
                if not token.strip():
                    st.error("? Please enter a verification code")
                else:
                    try:
                        from twofa import TwoFactorAuth
                        from ip_service import IPService
                        from security import SecurityManager
                        
                        # Get IP for logging
                        client_ip = IPService.get_client_ip()
                        
                        with get_session() as s:
                            # Verify token
                            is_valid = TwoFactorAuth.verify_token(
                                s, 
                                pending_user["id"], 
                                token.strip().replace("-", "").replace(" ", "")  # Clean token
                            )
                            
                            if is_valid:
                                # ========== 2FA SUCCESSFUL ==========
                                st.session_state.auth_user = pending_user
                                st.session_state.pop("pending_2fa_user", None)
                                
                                # Set default active location
                                if pending_user["role"] in ["admin-operations", "admin-it", "manager"]:
                                    from location_manager import LocationManager
                                    locations = LocationManager.get_all_locations(s, active_only=True)
                                    if locations:
                                        st.session_state.active_location_id = locations[0].id
                                else:
                                    st.session_state.active_location_id = pending_user.get("location_id")
                                
                                # Log successful 2FA (audit trail)
                                SecurityManager.log_audit(
                                    s, 
                                    pending_user["username"], 
                                    "2FA_SUCCESS",
                                    user_id=pending_user["id"],
                                    details="2FA verification successful",
                                    ip_address=client_ip
                                )
                                
                                # Log login attempt with IP tracking
                                SecurityManager.log_login_attempt(
                                    s, 
                                    pending_user["username"], 
                                    success=True,
                                    ip_address=client_ip,
                                    user_agent="Streamlit App",
                                    two_factor_used=True  # ? Mark 2FA used!
                                )
                                
                                st.success("? Verification successful!")
                                st.info("↩️ Redirecting to Home...")
                                
                                st.session_state["page"] = "Home"
                                
                                import time
                                time.sleep(1)
                                _st_safe_rerun()
                            else:
                                # ========== INVALID TOKEN ==========
                                st.error("? Invalid verification code. Please try again.")
                                
                                # Log failed 2FA attempt
                                with get_session() as s:
                                    SecurityManager.log_audit(
                                        s, 
                                        pending_user["username"], 
                                        "2FA_FAILED",
                                        user_id=pending_user["id"],
                                        details="Invalid 2FA token",
                                        success=False,
                                        ip_address=client_ip
                                    )
                                
                                st.warning("⚠️ Make sure you're entering the current code from your app")
                    
                    except Exception as ex:
                        st.error(f"? Verification failed: {ex}")
                        import traceback
                        st.code(traceback.format_exc())
            
            # ========== CANCEL BUTTON HANDLER ==========
            if cancel_btn:
                st.session_state.pop("pending_2fa_user", None)
                st.session_state["page"] = "Home"
                st.info("❌ Login cancelled")
                
                import time
                time.sleep(1)
                _st_safe_rerun()
        
        st.markdown("---")
        
        # ========== HELP SECTION ==========
        with st.expander("❓ Help & Troubleshooting", expanded=False):
            st.markdown("""
            **Using Authenticator App:**
            - Open Microsoft Authenticator (or your 2FA app)
            - Find "OTMS" account
            - Enter the current 6-digit code
            - Code refreshes every 30 seconds
            
            **Using Backup Code:**
            - Enter one of your saved backup codes
            - Format: XXXX-XXXX (8 characters)
            - Each code can only be used once
            
            **Lost Access?**
            - Contact your system administrator
            - They can disable 2FA for your account
            - You'll need to set up 2FA again
            
            **Time Sync Issues?**
            - Make sure your device time is correct
            - Authenticator apps need accurate time to work
            """)
        
        st.caption("🔐 Your account is protected with Two-Factor Authentication")

# ========================= MANAGE LOCATIONS (Admin Only) =========================
elif page == "Manage Locations":
    if st.session_state.get("auth_user", {}).get("role") != "admin-operations":
        header("Manage Locations")
        st.error("You do not have permission to access this page. Admin-Operations only.")
        st.stop()

    header("Manage Locations")
    current_user = st.session_state.get("auth_user") or {}
    
    tab1, tab2 = st.tabs(["View Locations", "Add Location"])
    
    # -------- View Locations --------
    with tab1:
        st.markdown("### All Locations")
        
        try:
            from location_manager import LocationManager
            with get_session() as s:
                locations = LocationManager.get_all_locations(s, active_only=False)
            
            if locations:
                # Display as table
                data = []
                for loc in locations:
                    stats = LocationManager.get_location_stats(s, loc.id)
                    data.append({
                        "ID": loc.id,
                        "Code": loc.code,
                        "Name": loc.name,
                        "Address": loc.address or "-",
                        "Status": "? Active" if loc.is_active else "? Inactive",
                        "Tanks": stats.get("tanks", 0),
                        # REMOVED: "YADE Barges": stats.get("yade_barges", 0),
                        "Transactions": stats.get("tank_transactions", 0),
                        "Voyages": stats.get("yade_voyages", 0),  # YADE voyages, not barges
                    })
                
                df = pd.DataFrame(data)
                st.dataframe(df, use_container_width=True, hide_index=True)
                
                # -------- Edit/Delete Location --------
                st.markdown("---")
                st.markdown("#### Edit Location")
                
                col1, col2 = st.columns([0.6, 0.4])
                
                with col1:
                    loc_options = {f"{loc.name} ({loc.code})": loc.id for loc in locations}
                    selected_loc = st.selectbox(
                        "Select Location to Edit",
                        options=list(loc_options.keys()),
                        key="edit_loc_select"
                    )
                    
                    if selected_loc:
                        loc_id = loc_options[selected_loc]
                        with get_session() as s:
                            loc = LocationManager.get_location_by_id(s, loc_id)
                        
                        if loc:
                            e1, e2 = st.columns(2)
                            with e1:
                                new_name = st.text_input("Name", value=loc.name, key="edit_loc_name")
                                new_code = st.text_input("Code", value=loc.code, key="edit_loc_code")
                            with e2:
                                new_address = st.text_area("Address", value=loc.address or "", key="edit_loc_address")
                                new_status = st.selectbox(
                                    "Status",
                                    ["Active", "Inactive"],
                                    index=0 if loc.is_active else 1,
                                    key="edit_loc_status"
                                )
                            
                            if st.button("💾 Save Changes", key="edit_loc_save"):
                                try:
                                    with get_session() as s:
                                        updated_loc = LocationManager.update_location(
                                            s,
                                            loc_id,
                                            name=new_name,
                                            code=new_code,
                                            address=new_address if new_address else None,
                                            is_active=(new_status == "Active")
                                        )
                                    st.success(f"Location '{updated_loc['name']}' updated successfully!")
                                    _st_safe_rerun()
                                except Exception as ex:
                                    st.error(f"Failed to update location: {ex}")
                
                with col2:
                    st.markdown("#### Deactivate Location")
                    st.caption("ℹ️ This will make the location inaccessible but preserve all data.")
                    
                    deact_loc = st.selectbox(
                        "Select Location",
                        options=list(loc_options.keys()),
                        key="deact_loc_select"
                    )
                    
                    confirm_text = st.text_input(
                        "Type location code to confirm",
                        key="deact_confirm"
                    )
                    
                    if st.button("⚠️ Deactivate Location", key="deact_btn"):
                        if deact_loc:
                            loc_id = loc_options[deact_loc]
                            with get_session() as s:
                                loc = LocationManager.get_location_by_id(s, loc_id)
                            
                            if loc and confirm_text.strip().upper() == loc.code:
                                try:
                                    with get_session() as s:
                                        if loc:
                                            _archive_payload_for_delete(
                                                s,
                                                "LocationDeactivate",
                                                str(loc.id),
                                                payload=RecycleBinManager.snapshot_record(loc),
                                                reason=f"Location {loc.code} deactivated by {current_user.get('username', 'unknown')}.",
                                                label=f"{loc.name} ({loc.code})",
                                            )
                                        LocationManager.delete_location(s, loc_id)
                                    st.success(f"Location '{loc.name}' deactivated.")
                                    _st_safe_rerun()
                                except Exception as ex:
                                    st.error(f"Failed to deactivate: {ex}")
                            else:
                                st.error("Confirmation code does not match.")

                # Add this NEW section below the deactivate section
                st.markdown("---")
                st.markdown("#### ⚠️ DANGER ZONE: Permanent Delete")

                with st.expander("🗑️ Permanently Delete Location (Irreversible)", expanded=False):
                    st.error("""
                    **⚠️ WARNING: This action is IRREVERSIBLE!**
                    
                    This will **permanently delete**:
                    - The location itself
                    - All tanks and tank calibration data
                    - All YADE barges and YADE calibration data
                    - All tank transactions
                    - All YADE voyages and related data
                    - All OTR records
                    
                    **This cannot be undone!**
                    """)
                    
                    perm_del_loc = st.selectbox(
                        "Select Location to DELETE PERMANENTLY",
                        options=list(loc_options.keys()),
                        key="perm_del_loc_select"
                    )
                    
                    st.markdown("##### Triple Confirmation Required")
                    
                    perm_confirm_1 = st.text_input(
                        "1️⃣ Type the location CODE exactly",
                        key="perm_confirm_1"
                    )
                    
                    perm_confirm_2 = st.text_input(
                        '2️⃣ Type "DELETE PERMANENTLY" to confirm',
                        key="perm_confirm_2"
                    )
                    
                    perm_confirm_3 = st.checkbox(
                        "3️⃣ I understand this action is irreversible and will delete ALL data",
                        key="perm_confirm_3"
                    )
                    
                    # Show what will be deleted
                    if perm_del_loc:
                        loc_id = loc_options[perm_del_loc]
                        try:
                            with get_session() as s:
                                loc = LocationManager.get_location_by_id(s, loc_id)
                                stats = LocationManager.get_location_stats(s, loc_id)
                            
                            if loc:
                                st.markdown("##### ⚠️ Data that will be DELETED:")
                                st.write({
                                    "Location": f"{loc.name} ({loc.code})",
                                    "Tanks": stats.get("tanks", 0),
                                    "YADE Barges": stats.get("yade_barges", 0),
                                    "Tank Transactions": stats.get("tank_transactions", 0),
                                    "YADE Voyages": stats.get("yade_voyages", 0),
                                })
                        except Exception:
                            pass
                    
                    if st.button("🗑️ PERMANENTLY DELETE LOCATION", key="perm_del_btn", type="primary"):
                        if not perm_del_loc:
                            st.error("Please select a location.")
                        else:
                            loc_id = loc_options[perm_del_loc]
                            with get_session() as s:
                                loc = LocationManager.get_location_by_id(s, loc_id)
                            
                            # Validate all three confirmations
                            if not loc:
                                st.error("Location not found.")
                            elif perm_confirm_1.strip().upper() != loc.code:
                                st.error("? Location code does not match.")
                            elif perm_confirm_2.strip() != "DELETE PERMANENTLY":
                                st.error('? You must type "DELETE PERMANENTLY" exactly.')
                            elif not perm_confirm_3:
                                st.error("? You must check the confirmation checkbox.")
                            else:
                                # All confirmations passed - proceed with deletion
                                try:
                                    with get_session() as s:
                                        loc_snapshot = LocationManager.get_location_by_id(s, loc_id)
                                        stats_snapshot = LocationManager.get_location_stats(s, loc_id)
                                        if loc_snapshot:
                                            payload = RecycleBinManager.snapshot_record(loc_snapshot)
                                            payload["stats"] = stats_snapshot
                                            _archive_payload_for_delete(
                                                s,
                                                "Location",
                                                str(loc_snapshot.id),
                                                payload=payload,
                                                reason=f"Permanent delete requested by {current_user.get('username', 'unknown')}.",
                                                label=f"{loc_snapshot.name} ({loc_snapshot.code})",
                                            )
                                        deletion_stats = LocationManager.permanently_delete_location(s, loc_id)
                                    
                                    st.success(f"? Location '{deletion_stats['location_name']}' permanently deleted.")
                                    st.json(deletion_stats)
                                    
                                    # Clear active location if it was the deleted one
                                    if st.session_state.get("active_location_id") == loc_id:
                                        st.session_state.pop("active_location_id", None)
                                    
                                    st.info("Reloading page in 3 seconds...")
                                    import time
                                    time.sleep(3)
                                    _st_safe_rerun()
                                    
                                except Exception as ex:
                                    st.error(f"Failed to permanently delete location: {ex}")
                                    import traceback
                                    st.code(traceback.format_exc())
            else:
                st.info("No locations found. Add one in the 'Add Location' tab.")
        
        except Exception as ex:
            st.error(f"Error loading locations: {ex}")
    
    # -------- Add Location --------
    with tab2:
        st.markdown("### Add New Location")
        
        with st.form("add_location_form"):
            c1, c2 = st.columns(2)
            with c1:
                loc_name = st.text_input("Location Name *", placeholder="e.g., Port Harcourt Terminal")
                loc_code = st.text_input("Location Code *", placeholder="e.g., PHT").upper()
            with c2:
                loc_address = st.text_area("Address", placeholder="Optional")
            
            submitted = st.form_submit_button("? Add Location", type="primary")

            if submitted:
                if not loc_name.strip():
                    st.error("Location name is required.")
                elif not loc_code.strip():
                    st.error("Location code is required.")
                else:
                    try:
                        from location_manager import LocationManager
                        with get_session() as s:
                            new_loc = LocationManager.create_location(
                                s,
                                name=loc_name.strip(),
                                code=loc_code.strip(),
                                address=loc_address.strip() if loc_address else None
                            )
                        # new_loc is now a dict, not an ORM object
                        st.success(f"? Location '{new_loc['name']}' ({new_loc['code']}) created successfully!")
                        _st_safe_rerun()
                    except Exception as ex:
                        st.error(f"Failed to create location: {ex}")

# ========================= MANAGE USERS (Admin Ops/IT) =========================
elif page == "Manage Users":
    if st.session_state.get("auth_user", {}).get("role") not in ["admin-operations", "admin-it"]:
        header("Manage Users")
        st.error("You do not have permission to access this page. Admin-Operations or Admin-IT only.")
        st.stop()

    header("Manage Users")
    
    tab1, tab2 = st.tabs(["View Users", "Add User"])
    
    # -------- View Users --------
    with tab1:
        st.markdown("### All Users")
        
        try:
            with get_session() as s:
                from models import User, Location
                users = s.query(User).order_by(User.username).all()
                
                if users:
                    data = []
                    for u in users:
                        loc_name = "-"
                        if u.location_id:
                            loc = s.query(Location).filter(Location.id == u.location_id).one_or_none()
                            if loc:
                                loc_name = f"{loc.name} ({loc.code})"
                        
                        data.append({
                            "ID": u.id,
                            "Username": u.username,
                            "Full Name": u.full_name or "�",
                            "Role": u.role.title(),
                            "Location": loc_name if u.role not in ["admin-operations", "admin-it", "manager"] else ("All Locations" if u.role in ["admin-operations", "manager"] else "System Admin"),
                            "Status": "? Active" if u.is_active else "? Inactive",
                            "Supervisor Code": ("Set" if u.supervisor_code_hash else "Not set") if u.role == "supervisor" else "-",
                            "Last Login": u.last_login.strftime("%Y-%m-%d %H:%M") if u.last_login else "Never"
                        })
                    
                    df = pd.DataFrame(data)
                    st.dataframe(df, use_container_width=True, hide_index=True)
                    
                    # Create user_options ONCE here
                    user_options = {u.username: u.id for u in users}
                    
                    # -------- User Management Actions --------
                    st.markdown("---")
                    st.markdown("#### User Management")
                    
                    col1, col2, col3, col4 = st.columns([0.25, 0.25, 0.25, 0.25])
                    
                    # ========== Column 1: Reset Password ==========
                    with col1:
                        st.markdown("##### Reset Password")
                        
                        selected_user_pwd = st.selectbox(
                            "Select User",
                            options=list(user_options.keys()),
                            key="mgmt_reset_pwd_user"  # UNIQUE KEY
                        )
                        
                        new_password = st.text_input(
                            "New Password",
                            type="password",
                            key="mgmt_reset_pwd_new"  # UNIQUE KEY
                        )
                        
                        confirm_password = st.text_input(
                            "Confirm Password",
                            type="password",
                            key="mgmt_reset_pwd_confirm"  # UNIQUE KEY
                        )
                        
                        if st.button("🔑 Reset Password", key="mgmt_reset_pwd_btn"):  # UNIQUE KEY
                            if not new_password:
                                st.error("Password cannot be empty.")
                            elif new_password != confirm_password:
                                st.error("Passwords do not match.")
                            elif len(new_password) < 4:
                                st.error("Password must be at least 4 characters.")
                            else:
                                try:
                                    from auth import AuthManager
                                    with get_session() as s:
                                        user_id = user_options[selected_user_pwd]
                                        AuthManager.update_password(s, user_id, new_password)
                                    st.success(f"Password reset for user '{selected_user_pwd}'.")
                                except Exception as ex:
                                    st.error(f"Failed to reset password: {ex}")

                        supervisor_usernames = [u.username for u in users if u.role == "supervisor"]
                        st.markdown("##### Reset Supervisor Code")
                        if not supervisor_usernames:
                            st.info("No supervisors available.")
                        else:
                            selected_supervisor = st.selectbox(
                                "Supervisor",
                                options=supervisor_usernames,
                                key="mgmt_reset_sup_user",
                            )
                            sup_new_code = st.text_input(
                                "New Supervisor Code",
                                type="password",
                                key="mgmt_reset_sup_code",
                            )
                            sup_confirm_code = st.text_input(
                                "Confirm Supervisor Code",
                                type="password",
                                key="mgmt_reset_sup_code_confirm",
                            )
                            if st.button("🔑 Reset Supervisor Code", key="mgmt_reset_sup_btn"):
                                if not sup_new_code:
                                    st.error("Supervisor code cannot be empty.")
                                elif sup_new_code != sup_confirm_code:
                                    st.error("Supervisor codes do not match.")
                                else:
                                    try:
                                        from auth import AuthManager
                                        with get_session() as s:
                                            user_id = user_options[selected_supervisor]
                                            AuthManager.set_supervisor_code(s, user_id, sup_new_code)
                                        SecurityManager.log_audit(
                                            None,
                                            (st.session_state.get("auth_user") or {}).get("username", "admin"),
                                            "SUPERVISOR_CODE_RESET",
                                            resource_type="User",
                                            resource_id=str(user_id),
                                            details=f"Supervisor code reset for {selected_supervisor}",
                                        )
                                        st.success(f"Supervisor code reset for '{selected_supervisor}'.")
                                        _st_safe_rerun()
                                    except Exception as ex:
                                        st.error(f"Failed to reset supervisor code: {ex}")
                    
                    # ========== Column 2: Transfer User Location ==========
                    with col2:
                        st.markdown("##### Transfer User")
                        st.caption("Change user's assigned location")
                        
                        transfer_user = st.selectbox(
                            "Select User to Transfer",
                            options=list(user_options.keys()),
                            key="mgmt_transfer_user_select"  # UNIQUE KEY
                        )
                        
                        # Show current location
                        if transfer_user:
                            user_id = user_options[transfer_user]
                            try:
                                with get_session() as s:
                                    from models import User, Location
                                    u = s.query(User).filter(User.id == user_id).one_or_none()
                                    if u:
                                        if u.role in ["admin-operations", "admin-it", "manager"]:
                                            st.info("Admin and manager users have access to all locations (no transfer needed).")
                                        else:
                                            current_loc = "Not assigned"
                                            if u.location_id:
                                                loc = s.query(Location).filter(Location.id == u.location_id).one_or_none()
                                                if loc:
                                                    current_loc = f"{loc.name} ({loc.code})"
                                            
                                            st.caption(f"Current: **{current_loc}**")
                                            
                                            # Get available locations
                                            from location_manager import LocationManager
                                            locs = LocationManager.get_all_locations(s, active_only=True)
                                            
                                            if locs:
                                                loc_options = {f"{loc.name} ({loc.code})": loc.id for loc in locs}
                                                new_location = st.selectbox(
                                                    "New Location",
                                                    options=list(loc_options.keys()),
                                                    key="mgmt_transfer_new_location"  # UNIQUE KEY
                                                )
                                                
                                                if st.button("🔄 Transfer User", key="mgmt_transfer_btn"):  # UNIQUE KEY
                                                    try:
                                                        from auth import AuthManager
                                                        new_loc_id = loc_options[new_location]
                                                        
                                                        with get_session() as s:
                                                            result = AuthManager.transfer_user_to_location(s, user_id, new_loc_id)
                                                        
                                                        st.success(f"? User '{transfer_user}' transferred!")
                                                        st.info(f"From: {result['old_location']}\nTo: {result['new_location']}")
                                                        
                                                        # If transferred user is currently logged in, update their session
                                                        current_user = st.session_state.get("auth_user")
                                                        if current_user and current_user.get("id") == user_id:
                                                            st.warning("ℹ️ You transferred yourself! Please re-login to see the new location.")
                                                            st.session_state.active_location_id = new_loc_id
                                                        
                                                        import time
                                                        time.sleep(2)
                                                        _st_safe_rerun()
                                                        
                                                    except Exception as ex:
                                                        st.error(f"Failed to transfer user: {ex}")
                            except Exception as ex:
                                st.error(f"Error loading user details: {ex}")
                    
                    # ========== Column 3: Toggle Active Status ==========
                    with col3:
                        st.markdown("##### Toggle Status")
                        st.caption("ℹ️ Deactivated users cannot login.")
                        
                        deact_user = st.selectbox(
                            "Select User",
                            options=list(user_options.keys()),
                            key="mgmt_deact_user_select"  # UNIQUE KEY
                        )
                        
                        if st.button("🔄 Toggle Active Status", key="mgmt_deact_user_btn"):  # UNIQUE KEY
                            try:
                                from auth import AuthManager
                                with get_session() as s:
                                    user_id = user_options[deact_user]
                                    result = AuthManager.toggle_user_status(s, user_id)
                                    status = "activated" if result["is_active"] else "deactivated"
                                    st.success(f"User '{deact_user}' {status}.")
                                    _st_safe_rerun()
                            except Exception as ex:
                                st.error(f"Failed to update user: {ex}")

                    # ========== Column 4: Reset 2FA ==========
                    with col4:
                        st.markdown("##### Reset 2FA")
                        st.caption("Clear authenticator keys so the user can re-enroll.")

                        reset_2fa_user = st.selectbox(
                            "Select User",
                            options=list(user_options.keys()),
                            key="mgmt_reset_2fa_user",
                        )

                        if st.button("🔐 Reset 2FA", key="mgmt_reset_2fa_btn"):
                            if not reset_2fa_user:
                                st.error("Please select a user.")
                            else:
                                try:
                                    with get_session() as s:
                                        from models import User

                                        user_id = user_options[reset_2fa_user]
                                        target = (
                                            s.query(User)
                                            .filter(User.id == user_id)
                                            .one_or_none()
                                        )
                                        if not target:
                                            st.error("User not found.")
                                        else:
                                            target.totp_secret = None
                                            target.totp_enabled = False
                                            target.backup_codes = None
                                            s.commit()
                                            SecurityManager.log_audit(
                                                s,
                                                (st.session_state.get("auth_user") or {}).get(
                                                    "username", "admin"
                                                ),
                                                "2FA_RESET",
                                                resource_type="User",
                                                resource_id=str(user_id),
                                                details=f"Admin reset 2FA for {reset_2fa_user}",
                                            )
                                            st.success(
                                                f"2FA has been reset for '{reset_2fa_user}'. "
                                                "They will be prompted to set up 2FA again on next login."
                                            )
                                except Exception as ex:
                                    st.error(f"Failed to reset 2FA: {ex}")
                    
                    # -------- CHANGE USER ROLE --------
                    st.markdown("---")
                    st.markdown("#### 🔄 Change User Role")
                    st.caption("Update user roles (e.g., promote operator to supervisor)")
                    
                    role_col1, role_col2 = st.columns([0.5, 0.5])
                    
                    # Initialize variables
                    current_user_for_role = None
                    new_role = None
                    role_change_user_id = None
                    
                    with role_col1:
                        change_role_user = st.selectbox(
                            "Select User",
                            options=list(user_options.keys()),
                            key="mgmt_change_role_user_select"
                        )
                        
                        # Show current role
                        if change_role_user:
                            role_change_user_id = user_options[change_role_user]
                            try:
                                with get_session() as s:
                                    from models import User
                                    current_user_for_role = s.query(User).filter(User.id == role_change_user_id).one_or_none()
                                    if current_user_for_role:
                                        st.caption(f"Current Role: **{current_user_for_role.role.title()}**")
                                        
                                        # Role selection - don't allow changing to same role
                                        available_roles = ["admin-operations", "admin-it", "manager", "supervisor", "operator"]
                                        role_display = {
                                            "admin-operations": "🔧 Admin-Operations - Full system & operational access",
                                            "admin-it": "💻 Admin-IT - System admin (no operations)",
                                            "manager": "👔 Manager - All locations (read-only)",
                                            "supervisor": "👷 Supervisor - Can approve actions",
                                            "operator": "👤 Operator - Standard access"
                                        }
                                        
                                        role_options = [role for role in available_roles if role != current_user_for_role.role]
                                        role_display_options = [role_display[role] for role in role_options]
                                        
                                        if role_display_options:
                                            new_role_display = st.selectbox(
                                                "New Role",
                                                options=role_display_options,
                                                key="mgmt_change_role_new_role"
                                            )
                                            
                                            # Extract actual role from display
                                            for role, display in role_display.items():
                                                if display == new_role_display:
                                                    new_role = role
                                                    break
                            except Exception as ex:
                                st.error(f"Error loading user details: {ex}")
                    
                    with role_col2:
                        st.markdown("##### Role Change Rules:")
                        st.info("""
                        **Admin-Operations Role:**
                        - Full system & operational access
                        - Not tied to any location
                        - Can manage users and make entries
                        
                        **Admin-IT Role:**
                        - System administration only
                        - Cannot access operations/reports
                        - Can manage users and system settings
                        
                        **Manager Role:**
                        - View all locations (read-only)
                        - Cannot make entries or approve tasks
                        - Not assigned to specific location
                        
                        **Supervisor Role:**
                        - Can approve operator actions
                        - Assigned to specific location
                        - Has supervisor code
                        
                        **Operator Role:**
                        - Standard data entry access
                        - Assigned to specific location
                        - Requires supervisor approval for some actions
                        """)
                        
                        if change_role_user and new_role and current_user_for_role:
                            st.warning(f"⚠️ You are about to change **{change_role_user}**'s role to **{new_role.title()}**")
                            
                            if new_role in ["admin-operations", "admin-it", "manager"]:
                                st.warning("ℹ️ **Note:** User will lose location assignment and get broader access.")
                            elif current_user_for_role.role in ["admin-operations", "admin-it", "manager"] and new_role in ["supervisor", "operator"]:
                                st.warning("ℹ️ **Note:** User will need to be assigned to a specific location after role change.")
                            
                            if st.button("🔄 Change Role", key="mgmt_change_role_btn", type="primary"):
                                try:
                                    from auth import AuthManager
                                    
                                    with get_session() as s:
                                        # Get user's current info
                                        current_user_obj = s.query(User).filter(User.id == role_change_user_id).one_or_none()
                                        old_role = current_user_obj.role if current_user_obj else "unknown"
                                        
                                        # Update role
                                        result = AuthManager.update_user_details(s, role_change_user_id, role=new_role)
                                        
                                        # Log the role change
                                        SecurityManager.log_audit(
                                            s,
                                            (st.session_state.get("auth_user") or {}).get("username", "admin"),
                                            "ROLE_CHANGE",
                                            resource_type="User",
                                            resource_id=str(role_change_user_id),
                                            details=f"Changed role from {old_role} to {new_role} for user {change_role_user}",
                                        )
                                    
                                    st.success(f"? Role changed successfully for '{change_role_user}'!")
                                    st.info(f"Old Role: {old_role.title()} ? New Role: {new_role.title()}")
                                    
                                    # Special messages based on role change
                                    if new_role in ["admin-operations", "admin-it", "manager"]:
                                        st.success("✅ User now has broader system access.")
                                    elif old_role in ["admin-operations", "admin-it", "manager"]:
                                        st.warning("ℹ️ Please assign this user to a location using the 'Transfer User' option above.")
                                    elif new_role == "supervisor" and not current_user_obj.supervisor_code_hash:
                                        st.info("ℹ️ Don't forget to set a supervisor code for this user using 'Reset Supervisor Code' above.")
                                    
                                    # If the logged-in user changed their own role, warn them
                                    current_logged_user = st.session_state.get("auth_user")
                                    if current_logged_user and current_logged_user.get("id") == role_change_user_id:
                                        st.warning("⚠️ You changed your own role! Please log out and log back in for changes to take full effect.")
                                    
                                    import time
                                    time.sleep(2)
                                    _st_safe_rerun()
                                    
                                except Exception as ex:
                                    st.error(f"Failed to change role: {ex}")
                                    log_error(f"Role change failed for user {change_role_user}: {ex}", exc_info=True)
                    
                    # -------- PERMANENT DELETE --------
                    st.markdown("---")
                    st.markdown("#### ⚠️ DANGER ZONE: Permanent Delete User")
                    
                    with st.expander("🗑️ Permanently Delete User (Irreversible)", expanded=False):
                        st.error("""
                        **⚠️ WARNING: This action is IRREVERSIBLE!**
                        
                        This will **permanently delete** the user account.
                        
                        **Notes:**
                        - Cannot delete the last active admin user
                        - User data in transaction logs will remain (created_by fields)
                        - This action cannot be undone!
                        """)
                        
                        perm_del_user = st.selectbox(
                            "Select User to DELETE PERMANENTLY",
                            options=list(user_options.keys()),
                            key="mgmt_perm_del_user_select"  # UNIQUE KEY
                        )
                        
                        st.markdown("##### Triple Confirmation Required")
                        
                        perm_confirm_1 = st.text_input(
                            "1️⃣ Type the username exactly",
                            key="mgmt_perm_user_confirm_1"  # UNIQUE KEY
                        )
                        
                        perm_confirm_2 = st.text_input(
                            '2️⃣ Type "DELETE USER" to confirm',
                            key="mgmt_perm_user_confirm_2"  # UNIQUE KEY
                        )
                        
                        perm_confirm_3 = st.checkbox(
                            "3️⃣ I understand this action is irreversible",
                            key="mgmt_perm_user_confirm_3"  # UNIQUE KEY
                        )
                        
                        # Show user details
                        if perm_del_user:
                            user_id = user_options[perm_del_user]
                            try:
                                with get_session() as s:
                                    from models import User, Location
                                    u = s.query(User).filter(User.id == user_id).one_or_none()
                                    
                                    if u:
                                        st.markdown("##### 👤 User Details:")
                                        user_details = {
                                            "Username": u.username,
                                            "Full Name": u.full_name or "-",
                                            "Role": u.role.title(),
                                            "Status": "? Active" if u.is_active else "? Inactive",
                                        }
                                        
                                        if u.location_id:
                                            loc = s.query(Location).filter(Location.id == u.location_id).one_or_none()
                                            if loc:
                                                user_details["Location"] = f"{loc.name} ({loc.code})"
                                        else:
                                            user_details["Location"] = "All Locations (Admin)"
                                        
                                        st.json(user_details)
                            except Exception:
                                pass
                        
                        if st.button("🗑️ PERMANENTLY DELETE USER", key="mgmt_perm_del_user_btn", type="primary"):  # UNIQUE KEY
                            if not perm_del_user:
                                st.error("Please select a user.")
                            else:
                                selected_username = perm_del_user
                                
                                # Validate all three confirmations
                                if perm_confirm_1.strip() != selected_username:
                                    st.error("? Username does not match.")
                                elif perm_confirm_2.strip() != "DELETE USER":
                                    st.error('? You must type "DELETE USER" exactly.')
                                elif not perm_confirm_3:
                                    st.error("? You must check the confirmation checkbox.")
                                else:
                                    # All confirmations passed - proceed with deletion
                                    try:
                                        from auth import AuthManager
                                        user_id = user_options[selected_username]
                                        
                                        with get_session() as s:
                                            user_obj = s.query(User).filter(User.id == user_id).one_or_none()
                                            if user_obj:
                                                payload = RecycleBinManager.snapshot_record(user_obj)
                                                _archive_payload_for_delete(
                                                    s,
                                                    resource_type="User",
                                                    resource_id=str(user_obj.id),
                                                    payload=payload,
                                                    reason=f"Permanent delete triggered by {(st.session_state.get('auth_user') or {}).get('username', 'admin')}",
                                                    label=user_obj.username,
                                                )
                                            deletion_info = AuthManager.permanently_delete_user(s, user_id)
                                        
                                        st.success(f"? User '{deletion_info['username']}' permanently deleted.")
                                        st.json(deletion_info)
                                        
                                        # If user deleted themselves, logout
                                        current_user = st.session_state.get("auth_user")
                                        if current_user and current_user.get("username") == deletion_info["username"]:
                                            st.warning("You deleted your own account. Logging out...")
                                            st.session_state.auth_user = None
                                            st.session_state.active_location_id = None
                                        
                                        st.info("Reloading page in 3 seconds...")
                                        import time
                                        time.sleep(3)
                                        _st_safe_rerun()
                                        
                                    except Exception as ex:
                                        st.error(f"Failed to permanently delete user: {ex}")
                                        import traceback
                                        st.code(traceback.format_exc())
                
                else:
                    st.info("No users found.")
        
        except Exception as ex:
            st.error(f"Error loading users: {ex}")
            import traceback
            st.code(traceback.format_exc())
    
    # -------- Add User --------
    with tab2:
        st.markdown("### Add New User")
        
        with st.expander("ℹ️ Role Descriptions", expanded=False):
            st.markdown("""
            **Operator:**
            - Standard data entry access
            - Assigned to specific location
            - Cannot delete or approve requests
            
            **Supervisor:**
            - Can approve operator actions and deletion requests
            - Assigned to specific location
            - Requires supervisor code
            
            **Manager:**
            - Read-only access to all locations
            - Can view reports but cannot make entries
            - Cannot approve tasks (read-only role)
            
            **Admin-IT:**
            - System administration only
            - Can manage users, audit logs, backups, 2FA
            - Cannot access operational pages or reports
            - Can approve password reset requests
            
            **Admin-Operations:**
            - Full system and operational access
            - Can manage users and make entries everywhere
            - Can approve all types of requests
            - Access to all locations
            """)
        
        with st.form("add_user_form"):
            c1, c2 = st.columns(2)
            new_supervisor_code = ""
            confirm_supervisor_code = ""
            with c1:
                new_username = st.text_input("Username *", placeholder="e.g., john.doe")
                new_fullname = st.text_input("Full Name *", placeholder="e.g., John Doe")
                new_role = st.selectbox("Role *", [
                    "operator", 
                    "supervisor", 
                    "manager", 
                    "admin-it", 
                    "admin-operations"
                ])
            
            with c2:
                new_password = st.text_input("Password *", type="password")
                confirm_new_password = st.text_input("Confirm Password *", type="password")
                
                # Location selection (only for non-admin and non-manager)
                if new_role not in ["admin-operations", "admin-it", "manager"]:
                    try:
                        from location_manager import LocationManager
                        with get_session() as s:
                            locs = LocationManager.get_all_locations(s, active_only=True)
                        
                        if locs:
                            loc_options = {f"{loc.name} ({loc.code})": loc.id for loc in locs}
                            selected_location = st.selectbox(
                                "Assigned Location *",
                                options=list(loc_options.keys()),
                                key="new_user_location"
                            )
                            new_location_id = loc_options[selected_location]
                        else:
                            st.warning("No active locations found. Create a location first.")
                            new_location_id = None
                    except Exception:
                        new_location_id = None
                else:
                    if new_role == "admin-operations":
                        st.info("Admin-Operations users have full access to all locations.")
                    elif new_role == "admin-it":
                        st.info("Admin-IT users manage system settings only (no location access).")
                    elif new_role == "manager":
                        st.info("Managers have read-only access to all locations.")
                    new_location_id = None
            
            if new_role == "supervisor":
                code_col1, code_col2 = st.columns(2)
                with code_col1:
                    new_supervisor_code = st.text_input(
                        "Supervisor Code *",
                        type="password",
                        key="new_user_supervisor_code",
                    )
                with code_col2:
                    confirm_supervisor_code = st.text_input(
                        "Confirm Supervisor Code *",
                        type="password",
                        key="new_user_supervisor_code_confirm",
                    )

            submitted = st.form_submit_button("? Create User", type="primary")
            
            if submitted:
                errors = []
                if not new_username.strip():
                    errors.append("Username is required.")
                if not new_fullname.strip():
                    errors.append("Full name is required.")
                if not new_password:
                    errors.append("Password is required.")
                elif len(new_password) < 4:
                    errors.append("Password must be at least 4 characters.")
                elif new_password != confirm_new_password:
                    errors.append("Passwords do not match.")
                if new_role not in ["admin-operations", "admin-it", "manager"] and not new_location_id:
                    errors.append("Location is required for non-admin users.")
                supervisor_code_value: Optional[str] = None
                if new_role == "supervisor":
                    if not new_supervisor_code:
                        errors.append("Supervisor code is required for supervisors.")
                    elif new_supervisor_code != confirm_supervisor_code:
                        errors.append("Supervisor codes do not match.")
                    else:
                        supervisor_code_value = new_supervisor_code
                
                if errors:
                    for e in errors:
                        st.error(e)
                else:
                    try:
                        from auth import AuthManager
                        with get_session() as s:
                            new_user = AuthManager.create_user(
                                s,
                                username=new_username.strip(),
                                password=new_password,
                                full_name=new_fullname.strip(),
                                role=new_role,
                                location_id=new_location_id,
                                supervisor_code=supervisor_code_value,
                            )
                        st.success(f"? User '{new_user['username']}' created successfully!")
                        _st_safe_rerun()
                    except Exception as ex:
                        st.error(f"Failed to create user: {ex}")

# ================= TANK TRANSACTIONS =================
elif page == "Tank Transactions":
    header("Tank Transactions")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.info("Admin-IT role is for system administration only (users, audit logs, backups, etc.).")
        st.stop()
    
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("Tank Transactions") is False:
                st.error("⚠️ Tank Transactions page is disabled for this location.")
                st.stop()
    except Exception:
        pass

    # -------- Check location access --------
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("⚠️ No active location selected. Please select a location from the Home page.")
        st.stop()

    # -------- Verify user has access to this location --------
    user = st.session_state.get("auth_user")
    if user:
        from auth import AuthManager
        if not AuthManager.can_access_location(user, active_location_id):
            st.error("🚫 You do not have access to this location.")
            st.stop()
    user_role = (user.get("role") or "").lower() if user else ""
    
    # ========== CHECK PERMISSIONS ==========
    from permission_manager import PermissionManager
    
    with get_session() as s:
        from location_manager import LocationManager
        
        # Get location info
        loc = LocationManager.get_location_by_id(s, active_location_id)
        if not loc:
            st.error("? Location not found.")
            st.stop()
        
        st.info(f"📍 **Active Location:** {loc.name} ({loc.code})")

        # Apply location-based page visibility: hide page if disabled in config (non-admin)
        try:
            with get_session() as _s_cfg:
                from location_config import LocationConfig
                _cfg = LocationConfig.get_config(_s_cfg, active_location_id)
            if not _cfg.get("page_visibility", {}).get("show_tank_transactions", True) and (user.get("role", "").lower() not in ["admin-operations", "manager"]):
                st.error("⚠️ Tank Transactions page is disabled for this location.")
                st.stop()
        except Exception:
            pass
        
        # Check if feature is allowed at this location (Admin can access everywhere)
        if not PermissionManager.can_access_feature(s, active_location_id, "tank_transactions", user["role"]):
            st.error("🚫 **Access Denied**")
            st.warning(f"**Tank Transactions** are not available at **{loc.name}**")
            
            # Show where it's available
            allowed_locs = PermissionManager.get_allowed_locations_for_feature(s, "tank_transactions")
            if allowed_locs:
                st.info(f"? This feature is available at: **{', '.join(allowed_locs)}**")
            
            st.markdown("---")
            st.caption(f"Current Location: **{loc.name} ({loc.code})**")
            st.caption("Tank Transactions Access: **? Denied**")
            st.stop()
        
        # Check if user can make entries
        can_make_entries = PermissionManager.can_make_entries(s, user["role"], active_location_id)
    
    # ============ FEATURE ENABLED - CONTINUE ============
    # Special handling for OFS Production & Evacuation (OML-157)
    try:
        _ofs_code_norm = (loc.code or "").replace(" ", "").replace("-", "").upper()
    except Exception:
        _ofs_code_norm = ""
    if _ofs_code_norm == "OML157":
        # Render the dedicated OFS Production & Evacuation page for this location
        try:
            render_ofs_production_page(active_location_id, loc, user)
        except Exception as ex:
            st.error(f"Failed to render OFS Production page: {ex}")
        # Stop further processing of Tank Transactions page
        st.stop()
    try:
        _loc_name_norm = (loc.name or "").strip().lower()
    except Exception:
        _loc_name_norm = ""
    _loc_name_upper = (loc.name or "").strip().upper()
    _loc_code_upper = (loc.code or "").strip().upper()
    _is_asemoku_jetty = (_loc_name_norm == "asemoku jetty")
    _is_bfs_location = (
        "BFS" in _loc_code_upper
        or "BFS" in _loc_name_upper
        or "BENEKU" in _loc_name_upper
    )
    _is_aggu_location = ("AGGU" in _loc_code_upper) or ("AGGU" in _loc_name_upper)
    _is_ndoni_location = ("NDONI" in _loc_code_upper) or ("NDONI" in _loc_name_upper)
    _show_tanker_tab = _is_aggu_location or _is_ndoni_location

    _meter_tab = None
    _condensate_tab = None
    _gpp_tab = None
    _tanker_tab = None
    _river_tab = None
    _produced_water_tab = None
    st_for_restore = None

    if _is_asemoku_jetty:
        tab_labels = ["Tank Transactions", "Meter Transactions", "River Draft", "Produced Water"]
        if _show_tanker_tab:
            tab_labels.append("No of Tankers")
        tabs = st.tabs(tab_labels)
        _ttab = tabs[0]
        _meter_tab = tabs[1]
        _river_tab = tabs[2]
        _produced_water_tab = tabs[3]
        if _show_tanker_tab:
            _tanker_tab = tabs[4]
        st_for_restore = st
        st = _ttab
    elif _is_bfs_location:
        tab_labels = ["Tank Transactions", "Condensate Records", "Production"]
        if _show_tanker_tab:
            tab_labels.append("No of Tankers")
        tabs = st.tabs(tab_labels)
        _ttab = tabs[0]
        _condensate_tab = tabs[1]
        _gpp_tab = tabs[2]
        if _show_tanker_tab:
            _tanker_tab = tabs[3]
        st_for_restore = st
        st = _ttab
    elif _show_tanker_tab:
        tab_labels = ["Tank Transactions"]
        if _is_ndoni_location:
            tab_labels.extend(["River Draft", "Produced Water"])
        tab_labels.append("No of Tankers")
        tabs = st.tabs(tab_labels)
        _ttab = tabs[0]
        st_for_restore = st
        st = _ttab
        idx = 1
        if _is_ndoni_location:
            _river_tab = tabs[idx]
            _produced_water_tab = tabs[idx + 1]
            idx += 2
        _tanker_tab = tabs[idx]

    # Get location config
    with get_session() as s:
        from location_config import LocationConfig
        
        # Load location-specific configuration
        config = LocationConfig.get_config(s, active_location_id)
        tabs_access = config.get("tabs_access", {})
        tt_tabs = tabs_access.get("Tank Transactions", {})
        if tt_tabs.get("Meter Transactions") is False:
            _meter_tab = None
        if tt_tabs.get("Condensate Records") is False:
            _condensate_tab = None
        if tt_tabs.get("Production") is False:
            _gpp_tab = None
        if tt_tabs.get("River Draft") is False:
            _river_tab = None
        if tt_tabs.get("Produced Water") is False:
            _produced_water_tab = None
        tank_config = config.get("tank_transactions", {})

    # Get available operations from config
    operation_options = tank_config.get("enabled_operations", [
        "Opening Stock", "OKW Receipt", "ANZ Receipt", "Other Receipts",
        "ITT - Receipt", "Dispatch to barge", "Other Dispatch", "ITT - Dispatch",
        "Closing Stock",
    ])
    if _is_bfs_location:
        operation_options = [op for op in operation_options if op != "Receipt - Condensate"]

    # Get product types from config
    product_options = tank_config.get("product_types", ["CRUDE", "CONDENSATE", "DPK", "AGO", "PMS"])

    # Get validation rules
    max_days_backward = tank_config.get("max_days_backward", 30)
    allow_future_dates = tank_config.get("allow_future_dates", False)
    auto_generate_ticket = tank_config.get("auto_generate_ticket_id", False)
    configured_prefix = (tank_config.get("ticket_id_prefix") or "").strip().upper()

    loc_prefix = ""
    if loc and getattr(loc, "name", None):
        letters_only = "".join(ch for ch in loc.name if ch.isalpha())
        if letters_only:
            loc_prefix = letters_only[:3].upper()

    ticket_prefix = loc_prefix or configured_prefix
    if not ticket_prefix and loc:
        ticket_prefix = ((loc.code or "")[:3]).upper()

    # Show configuration info
    with st.expander("⚙️ Location Configuration", expanded=False):
        st.caption(f"**Enabled Operations:** {len(operation_options)}")
        st.caption(f"**Product Types:** {', '.join(product_options)}")
        st.caption(f"**Max Days Backward:** {max_days_backward} days")
        st.caption(f"**Allow Future Dates:** {'Yes' if allow_future_dates else 'No'}")
        if auto_generate_ticket:
            st.caption(f"**Auto-Generate Ticket ID:** Enabled")
        if ticket_prefix:
            st.caption(f"**Ticket ID Prefix:** {ticket_prefix}")

    # ---------- imports / constants ----------
    import re, math, hashlib
    from datetime import datetime, date
    from sqlalchemy.exc import IntegrityError

    WAT60 = 999.012

    # ---------- tiny helpers ----------
    def hhmm_ok(s: str) -> bool:
        if not s or len(s) not in (4, 5):
            return False
        s = s.strip()
        if ":" not in s:
            return False
        h, m = s.split(":", 1)
        if not (h.isdigit() and m.isdigit()):
            return False
        h, m = int(h), int(m)
        return 0 <= h <= 23 and 0 <= m <= 59

    def op_code_4(op_text: str) -> str:
        cleaned = "".join(ch for ch in op_text if ch.isalpha()).upper()
        return (cleaned[:4] or "OPER")

    def mk_ticket_id(op_text: str, d: date, serial: int, prefix: str = "") -> str:
        """
        Generate location-aware ticket ID.
        Format: <LOC>-TIC-<OC4>-<DDMMYYYY>-<NNNN>
        If prefix is blank, we still use hyphen format without LOC.
        """
        oc4 = op_code_4(op_text)  # existing helper
        loc_code = (prefix or "").strip().upper()
        date_part = d.strftime("%d%m%Y")
        if loc_code:
            return f"{loc_code}-TIC-{oc4}-{date_part}-{serial:04d}"
        return f"TIC-{oc4}-{date_part}-{serial:04d}"

    def next_serial_for(op_text: str, d: date, prefix: str = "", location_id: int | None = None) -> int:
        """
        Get next serial for this (location + op + date) by scanning existing ticket_ids.
        Works even if old 'TIC/..' rows exist.
        """
        oc4 = op_code_4(op_text)
        loc_code = (prefix or "").strip().upper()
        date_part = d.strftime("%d%m%Y")

        # New (location-aware) prefix and legacy (slash) prefix:
        search_prefix_new = (f"{loc_code}-TIC-{oc4}-{date_part}-" if loc_code else f"TIC-{oc4}-{date_part}-")
        search_prefix_old = f"TIC/{oc4}/{d.strftime('%d-%m-%Y')}/"

        with get_session() as s:
            q = s.query(TankTransaction.ticket_id)
            if location_id is not None:
                q = q.filter(TankTransaction.location_id == int(location_id))
            rows = q.filter(
                (TankTransaction.ticket_id.like(search_prefix_new + "%")) |
                (TankTransaction.ticket_id.like(search_prefix_old + "%"))
            ).all()

        max_serial = 0
        for (tid,) in rows:
            if not tid:
                continue
            # New style: LOC-TIC-OC4-DDMMYYYY-NNNN
            if "-TIC-" in tid:
                parts = tid.split("-")
                try:
                    num = int(parts[-1])
                    if num > max_serial:
                        max_serial = num
                    continue
                except:
                    pass
            # Legacy: TIC/OC4/DD-MM-YYYY/NNNNNN
            if tid.startswith("TIC/"):
                parts = tid.split("/")
                if len(parts) >= 4:
                    try:
                        num = int(parts[-1])
                        if num > max_serial:
                            max_serial = num
                    except:
                        pass
        return max_serial + 1


    def c_to_f(c: float) -> float:
        if c is None: return 0.0
        return round((float(c) * 1.8) + 32.0, 1)

    def f_to_c(f: float) -> float:
        if c is None: return 0.0
        return round((float(f) - 32.0) / 1.8, 1)

    def _to_f(val: float, unit: str) -> float:
        """Return °F from val given unit ('°F' or '°C')."""
        return c_to_f(val) if unit.upper().startswith("C") else float(val or 0.0)

    def _to_c(val: float, unit: str) -> float:
        """Return °C from val given unit ('°F' or '°C')."""
        return f_to_c(val) if unit.upper().startswith("F") else float(val or 0.0)

    # ---- Excel-accurate transforms ----
    def density_from_api(api: float) -> float:
        if not api or api <= 0: return 0.0
        sg = 141.5 / (float(api) + 131.5)
        return round(sg * WAT60, 1)

    def api_from_density(density: float) -> float:
        if not density or density <= 0: return 0.0
        sg = float(density) / WAT60
        if sg <= 0: return 0.0
        return round(141.5 / sg - 131.5, 2)

    def convert_api_to_60_from_api(api_obs: float, sample_temp_val: float, temp_unit: str) -> float:
        """Your VBA (10 trials). Temp is ALWAYS °F internally."""
        if api_obs is None or api_obs <= 0:
            return 0.0
        tf = _to_f(sample_temp_val or 0.0, temp_unit)
        temp_diff = tf - 60.0
        rho_obs = (141.5 * WAT60 / (131.5 + float(api_obs))) * (
            (1.0 - 0.00001278 * temp_diff) - (0.0000000062 * temp_diff * temp_diff)
        )
        rho = rho_obs
        for _ in range(10):
            alfa = 341.0957 / (rho * rho)
            vcf  = math.exp(-alfa * temp_diff - 0.8 * alfa * alfa * temp_diff * temp_diff)
            rho  = rho_obs / vcf
        api60 = 141.5 * WAT60 / rho - 131.5
        return round(api60, 2)

    def convert_api_to_60_from_density(dens_obs_kgm3: float, sample_temp_val: float, temp_unit: str) -> float:
        """Density path (17 trials). Temp is ALWAYS °C internally."""
        if dens_obs_kgm3 is None or dens_obs_kgm3 <= 0:
            return 0.0
        tc = _to_c(sample_temp_val or 0.0, temp_unit)
        temp_diff = tc - 15.0
        
        # Hydrometer correction
        hyc = 1.0 - 0.000023 * temp_diff - 0.00000002 * temp_diff * temp_diff
        rho_obs_corrected = float(dens_obs_kgm3) * hyc
        
        # Initial density at 15°C
        rho15 = rho_obs_corrected
        
        # Iterative VCF calculation (17 iterations)
        for _ in range(17):
            # Thermal expansion coefficient K
            K = 613.9723 / (rho15 * rho15)
            
            # VCF calculation (temperature-based)
            vcf = math.exp(-K * temp_diff * (1.0 + 0.8 * K * temp_diff))
            
            # Update density at 15°C
            rho15 = rho_obs_corrected / vcf
        
        # Convert density at 15°C to API@60°F
        sg60 = rho15 / WAT60
        if sg60 <= 0:
            return 0.0
        
        api60 = 141.5 / sg60 - 131.5
        return round(api60, 2)

    # ---- VCF calculation ----
    def vcf_from_api60_and_temp(api60: float, tank_temp: float, tank_temp_unit: str, input_mode: str = "api") -> float:
        """Calculate VCF using ASTM D1250 Table 6A method"""
        if api60 is None or api60 <= 0:
            return 1.00000
        
        # Convert tank temp to °F if needed
        if tank_temp_unit == "°C":
            tank_temp_f = (tank_temp * 1.8) + 32.0
        else:
            tank_temp_f = tank_temp
        
        # Temperature difference from 60°F
        delta_t = tank_temp_f - 60.0
        
        if abs(delta_t) < 0.01:
            return 1.00000
        
        # Calculate density at 60°F
        sg60 = 141.5 / (api60 + 131.5)
        rho60 = sg60 * 999.012
        
        # Thermal expansion coefficient
        K0 = 341.0957
        alpha = K0 / (rho60 * rho60)
        
        # VCF calculation
        vcf = math.exp(-alpha * delta_t * (1.0 + 0.8 * alpha * delta_t))
        
        return round(float(vcf), 5)

    # ---- interpolation from CalibrationTank ----
    def _interp_vol_bbl(session, tank_name: str, dip_cm_val: float) -> float:
        """Linear interpolation on CalibrationTank."""
        if dip_cm_val is None:
            return 0.0
        rows = session.query(CalibrationTank).filter(
            CalibrationTank.tank_name == tank_name,
            CalibrationTank.location_id == active_location_id
        ).order_by(CalibrationTank.dip_cm.asc()).all()
        if not rows:
            return 0.0
        xs = [float(r.dip_cm or 0.0) for r in rows]
        ys = [float(r.volume_bbl or 0.0) for r in rows]
        if dip_cm_val <= xs[0]:
            return ys[0]
        if dip_cm_val >= xs[-1]:
            return ys[-1]
        import bisect
        i = bisect.bisect_left(xs, dip_cm_val)
        x1, y1 = xs[i-1], ys[i-1]
        x2, y2 = xs[i], ys[i]
        if x2 == x1:
            return y1
        t = (dip_cm_val - x1) / (x2 - x1)
        return y1 + t * (y2 - y1)

    # ---- LT Factor lookup ----
    def lookup_lt_factor(session, api60: float) -> float:
        """Lookup LT Factor from ASTM Table 11"""
        from models import Table11
        
        rows = session.query(Table11).order_by(Table11.api60).all()
        if not rows:
            return 0.0
        
        xs = [float(r.api60) for r in rows]
        ys = [float(r.lt_factor) for r in rows]
        
        if api60 <= xs[0]:
            return ys[0]
        if api60 >= xs[-1]:
            return ys[-1]
        
        import bisect
        i = bisect.bisect_left(xs, api60)
        x1, y1 = xs[i-1], ys[i-1]
        x2, y2 = xs[i], ys[i]
        
        if x2 == x1:
            return y1
        
        t = (api60 - x1) / (x2 - x1)
        return y1 + t * (y2 - y1)

    


# ---------- enum map ----------
    OP_MAP = {
        "Opening Stock": Operation.OPENING_STOCK,
        "Receipt": Operation.RECEIPT,
        "Receipt - Commingled": Operation.RECEIPT_CRUDE,
        "Receipt - Condensate": Operation.RECEIPT_CONDENSATE,
        "Receipt from Agu": Operation.RECEIPT_FROM_AGU,
        "Receipt from OFS": Operation.RECEIPT_FROM_OFS,
        "OKW Receipt": Operation.OKW_RECEIPT,
        "ANZ Receipt": Operation.ANZ_RECEIPT,
        "Other Receipts": Operation.OTHER_RECEIPTS,
        "Closing Stock": Operation.CLOSING_STOCK,
        "Dispatch to Barge": Operation.DISPATCH_TO_BARGE,
        "Dispatch to barge": Operation.DISPATCH_TO_BARGE,
        "Dispatch to Jetty": Operation.DISPATCH_TO_JETTY,
        "Other Dispatch": Operation.OTHER_DISPATCH,
        "ITT - Receipt": Operation.ITT_RECEIPT,
        "ITT - Dispatch": Operation.ITT_DISPATCH,
        "Settling": Operation.SETTLING,
        "Draining": Operation.DRAINING,
    }

    # ---------- UI ----------
    st.markdown("#### Add Ticket")

    # ============ OPERATION SELECTOR ===========
    operation = st.selectbox(
        "Operation *",
        options=[op.value for op in Operation],  # This will automatically include "Dispatch"
        key="tank_tx_operation"
    )

    # ============ CHECK IF CONDENSATE RECEIPT ============
    is_condensate_receipt = (operation == "Receipt - Condensate")

    if is_condensate_receipt:
        st.success("ℹ️ **Condensate Receipt Mode** - Meter reading entry (no tank selection)")

    # ============ DATE AND TIME ============
    import datetime as dt

    min_date = dt.date.today() - dt.timedelta(days=max_days_backward)
    max_date = dt.date.today() + dt.timedelta(days=7) if allow_future_dates else dt.date.today()

    date_col, time_col = st.columns(2)
    
    with date_col:
        tx_date = st.date_input(
            "2) Date *",
            value=dt.date.today(),
            min_value=min_date,
            max_value=max_date,
            key="tank_tx_date",
            help=f"Date range: {min_date.strftime('%d/%m/%Y')} to {max_date.strftime('%d/%m/%Y')}"
        )
    
    with time_col:
        if is_condensate_receipt:
            tx_time_str = "23:59"
            st.caption("Time auto-set to 23:59 for 24 hr condensate meter records.")
        else:
            tx_time_str = st.text_input("Time * (hh:mm)", value="08:00", key="tx_time")

    # ============ TANK SELECTOR ============
    tank_id = None
    tank_fk = None
    
    if not is_condensate_receipt:
        with get_session() as s:
            _tanks = s.query(Tank).filter(
                Tank.location_id == active_location_id,
                Tank.status == "ACTIVE"
            ).order_by(Tank.name).all()
        
        tank_names = [t.name for t in _tanks] if _tanks else ["(No tanks yet � add in Add Asset ? Tank Master)"]
        tank_by_name = {t.name: t for t in _tanks}
        
        tank_id = st.selectbox("3) Tank ID *", tank_names, index=0, key="tx_tank_id")
        
        if tank_id in tank_by_name:
            tank_fk = tank_by_name[tank_id].id
    else:
        tank_id = "CONDENSATE-RECEIPT"
        st.info("ℹ️ Tank selection not required for condensate receipt (receives into multiple tanks)")

    st.markdown("---")

    # ============ CONDENSATE METER READING ============
    opening_meter = None
    closing_meter = None
    condensate_qty_m3 = 0.0
    condensate_gov_bbl = 0.0

    if is_condensate_receipt:
        st.markdown("#### 📊 Condensate Meter Readings")
        
        meter_col1, meter_col2, meter_col3 = st.columns(3)
        
        with meter_col1:
            opening_meter = st.number_input(
                "Opening Meter Reading (m�) *",
                min_value=0.0,
                step=0.001,
                format="%.3f",
                key="opening_meter",
                help="Meter reading at start (cubic meters)"
            )
        
        with meter_col2:
            closing_meter = st.number_input(
                "Closing Meter Reading (m�) *",
                min_value=0.0,
                step=0.001,
                format="%.3f",
                key="closing_meter",
                help="Meter reading at end (cubic meters)"
            )
        
        with meter_col3:
            if closing_meter > opening_meter:
                condensate_qty_m3 = closing_meter - opening_meter
                condensate_gov_bbl = condensate_qty_m3 * 6.289
            else:
                condensate_qty_m3 = 0.0
                condensate_gov_bbl = 0.0
            
            st.metric(
                "Condensate Qty (m�)",
                f"{condensate_qty_m3:,.3f}",
                help="Calculated: Closing - Opening"
            )
            st.metric(
                "GOV (bbls)",
                f"{condensate_gov_bbl:,.2f}",
                help="Calculated: m� � 6.289"
            )
        
        tov_bbl = condensate_gov_bbl
        fw_bbl = 0.0
        gov_bbl = condensate_gov_bbl

    # ============ REGULAR DIP FIELDS ============
    if not is_condensate_receipt:
        st.markdown("#### 📏 Tank Measurements")
        
        c4, c5 = st.columns(2)
        with c4:
            dip_cm = st.number_input("Dip (cm) *", min_value=0.0, step=0.1, key="tx_dip_cm")
        with c5:
            water_cm = st.number_input("Water Level (cm) *", min_value=0.0, step=0.1, key="tx_water_cm")

        with get_session() as _s:
            tov_bbl = _interp_vol_bbl(_s, tank_id, float(dip_cm or 0.0))
            fw_bbl  = _interp_vol_bbl(_s, tank_id, float(water_cm or 0.0)) if float(water_cm or 0.0) > 0 else 0.0
        gov_bbl = max(tov_bbl - fw_bbl, 0.0)
        st.info(f"📊 Live Quantity � TOV: **{tov_bbl:.2f} bbl** | FW: **{fw_bbl:.2f} bbl** | GOV: **{gov_bbl:.2f} bbl**")
    else:
        dip_cm = 0.0
        water_cm = 0.0

    st.markdown("---")

    # ============ TEMPERATURE & QUALITY ============
    st.markdown("#### 🧪 Sample Parameters")

    st.caption("Tank Temperature (for VCF)")
    tcol1, tcol2 = st.columns([0.35, 0.65])
    with tcol1:
        tank_temp_unit = st.selectbox("Unit", ["°C", "°F"], index=0, key="tx_tank_temp_unit")
    with tcol2:
        tank_temp_val = _temperature_input(
            f"Temperature ({tank_temp_unit})",
            tank_temp_unit,
            "tx_tank_temp_val",
        )

    st.caption("Observed Property & Sample Temperature")

    col_mode, col_sample_unit = st.columns([0.48, 0.52])
    with col_mode:
        obs_mode = st.selectbox("Input Type", ["Observed API", "Observed Density (kg/m3)"], index=0, key="tx_obs_mode")
    with col_sample_unit:
        sample_unit = st.selectbox("Sample Temp Unit", ["°F", "°C"], index=0, key="tx_sample_unit")

    sample_temp_val = _temperature_input(
        "Sample Temperature",
        sample_unit,
        "tx_sample_temp_val",
    )

    in_col = st.columns(1)[0]
    if obs_mode == "Observed API":
        with in_col:
            api_obs_val = _bounded_number_input(
                "Observed API *",
                "tx_api_obs",
                API_MIN,
                API_MAX,
            )
        dens_obs_val = density_from_api(api_obs_val) if api_obs_val > 0 else 0.0
        st.caption(f"? Density: {dens_obs_val:.2f} kg/m3")
        api60_val = convert_api_to_60_from_api(api_obs_val or 0.0, sample_temp_val or 0.0, sample_unit)
    else:
        with in_col:
            dens_obs_val = _bounded_number_input(
                "Observed Density (kg/m3) *",
                "tx_dens_obs",
                DENSITY_MIN,
                DENSITY_MAX,
                step=0.1,
            )
        api_obs_val = api_from_density(dens_obs_val) if dens_obs_val > 0 else 0.0
        st.caption(f"? API: {api_obs_val:.2f}")
        api60_val = convert_api_to_60_from_density(dens_obs_val or 0.0, sample_temp_val or 0.0, sample_unit)

    # ============ BS&W ============
    if is_condensate_receipt:
        bsw_pct = 0.0
        st.info("ℹ️ BS&W is 0% for condensate (GSV = NSV)")
    else:
        bsw_pct = st.number_input("BS&W %", min_value=0.0, max_value=100.0, step=0.01,
                                key="tx_bsw_pct", help="Basic Sediment & Water percentage")

    # ============ CALCULATIONS ============
    sample_temp_c_val = _to_c(sample_temp_val or 0.0, sample_unit)
    sample_temp_f_val = _to_f(sample_temp_val or 0.0, sample_unit)
    tank_temp_c_val = _to_c(tank_temp_val, tank_temp_unit)
    tank_temp_f_val = _to_f(tank_temp_val, tank_temp_unit)

    input_mode = "density" if obs_mode == "Observed Density (kg/m3)" else "api"
    vcf_val = vcf_from_api60_and_temp(api60_val, tank_temp_val, tank_temp_unit, input_mode)
    
    gsv_bbl = round(gov_bbl * vcf_val, 2)
    bsw_vol_bbl = round(gsv_bbl * (bsw_pct / 100.0), 2)
    nsv_bbl = round(gsv_bbl - bsw_vol_bbl, 2)
    
    with get_session() as s:
        lt_factor = lookup_lt_factor(s, api60_val)
    
    lt_val = round(nsv_bbl * lt_factor, 2)
    mt_val = round(lt_val * 1.01605, 2)
    
    if is_condensate_receipt:
        st.success(f"📊 **Live Calculations:** GOV: {gov_bbl:,.2f} bbls | API@60: {api60_val:.2f} | VCF: {vcf_val:.5f} | GSV: {gsv_bbl:,.2f} bbls | NSV: {nsv_bbl:,.2f} bbls | LT: {lt_val:,.2f} | MT: {mt_val:,.2f}")
    else:
        if gov_bbl > 0 and api60_val > 0:
            st.info(f"📊 **Calculations:** GOV: {gov_bbl:,.2f} bbls | API@60: {api60_val:.2f} | VCF: {vcf_val:.5f} | GSV: {gsv_bbl:,.2f} bbls | NSV: {nsv_bbl:,.2f} bbls | LT: {lt_val:,.2f} | MT: {mt_val:,.2f}")

    # ============ TICKET ID PREVIEW ============
    if auto_generate_ticket:
        try:
            temp_serial = next_serial_for(operation, tx_date, ticket_prefix, active_location_id)
            preview_ticket = mk_ticket_id(operation, tx_date, temp_serial, ticket_prefix)
            st.success(f"🎫 **Auto-Generated Ticket ID:** {preview_ticket}")
        except Exception:
            st.info("ℹ️ Ticket ID will be generated upon save")

    # ============ SAVE BUTTON ============
    save_btn = st.button("💾 Save to DB", type="primary", key="tx_save_btn")

    if save_btn:
        errs = []
        if not is_condensate_receipt:
            if not tank_id or tank_id.startswith("(No tanks yet"):
                errs.append("Please add tanks first in **Add Asset ? Tank Master**.")
        if (not is_condensate_receipt) and (not hhmm_ok(tx_time_str)):
            errs.append("Time must be in hh:mm (24-hour) format.")
        if is_condensate_receipt and (opening_meter is None or closing_meter is None):
            errs.append("Please enter both opening and closing meter readings.")
        if is_condensate_receipt and opening_meter is not None and closing_meter is not None:
            if closing_meter <= opening_meter:
                errs.append("Closing meter reading must be greater than opening meter reading.")

        if errs:
            for e in errs:
                st.error(e)
        else:
            if is_condensate_receipt:
                tx_time_obj = time(23, 59)
            else:
                try:
                    tx_time_obj = datetime.strptime(tx_time_str, "%H:%M").time()
                except Exception:
                    st.error("Invalid time format. Use HH:MM (24-hour).")
                    tx_time_obj = None

            if tx_time_obj:
                try:
                    # Resolve location prefix (first 3 letters of location name)
                    with get_session() as s_lookup:
                        from location_manager import LocationManager
                        _loc = LocationManager.get_location_by_id(s_lookup, active_location_id)
                        location_code = (ticket_prefix or "").upper()
                        if _loc and not location_code:
                            if getattr(_loc, "name", None):
                                letters_only = "".join(ch for ch in _loc.name if ch.isalpha())
                                if letters_only:
                                    location_code = letters_only[:3].upper()
                            if not location_code:
                                location_code = ((_loc.code or "")[:3]).upper()

                    # Serial + Ticket ID
                    serial = next_serial_for(operation, tx_date, location_code, active_location_id)
                    ticket_id_real = mk_ticket_id(operation, tx_date, serial, location_code)

                    # Normalize & coerce operation to DB enum / value
                    op_norm = _normalize_operation(location_code, operation)
                    op_db   = _coerce_operation_for_db(op_norm)
                    if op_db is None:
                        st.error(f"Unsupported operation label: {operation}")
                        st.stop()


                    with get_session() as s:
                        # INSERT into tank_transactions (let DB autogenerate the integer PK)
                        rec = TankTransaction(
                            location_id=active_location_id,
                            ticket_id=ticket_id_real,
                            operation=op_db,                     # ? SAEnum, not None
                            tank_id=tank_fk,
                            tank_name=tank_id,
                            date=tx_date,
                            time=tx_time_obj,
                            dip_cm=float(dip_cm or 0.0) if not is_condensate_receipt else None,
                            water_cm=float(water_cm or 0.0) if not is_condensate_receipt else None,
                            opening_meter_reading=float(opening_meter) if is_condensate_receipt else None,
                            closing_meter_reading=float(closing_meter) if is_condensate_receipt else None,
                            condensate_qty_m3=float(condensate_qty_m3) if is_condensate_receipt else None,
                            tank_temp_c=float(tank_temp_c_val or 0.0),
                            tank_temp_f=float(tank_temp_f_val or 0.0),
                            sample_temp_c=float(sample_temp_c_val or 0.0),
                            sample_temp_f=float(sample_temp_f_val or 0.0),
                            api_observed=float(api_obs_val or 0.0),
                            density_observed=float(dens_obs_val or 0.0),
                            bsw_pct=float(bsw_pct or 0.0),
                            qty_bbls=float(tov_bbl or 0.0),
                            remarks=None,
                            created_by=user["username"]
                        )
                        s.add(rec)
                        s.flush()                 # get autoincremented PK
                        new_id = rec.id

                        # Mirror insert to OTR only for non-condensate transactions
                        if not is_condensate_receipt:
                            s.add(OTRRecord(
                                location_id=active_location_id,
                                ticket_id=ticket_id_real,
                                tank_id=tank_id,
                                date=tx_date,
                                time=tx_time_obj,
                                operation=operation,  # plain label is fine for OTR
                                dip_cm=float(dip_cm or 0.0),
                                total_volume_bbl=float(tov_bbl or 0.0),
                                water_cm=float(water_cm or 0.0),
                                free_water_bbl=float(fw_bbl or 0.0),
                                gov_bbl=float(gov_bbl or 0.0),
                                api60=float(api60_val or 0.0),
                                vcf=float(vcf_val),
                                gsv_bbl=float(gsv_bbl or 0.0),
                                bsw_vol_bbl=float(bsw_vol_bbl or 0.0),
                                nsv_bbl=float(nsv_bbl or 0.0),
                                lt=float(lt_val or 0.0),
                                mt=float(mt_val or 0.0),
                            ))

                        # Audit log
                        from security import SecurityManager
                        SecurityManager.log_audit(
                            s, user["username"], "CREATE",
                            resource_type="TankTransaction",
                            resource_id=new_id,   # use the integer PK
                            details=f"Created {'condensate receipt' if is_condensate_receipt else 'tank transaction'}: {operation}, Ticket: {ticket_id_real}",
                            user_id=user["id"],
                            location_id=active_location_id
                        )

                        s.commit()

                    st.success("? Transaction saved successfully!")
                    st.info(f"ℹ️ **Transaction ID:** {new_id}")
                    st.info(f"🎫 **Ticket ID:** {ticket_id_real}")


                    if is_condensate_receipt:
                        st.info(f"ℹ️ Condensate Receipt: {condensate_qty_m3:.3f} m� ? {gov_bbl:.2f} bbl (GOV) ? {nsv_bbl:.2f} bbl (NSV) ? {lt_val:.2f} (LT) ? {mt_val:.2f} MT")

                    st.balloons()
                    import time as _t
                    _t.sleep(2)
                    _st_safe_rerun()

                except Exception as ex:
                    st.error(f"Failed to save: {ex}")
                    import traceback as _tb
                    st.code(_tb.format_exc())


    # Restore original Streamlit context if we switched to a tab container
    if st_for_restore is not None:
        try:
            st = st_for_restore
        except Exception:
            pass

    if _meter_tab is not None:
        with _meter_tab:
            st.markdown("#### Meter Transactions (Asemoku Jetty)")
            st.caption("Manual entry: Date, Opening, Closing, Remarks")

            # Load existing entries for this location
            with get_session() as _s:
                _rows = (
                    _s.query(MeterTransaction)
                    .filter(MeterTransaction.location_id == active_location_id)
                    .order_by(MeterTransaction.date.desc())
                    .all()
                )

            import pandas as _pd
            # If an edit is in progress, show edit form
            _editing_id = st.session_state.get("meter_edit_id")
            if _editing_id is not None:
                st.markdown("##### Edit Meter Entry")
                with get_session() as _sedit:
                    _rec = _sedit.query(MeterTransaction).filter(
                        MeterTransaction.id == int(_editing_id),
                        MeterTransaction.location_id == active_location_id,
                    ).one_or_none()
                if _rec:
                    if _deny_edit_for_lock(_rec, "MeterTransaction", f"{_rec.date}"):
                        st.session_state.pop("meter_edit_id", None)
                        _st_safe_rerun()
                    else:
                        with st.form(key=f"meter_edit_form_{_editing_id}"):
                            _e_date = st.date_input("Date", value=_rec.date)
                        _e_om1  = st.number_input("Opening reading (Meter 1)", value=float(_rec.opening_meter_reading or 0.0))
                        _e_cm1  = st.number_input("Closing reading (Meter 1)", value=float(_rec.closing_meter_reading or 0.0))
                        _e_om2  = st.number_input("Opening reading (Meter 2)", value=float(getattr(_rec, "opening_meter2_reading", 0.0) or 0.0))
                        _e_cm2  = st.number_input("Closing reading (Meter 2)", value=float(getattr(_rec, "closing_meter2_reading", 0.0) or 0.0))
                        _e_rem  = st.text_area("Remarks", value=_rec.remarks or "")
                        _save   = st.form_submit_button("Save Changes", type="primary")
                    if _save:
                        try:
                            with get_session() as _s2:
                                _rec2 = _s2.query(MeterTransaction).filter(
                                    MeterTransaction.id == int(_editing_id),
                                    MeterTransaction.location_id == active_location_id,
                                ).one_or_none()
                                if _rec2:
                                    _rec2.date = _e_date
                                    _rec2.opening_meter_reading  = float(_e_om1)
                                    _rec2.closing_meter_reading  = float(_e_cm1)
                                    _rec2.opening_meter2_reading = float(_e_om2)
                                    _rec2.closing_meter2_reading = float(_e_cm2)
                                    _rec2.net_qty = (_e_cm1 - _e_om1) + (_e_cm2 - _e_om2)
                                    _rec2.remarks = _e_rem
                                    _s2.commit()
                                    # ----------------------- Audit log for meter entry update -----------------------
                                    try:
                                        from security import SecurityManager  # type: ignore
                                        user_ctx = st.session_state.get("auth_user") or {}
                                        username = user_ctx.get("username", "unknown")
                                        user_id = user_ctx.get("id")
                                        # Use the editing ID as the resource identifier
                                        rec_id = str(_editing_id)
                                        SecurityManager.log_audit(
                                            None,
                                            username,
                                            "UPDATE",
                                            resource_type="MeterTransaction",
                                            resource_id=rec_id,
                                            details=f"Updated meter entry on {_e_date} with net quantity {(_e_cm1 - _e_om1) + (_e_cm2 - _e_om2):.2f}",
                                            user_id=user_id,
                                            location_id=active_location_id,
                                        )
                                    except Exception:
                                        pass
                                    st.success("Meter entry updated.")
                                    st.session_state.pop("meter_edit_id", None)
                                    _st_safe_rerun()
                        except Exception as _ex:
                            st.error(f"Failed to update: {_ex}")
            else:
                st.markdown("##### Add Meter Entry")
                with st.form("meter_add_form"):
                    _date = st.date_input("Date", value=date.today())
                    _om1 = st.number_input("Opening reading (Meter 1)", value=0.0)
                    _cm1 = st.number_input("Closing reading (Meter 1)", value=0.0)
                    _om2 = st.number_input("Opening reading (Meter 2)", value=0.0)
                    _cm2 = st.number_input("Closing reading (Meter 2)", value=0.0)
                    _remarks = st.text_area("Remarks")
                    _save = st.form_submit_button("Save Meter Entry", type="primary")
                if _save:
                    try:
                        with get_session() as _s3:
                            # Construct new meter transaction record
                            new_meter_tx = MeterTransaction(
                                location_id=active_location_id,
                                date=_date,
                                opening_meter_reading=_om1,
                                closing_meter_reading=_cm1,
                                opening_meter2_reading=_om2,
                                closing_meter2_reading=_cm2,
                                net_qty=(_cm1 - _om1) + (_cm2 - _om2),
                                remarks=_remarks,
                            )
                            _s3.add(new_meter_tx)
                            # Flush to assign primary key
                            _s3.flush()
                            new_id = new_meter_tx.id
                            _s3.commit()
                        # Audit log outside transaction
                        try:
                            from security import SecurityManager  # type: ignore
                            user_ctx = st.session_state.get("auth_user") or {}
                            username = user_ctx.get("username", "unknown")
                            user_id = user_ctx.get("id")
                            SecurityManager.log_audit(
                                None,
                                username,
                                "CREATE",
                                resource_type="MeterTransaction",
                                resource_id=str(new_id),
                                details=f"Created meter entry on {_date} with net quantity {(_cm1 - _om1) + (_cm2 - _om2):.2f}",
                                user_id=user_id,
                                location_id=active_location_id,
                            )
                        except Exception:
                            pass
                        st.success("Meter entry saved.")
                        _st_safe_rerun()
                    except Exception as _ex:
                        st.error(f"Failed to save: {_ex}")

            st.markdown("##### Saved Meter Entries")
            if not _rows:
                st.info("No meter entries saved yet.")
            else:
                _df = _pd.DataFrame([{
                    "Date": r.date,
                    "Opening Meter 1": r.opening_meter_reading,
                    "Closing Meter 1": r.closing_meter_reading,
                    "Opening Meter 2": r.opening_meter2_reading,
                    "Closing Meter 2": r.closing_meter2_reading,
                    "Net Qty": r.net_qty,
                    "Remarks": r.remarks,
                } for r in _rows])
                st.dataframe(_df, use_container_width=True, hide_index=True)

            if _rows:
                st.markdown("##### Delete Meter Entry")
                _del_id = st.selectbox(
                    "Select entry to delete",
                    options=[("(cancel)", None)] + [(f"{r.id} ({r.date})", r.id) for r in _rows],
                    format_func=lambda x: x[0] if isinstance(x, tuple) else "(cancel)",
                    key="meter_delete_selector"
                )
                if isinstance(_del_id, tuple):
                    _, _target_id = _del_id
                else:
                    _target_id = None

                if _target_id:
                    _confirm = st.button("Delete Selected Meter Entry", type="primary")
                    if _confirm:
                        try:
                            with get_session() as _s4:
                                _rec_del = _s4.query(MeterTransaction).filter(
                                    MeterTransaction.id == int(_target_id),
                                    MeterTransaction.location_id == active_location_id,
                                ).one_or_none()
                                if _rec_del:
                                    # Capture details BEFORE delete for audit
                                    _details = (
                                        f"date={_rec_del.date}, "
                                        f"om1={_rec_del.opening_meter_reading}, "
                                        f"cm1={_rec_del.closing_meter_reading}, "
                                        f"om2={getattr(_rec_del, 'opening_meter2_reading', 0.0)}, "
                                        f"cm2={getattr(_rec_del, 'closing_meter2_reading', 0.0)}, "
                                        f"net_qty={_rec_del.net_qty}"
                                    )

                                    # Archive instead of deleting outright
                                    _archive_record_for_delete(
                                        _s4,
                                        _rec_del,
                                        "MeterTransaction",
                                        reason=f"Marked meter entry ID={_rec_del.id} for deletion; {_details}",
                                        label=str(_rec_del.date),
                                    )

                                st.success("Meter entry deleted.")
                                _st_safe_rerun()
                        except Exception as _ex:
                            st.error(f"Failed to delete: {_ex}")


    if _condensate_tab is not None:
        with _condensate_tab:
            st.markdown("#### Condensate Records (Beneku)")
            st.caption("24-hour condensate meter receipts for BFS.")
            if not can_make_entries:
                st.info("You have view-only access at this location.")

            today = date.today()
            min_date = today - timedelta(days=max_days_backward)
            max_date_val = today + (timedelta(days=7) if allow_future_dates else timedelta(days=0))

            st.markdown("##### Add Condensate Receipt")
            cond_date = st.date_input(
                "Date *",
                value=today,
                min_value=min_date,
                max_value=max_date_val,
                key="cond_tab_date",
                help=f"Date range: {min_date.strftime('%d/%m/%Y')} to {max_date_val.strftime('%d/%m/%Y')}"
            )

            meter_col1, meter_col2 = st.columns(2)
            with meter_col1:
                cond_opening = st.number_input(
                    "Opening Meter Reading (m�) *",
                    min_value=0.0,
                    step=0.001,
                    format="%.3f",
                    key="cond_tab_open"
                )
            with meter_col2:
                cond_closing = st.number_input(
                    "Closing Meter Reading (m�) *",
                    min_value=0.0,
                    step=0.001,
                    format="%.3f",
                    key="cond_tab_close"
                )

            cond_net_m3 = max(cond_closing - cond_opening, 0.0)
            cond_gov_bbl = cond_net_m3 * CONDENSATE_M3_TO_BBL
            metric_col1, metric_col2 = st.columns(2)
            metric_col1.metric("Net Receipt (m�)", f"{cond_net_m3:,.3f}")
            metric_col2.metric("GOV (bbls)", f"{cond_gov_bbl:,.2f}")

            st.markdown("##### Sample Parameters")
            tank_temp_unit = st.selectbox("Tank Temp Unit", ["°C", "°F"], index=0, key="cond_tab_tank_temp_unit")
            tank_temp_val = _temperature_input(
                f"Tank Temperature ({tank_temp_unit})",
                tank_temp_unit,
                "cond_tab_tank_temp_val",
            )

            obs_mode = st.selectbox("Input Type", ["Observed API", "Observed Density (kg/m3)"], index=0, key="cond_tab_obs_mode")
            sample_unit = st.selectbox("Sample Temp Unit", ["°F", "°C"], index=0, key="cond_tab_sample_unit")
            sample_temp_val = _temperature_input(
                "Sample Temperature",
                sample_unit,
                "cond_tab_sample_temp",
            )

            if obs_mode == "Observed API":
                cond_api_obs = _bounded_number_input(
                    "Observed API *",
                    "cond_tab_api_obs",
                    API_MIN,
                    API_MAX,
                )
                cond_dens_obs = density_from_api(cond_api_obs) if cond_api_obs > 0 else 0.0
                st.caption(f"Derived Density: {cond_dens_obs:.2f} kg/m3")
            else:
                cond_dens_obs = _bounded_number_input(
                    "Observed Density (kg/m3) *",
                    "cond_tab_dens_obs",
                    DENSITY_MIN,
                    DENSITY_MAX,
                    step=0.1,
                )
                cond_api_obs = api_from_density(cond_dens_obs) if cond_dens_obs > 0 else 0.0
                st.caption(f"Derived API: {cond_api_obs:.2f}")

            sample_temp_c_val = _to_c(sample_temp_val or 0.0, sample_unit)
            sample_temp_f_val = _to_f(sample_temp_val or 0.0, sample_unit)
            tank_temp_c_val = _to_c(tank_temp_val or 0.0, tank_temp_unit)
            tank_temp_f_val = _to_f(tank_temp_val or 0.0, tank_temp_unit)

            if cond_api_obs > 0:
                cond_api60 = convert_api_to_60_from_api(cond_api_obs, sample_temp_val or 0.0, sample_unit)
            elif cond_dens_obs > 0:
                cond_api60 = convert_api_to_60_from_density(cond_dens_obs, sample_temp_val or 0.0, sample_unit)
            else:
                cond_api60 = 0.0

            input_mode = "density" if obs_mode != "Observed API" else "api"
            cond_vcf = vcf_from_api60_and_temp(cond_api60, tank_temp_val or 0.0, tank_temp_unit, input_mode)
            cond_gsv_bbl = round(cond_gov_bbl * cond_vcf, 2)
            cond_nsv_bbl = cond_gsv_bbl  # BS&W = 0

            with get_session() as _s_lt:
                cond_lt_factor = lookup_lt_factor(_s_lt, cond_api60) if cond_api60 > 0 else 0.0
            cond_lt = round(cond_nsv_bbl * cond_lt_factor, 2)
            cond_mt = round(cond_lt * 1.01605, 2)

            st.info(
                f"Calculated ? GOV: {cond_gov_bbl:,.2f} bbl | API@60: {cond_api60:.2f} | "
                f"VCF: {cond_vcf:.5f} | GSV: {cond_gsv_bbl:,.2f} bbl | LT: {cond_lt:,.2f} | MT: {cond_mt:,.2f}"
            )

            cond_errors = []
            if cond_closing <= cond_opening:
                cond_errors.append("Closing meter reading must exceed opening reading.")
            if cond_net_m3 <= 0:
                cond_errors.append("Net receipt must be positive.")

            cond_save = st.button(
                "Save Condensate Receipt",
                type="primary",
                key="cond_tab_save_btn",
                disabled=not can_make_entries
            )

            if cond_save:
                if cond_errors:
                    for err in cond_errors:
                        st.error(err)
                else:
                    from datetime import time as _dt_time
                    tx_time_obj = _dt_time(23, 59)
                    operation = "Receipt - Condensate"
                    try:
                        ticket_prefix_effective = (ticket_prefix or "").upper()
                        loc_code_for_ops = (getattr(loc, "code", "") or "").upper()

                        with get_session() as s_lookup:
                            from location_manager import LocationManager
                            _loc = LocationManager.get_location_by_id(s_lookup, active_location_id)
                            if _loc:
                                loc_code_for_ops = (getattr(_loc, "code", "") or loc_code_for_ops or "").upper()
                                if not ticket_prefix_effective:
                                    name_val = getattr(_loc, "name", None)
                                    if name_val:
                                        letters_only = "".join(ch for ch in name_val if ch.isalpha())
                                        if letters_only:
                                            ticket_prefix_effective = letters_only[:3].upper()
                                    if not ticket_prefix_effective:
                                        ticket_prefix_effective = ((getattr(_loc, "code", "") or "")[:3]).upper()

                        serial = next_serial_for(operation, cond_date, ticket_prefix_effective, active_location_id)
                        ticket_id_real = mk_ticket_id(operation, cond_date, serial, ticket_prefix_effective)
                        op_norm = _normalize_operation(loc_code_for_ops or ticket_prefix_effective, operation)
                        op_db = _coerce_operation_for_db(op_norm)
                        if op_db is None:
                            st.error(f"Unsupported operation label: {operation}")
                            st.stop()

                        with get_session() as s:
                            rec = TankTransaction(
                                location_id=active_location_id,
                                ticket_id=ticket_id_real,
                                operation=op_db,
                                tank_id=None,
                                tank_name="CONDENSATE-RECEIPT",
                                date=cond_date,
                                time=tx_time_obj,
                                dip_cm=None,
                                water_cm=None,
                                opening_meter_reading=cond_opening,
                                closing_meter_reading=cond_closing,
                                condensate_qty_m3=cond_net_m3,
                                tank_temp_c=tank_temp_c_val,
                                tank_temp_f=tank_temp_f_val,
                                sample_temp_c=sample_temp_c_val,
                                sample_temp_f=sample_temp_f_val,
                                api_observed=cond_api_obs,
                                density_observed=cond_dens_obs,
                                bsw_pct=0.0,
                                qty_bbls=cond_gov_bbl,
                                remarks=None,
                                created_by=user["username"],
                            )
                            s.add(rec)
                            s.flush()
                            new_id = rec.id

                            from security import SecurityManager
                            SecurityManager.log_audit(
                                s,
                                user["username"],
                                "CREATE",
                                resource_type="TankTransaction",
                                resource_id=new_id,
                                details=f"Created condensate receipt via dedicated tab: {operation}, Ticket: {ticket_id_real}",
                                user_id=user["id"],
                                location_id=active_location_id
                            )

                            s.commit()

                        st.success("Condensate receipt saved successfully.")
                        st.info(f"Ticket ID: {ticket_id_real} | GOV: {cond_gov_bbl:,.2f} bbl | GSV: {cond_gsv_bbl:,.2f} bbl")
                        st.balloons()
                        import time as _t
                        _t.sleep(1)
                        _st_safe_rerun()
                    except Exception as ex:
                        st.error(f"Failed to save condensate receipt: {ex}")

            st.markdown("##### Saved Condensate Records")
            cond_records, _ = load_condensate_transactions(active_location_id, limit=500)
            if not cond_records:
                st.info("No condensate receipts saved yet.")
            else:
                cond_df = pd.DataFrame(cond_records)
                display_cols = [
                    "Ticket ID", "Date", "Opening (m3)", "Closing (m3)",
                    "Net Receipt (m3)", "GOV (bbls)", "API @ 60",
                    "VCF", "GSV (bbls)", "LT", "MT"
                ]
                st.dataframe(cond_df[display_cols], use_container_width=True, hide_index=True)

    if _gpp_tab is not None:
        with _gpp_tab:
            st.markdown("#### Production (Beneku)")
            st.caption("Manual entry and tracking of OKW and GPP production figures.")

            user_role = (user.get("role") or "").lower()
            can_delete_gpp = can_make_entries and user_role != "operator"
            if user_role == "operator":
                st.warning("Operators can view and edit production records but cannot delete them.")

            today = date.today()
            min_date = today - timedelta(days=max_days_backward)
            max_date_val = today + (timedelta(days=7) if allow_future_dates else timedelta(days=0))

            def _ensure_gpp_form_defaults():
                if "gpp_form_date" not in st.session_state:
                    st.session_state["gpp_form_date"] = today
                if "gpp_form_okw" not in st.session_state:
                    st.session_state["gpp_form_okw"] = 0.0
                if "gpp_form_gpp1" not in st.session_state:
                    st.session_state["gpp_form_gpp1"] = 0.0
                if "gpp_form_gpp2" not in st.session_state:
                    st.session_state["gpp_form_gpp2"] = 0.0
                if "gpp_form_remarks" not in st.session_state:
                    st.session_state["gpp_form_remarks"] = ""
                if "gpp_edit_id" not in st.session_state:
                    st.session_state["gpp_edit_id"] = None
                # Default closing stock for GPP production
                if "gpp_form_closing" not in st.session_state:
                    st.session_state["gpp_form_closing"] = 0.0

            def _reset_gpp_form():
                st.session_state["gpp_edit_id"] = None
                st.session_state["gpp_form_date"] = today
                st.session_state["gpp_form_okw"] = 0.0
                st.session_state["gpp_form_gpp1"] = 0.0
                st.session_state["gpp_form_gpp2"] = 0.0
                st.session_state["gpp_form_remarks"] = ""
                st.session_state["gpp_form_closing"] = 0.0

            _ensure_gpp_form_defaults()
            is_editing_gpp = st.session_state.get("gpp_edit_id") is not None
            # Show info when editing an existing production record
            if is_editing_gpp:
                st.info(f"Editing record for {st.session_state.get('gpp_form_date')}")

            st.markdown("##### Manual Entry")
            # Define columns for date, OKW, GPP1, GPP2, GPP closing stock, total metric and remarks
            entry_cols = st.columns([0.15, 0.15, 0.15, 0.15, 0.15, 0.10, 0.15])
            with entry_cols[0]:
                gpp_date_val = st.date_input(
                    "Date",
                    value=st.session_state.get("gpp_form_date", today),
                    min_value=min_date,
                    max_value=max_date_val,
                    key="gpp_prod_date_input",
                )
                st.session_state["gpp_form_date"] = gpp_date_val
            with entry_cols[1]:
                okw_val = st.number_input(
                    "OKW Production",
                    min_value=0.0,
                    step=1.0,
                    value=float(st.session_state.get("gpp_form_okw", 0.0)),
                    key="gpp_prod_okw_input",
                )
                st.session_state["gpp_form_okw"] = okw_val
            with entry_cols[2]:
                gpp1_val = st.number_input(
                    "GPP1 Production",
                    min_value=0.0,
                    step=1.0,
                    value=float(st.session_state.get("gpp_form_gpp1", 0.0)),
                    key="gpp_prod_gpp1_input",
                )
                st.session_state["gpp_form_gpp1"] = gpp1_val
            with entry_cols[3]:
                gpp2_val = st.number_input(
                    "GPP2 Production",
                    min_value=0.0,
                    step=1.0,
                    value=float(st.session_state.get("gpp_form_gpp2", 0.0)),
                    key="gpp_prod_gpp2_input",
                )
                st.session_state["gpp_form_gpp2"] = gpp2_val
            with entry_cols[4]:
                gpp_cs_val = st.number_input(
                    "GPP Closing Stock",
                    min_value=0.0,
                    step=1.0,
                    value=float(st.session_state.get("gpp_form_closing", 0.0)),
                    key="gpp_prod_cs_input",
                )
                st.session_state["gpp_form_closing"] = gpp_cs_val
            total_val = round((gpp1_val or 0.0) + (gpp2_val or 0.0), 2)
            with entry_cols[5]:
                st.metric("Total GPP Production", f"{total_val:,.2f}")
            with entry_cols[6]:
                remarks_val = st.text_input(
                    "Remarks",
                    value=st.session_state.get("gpp_form_remarks", ""),
                    key="gpp_prod_remarks_input",
                )
                st.session_state["gpp_form_remarks"] = remarks_val

            save_label = "Update Record" if is_editing_gpp else "Save Production Entry"
            action_cols = st.columns([0.2, 0.2, 0.6])
            save_clicked = action_cols[0].button(
                save_label,
                type="primary",
                disabled=not can_make_entries,
                key="gpp_save_btn",
            )
            cancel_clicked = False
            if is_editing_gpp:
                cancel_clicked = action_cols[1].button("Cancel Edit", key="gpp_cancel_btn")

            if cancel_clicked:
                _reset_gpp_form()
                _st_safe_rerun()

            if save_clicked:
                errors = []
                if gpp_date_val is None:
                    errors.append("Date is required.")
                if total_val <= 0:
                    errors.append("Total production must be greater than zero.")

                if errors:
                    for err in errors:
                        st.error(err)
                else:
                    try:
                        with get_session() as s:
                            if is_editing_gpp:
                                rec = (
                                    s.query(GPPProductionRecord)
                                    .filter(
                                        GPPProductionRecord.id == int(st.session_state["gpp_edit_id"]),
                                        GPPProductionRecord.location_id == active_location_id,
                                    )
                                    .one_or_none()
                                )
                                if not rec:
                                    st.error("Selected record no longer exists.")
                                else:
                                    # Update fields for editing
                                    rec.date = gpp_date_val
                                    rec.okw_production = float(okw_val or 0.0)
                                    rec.gpp1_production = float(gpp1_val or 0.0)
                                    rec.gpp2_production = float(gpp2_val or 0.0)
                                    rec.total_production = total_val
                                    rec.gpp_closing_stock = float(st.session_state.get("gpp_form_closing", 0.0) or 0.0)
                                    rec.remarks = (remarks_val or "").strip()
                                    rec.updated_by = user.get("username", "unknown")

                                    SecurityManager.log_audit(
                                        s,
                                        user.get("username", "unknown"),
                                        "UPDATE",
                                        resource_type="GPPProductionRecord",
                                        resource_id=rec.id,
                                        details=f"Updated production record for {rec.date}",
                                        user_id=user.get("id"),
                                        location_id=active_location_id,
                                    )
                                    s.commit()
                                    st.success("Production record updated.")
                                    _reset_gpp_form()
                                    _st_safe_rerun()
                            else:
                                _remarks_final = (remarks_val or "").strip()
                                rec = GPPProductionRecord(
                                    location_id=active_location_id,
                                    date=gpp_date_val,
                                    okw_production=float(okw_val or 0.0),
                                    gpp1_production=float(gpp1_val or 0.0),
                                    gpp2_production=float(gpp2_val or 0.0),
                                    total_production=total_val,
                                    gpp_closing_stock=float(st.session_state.get("gpp_form_closing", 0.0) or 0.0),
                                    remarks=_remarks_final,
                                    created_by=user.get("username", "unknown"),
                                )
                                s.add(rec)
                                s.flush()
                                SecurityManager.log_audit(
                                    s,
                                    user.get("username", "unknown"),
                                    "CREATE",
                                    resource_type="GPPProductionRecord",
                                    resource_id=rec.id,
                                    details=f"Created production record for {gpp_date_val}",
                                    user_id=user.get("id"),
                                    location_id=active_location_id,
                                )
                                s.commit()
                                st.success("Production record saved.")
                                _reset_gpp_form()
                                _st_safe_rerun()
                    except Exception as ex:
                        st.error(f"Failed to save record: {ex}")

            records = load_gpp_production_records(active_location_id, limit=1000)
            gpp_df = pd.DataFrame(records)
            gpp_dates = gpp_df["Date"].tolist() if not gpp_df.empty else []
            gpp_min_date, gpp_max_date = _derive_filter_bounds(gpp_dates)
            gpp_from_default = _ensure_date_key_in_bounds(
                "gpp_filter_from", gpp_min_date, gpp_max_date, gpp_min_date
            )
            gpp_to_default = _ensure_date_key_in_bounds(
                "gpp_filter_to", gpp_min_date, gpp_max_date, gpp_max_date
            )

            st.markdown("##### Live Filters")
            filter_cols = st.columns([0.2, 0.2, 0.25, 0.35])
            with filter_cols[0]:
                filt_from = st.date_input(
                    "From date",
                    value=gpp_from_default,
                    min_value=gpp_min_date,
                    max_value=gpp_max_date,
                    key="gpp_filter_from",
                )
            with filter_cols[1]:
                filt_to = st.date_input(
                    "To date",
                    value=gpp_to_default,
                    min_value=gpp_min_date,
                    max_value=gpp_max_date,
                    key="gpp_filter_to",
                )
            with filter_cols[2]:
                min_total = st.number_input(
                    "Min total (bbls)",
                    min_value=0.0,
                    step=100.0,
                    key="gpp_filter_min_total",
                )
            with filter_cols[3]:
                search_term = st.text_input(
                    "Search remarks / user",
                    key="gpp_filter_search",
                ).strip().lower()

            if not gpp_df.empty:
                gpp_df["Date"] = pd.to_datetime(gpp_df["Date"]).dt.date
                gpp_df["Updated At"] = (
                    pd.to_datetime(gpp_df["Updated At"], errors="coerce")
                    .dt.strftime("%Y-%m-%d %H:%M:%S")
                    .fillna("")
                )

                if filt_from:
                    gpp_df = gpp_df[gpp_df["Date"] >= filt_from]
                if filt_to:
                    gpp_df = gpp_df[gpp_df["Date"] <= filt_to]
                if min_total and min_total > 0:
                    gpp_df = gpp_df[gpp_df["Total GPP Production"] >= min_total]
                if search_term:
                    gpp_df = gpp_df[
                        gpp_df.apply(
                            lambda r: search_term in str(r["Remarks"]).lower()
                            or search_term in str(r["Created By"]).lower()
                            or search_term in str(r["Updated By"]).lower(),
                            axis=1,
                        )
                    ]

            st.caption(f"{len(gpp_df)} record(s) shown")
            # Build interactive table for production records.
            # Include GPP Closing Stock and provide edit/delete actions in each row.
            display_cols = [
                "Date",
                "OKW Production",
                "GPP1 Production",
                "GPP2 Production",
                "GPP Closing Stock",
                "Total GPP Production",
                "Remarks",
                "Created By",
                "Updated By",
                "Updated At",
            ]
            if gpp_df.empty:
                st.info("No production records found for the selected filters.")
            else:
                st.markdown("##### Production Records")
                # Define column widths; adjust widths to accommodate additional columns and actions
                col_widths = [0.13, 0.1, 0.1, 0.1, 0.13, 0.13, 0.21, 0.05, 0.05]
                header_cols = st.columns(col_widths)
                header_cols[0].markdown("**Date**")
                header_cols[1].markdown("**OKW Prod**")
                header_cols[2].markdown("**GPP1 Prod**")
                header_cols[3].markdown("**GPP2 Prod**")
                header_cols[4].markdown("**GPP Closing**")
                header_cols[5].markdown("**Total GPP**")
                header_cols[6].markdown("**Remarks**")
                header_cols[7].markdown("**✏️**")
                header_cols[8].markdown("**🗑️**")

                # Sort records by date descending
                manage_records = gpp_df.sort_values(by="Date", ascending=False).to_dict("records")
                # Ensure delete confirmation id exists in session_state
                st.session_state.setdefault("gpp_confirm_delete_id", None)
                for rec in manage_records:
                    row_cols = st.columns(col_widths)
                    row_cols[0].write(str(rec["Date"]))
                    row_cols[1].write(f"{rec['OKW Production']:,.2f}")
                    row_cols[2].write(f"{rec['GPP1 Production']:,.2f}")
                    row_cols[3].write(f"{rec['GPP2 Production']:,.2f}")
                    row_cols[4].write(f"{rec.get('GPP Closing Stock', 0.0):,.2f}")
                    row_cols[5].write(f"{rec['Total GPP Production']:,.2f}")
                    row_cols[6].write((rec.get('Remarks') or '')[:50])
                    edit_btn = row_cols[7].button(
                        "✏️",
                        key=f"gpp_edit_{rec['id']}",
                        help="Edit this record",
                        disabled=not can_make_entries,
                    )
                    delete_btn = row_cols[8].button(
                        "🗑️",
                        key=f"gpp_delete_{rec['id']}",
                        help="Delete this record",
                        disabled=not can_delete_gpp,
                    )
                    if edit_btn:
                        allow_edit = True
                        with get_session() as _lock_s:
                            obj = (
                                _lock_s.query(GPPProductionRecord)
                                .filter(
                                    GPPProductionRecord.id == int(rec["id"]),
                                    GPPProductionRecord.location_id == active_location_id,
                                )
                                .one_or_none()
                            )
                            if obj and _deny_edit_for_lock(obj, "GPPProductionRecord", f"{obj.date}"):
                                allow_edit = False
                        if allow_edit:
                            st.session_state["gpp_edit_id"] = rec["id"]
                            date_val = rec["Date"]
                            if isinstance(date_val, str):
                                try:
                                    date_val = datetime.strptime(date_val, "%Y-%m-%d").date()
                                except Exception:
                                    date_val = today
                            st.session_state["gpp_form_date"] = date_val
                            st.session_state["gpp_form_okw"] = rec["OKW Production"]
                            st.session_state["gpp_form_gpp1"] = rec["GPP1 Production"]
                            st.session_state["gpp_form_gpp2"] = rec["GPP2 Production"]
                            st.session_state["gpp_form_closing"] = rec.get("GPP Closing Stock", 0.0)
                            st.session_state["gpp_form_remarks"] = rec.get("Remarks") or ""
                            _st_safe_rerun()
                    if delete_btn:
                        st.session_state["gpp_confirm_delete_id"] = rec["id"]
                        _st_safe_rerun()

                # Render deletion confirmation prompt
                confirm_id = st.session_state.get("gpp_confirm_delete_id")
                if confirm_id:
                    target_rec = next((r for r in manage_records if r["id"] == confirm_id), None)
                    if target_rec:
                        st.warning(
                            f"Are you sure you want to delete the production record for **{target_rec['Date']}**? This action cannot be undone.",
                            icon="ℹ️",
                        )
                        confirm_cols = st.columns([0.25, 0.25, 0.5])
                        confirm_delete = confirm_cols[0].button(
                            "Yes, delete",
                            key=f"gpp_confirm_yes_{confirm_id}",
                            type="primary",
                            disabled=not can_delete_gpp,
                        )
                        cancel_delete = confirm_cols[1].button(
                            "Cancel",
                            key=f"gpp_confirm_no_{confirm_id}",
                        )
                        if confirm_delete:
                            try:
                                with get_session() as s:
                                    row = (
                                        s.query(GPPProductionRecord)
                                        .filter(
                                            GPPProductionRecord.id == int(confirm_id),
                                            GPPProductionRecord.location_id == active_location_id,
                                        )
                                        .one_or_none()
                                    )
                                    if not row:
                                        st.warning("Record already removed.")
                                    else:
                                        _archive_record_for_delete(
                                            s,
                                            row,
                                            "GPPProductionRecord",
                                            reason=f"Marked production record for {row.date} as deleted.",
                                            label=f"{row.date}",
                                        )
                                        SecurityManager.log_audit(
                                            s,
                                            user.get("username", "unknown"),
                                            "DELETE",
                                            resource_type="GPPProductionRecord",
                                            resource_id=row.id,
                                            details=f"Deleted production record for {row.date}",
                                            user_id=user.get("id"),
                                            location_id=active_location_id,
                                        )
                                        s.commit()
                                        st.success("Record deleted successfully.")
                            except Exception as ex:
                                st.error(f"Failed to delete record: {ex}")
                            # Reset confirmation and form state
                            st.session_state["gpp_confirm_delete_id"] = None
                            _reset_gpp_form()
                            _st_safe_rerun()
                        elif cancel_delete:
                            st.session_state["gpp_confirm_delete_id"] = None
                            _st_safe_rerun()


    if _river_tab is not None:
        with _river_tab:
            st.markdown("#### River Draft")
            st.caption("Manual entry for daily river draft and rainfall snapshots.")

            user_role = (user.get("role") or "").lower() if user else ""
            can_delete_river = can_make_entries and user_role != "operator"
            if user_role == "operator":
                st.warning("Operators can add or edit entries but cannot delete them.")

            today = date.today()
            min_date = today - timedelta(days=max_days_backward)
            max_date_val = today + (timedelta(days=7) if allow_future_dates else timedelta(days=0))

            date_key = f"river_form_date_{active_location_id}"
            draft_key = f"river_form_draft_{active_location_id}"
            rain_key = f"river_form_rain_{active_location_id}"
            edit_key = f"river_form_edit_{active_location_id}"
            date_widget_key = f"{date_key}_widget"
            draft_widget_key = f"{draft_key}_widget"
            rain_widget_key = f"{rain_key}_widget"

            def _ensure_river_defaults():
                st.session_state.setdefault(date_key, today)
                st.session_state.setdefault(draft_key, 0.0)
                st.session_state.setdefault(rain_key, 0.0)
                st.session_state.setdefault(edit_key, None)

            def _reset_river_form():
                st.session_state[edit_key] = None
                st.session_state[date_key] = today
                st.session_state[draft_key] = 0.0
                st.session_state[rain_key] = 0.0
                st.session_state.pop(date_widget_key, None)
                st.session_state.pop(draft_widget_key, None)
                st.session_state.pop(rain_widget_key, None)

            _ensure_river_defaults()
            is_editing_river = st.session_state.get(edit_key) is not None
            if is_editing_river:
                st.info(f"Editing entry for {st.session_state.get(date_key)}")

            with st.container(border=True):
                st.markdown("##### Manual Entry")
                entry_cols = st.columns([0.3, 0.35, 0.35])
                with entry_cols[0]:
                    rd_date_val = st.date_input(
                        "Date",
                        value=st.session_state.get(date_key, today),
                        min_value=min_date,
                        max_value=max_date_val,
                        key=date_widget_key,
                    )
                with entry_cols[1]:
                    rd_draft_val = st.number_input(
                        "River Draft (m)",
                        min_value=0.0,
                        step=0.1,
                        value=float(st.session_state.get(draft_key, 0.0)),
                        key=draft_widget_key,
                    )
                with entry_cols[2]:
                    rd_rain_val = st.number_input(
                        "Rainfall (cm)",
                        min_value=0.0,
                        step=0.1,
                        value=float(st.session_state.get(rain_key, 0.0)),
                        key=rain_widget_key,
                    )

                action_cols = st.columns([0.2, 0.2, 0.6])
                save_label = "Update Entry" if is_editing_river else "Save Entry"
                save_clicked = action_cols[0].button(
                    save_label,
                    type="primary",
                    disabled=not can_make_entries,
                    key=f"river_save_{active_location_id}",
                )
                cancel_clicked = False
                if is_editing_river:
                    cancel_clicked = action_cols[1].button(
                        "Cancel Edit",
                        key=f"river_cancel_{active_location_id}",
                    )

                if cancel_clicked:
                    _reset_river_form()
                    _st_safe_rerun()

                if save_clicked:
                    errors = []
                    if rd_date_val is None:
                        errors.append("Date is required.")

                    if errors:
                        for err in errors:
                            st.error(err)
                    else:
                        try:
                            with get_session() as sess:
                                if is_editing_river:
                                    rec = (
                                        sess.query(RiverDraftRecord)
                                        .filter(
                                            RiverDraftRecord.id == int(st.session_state[edit_key]),
                                            RiverDraftRecord.location_id == active_location_id,
                                        )
                                        .one_or_none()
                                    )
                                    if not rec:
                                        st.error("Selected entry no longer exists.")
                                    else:
                                        rec.date = rd_date_val
                                        rec.river_draft_m = float(rd_draft_val)
                                        rec.rainfall_cm = float(rd_rain_val)
                                        rec.updated_by = user.get("username", "unknown")
                                        SecurityManager.log_audit(
                                            sess,
                                            user.get("username", "unknown"),
                                            "UPDATE",
                                            resource_type="RiverDraftRecord",
                                            resource_id=rec.id,
                                            details=f"Updated river draft entry for {rec.date}",
                                            user_id=user.get("id"),
                                            location_id=active_location_id,
                                        )
                                        sess.commit()
                                        st.success("River draft entry updated.")
                                        _reset_river_form()
                                        _st_safe_rerun()
                                else:
                                    rec = RiverDraftRecord(
                                        location_id=active_location_id,
                                        date=rd_date_val,
                                        river_draft_m=float(rd_draft_val),
                                        rainfall_cm=float(rd_rain_val),
                                        created_by=user.get("username", "unknown"),
                                    )
                                    sess.add(rec)
                                    sess.flush()
                                    SecurityManager.log_audit(
                                        sess,
                                        user.get("username", "unknown"),
                                        "CREATE",
                                        resource_type="RiverDraftRecord",
                                        resource_id=rec.id,
                                        details=f"Created river draft entry for {rd_date_val}",
                                        user_id=user.get("id"),
                                        location_id=active_location_id,
                                    )
                                    sess.commit()
                                    st.success("River draft entry saved.")
                                    _reset_river_form()
                                    _st_safe_rerun()
                        except Exception as ex:
                            st.error(f"Failed to save entry: {ex}")

            river_records = load_river_draft_records(active_location_id, limit=1000)
            rd_df = pd.DataFrame(river_records)
            if not rd_df.empty:
                rd_df["Date"] = pd.to_datetime(rd_df["Date"]).dt.date
            rd_dates = rd_df["Date"].tolist() if not rd_df.empty else []
            river_min_date, river_max_date = _derive_filter_bounds(rd_dates)
            river_from_default = _ensure_date_key_in_bounds(
                f"river_filter_from_{active_location_id}",
                river_min_date,
                river_max_date,
                river_min_date,
            )
            river_to_default = _ensure_date_key_in_bounds(
                f"river_filter_to_{active_location_id}",
                river_min_date,
                river_max_date,
                river_max_date,
            )

            st.markdown("##### Live Filters")
            filter_cols = st.columns(2)
            river_filter_from = filter_cols[0].date_input(
                "From date",
                value=river_from_default,
                min_value=river_min_date,
                max_value=river_max_date,
                key=f"river_filter_from_{active_location_id}",
            )
            river_filter_to = filter_cols[1].date_input(
                "To date",
                value=river_to_default,
                min_value=river_min_date,
                max_value=river_max_date,
                key=f"river_filter_to_{active_location_id}",
            )

            if not rd_df.empty:
                if river_filter_from:
                    rd_df = rd_df[rd_df["Date"] >= river_filter_from]
                if river_filter_to:
                    rd_df = rd_df[rd_df["Date"] <= river_filter_to]
                rd_df["Updated At"] = (
                    pd.to_datetime(rd_df["Updated At"], errors="coerce")
                    .dt.strftime("%Y-%m-%d %H:%M:%S")
                    .fillna("")
                )

            st.caption(f"{len(rd_df)} record(s) shown")

            display_cols = [
                "Date",
                "River Draft (m)",
                "Rainfall (cm)",
                "Created By",
                "Updated By",
                "Updated At",
            ]
            if rd_df.empty:
                st.info("No entries for the selected filters.")
            else:
                st.dataframe(rd_df[display_cols], use_container_width=True, hide_index=True)

                st.markdown("###### Manage Entries")
                for rec in rd_df.sort_values(by="Date", ascending=False).to_dict("records"):
                    row_cols = st.columns([0.2, 0.2, 0.2, 0.25, 0.075, 0.075])
                    row_cols[0].write(str(rec["Date"]))
                    row_cols[1].write(f"{float(rec['River Draft (m)']):,.2f}")
                    row_cols[2].write(f"{float(rec['Rainfall (cm)']):,.2f}")
                    row_cols[3].write(rec.get("Updated By") or rec.get("Created By") or "-")
                    edit_btn = row_cols[4].button(
                        "Edit",
                        key=f"river_edit_{rec['id']}",
                        disabled=not can_make_entries,
                    )
                    delete_btn = row_cols[5].button(
                        "Delete",
                        key=f"river_delete_{rec['id']}",
                        disabled=not can_delete_river,
                    )

                    if edit_btn:
                        st.session_state[edit_key] = rec["id"]
                        st.session_state[date_key] = rec["Date"]
                        st.session_state[draft_key] = float(rec["River Draft (m)"] or 0.0)
                        st.session_state[rain_key] = float(rec["Rainfall (cm)"] or 0.0)
                        _st_safe_rerun()

                    confirm_key = f"river_delete_confirm_{rec['id']}"
                    if delete_btn:
                        st.session_state[confirm_key] = True
                    if st.session_state.get(confirm_key):
                        st.warning("Delete this entry? This action cannot be undone.")
                        c1, c2 = st.columns(2)
                        if c1.button("Yes, delete", key=f"{confirm_key}_yes"):
                            try:
                                with get_session() as sess:
                                    row = (
                                        sess.query(RiverDraftRecord)
                                        .filter(
                                            RiverDraftRecord.id == rec["id"],
                                            RiverDraftRecord.location_id == active_location_id,
                                        )
                                        .one_or_none()
                                    )
                                    if not row:
                                        st.warning("Entry already deleted.")
                                    else:
                                        _archive_record_for_delete(
                                            sess,
                                            row,
                                            "RiverDraftRecord",
                                            reason=f"Deleted river draft entry for {row.date}",
                                            label=str(row.date),
                                        )
                                        SecurityManager.log_audit(
                                            sess,
                                            user.get("username", "unknown"),
                                            "DELETE",
                                            resource_type="RiverDraftRecord",
                                            resource_id=row.id,
                                            details=f"Deleted river draft entry for {row.date}",
                                            user_id=user.get("id"),
                                            location_id=active_location_id,
                                        )
                                        sess.commit()
                                        st.success("Entry deleted.")
                                        _reset_river_form()
                                        _st_safe_rerun()
                            except Exception as ex:
                                st.error(f"Failed to delete entry: {ex}")
                            finally:
                                st.session_state.pop(confirm_key, None)
                        if c2.button("Cancel", key=f"{confirm_key}_no"):
                            st.session_state.pop(confirm_key, None)

    if _produced_water_tab is not None:
        with _produced_water_tab:
            st.markdown("#### Produced Water")
            st.caption("Manual entry for produced water volumes (bbls).")

            user_role = (user.get("role") or "").lower() if user else ""
            can_delete_pw = can_make_entries and user_role != "operator"
            if user_role == "operator":
                st.warning("Operators can add or edit produced water entries but cannot delete them.")

            today = date.today()
            min_date = today - timedelta(days=max_days_backward)
            max_date_val = today + (timedelta(days=7) if allow_future_dates else timedelta(days=0))

            pw_date_key = f"pw_form_date_{active_location_id}"
            pw_value_key = f"pw_form_value_{active_location_id}"
            pw_edit_key = f"pw_form_edit_{active_location_id}"
            pw_date_widget = f"{pw_date_key}_widget"
            pw_value_widget = f"{pw_value_key}_widget"

            def _ensure_pw_defaults():
                st.session_state.setdefault(pw_date_key, today)
                st.session_state.setdefault(pw_value_key, 0.0)
                st.session_state.setdefault(pw_edit_key, None)

            def _reset_pw_form():
                st.session_state[pw_edit_key] = None
                st.session_state[pw_date_key] = today
                st.session_state[pw_value_key] = 0.0
                st.session_state.pop(pw_date_widget, None)
                st.session_state.pop(pw_value_widget, None)

            _ensure_pw_defaults()
            is_editing_pw = st.session_state.get(pw_edit_key) is not None
            if is_editing_pw:
                st.info(f"Editing entry for {st.session_state.get(pw_date_key)}")

            with st.container(border=True):
                st.markdown("##### Manual Entry")
                entry_cols = st.columns([0.4, 0.6])
                with entry_cols[0]:
                    pw_date_val = st.date_input(
                        "Date",
                        value=st.session_state.get(pw_date_key, today),
                        min_value=min_date,
                        max_value=max_date_val,
                        key=pw_date_widget,
                    )
                with entry_cols[1]:
                    pw_value_val = st.number_input(
                        "Produced Water (bbls)",
                        min_value=0.0,
                        step=1.0,
                        value=float(st.session_state.get(pw_value_key, 0.0)),
                        key=pw_value_widget,
                    )

                action_cols = st.columns([0.2, 0.2, 0.6])
                save_label = "Update Entry" if is_editing_pw else "Save Entry"
                save_clicked = action_cols[0].button(
                    save_label,
                    type="primary",
                    disabled=not can_make_entries,
                    key=f"pw_save_{active_location_id}",
                )
                cancel_clicked = False
                if is_editing_pw:
                    cancel_clicked = action_cols[1].button(
                        "Cancel Edit",
                        key=f"pw_cancel_{active_location_id}",
                    )

                if cancel_clicked:
                    _reset_pw_form()
                    _st_safe_rerun()

                if save_clicked:
                    errors = []
                    if pw_date_val is None:
                        errors.append("Date is required.")

                    if errors:
                        for err in errors:
                            st.error(err)
                    else:
                        try:
                            with get_session() as sess:
                                if is_editing_pw:
                                    rec = (
                                        sess.query(ProducedWaterRecord)
                                        .filter(
                                            ProducedWaterRecord.id == int(st.session_state[pw_edit_key]),
                                            ProducedWaterRecord.location_id == active_location_id,
                                        )
                                        .one_or_none()
                                    )
                                    if not rec:
                                        st.error("Selected entry no longer exists.")
                                    else:
                                        rec.date = pw_date_val
                                        rec.produced_water_bbl = float(pw_value_val)
                                        rec.updated_by = user.get("username", "unknown")
                                        SecurityManager.log_audit(
                                            sess,
                                            user.get("username", "unknown"),
                                            "UPDATE",
                                            resource_type="ProducedWaterRecord",
                                            resource_id=rec.id,
                                            details=f"Updated produced water entry for {rec.date}",
                                            user_id=user.get("id"),
                                            location_id=active_location_id,
                                        )
                                        sess.commit()
                                        st.success("Produced water entry updated.")
                                        _reset_pw_form()
                                        _st_safe_rerun()
                                else:
                                    rec = ProducedWaterRecord(
                                        location_id=active_location_id,
                                        date=pw_date_val,
                                        produced_water_bbl=float(pw_value_val),
                                        created_by=user.get("username", "unknown"),
                                    )
                                    sess.add(rec)
                                    sess.flush()
                                    SecurityManager.log_audit(
                                        sess,
                                        user.get("username", "unknown"),
                                        "CREATE",
                                        resource_type="ProducedWaterRecord",
                                        resource_id=rec.id,
                                        details=f"Created produced water entry for {pw_date_val}",
                                        user_id=user.get("id"),
                                        location_id=active_location_id,
                                    )
                                    sess.commit()
                                    st.success("Produced water entry saved.")
                                    _reset_pw_form()
                                    _st_safe_rerun()
                        except Exception as ex:
                            st.error(f"Failed to save entry: {ex}")

            pw_records = load_produced_water_records(active_location_id, limit=1000)
            pw_df = pd.DataFrame(pw_records)
            if not pw_df.empty:
                pw_df["Date"] = pd.to_datetime(pw_df["Date"]).dt.date
            pw_dates = pw_df["Date"].tolist() if not pw_df.empty else []
            pw_min_date, pw_max_date = _derive_filter_bounds(pw_dates)
            pw_from_default = _ensure_date_key_in_bounds(
                f"pw_filter_from_{active_location_id}",
                pw_min_date,
                pw_max_date,
                pw_min_date,
            )
            pw_to_default = _ensure_date_key_in_bounds(
                f"pw_filter_to_{active_location_id}",
                pw_min_date,
                pw_max_date,
                pw_max_date,
            )

            st.markdown("##### Live Filters")
            filter_cols = st.columns(2)
            pw_filter_from = filter_cols[0].date_input(
                "From date",
                value=pw_from_default,
                min_value=pw_min_date,
                max_value=pw_max_date,
                key=f"pw_filter_from_{active_location_id}",
            )
            pw_filter_to = filter_cols[1].date_input(
                "To date",
                value=pw_to_default,
                min_value=pw_min_date,
                max_value=pw_max_date,
                key=f"pw_filter_to_{active_location_id}",
            )

            if not pw_df.empty:
                if pw_filter_from:
                    pw_df = pw_df[pw_df["Date"] >= pw_filter_from]
                if pw_filter_to:
                    pw_df = pw_df[pw_df["Date"] <= pw_filter_to]
                pw_df["Updated At"] = (
                    pd.to_datetime(pw_df["Updated At"], errors="coerce")
                    .dt.strftime("%Y-%m-%d %H:%M:%S")
                    .fillna("")
                )

            st.caption(f"{len(pw_df)} record(s) shown")

            pw_display_cols = [
                "Date",
                "Produced Water (bbls)",
                "Created By",
                "Updated By",
                "Updated At",
            ]
            if pw_df.empty:
                st.info("No entries for the selected filters.")
            else:
                st.dataframe(pw_df[pw_display_cols], use_container_width=True, hide_index=True)

                st.markdown("###### Manage Entries")
                for rec in pw_df.sort_values(by="Date", ascending=False).to_dict("records"):
                    row_cols = st.columns([0.25, 0.25, 0.3, 0.1, 0.1])
                    row_cols[0].write(str(rec["Date"]))
                    row_cols[1].write(f"{float(rec['Produced Water (bbls)']):,.2f}")
                    row_cols[2].write(rec.get("Updated By") or rec.get("Created By") or "-")
                    edit_btn = row_cols[3].button(
                        "Edit",
                        key=f"pw_edit_{rec['id']}",
                        disabled=not can_make_entries,
                    )
                    delete_btn = row_cols[4].button(
                        "Delete",
                        key=f"pw_delete_{rec['id']}",
                        disabled=not can_delete_pw,
                    )

                    if edit_btn:
                        st.session_state[pw_edit_key] = rec["id"]
                        st.session_state[pw_date_key] = rec["Date"]
                        st.session_state[pw_value_key] = float(rec["Produced Water (bbls)"] or 0.0)
                        _st_safe_rerun()

                    confirm_key = f"pw_delete_confirm_{rec['id']}"
                    if delete_btn:
                        st.session_state[confirm_key] = True
                    if st.session_state.get(confirm_key):
                        st.warning("Delete this entry? This action cannot be undone.")
                        c1, c2 = st.columns(2)
                        if c1.button("Yes, delete", key=f"{confirm_key}_yes"):
                            try:
                                with get_session() as sess:
                                    row = (
                                        sess.query(ProducedWaterRecord)
                                        .filter(
                                            ProducedWaterRecord.id == rec["id"],
                                            ProducedWaterRecord.location_id == active_location_id,
                                        )
                                        .one_or_none()
                                    )
                                    if not row:
                                        st.warning("Entry already deleted.")
                                    else:
                                        _archive_record_for_delete(
                                            sess,
                                            row,
                                            "ProducedWaterRecord",
                                            reason=f"Deleted produced water entry for {row.date}",
                                            label=str(row.date),
                                        )
                                        SecurityManager.log_audit(
                                            sess,
                                            user.get("username", "unknown"),
                                            "DELETE",
                                            resource_type="ProducedWaterRecord",
                                            resource_id=row.id,
                                            details=f"Deleted produced water entry for {row.date}",
                                            user_id=user.get("id"),
                                            location_id=active_location_id,
                                        )
                                        sess.commit()
                                        st.success("Entry deleted.")
                                        _reset_pw_form()
                                        _st_safe_rerun()
                            except Exception as ex:
                                st.error(f"Failed to delete entry: {ex}")
                            finally:
                                st.session_state.pop(confirm_key, None)
                        if c2.button("Cancel", key=f"{confirm_key}_no"):
                            st.session_state.pop(confirm_key, None)

    if _tanker_tab is not None:
        with _tanker_tab:
            st.markdown("#### No of Tankers")
            if not (_is_aggu_location or _is_ndoni_location):
                st.info("This tab is only available for Aggu and Ndoni locations.")
            else:
                is_aggu_site = _is_aggu_location
                mode_label = "Aggu" if is_aggu_site else "Ndoni"
                st.caption(
                    "Live tracker for tanker movements at "
                    f"{mode_label}. S.No auto-increments per saved entry."
                )

                today = date.today()
                min_date = today - timedelta(days=max_days_backward)
                max_date_val = today + (timedelta(days=7) if allow_future_dates else timedelta(days=0))

                date_key = f"tanker_date_{active_location_id}"
                dispatched_key = f"tanker_dispatched_{active_location_id}"
                from_aggu_key = f"tanker_from_aggu_{active_location_id}"
                from_ofs_key = f"tanker_from_ofs_{active_location_id}"
                # New key for separate "Other Tankers" input (Ndoni only)
                other_key = f"tanker_other_{active_location_id}"
                remarks_key = f"tanker_remarks_{active_location_id}"
                edit_key = f"tanker_edit_id_{active_location_id}"
                prefill_key = f"tanker_form_prefill_{active_location_id}"

                def _default_form_values():
                    return {
                        "date": today,
                        "dispatched": 0.0,
                        "from_aggu": 0.0,
                        "from_ofs": 0.0,
                        # Include separate "other" field for Ndoni (initially 0)
                        "other": 0.0,
                        "remarks": "",
                    }

                def _apply_form_values(values: Dict[str, Any]):
                    merged = _default_form_values()
                    merged.update({k: v for k, v in (values or {}).items() if v is not None})
                    st.session_state[date_key] = merged["date"]
                    if is_aggu_site:
                        st.session_state[dispatched_key] = float(merged["dispatched"] or 0.0)
                    else:
                        st.session_state[from_aggu_key] = float(merged.get("from_aggu") or 0.0)
                        st.session_state[from_ofs_key] = float(merged.get("from_ofs") or 0.0)
                        # Apply separate other_tankers field for Ndoni
                        st.session_state[other_key] = float(merged.get("other") or 0.0)
                    st.session_state[remarks_key] = merged.get("remarks") or ""

                def _ensure_tanker_defaults():
                    st.session_state.setdefault(edit_key, None)
                    pending = st.session_state.pop(prefill_key, None)
                    if pending is not None or date_key not in st.session_state:
                        _apply_form_values(pending or {})
                    else:
                        st.session_state.setdefault(date_key, today)
                        if is_aggu_site:
                            st.session_state.setdefault(dispatched_key, 0.0)
                        else:
                            st.session_state.setdefault(from_aggu_key, 0.0)
                            st.session_state.setdefault(from_ofs_key, 0.0)
                            # Initialise other_key for Ndoni
                            st.session_state.setdefault(other_key, 0.0)
                        st.session_state.setdefault(remarks_key, "")

                def _reset_tanker_form():
                    st.session_state[edit_key] = None
                    st.session_state[prefill_key] = _default_form_values()

                _ensure_tanker_defaults()
                editing_id = st.session_state.get(edit_key)
                is_editing_tanker = editing_id is not None

                if is_editing_tanker:
                    st.info(f"Editing entry #{editing_id} for {st.session_state.get(date_key)}")

                with st.container(border=True):
                    st.markdown("##### Manual Entry")
                    # For Ndoni we need an extra column for "Other Tankers" input
                    entry_cols = st.columns(3 if is_aggu_site else 5)
                    with entry_cols[0]:
                        st.date_input(
                            "Date",
                            min_value=min_date,
                            max_value=max_date_val,
                            key=date_key,
                        )

                    if is_aggu_site:
                        with entry_cols[1]:
                            st.number_input(
                                "Tankers Dispatched",
                                min_value=0.0,
                                step=1.0,
                                key=dispatched_key,
                            )
                        remarks_col = entry_cols[2]
                    else:
                        with entry_cols[1]:
                            st.number_input(
                                "Tankers from Aggu",
                                min_value=0.0,
                                step=1.0,
                                key=from_aggu_key,
                            )
                        with entry_cols[2]:
                            st.number_input(
                                "Tankers from OFS",
                                min_value=0.0,
                                step=1.0,
                                key=from_ofs_key,
                            )
                        with entry_cols[3]:
                            st.number_input(
                                "Other Tankers",
                                min_value=0.0,
                                step=1.0,
                                key=other_key,
                            )
                        remarks_col = entry_cols[4]

                    with remarks_col:
                        st.text_area(
                            "Remarks",
                            key=remarks_key,
                        )

                    action_cols = st.columns([0.2, 0.2, 0.6])
                    save_label = "Update Entry" if is_editing_tanker else "Save Entry"
                    save_clicked = action_cols[0].button(
                        save_label,
                        type="primary",
                        disabled=not can_make_entries,
                        key=f"tanker_save_btn_{active_location_id}",
                    )
                    cancel_clicked = False
                    if is_editing_tanker:
                        cancel_clicked = action_cols[1].button(
                            "Cancel Edit",
                            key=f"tanker_cancel_btn_{active_location_id}",
                        )

                    if cancel_clicked:
                        _reset_tanker_form()
                        _st_safe_rerun()

                    if save_clicked:
                        date_val = st.session_state.get(date_key)
                        dispatched_val = float(st.session_state.get(dispatched_key, 0.0) or 0.0)
                        from_aggu_val = float(st.session_state.get(from_aggu_key, 0.0) or 0.0)
                        from_ofs_val = float(st.session_state.get(from_ofs_key, 0.0) or 0.0)
                        # Read separate other_tankers value for Ndoni
                        other_val = float(st.session_state.get(other_key, 0.0) or 0.0)
                        remarks_val = (st.session_state.get(remarks_key) or "").strip()

                        errors: List[str] = []
                        if not date_val:
                            errors.append("Date is required.")
                        if is_aggu_site and dispatched_val <= 0:
                            errors.append("Tankers dispatched must be greater than zero.")
                        if (not is_aggu_site) and (from_aggu_val <= 0 and from_ofs_val <= 0 and other_val <= 0):
                            errors.append("At least one tanker count must be greater than zero.")

                        if errors:
                            for err in errors:
                                st.error(err)
                        else:
                            try:
                                with get_session() as sess:
                                    if is_editing_tanker:
                                        rec = (
                                            sess.query(LocationTankerEntry)
                                            .filter(
                                                LocationTankerEntry.id == int(editing_id),
                                                LocationTankerEntry.location_id == active_location_id,
                                            )
                                            .one_or_none()
                                        )
                                        if not rec:
                                            st.error("Selected entry no longer exists.")
                                        else:
                                            rec.date = date_val
                                            rec.tankers_dispatched = dispatched_val if is_aggu_site else 0.0
                                            rec.tankers_from_aggu = from_aggu_val if not is_aggu_site else 0.0
                                            rec.tankers_from_ofs = from_ofs_val if not is_aggu_site else 0.0
                                            # Set separate other_tankers on edit for Ndoni
                                            rec.other_tankers = other_val if not is_aggu_site else 0.0
                                            rec.remarks = remarks_val
                                            rec.updated_by = user.get("username", "unknown")
                                            SecurityManager.log_audit(
                                                sess,
                                                user.get("username", "unknown"),
                                                "UPDATE",
                                                resource_type="LocationTankerEntry",
                                                resource_id=rec.id,
                                                details=f"Updated tanker entry for {rec.date}",
                                                user_id=user.get("id"),
                                                location_id=active_location_id,
                                            )
                                            sess.commit()
                                            st.success("Entry updated successfully.")
                                            _reset_tanker_form()
                                            _st_safe_rerun()
                                    else:
                                        serial_no = _next_tanker_serial(sess, active_location_id)
                                        rec = LocationTankerEntry(
                                            location_id=active_location_id,
                                            serial_no=serial_no,
                                            date=date_val,
                                            tankers_dispatched=dispatched_val if is_aggu_site else 0.0,
                                            tankers_from_aggu=from_aggu_val if not is_aggu_site else 0.0,
                                            tankers_from_ofs=from_ofs_val if not is_aggu_site else 0.0,
                                            # Persist separate other_tankers for Ndoni
                                            other_tankers=other_val if not is_aggu_site else 0.0,
                                            remarks=remarks_val,
                                            created_by=user.get("username", "unknown"),
                                        )
                                        sess.add(rec)
                                        sess.flush()
                                        SecurityManager.log_audit(
                                            sess,
                                            user.get("username", "unknown"),
                                            "CREATE",
                                            resource_type="LocationTankerEntry",
                                            resource_id=rec.id,
                                            details=f"Created tanker entry for {date_val}",
                                            user_id=user.get("id"),
                                            location_id=active_location_id,
                                        )
                                        sess.commit()
                                        st.success("Entry saved successfully.")
                                        _reset_tanker_form()
                                        _st_safe_rerun()
                            except Exception as ex:
                                st.error(f"Failed to save entry: {ex}")

                with get_session() as sess:
                    rows = (
                        sess.query(LocationTankerEntry)
                        .filter(LocationTankerEntry.location_id == active_location_id)
                        .order_by(LocationTankerEntry.date.desc(), LocationTankerEntry.serial_no.desc())
                        .all()
                    )

                tanker_dates = [r.date for r in rows if isinstance(r.date, date)]
                tanker_min, tanker_max = _derive_filter_bounds(tanker_dates)
                tanker_from_default = _ensure_date_key_in_bounds(
                    f"tanker_filter_from_{active_location_id}",
                    tanker_min,
                    tanker_max,
                    tanker_min,
                )
                tanker_to_default = _ensure_date_key_in_bounds(
                    f"tanker_filter_to_{active_location_id}",
                    tanker_min,
                    tanker_max,
                    tanker_max,
                )

                st.markdown("##### Live Filters")
                history_cols = st.columns([0.25, 0.25, 0.5])
                with history_cols[0]:
                    hist_from = st.date_input(
                        "From",
                        value=tanker_from_default,
                        min_value=tanker_min,
                        max_value=tanker_max,
                        key=f"tanker_filter_from_{active_location_id}",
                    )
                with history_cols[1]:
                    hist_to = st.date_input(
                        "To",
                        value=tanker_to_default,
                        min_value=tanker_min,
                        max_value=tanker_max,
                        key=f"tanker_filter_to_{active_location_id}",
                    )
                with history_cols[2]:
                    search_note = st.text_input(
                        "Search remarks",
                        key=f"tanker_filter_search_{active_location_id}",
                    ).strip().lower()

                filtered_rows = []
                for rec in rows:
                    if hist_from and rec.date < hist_from:
                        continue
                    if hist_to and rec.date > hist_to:
                        continue
                    if search_note and search_note not in (rec.remarks or "").lower():
                        continue
                    filtered_rows.append(rec)

                st.caption(f"{len(filtered_rows)} record(s) shown")

                if not filtered_rows:
                    st.info("No tanker entries found for the selected filters.")
                else:
                    if is_aggu_site:
                        header_labels = [
                            "S.No",
                            "Date",
                            "Tankers Dispatched",
                            "Remarks",
                            "Actions",
                        ]
                        widths = [0.09, 0.18, 0.2, 0.39, 0.14]
                    else:
                        header_labels = [
                            "S.No",
                            "Date",
                            "Tankers from Aggu",
                            "Tankers from OFS",
                            "Other Tankers",
                            "Remarks",
                            "Actions",
                        ]
                        # Widths should sum to 1.0; allocate extra column for other tankers
                        widths = [0.07, 0.14, 0.16, 0.17, 0.17, 0.23, 0.06]

                    header_cols = st.columns(widths)
                    for col, label in zip(header_cols, header_labels):
                        col.markdown(f"**{label}**")

                    can_delete_tankers = can_make_entries and user_role != "operator"

                    for rec in filtered_rows:
                        row_cols = st.columns(widths)
                        row_cols[0].write(int(rec.serial_no))
                        row_cols[1].write(rec.date.strftime("%d-%b-%Y"))
                        if is_aggu_site:
                            row_cols[2].write(f"{rec.tankers_dispatched:,.0f}")
                            remark_col_index = 3
                            action_col_index = 4
                        else:
                            row_cols[2].write(f"{rec.tankers_from_aggu:,.0f}")
                            row_cols[3].write(f"{rec.tankers_from_ofs:,.0f}")
                            # Show separate "Other Tankers" column
                            row_cols[4].write(f"{rec.other_tankers:,.0f}")
                            remark_col_index = 5
                            action_col_index = 6

                        badge = user_with_caution(rec.created_by, rec.updated_by, rec.updated_at)
                        remarks_html = (
                            f"{rec.remarks or '-'}<br/><span style='color:#6c757d;font-size:0.75rem;'>{badge}</span>"
                        )
                        row_cols[remark_col_index].markdown(remarks_html, unsafe_allow_html=True)

                        with row_cols[action_col_index]:
                            action_col = st.columns(2)
                            edit_btn = action_col[0].button(
                                "✏️",
                                key=f"tanker_edit_{rec.id}",
                                disabled=not can_make_entries,
                            )
                            delete_btn = action_col[1].button(
                                "🗑️",
                                key=f"tanker_delete_{rec.id}",
                                disabled=not can_delete_tankers,
                            )

                            if edit_btn:
                                if not _deny_edit_for_lock(rec, "LocationTankerEntry", f"{rec.date}"):
                                    st.session_state[edit_key] = rec.id
                                    st.session_state[prefill_key] = {
                                        "date": rec.date,
                                        "dispatched": float(rec.tankers_dispatched or 0.0),
                                        "from_aggu": float(rec.tankers_from_aggu or 0.0),
                                        "from_ofs": float(rec.tankers_from_ofs or 0.0),
                                        # Pre-fill separate other_tankers field for Ndoni
                                        "other": float(rec.other_tankers or 0.0),
                                        "remarks": rec.remarks or "",
                                    }
                                    _st_safe_rerun()

                            confirm_key = f"tanker_confirm_delete_{rec.id}"
                            if delete_btn:
                                st.session_state[confirm_key] = True

                            if st.session_state.get(confirm_key):
                                st.warning("Delete this entry? This action cannot be undone.")
                                conf_cols = st.columns(2)
                                if conf_cols[0].button(
                                    "Yes, delete",
                                    key=f"{confirm_key}_yes",
                                    type="primary",
                                ):
                                    try:
                                        with get_session() as sess:
                                            row = (
                                                sess.query(LocationTankerEntry)
                                                .filter(
                                                    LocationTankerEntry.id == rec.id,
                                                    LocationTankerEntry.location_id == active_location_id,
                                                )
                                                .one_or_none()
                                            )
                                            if not row:
                                                st.warning("Entry already removed.")
                                            else:
                                                _archive_record_for_delete(
                                                    sess,
                                                    row,
                                                    "LocationTankerEntry",
                                                    reason=f"Marked tanker entry for {row.date} for deletion.",
                                                    label=f"{row.date}",
                                                )
                                                sess.commit()
                                                st.success("Entry moved to recycle bin.")
                                                _reset_tanker_form()
                                                _st_safe_rerun()
                                    except Exception as ex:
                                        st.error(f"Failed to delete entry: {ex}")
                                    finally:
                                        st.session_state.pop(confirm_key, None)
                                if conf_cols[1].button(
                                    "Cancel",
                                    key=f"{confirm_key}_no",
                                ):
                                    st.session_state.pop(confirm_key, None)

# ================================= YADE TRANSACTIONS ================================
elif page == "Yade Transactions":
    header("Yade Transactions")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()
    
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("Yade Transactions") is False:
                st.error("⚠️ YADE Transactions page is disabled for this location.")
                st.stop()
    except Exception:
        pass
    st.markdown("#### Record YADE Barge Loadings")
    
    # ============ LOCATION ACCESS CHECK ============
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("⚠️ No active location selected. Please select a location from the Home page.")
        st.stop()
    
    # Verify user has access to this location
    user = st.session_state.get("auth_user")
    if user:
        from auth import AuthManager
        if not AuthManager.can_access_location(user, active_location_id):
            st.error("🚫 You do not have access to this location.")
            st.stop()
    
    # ========== CHECK PERMISSIONS ==========
    from permission_manager import PermissionManager
    
    with get_session() as s:
        from location_manager import LocationManager
        
        # Get location info
        loc = LocationManager.get_location_by_id(s, active_location_id)
        if not loc:
            st.error("? Location not found.")
            st.stop()
        
        st.info(f"📍 **Active Location:** {loc.name} ({loc.code})")

        # Apply location-based page visibility: hide page if disabled in config (non-admin)
        try:
            with get_session() as _s_cfg:
                from location_config import LocationConfig
                _cfg = LocationConfig.get_config(_s_cfg, active_location_id)
            if not _cfg.get("page_visibility", {}).get("show_yade_transactions", False) and (user.get("role", "").lower() not in ["admin-operations", "manager"]):
                st.error("⚠️ YADE Transactions page is disabled for this location.")
                st.stop()
        except Exception:
            pass
        
        # Check if feature is allowed at this location (Admin can access everywhere)
        if not PermissionManager.can_access_feature(s, active_location_id, "yade_transactions", user["role"]):
            st.error("🚫 **Access Denied**")
            st.warning(f"**YADE Transactions** are not available at **{loc.name}**")
            
            # Show where it's available
            allowed_locs = PermissionManager.get_allowed_locations_for_feature(s, "yade_transactions")
            if allowed_locs:
                st.info(f"? This feature is available at: **{', '.join(allowed_locs)}**")
            
            st.markdown("---")
            st.caption(f"Current Location: **{loc.name} ({loc.code})**")
            st.caption("YADE Transactions Access: **? Denied**")
            st.stop()
        
        # Check if user can make entries
        can_make_entries = PermissionManager.can_make_entries(s, user["role"], active_location_id)
    
    # ============ YADE ENABLED - SHOW SUCCESS MESSAGE ============
    st.success(f"? YADE Transactions enabled at {loc.name}")
    
    # ------------ helpers ------------
    def hhmm_ok(s: str) -> bool:
        if not s or len(s) not in (4, 5): return False
        s = s.strip()
        if ":" not in s: return False
        h, m = s.split(":", 1)
        if not (h.isdigit() and m.isdigit()): return False
        h, m = int(h), int(m)
        return 0 <= h <= 23 and 0 <= m <= 59

    def only_digits_hyphen(s: str) -> bool:
        return bool(re.fullmatch(r"[0-9-]+", s)) and any(ch.isdigit() for ch in s)

    # YADE barges from DB - Global (not location-filtered)
    with get_session() as s:
        _barges = s.query(YadeBarge).order_by(YadeBarge.name).all()

    yade_names = [b.name for b in _barges] if _barges else ["(No YADE barges � add in Add Asset)"]
    design_map = {b.name: str(b.design) for b in _barges}

    # ============ YADE HELPER FUNCTIONS ============

    def _persist_toa_from_current_inputs(
        session,
        voyage_obj,
        yade_name: str,
        tank_ids: list,
        num_samples: int
    ):
        """
        Persist TOA (Transfer of Account) data from current YADE voyage inputs.
        Creates TOA summary and stage records with ACTUAL calculations.
        """
        from models import TOAYadeSummary, TOAYadeStage, YadeDip, YadeSampleParam
        from datetime import datetime
        
        try:
            # Import the calculator
            try:
                from yade_toa_calculator import calculate_yade_toa
            except ImportError:
                st.warning("⚠️ yade_toa_calculator not found. Using placeholder TOA values.")
                # Create placeholder TOA
                summary = TOAYadeSummary(
                    voyage_id=voyage_obj.id,
                    ticket_id=f"YADE-{voyage_obj.voyage_no}",
                    date=voyage_obj.date,
                    time=voyage_obj.time,
                    yade_name=yade_name,
                    convoy_no=voyage_obj.convoy_no,
                    destination=voyage_obj.destination,
                    loading_berth=voyage_obj.loading_berth,
                    gsv_before_bbl=0.0,
                    gsv_after_bbl=0.0,
                    gsv_loaded_bbl=0.0
                )
                session.add(summary)
                
                for stage_name in ["before", "after"]:
                    stage = TOAYadeStage(
                        voyage_id=voyage_obj.id,
                        stage=stage_name,
                        gov_bbl=0.0,
                        gsv_bbl=0.0,
                        bsw_pct=0.0,
                        bsw_bbl=0.0,
                        nsv_bbl=0.0,
                        lt=0.0,
                        mt=0.0,
                        fw_bbl=0.0
                    )
                    session.add(stage)
                return
            
            # Remove existing summary/stage data for this voyage before recalculating
            session.query(TOAYadeStage).filter(TOAYadeStage.voyage_id == voyage_obj.id).delete(synchronize_session=False)
            session.query(TOAYadeSummary).filter(TOAYadeSummary.voyage_id == voyage_obj.id).delete(synchronize_session=False)
            session.flush()

            # Get dips from database (already saved)
            before_dips_db = session.query(YadeDip).filter(
                YadeDip.voyage_id == voyage_obj.id,
                YadeDip.stage == "before"
            ).all()
            
            after_dips_db = session.query(YadeDip).filter(
                YadeDip.voyage_id == voyage_obj.id,
                YadeDip.stage == "after"
            ).all()
            
            # Get sample params from database
            before_params_db = session.query(YadeSampleParam).filter(
                YadeSampleParam.voyage_id == voyage_obj.id,
                YadeSampleParam.stage == "before"
            ).first()
            
            after_params_db = session.query(YadeSampleParam).filter(
                YadeSampleParam.voyage_id == voyage_obj.id,
                YadeSampleParam.stage == "after"
            ).first()
            
            # Prepare dip data
            dip_data = {
                "before": {},
                "after": {}
            }
            
            for dip in before_dips_db:
                dip_data["before"][dip.tank_id] = {
                    "total_cm": float(dip.total_cm or 0.0),
                    "water_cm": float(dip.water_cm or 0.0)
                }
            
            for dip in after_dips_db:
                dip_data["after"][dip.tank_id] = {
                    "total_cm": float(dip.total_cm or 0.0),
                    "water_cm": float(dip.water_cm or 0.0)
                }
            
            # Prepare sample data
            sample_data = {
                "before": {
                    "obs_mode": before_params_db.obs_mode if before_params_db else "Observed API",
                    "obs_val": float(before_params_db.obs_val or 0.0) if before_params_db else 0.0,
                    "sample_temp": float(before_params_db.sample_temp or 60.0) if before_params_db else 60.0,
                    "tank_temp": float(before_params_db.tank_temp or 60.0) if before_params_db else 60.0,
                    "bsw_pct": float(before_params_db.bsw_pct or 0.0) if before_params_db else 0.0,
                    "ccf": float(before_params_db.ccf or 1.0) if before_params_db else 1.0,
                },
                "after": {
                    "obs_mode": after_params_db.obs_mode if after_params_db else "Observed API",
                    "obs_val": float(after_params_db.obs_val or 0.0) if after_params_db else 0.0,
                    "sample_temp": float(after_params_db.sample_temp or 60.0) if after_params_db else 60.0,
                    "tank_temp": float(after_params_db.tank_temp or 60.0) if after_params_db else 60.0,
                    "bsw_pct": float(after_params_db.bsw_pct or 0.0) if after_params_db else 0.0,
                    "ccf": float(after_params_db.ccf or 1.0) if after_params_db else 1.0,
                }
            }
            
            # Calculate TOA
            toa_result = calculate_yade_toa(
                yade_name=yade_name,
                dip_data=dip_data,
                sample_data=sample_data,
                session=session
            )
            
            if not toa_result:
                print("⚠️  TOA calculation returned None, using placeholders")
                toa_result = {
                    "before": {"gov_bbl": 0, "gsv_bbl": 0, "bsw_pct": 0, "bsw_bbl": 0, "nsv_bbl": 0, "lt": 0, "mt": 0, "fw_bbl": 0},
                    "after": {"gov_bbl": 0, "gsv_bbl": 0, "bsw_pct": 0, "bsw_bbl": 0, "nsv_bbl": 0, "lt": 0, "mt": 0, "fw_bbl": 0},
                    "loaded": {"gsv_bbl": 0}
                }
            
            # Create TOA Summary
            summary = TOAYadeSummary(
                voyage_id=voyage_obj.id,
                ticket_id=f"YADE-{voyage_obj.voyage_no}",
                date=voyage_obj.date,
                time=voyage_obj.time,
                yade_name=yade_name,
                convoy_no=voyage_obj.convoy_no,
                destination=voyage_obj.destination,
                loading_berth=voyage_obj.loading_berth,
                gsv_before_bbl=toa_result.get("before", {}).get("gsv_bbl", 0.0),
                gsv_after_bbl=toa_result.get("after", {}).get("gsv_bbl", 0.0),
                gsv_loaded_bbl=toa_result.get("loaded", {}).get("gsv_bbl", 0.0)
            )
            
            session.add(summary)
            
            # Create TOA Stage records
            for stage_name in ["before", "after"]:
                stage_data = toa_result.get(stage_name, {})
                
                stage = TOAYadeStage(
                    voyage_id=voyage_obj.id,
                    stage=stage_name,
                    gov_bbl=stage_data.get("gov_bbl", 0.0),
                    gsv_bbl=stage_data.get("gsv_bbl", 0.0),
                    bsw_pct=stage_data.get("bsw_pct", 0.0),
                    bsw_bbl=stage_data.get("bsw_bbl", 0.0),
                    nsv_bbl=stage_data.get("nsv_bbl", 0.0),
                    lt=stage_data.get("lt", 0.0),
                    mt=stage_data.get("mt", 0.0),
                    fw_bbl=stage_data.get("fw_bbl", 0.0)
                )
                
                session.add(stage)
            
            print(f"? TOA data calculated and saved for voyage {voyage_obj.id}")
        
        except Exception as ex:
            print(f"⚠️  Failed to persist TOA: {ex}")
            import traceback
            traceback.print_exc()


    def _save_yade_dips(session, voyage_id: int, tank_ids: list, stage: str):
        """Save YADE dip readings for a specific stage"""
        from models import YadeDip
        
        dips_key = f"yade_{stage}_dips"
        dips = st.session_state.get(dips_key, {})
        
        for tank_id in tank_ids:
            total_cm = dips.get(f"{tank_id}_total", 0.0)
            water_cm = dips.get(f"{tank_id}_water", 0.0)
            
            dip_entry = YadeDip(
                voyage_id=voyage_id,
                tank_id=tank_id,
                stage=stage,
                total_cm=total_cm,
                water_cm=water_cm
            )
            
            session.add(dip_entry)


    def _save_yade_sample_params(session, voyage_id: int, stage: str):
        """Save YADE sample parameters for a specific stage"""
        from models import YadeSampleParam
        
        params_key = f"yade_{stage}_params"
        params = st.session_state.get(params_key, {})
        
        obs_mode = params.get("obs_mode", "API")
        obs_val = params.get("obs_val", 0.0)
        sample_unit = params.get("sample_unit", "C")
        sample_temp = params.get("sample_temp", 0.0)
        tank_temp = params.get("tank_temp", 0.0)
        ccf = params.get("ccf", 1.0)
        bsw_pct = params.get("bsw_pct", 0.0)
        
        sample_param = YadeSampleParam(
            voyage_id=voyage_id,
            stage=stage,
            obs_mode=obs_mode,
            obs_val=obs_val,
            sample_unit=sample_unit,
            sample_temp=sample_temp,
            tank_temp=tank_temp,
            ccf=ccf,
            bsw_pct=bsw_pct
        )
        
        session.add(sample_param)


    def _save_yade_seal_details(session, voyage_id: int):
        """Save YADE seal details"""
        from models import YadeSealDetail
        
        seals = st.session_state.get("yade_seals", {})
        
        seal_detail = YadeSealDetail(
            voyage_id=voyage_id,
            c1_mh1=seals.get("c1_mh1"),
            c1_mh2=seals.get("c1_mh2"),
            c1_lock=seals.get("c1_lock"),
            c1_diphatch=seals.get("c1_diphatch"),
            c2_mh1=seals.get("c2_mh1"),
            c2_mh2=seals.get("c2_mh2"),
            c2_lock=seals.get("c2_lock"),
            c2_diphatch=seals.get("c2_diphatch"),
            p1_mh1=seals.get("p1_mh1"),
            p1_mh2=seals.get("p1_mh2"),
            p1_lock=seals.get("p1_lock"),
            p1_diphatch=seals.get("p1_diphatch"),
            p2_mh1=seals.get("p2_mh1"),
            p2_mh2=seals.get("p2_mh2"),
            p2_lock=seals.get("p2_lock"),
            p2_diphatch=seals.get("p2_diphatch"),
            s1_mh1=seals.get("s1_mh1"),
            s1_mh2=seals.get("s1_mh2"),
            s1_lock=seals.get("s1_lock"),
            s1_diphatch=seals.get("s1_diphatch"),
            s2_mh1=seals.get("s2_mh1"),
            s2_mh2=seals.get("s2_mh2"),
            s2_lock=seals.get("s2_lock"),
            s2_diphatch=seals.get("s2_diphatch")
        )
        
        session.add(seal_detail)

    # ------------ TOP METADATA ------------
    st.markdown("#### Top Metadata")

    # [REST OF YOUR YADE FORM CODE - KEEP EVERYTHING AS IS]
    # ... (all your existing form fields, dip entries, sample parameters, seals, etc.)
    
    # Provide a helpful hint with light‑bulb icon and arrow for navigation
    st.info("💡 **View saved YADE voyages in:** View Transactions → YADE Voyages")

    # ------------ TOP METADATA ------------
    st.markdown("#### New YADE Voyage Entry")

    m1, m2, m3 = st.columns(3)
    with m1:
        yade_no = st.selectbox("1) YADE No *", yade_names, index=0, key="yt_yade_no")
        selected_design = design_map.get(yade_no)
        design_choice = selected_design or st.selectbox("Tank Design *", ["6", "4"], index=0, key="yt_design_fallback")
    with m2:
        voyage_no = st.text_input("2) Voyage number * (digits & '-' only)", placeholder="e.g., 12-3", key="yt_voyage_no")
        convoy_no = st.text_input("3) Convoy number * (digits & '-' only)", placeholder="e.g., 5-1", key="yt_convoy_no")
    with m3:
        tx_date = st.date_input("4) Date * (DD/MM/YYYY)", value=date.today(), format="DD/MM/YYYY", key="yt_date")
        tx_time = st.text_input("5) Time * (HH:MM)", value="08:00", key="yt_time")

    m4, m5, m6 = st.columns(3)
    with m4:
        cargo = st.selectbox("6) Cargo *",
                             [x.value for x in CargoKind],
                             key="yt_cargo")
    with m5:
        destination = st.selectbox("7) Destination *", [x.value for x in DestinationKind], index=0, key="yt_destination")
    with m6:
        loading_berth = st.selectbox("8) Loading Berth *", [x.value for x in LoadingBerthKind], key="yt_berth")

    st.markdown("---")

    # ------------ TANK SET BY DESIGN ------------
    tank_ids_6 = ["C1", "C2", "P1", "P2", "S1", "S2"]
    tank_ids_4 = ["P1", "P2", "S1", "S2"]
    tank_ids = tank_ids_6 if str(design_choice) == "6" else tank_ids_4

    # ------------ Dip Entry Tables (Before / After) ------------
    st.markdown("#### Dip Entry Tables")
    left, right = st.columns(2)

    with left:
        st.markdown("##### Before Loading/Unloading")
        b_dcol, b_tcol = st.columns(2)
        with b_dcol:
            before_date = st.date_input("Gauging Date (Before)", value=tx_date, format="DD/MM/YYYY", key="before_date")
        with b_tcol:
            before_time = st.text_input("Gauging Time (Before) (HH:MM)", value="07:30", key="before_time")

        st.caption("Enter **Total Dip** and **Water Dip** (cm) for each tank")
        for tid in tank_ids:
            r1, r2, r3 = st.columns([0.25, 0.375, 0.375])
            with r1:
                st.text_input("Tank", value=tid, disabled=True, key=f"before_tank_{tid}")
            with r2:
                st.number_input("Total Dip (cm)", min_value=0.0, step=0.1, key=f"before_total_{tid}")
            with r3:
                st.number_input("Water Dip (cm)", min_value=0.0, step=0.1, key=f"before_water_{tid}")

    with right:
        st.markdown("##### After Loading/Unloading")
        a_dcol, a_tcol = st.columns(2)
        with a_dcol:
            after_date = st.date_input("Gauging Date (After)", value=tx_date, format="DD/MM/YYYY", key="after_date")
        with a_tcol:
            after_time = st.text_input("Gauging Time (After) (HH:MM)", value="17:30", key="after_time")

        st.caption("Enter **Total Dip** and **Water Dip** (cm) for each tank")
        for tid in tank_ids:
            r1, r2, r3 = st.columns([0.25, 0.375, 0.375])
            with r1:
                st.text_input("Tank ", value=tid, disabled=True, key=f"after_tank_{tid}")
            with r2:
                st.number_input("Total Dip (cm) ", min_value=0.0, step=0.1, key=f"after_total_{tid}")
            with r3:
                st.number_input("Water Dip (cm) ", min_value=0.0, step=0.1, key=f"after_water_{tid}")

    st.markdown("---")
    
    # ====================== SAMPLE PARAMETERS (Before / After) ======================
    st.markdown("### Sample Parameters")

    def _to_f(c_or_f: float, unit: str) -> float:
        if unit.upper().startswith("C"):
            return round((float(c_or_f) * 1.8) + 32.0, 1)
        return float(c_or_f or 0.0)

    def _to_c(c_or_f: float, unit: str) -> float:
        if unit.upper().startswith("F"):
            return round((float(c_or_f) - 32.0) / 1.8, 1)
        return float(c_or_f or 0.0)

    WAT60_LOCAL = 999.012
    
    def api_from_density(density_kgm3: float) -> float:
        if not density_kgm3 or density_kgm3 <= 0: return 0.0
        sg = float(density_kgm3) / WAT60_LOCAL
        if sg <= 0: return 0.0
        return round(141.5 / sg - 131.5, 2)

    def density_from_api(api: float) -> float:
        if not api or api <= 0: return 0.0
        sg = 141.5 / (float(api) + 131.5)
        return round(sg * WAT60_LOCAL, 1)

    safe_yade = re.sub(r'[^A-Za-z0-9]', '_', str(yade_no))
    safe_voy  = re.sub(r'[^A-Za-z0-9]', '_', str(voyage_no))
    ns_sp     = f"ysp_{safe_yade}_{safe_voy}"

    if "yade_sample_params" not in st.session_state:
        st.session_state["yade_sample_params"] = {}
    if ns_sp not in st.session_state["yade_sample_params"]:
        st.session_state["yade_sample_params"][ns_sp] = {}

    def _sample_param_row(stage_key: str):
        st.markdown(f"#### {stage_key.title()}")

        c1, c2, c3, c4 = st.columns([0.28, 0.24, 0.24, 0.24])
        with c1:
            obs_mode = st.selectbox(
                "Observed Input",
                ["Observed API", "Observed Density (kg/m3)"],
                index=0,
                key=f"{ns_sp}_{stage_key}_obs_mode"
            )
        with c2:
            sample_unit = st.selectbox(
                "Sample Temperature Unit",
                ["°F", "°C"],
                index=0,
                key=f"{ns_sp}_{stage_key}_sample_unit"
            )
        with c3:
            sample_temp = _temperature_input(
                "Sample Temperature",
                sample_unit,
                key=f"{ns_sp}_{stage_key}_sample_temp",
            )
        with c4:
            tank_temp = _temperature_input(
                "Tank Temperature",
                sample_unit,
                key=f"{ns_sp}_{stage_key}_tank_temp",
            )

        d1, d2, d3 = st.columns([0.34, 0.33, 0.33])
        with d1:
            obs_min, obs_max = _observed_value_bounds(obs_mode)
            obs_val = _bounded_number_input(
                "Observed Value",
                key=f"{ns_sp}_{stage_key}_obs_val",
                min_value=obs_min,
                max_value=obs_max,
                step=0.1,
            )
        with d2:
            ccf = st.number_input(
                "Calibration Correction Factor",
                min_value=0.000001,
                value=1.0,
                step=0.0001,
                key=f"{ns_sp}_{stage_key}_ccf",
                help="Default 1.0000. Cannot be 0."
            )
        with d3:
            bsw_pct = st.number_input(
                "BS&W %",
                min_value=0.0, max_value=100.0, step=0.01,
                key=f"{ns_sp}_{stage_key}_bsw_pct",
                help="Basic Sediment & Water percentage (e.g., 0.25)."
            )

        st.session_state["yade_sample_params"][ns_sp][stage_key] = {
            "obs_mode": obs_mode,
            "obs_val": float(obs_val or 0.0),
            "sample_unit": sample_unit,
            "sample_temp": float(sample_temp or 0.0),
            "tank_temp": float(tank_temp or 0.0),
            "ccf": float(ccf or 1.0),
            "bsw_pct": float(bsw_pct or 0.0),
        }

    col_before, col_after = st.columns(2)
    with col_before:
        _sample_param_row("before")
    with col_after:
        _sample_param_row("after")

    # ===== SEAL DETAILS =====
    st.markdown("---")
    st.markdown("### Seal Details")

    tanks_seal = ["C1","C2","P1","P2","S1","S2"] if str(design_choice) == "6" else ["P1","P2","S1","S2"]

    _safe_yade = re.sub(r"[^A-Za-z0-9]", "_", str(yade_no))
    _safe_voy  = re.sub(r"[^A-Za-z0-9]", "_", str(voyage_no))
    ns_seal    = f"yseal_{_safe_yade}_{_safe_voy}"

    if "yade_seals" not in st.session_state:
        st.session_state["yade_seals"] = {}

    if ns_seal not in st.session_state["yade_seals"]:
        st.session_state["yade_seals"][ns_seal] = {t: {"mh1":"", "mh2":"", "lock":"", "diph":""} for t in tanks_seal}

    hdr = st.columns([0.10, 0.225, 0.225, 0.225, 0.225])
    hdr[0].markdown("**Tank**")
    hdr[1].markdown("**Manhole-1 Seal No**")
    hdr[2].markdown("**Manhole-2 Seal No**")
    hdr[3].markdown("**Lock No**")
    hdr[4].markdown("**Dip Hatch Seal No**")

    for t in tanks_seal:
        row = st.columns([0.10, 0.225, 0.225, 0.225, 0.225])
        row[0].write(t)
        kbase = f"{ns_seal}_{t}"

        mh1 = row[1].text_input("Manhole-1 Seal No", key=f"{kbase}_mh1",
                                value=st.session_state["yade_seals"][ns_seal][t]["mh1"], label_visibility="collapsed")
        mh2 = row[2].text_input("Manhole-2 Seal No", key=f"{kbase}_mh2",
                                value=st.session_state["yade_seals"][ns_seal][t]["mh2"], label_visibility="collapsed")
        lk  = row[3].text_input("Lock No",            key=f"{kbase}_lock",
                                value=st.session_state["yade_seals"][ns_seal][t]["lock"], label_visibility="collapsed")
        dh  = row[4].text_input("Dip Hatch Seal No",  key=f"{kbase}_diph",
                                value=st.session_state["yade_seals"][ns_seal][t]["diph"], label_visibility="collapsed")

        st.session_state["yade_seals"][ns_seal][t]["mh1"]  = mh1.strip()
        st.session_state["yade_seals"][ns_seal][t]["mh2"]  = mh2.strip()
        st.session_state["yade_seals"][ns_seal][t]["lock"] = lk.strip()
        st.session_state["yade_seals"][ns_seal][t]["diph"] = dh.strip()

    # ---- FINAL Save button at very bottom ----
    st.markdown("---")
    save_key = f"yade_save_btn_{safe_yade}_{safe_voy}"
    # Use floppy‑disk icon for the save action
    save_clicked = st.button("💾 Save YADE Voyage", type="primary", key=save_key, use_container_width=True)

    # ------------ SAVE (bottom) ------------
    if save_clicked:
        errs = []
        if "(No YADE barges" in yade_no:
            errs.append("Please add YADE barges under **Add Asset** and select a valid YADE No.")
        if not only_digits_hyphen(voyage_no):
            errs.append("Voyage number: only digits and '-' allowed.")
        if not only_digits_hyphen(convoy_no):
            errs.append("Convoy number: only digits and '-' allowed.")
        if not hhmm_ok(tx_time) or not hhmm_ok(before_time) or not hhmm_ok(after_time):
            errs.append("All times must be HH:MM (24-hour).")

        if errs:
            for e in errs:
                st.error(e)
        else:
            try:
                tx_time_obj = datetime.strptime(tx_time, "%H:%M").time()
                btime_obj   = datetime.strptime(before_time, "%H:%M").time()
                atime_obj   = datetime.strptime(after_time, "%H:%M").time()
            except Exception:
                st.error("Time parsing failed. Use HH:MM (24-hour).")
                tx_time_obj = btime_obj = atime_obj = None

            if all([tx_time_obj, btime_obj, atime_obj]):
                try:
                    from models import YadeVoyage, YadeDip, YadeSampleParam

                    current_user = (st.session_state.get("auth_user") or {}).get("username", "unknown")

                    with get_session() as s:
                        voy = YadeVoyage(
                            location_id=active_location_id,
                            yade_name=yade_no,
                            design=str(design_choice),
                            voyage_no=voyage_no.strip(),
                            convoy_no=convoy_no.strip(),
                            date=tx_date,
                            time=tx_time_obj,
                            cargo=cargo,
                            destination=destination,
                            loading_berth=loading_berth,
                            before_gauge_date=before_date,
                            before_gauge_time=btime_obj,
                            after_gauge_date=after_date,
                            after_gauge_time=atime_obj,
                            created_by=current_user
                        )
                        s.add(voy)
                        s.flush()

                        # Sample Parameters
                        sp_store = st.session_state.get("yade_sample_params", {})
                        blk = sp_store.get(ns_sp, sp_store)

                        def _upsert_stage_params(stage_key: str):
                            data = blk.get(stage_key, {}) or {
                                "obs_mode": "Observed API",
                                "obs_val": 0.0,
                                "sample_unit": "°F",
                                "sample_temp": 0.0,
                                "tank_temp": 0.0,
                                "ccf": 1.0,
                                "bsw_pct": 0.0,
                            }
                            ex = (
                                s.query(YadeSampleParam)
                                .filter(YadeSampleParam.voyage_id == voy.id,
                                        YadeSampleParam.stage == stage_key)
                                .one_or_none()
                            )
                            if ex is None:
                                ex = YadeSampleParam(voyage_id=voy.id, stage=stage_key)
                                s.add(ex)
                            ex.obs_mode    = str(data.get("obs_mode") or "Observed API")
                            ex.obs_val     = float(data.get("obs_val") or 0.0)
                            ex.sample_unit = str(data.get("sample_unit") or "°F")
                            ex.sample_temp = float(data.get("sample_temp") or 0.0)
                            ex.tank_temp   = float(data.get("tank_temp") or 0.0)
                            ex.ccf         = max(float(data.get("ccf") or 1.0), 0.000001)
                            ex.bsw_pct     = float(data.get("bsw_pct") or 0.0)

                        _upsert_stage_params("before")
                        _upsert_stage_params("after")

                        # Dips
                        for tid in tank_ids:
                            s.add_all([
                                YadeDip(
                                    voyage_id=voy.id,
                                    tank_id=tid,
                                    stage="before",
                                    total_cm=float(st.session_state.get(f"before_total_{tid}", 0.0) or 0.0),
                                    water_cm=float(st.session_state.get(f"before_water_{tid}", 0.0) or 0.0),
                                ),
                                YadeDip(
                                    voyage_id=voy.id,
                                    tank_id=tid,
                                    stage="after",
                                    total_cm=float(st.session_state.get(f"after_total_{tid}", 0.0) or 0.0),
                                    water_cm=float(st.session_state.get(f"after_water_{tid}", 0.0) or 0.0),
                                ),
                            ])

                        # Seal Details
                        if YadeSealDetail is not None:
                            seals_pack = st.session_state.get("yade_seals", {}).get(ns_seal, {}) or {}
                            for_save_tanks = ["C1","C2","P1","P2","S1","S2"] if str(design_choice) == "6" else ["P1","P2","S1","S2"]

                            row = (
                                s.query(YadeSealDetail)
                                .filter(YadeSealDetail.voyage_id == voy.id)
                                .one_or_none()
                            )
                            if row is None:
                                row = YadeSealDetail(voyage_id=voy.id)
                                s.add(row)

                            for t in for_save_tanks:
                                data = seals_pack.get(t, {})
                                k = t.lower()
                                setattr(row, f"{k}_mh1",      (data.get("mh1","") or "").strip())
                                setattr(row, f"{k}_mh2",      (data.get("mh2","") or "").strip())
                                setattr(row, f"{k}_lock",     (data.get("lock","") or "").strip())
                                setattr(row, f"{k}_diphatch", (data.get("diph","") or "").strip())

                        # Compute TOA
                        _persist_toa_from_current_inputs(s, voy, yade_no, tank_ids, ns_sp)

                        s.commit()
                        
                        # Log audit
                        from security import SecurityManager
                        SecurityManager.log_audit(
                            s, current_user, "CREATE",
                            resource_type="YadeVoyage",
                            resource_id=str(voy.id),
                            details=f"Created YADE voyage: {yade_no} - Voyage {voyage_no}",
                            user_id=user.get("id"),
                            location_id=active_location_id
                        )

                    st.success(f"? YADE Voyage saved for {yade_no} � Voyage {voyage_no}")
                    import time
                    time.sleep(1)
                    _st_safe_rerun()

                except Exception as ex:
                    log_error(f"Failed to save YADE voyage: {ex}", exc_info=True)
                    st.error(f"Failed to save YADE Voyage: {ex}")
                    import traceback
                    st.code(traceback.format_exc())

# ========================= YADE TRACKING PAGE =========================

elif page == "Yade Tracking":
    header("Yade Tracking")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()
    
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("Yade Tracking") is False:
                st.caption("Yade Tracking Access: **? Denied**")
                st.stop()
    except Exception:
        pass
    st.markdown("#### Jetty Departure ? Agge Arrival tracker")
    st.caption("Live comparison of YADE voyages captured at Asemoku Jetty, Ndoni, and Agge.")

    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("⚠️ No active location selected. Please pick a location on the Home page.")
        st.stop()

    user = st.session_state.get("auth_user")
    if user:
        from auth import AuthManager

        if not AuthManager.can_access_location(user, active_location_id):
            st.error("🚫 You do not have access to this location.")
            st.stop()
    else:
        user = {}
    user_role = (user or {}).get("role", "operator")

    from permission_manager import PermissionManager

    can_view_tracking = False
    allowed_tracking_locations: List[str] = []
    tracking_meta: Dict[str, Optional[Dict[str, Any]]] = {}
    jetty_rows: List[Dict[str, Any]] = []
    agge_rows: List[Dict[str, Any]] = []
    missing_targets: List[str] = []
    location_name = ""
    location_code = ""
    jetty_keys: List[str] = []
    agge_keys: List[str] = []

    with get_session() as s:
        from location_manager import LocationManager

        loc = LocationManager.get_location_by_id(s, active_location_id)
        if not loc:
            st.error("? Location not found.")
            st.stop()

        location_name = loc.name
        location_code = loc.code
        st.info(f"📍 **Active Location:** {loc.name} ({loc.code})")

        can_view_tracking = PermissionManager.can_access_feature(
            s, active_location_id, "yade_transactions", user_role
        )

        if not can_view_tracking:
            allowed_tracking_locations = PermissionManager.get_allowed_locations_for_feature(
                s, "yade_transactions"
            )
        else:
            tracking_meta = _resolve_yade_tracking_locations(s)
            missing_targets = [
                meta["label"]
                for key, meta in _YADE_TRACKING_TARGETS.items()
                if not tracking_meta.get(key)
            ]
            jetty_keys = [key for key in ("ASEMOKU", "NDONI") if tracking_meta.get(key)]
            jetty_ids = [tracking_meta[key]["id"] for key in jetty_keys]
            agge_keys = ["AGGE"] if tracking_meta.get("AGGE") else []
            agge_ids = [tracking_meta["AGGE"]["id"]] if agge_keys else []
            jetty_rows = _load_yade_tracking_rows(s, jetty_ids)
            agge_rows = _load_yade_tracking_rows(s, agge_ids)

    if not can_view_tracking:
        st.error("🚫 **Access Denied**")
        st.warning(f"**Yade Tracking** is not available at **{location_name or 'this location'}**")
        if allowed_tracking_locations:
            st.info(f"? Available at: **{', '.join(allowed_tracking_locations)}**")
        st.markdown("---")
        st.caption(f"Current Location: **{location_name} ({location_code})**")
        st.caption("Yade Tracking Access: **? Denied**")
        st.stop()

    if missing_targets:
        st.warning(
            "Locations missing from the database: "
            + ", ".join(missing_targets)
            + ". Their YADE voyages will not appear until the locations are configured."
        )

    def _source_labels(keys: List[str]) -> List[str]:
        labels: List[str] = []
        for key in keys:
            meta = tracking_meta.get(key)
            if meta:
                labels.append(meta.get("name") or meta.get("code") or _YADE_TRACKING_TARGETS[key]["label"])
        return labels

    def _render_tracking_table(
        title: str,
        rows: List[Dict[str, Any]],
        key_prefix: str,
        keys: List[str],
        rename_map: Optional[Dict[str, str]] = None,
    ):
        st.markdown(f"### {title}")
        sources = _source_labels(keys)
        if sources:
            st.caption("Data sources: " + ", ".join(sources))
        if not rows:
            st.info("No YADE voyages captured yet.")
            return

        df = pd.DataFrame(rows)
        if df.empty:
            st.info("No YADE voyages captured yet.")
            return

        def _fmt_date_cell(val):
            if isinstance(val, (datetime, date)):
                return val.strftime("%Y-%m-%d")
            if not val:
                return ""
            try:
                return pd.to_datetime(val).date().strftime("%Y-%m-%d")
            except Exception:
                return str(val)

        df["_Date"] = df["Date"].apply(_fmt_date_cell)
        df["_Convoy"] = df["Convoy No"].fillna("").astype(str)
        df["_Yade"] = df["Yade No"].fillna("").astype(str)
        df["_Berth"] = df["Loading berth"].fillna("").astype(str)

        f_cols = st.columns(4)
        date_opts = sorted([d for d in df["_Date"].unique() if d])
        convoy_opts = sorted([c for c in df["_Convoy"].unique() if c])
        yade_opts = sorted([c for c in df["_Yade"].unique() if c])
        berth_opts = sorted([c for c in df["_Berth"].unique() if c])

        selected_dates = f_cols[0].multiselect(
            "Date", options=date_opts, default=[], key=f"{key_prefix}_date"
        )
        selected_convoys = f_cols[1].multiselect(
            "Convoy No", options=convoy_opts, default=[], key=f"{key_prefix}_convoy"
        )
        selected_yades = f_cols[2].multiselect(
            "Yade No", options=yade_opts, default=[], key=f"{key_prefix}_yade"
        )
        selected_berths = f_cols[3].multiselect(
            "Loading berth", options=berth_opts, default=[], key=f"{key_prefix}_berth"
        )

        if selected_dates:
            df = df[df["_Date"].isin(selected_dates)]
        if selected_convoys:
            df = df[df["_Convoy"].isin(selected_convoys)]
        if selected_yades:
            df = df[df["_Yade"].isin(selected_yades)]
        if selected_berths:
            df = df[df["_Berth"].isin(selected_berths)]

        display_df = df[["Date", "Convoy No", "Yade No", "ROB qty", "TOB qty", "Loading berth"]].copy()
        display_df["Date"] = df["_Date"]
        display_df["Convoy No"] = df["_Convoy"]
        display_df["Yade No"] = df["_Yade"]
        display_df["Loading berth"] = df["_Berth"]

        def _fmt_qty(val):
            return f"{val:,.2f}" if val is not None else "�"

        display_df["ROB qty"] = display_df["ROB qty"].apply(_fmt_qty)
        display_df["TOB qty"] = display_df["TOB qty"].apply(_fmt_qty)

        if rename_map:
            display_df.rename(columns=rename_map, inplace=True)

        st.dataframe(
            display_df,
            hide_index=True,
            use_container_width=True,
        )
        st.caption(f"{len(display_df)} voyage(s) shown")

    left, right = st.columns(2)
    with left:
        _render_tracking_table("Jetty Departure", jetty_rows, "yt_track_depart", jetty_keys)
    with right:
        _render_tracking_table(
            "Agge Arrival",
            agge_rows,
            "yt_track_agge",
            agge_keys,
            rename_map={"ROB qty": "TOB qty", "TOB qty": "ROB qty"},
        )

# ========================= TANKER TRANSACTIONS PAGE =========================

elif page == "Tanker Transactions":
    header("Tanker Transactions")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()
    
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("Tanker Transactions") is False:
                st.error("🚫 Tanker Transactions page is disabled for this location.")
                st.stop()
    except Exception:
        pass
    st.markdown("#### Record Tanker Dispatches")
    
    # ============ LOCATION ACCESS CHECK ============
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("⚠️ No active location selected.")
        st.stop()
    
    user = st.session_state.get("auth_user")
    if user:
        from auth import AuthManager
        if not AuthManager.can_access_location(user, active_location_id):
            st.error("🚫 You do not have access to this location.")
            st.stop()
    
    # ========== CHECK PERMISSIONS ==========
    from permission_manager import PermissionManager
    
    with get_session() as s:
        from location_manager import LocationManager
        
        # Get location info
        loc = LocationManager.get_location_by_id(s, active_location_id)
        if not loc:
            st.error("? Location not found.")
            st.stop()
        
        st.info(f"📍 **Active Location:** {loc.name} ({loc.code})")

        # Apply location-based page visibility: hide page if disabled in config (non-admin)
        try:
            with get_session() as _s_cfg:
                from location_config import LocationConfig
                _cfg = LocationConfig.get_config(_s_cfg, active_location_id)
            if not _cfg.get("page_visibility", {}).get("show_tanker_transactions", False) and (user.get("role", "").lower() not in ["admin-operations", "manager"]):
                st.error("🚫 Tanker Transactions page is disabled for this location.")
                st.stop()
        except Exception:
            pass
        
        # Check if feature is allowed at this location (Admin can access everywhere)
        if not PermissionManager.can_access_feature(s, active_location_id, "tanker_transactions", user["role"]):
            st.error("🚫 **Access Denied**")
            st.warning(f"**Tanker Transactions** are not available at **{loc.name}**")
            
            # Show where it's available
            allowed_locs = PermissionManager.get_allowed_locations_for_feature(s, "tanker_transactions")
            if allowed_locs:
                st.info(f"? This feature is available at: **{', '.join(allowed_locs)}**")
            
            st.markdown("---")
            st.caption(f"Current Location: **{loc.name} ({loc.code})**")
            st.caption("Tanker Transactions Access: **? Denied**")
            st.stop()
        
        # Check if user can make entries
        can_make_entries = PermissionManager.can_make_entries(s, user["role"], active_location_id)
    
    # ============ TANKER ENABLED - SHOW SUCCESS ============
    st.success(f"? Tanker Transactions enabled at {loc.name}")
    
    # ============ HELPER FUNCTIONS ============
    
    def interpolate_tanker_volume(session, tanker_name: str, compartment: str, dip_mm: float) -> float:
        """Linear interpolation for tanker volume from calibration data"""
        from models import TankerCalibration
        
        cal_data = session.query(TankerCalibration).filter(
            TankerCalibration.tanker_name == tanker_name,
            TankerCalibration.compartment == compartment
        ).order_by(TankerCalibration.dip_mm.asc()).all()
        
        if not cal_data:
            return 0.0
        
        xs = [float(c.dip_mm) for c in cal_data]
        ys = [float(c.volume_litres) for c in cal_data]
        
        if dip_mm <= xs[0]:
            return ys[0]
        if dip_mm >= xs[-1]:
            return ys[-1]
        
        import bisect
        i = bisect.bisect_left(xs, dip_mm)
        x1, y1 = xs[i-1], ys[i-1]
        x2, y2 = xs[i], ys[i]
        
        if x2 == x1:
            return y1
        
        t = (dip_mm - x1) / (x2 - x1)
        return y1 + t * (y2 - y1)
    
    # Temperature conversion helpers
    def c_to_f(c: float) -> float:
        if c is None: return 0.0
        return round((float(c) * 1.8) + 32.0, 1)

    def f_to_c(f: float) -> float:
        if f is None: return 0.0
        return round((float(f) - 32.0) / 1.8, 1)
    
    def _to_f(val: float, unit: str) -> float:
        """Return °F from val given unit ('°F' or '°C')."""
        return c_to_f(val) if unit.upper().startswith("C") else float(val or 0.0)

    def _to_c(val: float, unit: str) -> float:
        """Return °C from val given unit ('°F' or '°C')."""
        return f_to_c(val) if unit.upper().startswith("F") else float(val or 0.0)
    
    # API/Density conversion
    WAT60 = 999.012
    
    def api_from_density(density: float) -> float:
        if not density or density <= 0: return 0.0
        sg = float(density) / WAT60
        if sg <= 0: return 0.0
        return round(141.5 / sg - 131.5, 2)
    
    def density_from_api(api: float) -> float:
        if not api or api <= 0: return 0.0
        sg = 141.5 / (float(api) + 131.5)
        return round(sg * WAT60, 1)
    
    def convert_api_to_60_from_api(api_obs: float, sample_temp_val: float, temp_unit: str) -> float:
        """Your VBA (10 trials). Temp is ALWAYS °F internally."""
        if api_obs is None or api_obs <= 0:
            return 0.0
        tf = _to_f(sample_temp_val or 0.0, temp_unit)
        temp_diff = tf - 60.0
        rho_obs = (141.5 * WAT60 / (131.5 + float(api_obs))) * (
            (1.0 - 0.00001278 * temp_diff) - (0.0000000062 * temp_diff * temp_diff)
        )
        rho = rho_obs
        for _ in range(10):
            alfa = 341.0957 / (rho * rho)
            vcf  = math.exp(-alfa * temp_diff - 0.8 * alfa * alfa * temp_diff * temp_diff)
            rho  = rho_obs / vcf
        api60 = 141.5 * WAT60 / rho - 131.5
        return round(api60, 2)

    def convert_api_to_60_from_density(dens_obs_kgm3: float, sample_temp_val: float, temp_unit: str) -> float:
        """Density path (17 trials). Temp is ALWAYS °C internally."""
        if dens_obs_kgm3 is None or dens_obs_kgm3 <= 0:
            return 0.0
        tc = _to_c(sample_temp_val or 0.0, temp_unit)
        temp_diff = tc - 15.0
        
        # Hydrometer correction
        hyc = 1.0 - 0.000023 * temp_diff - 0.00000002 * temp_diff * temp_diff
        rho_obs_corrected = float(dens_obs_kgm3) * hyc
        
        # Initial density at 15°C
        rho15 = rho_obs_corrected
        
        # Iterative VCF calculation (17 iterations)
        for _ in range(17):
            K = 613.9723 / (rho15 * rho15)
            vcf = math.exp(-K * temp_diff * (1.0 + 0.8 * K * temp_diff))
            rho15 = rho_obs_corrected / vcf
        
        sg60 = rho15 / WAT60
        if sg60 <= 0:
            return 0.0
        
        api60 = 141.5 / sg60 - 131.5
        return round(api60, 2)

    def vcf_from_api60_and_temp(api60: float, tank_temp: float, tank_temp_unit: str, input_mode: str = "api") -> float:
        """Calculate VCF using ASTM D1250 Table 6A method"""
        if api60 is None or api60 <= 0:
            return 1.00000
        
        if tank_temp_unit == "°C":
            tank_temp_f = (tank_temp * 1.8) + 32.0
        else:
            tank_temp_f = tank_temp
        
        delta_t = tank_temp_f - 60.0
        
        if abs(delta_t) < 0.01:
            return 1.00000
        
        sg60 = 141.5 / (api60 + 131.5)
        rho60 = sg60 * 999.012
        
        K0 = 341.0957
        alpha = K0 / (rho60 * rho60)
        
        vcf = math.exp(-alpha * delta_t * (1.0 + 0.8 * alpha * delta_t))
        
        return round(float(vcf), 5)
    
    # LT lookup from ASTM Table 11
    def lookup_lt(session, api60: float) -> float:
        from models import Table11
        
        rows = session.query(Table11).order_by(Table11.api60).all()
        if not rows:
            return 0.0
        
        xs = [float(r.api60) for r in rows]
        ys = [float(r.lt_factor) for r in rows]
        
        if api60 <= xs[0]:
            return ys[0]
        if api60 >= xs[-1]:
            return ys[-1]
        
        import bisect
        i = bisect.bisect_left(xs, api60)
        x1, y1 = xs[i-1], ys[i-1]
        x2, y2 = xs[i], ys[i]
        
        if x2 == x1:
            return y1
        
        t = (api60 - x1) / (x2 - x1)
        return y1 + t * (y2 - y1)
    
    # ============ GET TANKERS ============
    from models import Tanker
    with get_session() as s:
        tankers = s.query(Tanker).filter(
            Tanker.status == "ACTIVE"
        ).order_by(Tanker.name).all()
    
    if not tankers:
        # Show warning with appropriate icon and arrow
        st.warning("⚠️ No tankers available. Please add tankers in Add Asset → Tanker Master.")
        st.stop()
    
    tanker_names = [t.name for t in tankers]
    
    # ==================== VIEW SAVED TANKER TRANSACTIONS ====================
    st.markdown("---")
    # Section header with clipboard icon
    st.markdown("### 📋 Saved Tanker Transactions")

    try:
        with get_session() as s:
            # Get recent tanker transactions for this location
            transactions = s.query(TankerTransaction).filter(
                TankerTransaction.location_id == active_location_id
            ).order_by(
                TankerTransaction.transaction_date.desc(),
                TankerTransaction.transaction_time.desc()
            ).limit(50).all()

            if not transactions:
                # Mailbox icon when there are no records
                st.info("📭 No tanker transactions found. Create your first transaction below!")
            else:
                # Create dropdown options
                tx_options = {}
                for tx in transactions:
                    label = f"{tx.tanker_name} | Convoy: {tx.convoy_no} | {tx.transaction_date.strftime('%Y-%m-%d')} | {tx.destination}"
                    tx_options[label] = tx.id
                
                # Dropdown selector
                col1, col2 = st.columns([0.7, 0.3])
                
                with col1:
                    selected_tx_label = st.selectbox(
                        "🔍 Select Tanker Transaction to View",
                        options=list(tx_options.keys()),
                        key="tanker_tx_selector"
                    )
                
                with col2:
                    view_tx_details = st.button("👁️ View Details", use_container_width=True, key="view_tanker_details_btn")
                
                selected_tx_id = tx_options[selected_tx_label]
                
                # VIEW DETAILS
                if view_tx_details or st.session_state.get("show_tanker_details", False):
                    st.session_state["show_tanker_details"] = True
                    
                    tx = s.query(TankerTransaction).filter(TankerTransaction.id == selected_tx_id).first()

                    if tx:
                        st.markdown("---")
                        # Heading with tanker icon
                        st.markdown(f"#### 🚚 Tanker Transaction - {tx.tanker_name}")

                        ns = "tanker" + hashlib.md5(str(tx.id).encode("utf-8")).hexdigest()[:8]
                        is_editing = (
                            st.session_state.get("tanker_edit_mode", False)
                            and st.session_state.get("tanker_edit_id") == tx.id
                        )

                        action_cols = st.columns([0.7, 0.3])
                        with action_cols[0]:
                            if not is_editing:
                                if st.button("✏️ Edit", key=f"{ns}_edit_btn", help="Edit this tanker transaction"):
                                    if not _deny_edit_for_lock(tx, "TankerTransaction", f"{tx.ticket_id or tx.id}"):
                                        st.session_state["tanker_edit_mode"] = True
                                        st.session_state["tanker_edit_id"] = tx.id
                                        _st_safe_rerun()
                        with action_cols[1]:
                            if st.button("↩️ Close Viewer", key=f"{ns}_close_btn"):
                                st.session_state.pop("show_tanker_details", None)
                                st.session_state.pop("tanker_edit_mode", None)
                                st.session_state.pop("tanker_edit_id", None)
                                _st_safe_rerun()

                        # Basic Info
                        info_col1, info_col2, info_col3 = st.columns(3)
                        
                        with info_col1:
                            st.metric("Tanker Name", tx.tanker_name)
                            st.metric("Chassis No", tx.chassis_no or "N/A")
                            st.metric("Convoy No", tx.convoy_no)
                        
                        with info_col2:
                            st.metric("Date", tx.transaction_date.strftime("%Y-%m-%d"))
                            st.metric("Time", str(tx.transaction_time))
                            st.metric("Cargo", tx.cargo)
                        
                        with info_col3:
                            st.metric("Destination", tx.destination)
                            st.metric("Loading Bay", tx.loading_bay or "N/A")
                            st.metric("Compartment", f"{tx.compartment} (via {tx.manhole})")
                        
                        # Dip Readings
                        st.markdown("##### 📏 Dip Readings")
                        dip_col1, dip_col2 = st.columns(2)
                        
                        with dip_col1:
                            st.metric("Total Dip (cm)", f"{tx.total_dip_cm:.2f}")
                            st.metric("Total Dip (mm)", f"{tx.total_dip_mm:.2f}")
                        
                        with dip_col2:
                            st.metric("Water Dip (cm)", f"{tx.water_dip_cm:.2f}")
                            st.metric("Water Dip (mm)", f"{tx.water_dip_mm:.2f}")
                        
                        # Temperatures
                        st.markdown("##### 🌡️ Temperatures")
                        temp_col1, temp_col2, temp_col3, temp_col4 = st.columns(4)
                        
                        with temp_col1:
                            st.metric("Tank Temp (°C)", f"{tx.tank_temp_c:.2f}" if tx.tank_temp_c else "N/A")
                        
                        with temp_col2:
                            st.metric("Tank Temp (°F)", f"{tx.tank_temp_f:.2f}" if tx.tank_temp_f else "N/A")
                        
                        with temp_col3:
                            st.metric("Sample Temp (°C)", f"{tx.sample_temp_c:.2f}" if tx.sample_temp_c else "N/A")
                        
                        with temp_col4:
                            st.metric("Sample Temp (°F)", f"{tx.sample_temp_f:.2f}" if tx.sample_temp_f else "N/A")
                        
                        # Volume Calculations
                        st.markdown("##### 📊 Volume Calculations")
                        vol_col1, vol_col2, vol_col3 = st.columns(3)
                        
                        with vol_col1:
                            st.metric("Total Volume", f"{tx.total_volume_bbl:,.2f} bbls")
                            st.metric("GOV", f"{tx.gov_bbl:,.2f} bbls")
                            st.metric("GSV", f"{tx.gsv_bbl:,.2f} bbls")
                        
                        with vol_col2:
                            st.metric("Water Volume", f"{tx.water_volume_bbl:,.2f} bbls")
                            st.metric("BS&W %", f"{tx.bsw_pct:.2f}%")
                            st.metric("BS&W Volume", f"{tx.bsw_vol_bbl:,.2f} bbls")
                        
                        with vol_col3:
                            st.metric("NSV", f"{tx.nsv_bbl:,.2f} bbls")
                            st.metric("API@60", f"{tx.api60:.2f}" if tx.api60 else "N/A")
                            st.metric("VCF", f"{tx.vcf:.4f}" if tx.vcf else "N/A")
                        
                        # Additional Metrics
                        st.markdown("##### 📐 Additional Calculations")
                        add_col1, add_col2, add_col3 = st.columns(3)
                        
                        with add_col1:
                            st.metric("LT Factor", f"{tx.lt:.4f}" if tx.lt else "N/A")
                        
                        with add_col2:
                            lt_val = tx.nsv_bbl * tx.lt if tx.lt else 0
                            st.metric("LT (Long Tons)", f"{lt_val:,.2f}")
                        
                        with add_col3:
                            st.metric("MT (Metric Tons)", f"{tx.mt:,.2f}" if tx.mt else "N/A")
                        
                        # Seal Numbers
                        st.markdown("##### 🔐 Seal Numbers")
                        seal_col1, seal_col2, seal_col3, seal_col4 = st.columns(4)
                        
                        with seal_col1:
                            st.caption(f"**C1:** {tx.seal_c1 or 'N/A'}")
                        
                        with seal_col2:
                            st.caption(f"**C2:** {tx.seal_c2 or 'N/A'}")
                        
                        with seal_col3:
                            st.caption(f"**M1:** {tx.seal_m1 or 'N/A'}")
                        
                        with seal_col4:
                            st.caption(f"**M2:** {tx.seal_m2 or 'N/A'}")
                        
                        # Remarks
                        if tx.remarks:
                            st.markdown("##### 📝 Remarks")
                            st.info(tx.remarks)
                        
                        # Audit Info
                        st.markdown("##### 📋 Audit Trail")
                        audit_col1, audit_col2 = st.columns(2)
                        
                        with audit_col1:
                            st.caption(f"**Created By:** {tx.created_by}")
                            st.caption(f"**Created At:** {tx.created_at.strftime('%Y-%m-%d %H:%M:%S')}" if tx.created_at else "N/A")
                        
                        with audit_col2:
                            if tx.updated_by:
                                st.caption(f"**Updated By:** {tx.updated_by}")
                                st.caption(f"**Updated At:** {tx.updated_at.strftime('%Y-%m-%d %H:%M:%S')}" if tx.updated_at else "N/A")

                        if is_editing:
                            st.markdown("#### ✏️ Update Measurements")
                            with st.form(f"{ns}_edit_form"):
                                dip_col_edit1, dip_col_edit2 = st.columns(2)
                                with dip_col_edit1:
                                    edit_total_dip_cm = st.number_input(
                                        "Total Dip (cm)",
                                        min_value=0.0,
                                        value=float(tx.total_dip_cm or 0.0),
                                        step=0.1,
                                        key=f"{ns}_edit_total_dip_cm",
                                    )
                                    edit_water_dip_cm = st.number_input(
                                        "Water Dip (cm)",
                                        min_value=0.0,
                                        value=float(tx.water_dip_cm or 0.0),
                                        step=0.1,
                                        key=f"{ns}_edit_water_dip_cm",
                                    )
                                    edit_bsw_pct = st.number_input(
                                        "BS&W %",
                                        min_value=0.0,
                                        value=float(tx.bsw_pct or 0.0),
                                        step=0.01,
                                        key=f"{ns}_edit_bsw_pct",
                                    )
                                with dip_col_edit2:
                                    edit_api_obs = _bounded_number_input(
                                        "Observed API",
                                        key=f"{ns}_edit_api_obs",
                                        min_value=API_MIN,
                                        max_value=API_MAX,
                                        value=float(tx.api_observed or 0.0),
                                        step=0.1,
                                    )
                                    edit_density_obs = _bounded_number_input(
                                        "Observed Density (kg/m3)",
                                        key=f"{ns}_edit_density_obs",
                                        min_value=DENSITY_MIN,
                                        max_value=DENSITY_MAX,
                                        value=float(tx.density_observed or 0.0),
                                        step=0.1,
                                    )

                                temp_cols_edit = st.columns(4)
                                with temp_cols_edit[0]:
                                    edit_tank_temp_c = _temperature_input(
                                        "Tank Temp (°C)",
                                        "°C",
                                        key=f"{ns}_edit_tank_temp_c",
                                        value=float(tx.tank_temp_c or 0.0),
                                    )
                                with temp_cols_edit[1]:
                                    edit_tank_temp_f = _temperature_input(
                                        "Tank Temp (°F)",
                                        "°F",
                                        key=f"{ns}_edit_tank_temp_f",
                                        value=float(tx.tank_temp_f or 0.0),
                                    )
                                with temp_cols_edit[2]:
                                    edit_sample_temp_c = _temperature_input(
                                        "Sample Temp (°C)",
                                        "°C",
                                        key=f"{ns}_edit_sample_temp_c",
                                        value=float(tx.sample_temp_c or 0.0),
                                    )
                                with temp_cols_edit[3]:
                                    edit_sample_temp_f = _temperature_input(
                                        "Sample Temp (°F)",
                                        "°F",
                                        key=f"{ns}_edit_sample_temp_f",
                                        value=float(tx.sample_temp_f or 0.0),
                                    )

                                edit_remarks = st.text_area(
                                    "Remarks",
                                    value=tx.remarks or "",
                                    key=f"{ns}_edit_remarks",
                                )

                                # Use floppy disk icon for saving changes
                                save_tanker_edit = st.form_submit_button("💾 Save Changes", type="primary")

                            if st.button("✖️ Cancel edit", key=f"{ns}_cancel_edit"):
                                st.session_state.pop("tanker_edit_mode", None)
                                st.session_state.pop("tanker_edit_id", None)
                                _st_safe_rerun()

                            if save_tanker_edit:
                                if edit_total_dip_cm <= 0:
                                    st.error("Total Dip must be greater than zero.")
                                elif edit_api_obs <= 0 and edit_density_obs <= 0:
                                    st.error("Please provide either Observed API or Density.")
                                else:
                                    try:
                                        from datetime import datetime as dt_now

                                        total_dip_mm_val = edit_total_dip_cm * 10.0
                                        water_dip_mm_val = edit_water_dip_cm * 10.0

                                        with get_session() as s_update:
                                            db_tx = s_update.query(TankerTransaction).filter(TankerTransaction.id == tx.id).one_or_none()
                                            if not db_tx:
                                                raise ValueError("Transaction not found.")

                                            total_vol_litres = interpolate_tanker_volume(s_update, db_tx.tanker_name, db_tx.compartment, total_dip_mm_val)
                                            water_vol_litres = interpolate_tanker_volume(s_update, db_tx.tanker_name, db_tx.compartment, water_dip_mm_val)

                                            total_vol_bbl = total_vol_litres / 158.987
                                            water_vol_bbl = water_vol_litres / 158.987
                                            gov_bbl = max(total_vol_bbl - water_vol_bbl, 0.0)

                                            sample_temp_c_calc = edit_sample_temp_c or ((edit_sample_temp_f - 32.0) / 1.8 if edit_sample_temp_f else 0.0)
                                            sample_temp_f_calc = edit_sample_temp_f or ((edit_sample_temp_c * 1.8) + 32.0 if edit_sample_temp_c else 0.0)
                                            tank_temp_c_calc = edit_tank_temp_c or ((edit_tank_temp_f - 32.0) / 1.8 if edit_tank_temp_f else 0.0)

                                            if edit_api_obs > 0:
                                                api60 = convert_api_to_60_from_api(edit_api_obs, sample_temp_f_calc or 60.0, "°F")
                                                input_mode = "api"
                                            else:
                                                api60 = convert_api_to_60_from_density(edit_density_obs, sample_temp_c_calc or 15.0, "°C")
                                                input_mode = "density"

                                            vcf_val = vcf_from_api60_and_temp(api60, tank_temp_c_calc or 60.0, "°C", input_mode)
                                            gsv_bbl = round(gov_bbl * vcf_val, 2)
                                            bsw_vol_bbl = round(gsv_bbl * (edit_bsw_pct / 100.0), 2)
                                            nsv_bbl = round(gsv_bbl - bsw_vol_bbl, 2)
                                            lt_factor = lookup_lt(s_update, api60) if api60 > 0 else 0.0
                                            lt_val = round(nsv_bbl * lt_factor, 2)
                                            mt_val = round(lt_val * 1.01605, 2)

                                            editor_name = (st.session_state.get("auth_user") or {}).get("username", "unknown")

                                            db_tx.total_dip_cm = edit_total_dip_cm
                                            db_tx.total_dip_mm = total_dip_mm_val
                                            db_tx.water_dip_cm = edit_water_dip_cm
                                            db_tx.water_dip_mm = water_dip_mm_val
                                            db_tx.tank_temp_c = edit_tank_temp_c
                                            db_tx.tank_temp_f = edit_tank_temp_f
                                            db_tx.sample_temp_c = edit_sample_temp_c
                                            db_tx.sample_temp_f = edit_sample_temp_f
                                            db_tx.api_observed = edit_api_obs
                                            db_tx.density_observed = edit_density_obs
                                            db_tx.bsw_pct = edit_bsw_pct
                                            db_tx.total_volume_bbl = float(round(total_vol_bbl, 3))
                                            db_tx.water_volume_bbl = float(round(water_vol_bbl, 3))
                                            db_tx.gov_bbl = float(round(gov_bbl, 3))
                                            db_tx.api60 = float(api60)
                                            db_tx.vcf = float(vcf_val)
                                            db_tx.gsv_bbl = float(gsv_bbl)
                                            db_tx.bsw_vol_bbl = float(bsw_vol_bbl)
                                            db_tx.nsv_bbl = float(nsv_bbl)
                                            db_tx.lt = float(lt_factor)
                                            db_tx.mt = float(mt_val)
                                            db_tx.remarks = edit_remarks.strip() if edit_remarks else None
                                            db_tx.updated_by = editor_name
                                            db_tx.updated_at = dt_now.now()

                                            s_update.commit()
                                            # ----------------------- Audit log for tanker transaction update -----------------------
                                            try:
                                                from security import SecurityManager  # type: ignore
                                                user_ctx = st.session_state.get("auth_user") or {}
                                                username = user_ctx.get("username", "unknown")
                                                user_id = user_ctx.get("id")
                                                location_id = active_location_id
                                                # Determine resource ID using DB primary key if available; fallback to tanker name & convoy number
                                                res_id = str(getattr(db_tx, "id", "")) or f"{getattr(db_tx, 'tanker_name', '')}-{getattr(db_tx, 'convoy_no', '')}"
                                                SecurityManager.log_audit(
                                                    None,
                                                    username,
                                                    "UPDATE",
                                                    resource_type="TankerTransaction",
                                                    resource_id=res_id,
                                                    details=f"Updated tanker transaction {res_id}",
                                                    user_id=user_id,
                                                    location_id=location_id,
                                                )
                                            except Exception:
                                                pass

                                        st.success("? Tanker transaction updated.")
                                        st.session_state.pop("tanker_edit_mode", None)
                                        st.session_state.pop("tanker_edit_id", None)
                                        _st_safe_rerun()
                                    except Exception as ex:
                                        log_error(f"Tanker edit failed: {ex}", exc_info=True)
                                        st.error(f"Failed to update tanker transaction: {ex}")

                        # Close button
                        if st.button("? Close Details", key="close_tanker_details"):
                            st.session_state.pop("show_tanker_details", None)
                            st.session_state.pop("tanker_edit_mode", None)
                            st.session_state.pop("tanker_edit_id", None)
                            _st_safe_rerun()

    except Exception as ex:
        st.error(f"? Failed to load transactions: {ex}")
        import traceback
        st.code(traceback.format_exc())

    st.markdown("---")
    
    # ============ TANKER TRANSACTION FORM ============
    st.markdown("### Add New Tanker Transaction")
    
    with st.form("tanker_transaction_form"):
        # -------- TOP METADATA --------
        st.markdown("#### Metadata")
        
        meta_col1, meta_col2, meta_col3 = st.columns(3)
        
        with meta_col1:
            tanker_name = st.selectbox("Tanker Name/ID *", tanker_names, key="tanker_name")
            chassis_no = st.text_input("Chassis Number", placeholder="e.g., CH-12345", key="chassis_no")
        
        with meta_col2:
            convoy_no = st.text_input("Convoy Number *", placeholder="e.g., CVY-001", key="convoy_no")
            from datetime import date
            tx_date = st.date_input("Date *", value=date.today(), key="tanker_date")
        
        with meta_col3:
            cargo = st.selectbox(
                "Cargo *",
                options=["OKW", "ANZ", "CONDENSATE", "CRUDE"],
                key="tanker_cargo"
            )
            tx_time_str = st.text_input("Time * (HH:MM)", value="08:00", key="tanker_time")
        
        meta_col4, meta_col5 = st.columns(2)
        
        with meta_col4:
            destination = st.selectbox(
                "Destination *",
                options=["Aggu", "OFS", "Ogini", "GPP", "Ndoni", "Other"],
                key="tanker_destination"
            )
        
        with meta_col5:
            loading_bay = st.selectbox(
                "Loading Bay",
                options=["Aggu", "Ogini", "OFS", "N/A"],
                key="tanker_loading_bay"
            )
        
        st.markdown("---")
        
        # -------- MANHOLE SELECTOR --------
        st.markdown("#### Compartment")
        
        manhole = st.selectbox(
            "Manhole (Dip Reading Point) *",
            options=["C1", "C2"],
            key="manhole_selector",
            help="Select which manhole was used to take the dip reading"
        )
        
        compartment = manhole
        
        st.caption(f"📍 Selected Manhole: {manhole}")
        
        st.markdown("---")
        
        # -------- DIP READINGS --------
        st.markdown("#### Dip Readings")
        
        dip_col1, dip_col2 = st.columns(2)
        
        with dip_col1:
            total_dip_cm = st.number_input(
                "Total Dip (cm) *",
                min_value=0.0,
                step=0.1,
                key="total_dip_cm"
            )
        
        with dip_col2:
            water_dip_cm = st.number_input(
                "Water Dip (cm) *",
                min_value=0.0,
                step=0.1,
                key="water_dip_cm"
            )
        
        # Show quick volume preview
        total_dip_mm = total_dip_cm * 10
        water_dip_mm = water_dip_cm * 10
        
        with get_session() as s:
            total_vol_litres = interpolate_tanker_volume(s, tanker_name, compartment, total_dip_mm)
            water_vol_litres = interpolate_tanker_volume(s, tanker_name, compartment, water_dip_mm)
        
        total_vol_bbl = total_vol_litres / 158.987
        water_vol_bbl = water_vol_litres / 158.987
        gov_bbl = max(total_vol_bbl - water_vol_bbl, 0.0)
        
        st.caption(f"💧 Quick Check: GOV ≈ {gov_bbl:,.2f} bbls")
        
        # -------- BS&W % --------
        bsw_pct = st.number_input(
            "BS&W % *",
            min_value=0.0,
            max_value=100.0,
            step=0.01,
            value=0.0,
            key="tanker_bsw_pct"
        )
        
        st.markdown("---")
        
        # -------- TEMPERATURE READINGS --------
        st.markdown("#### Temperature Readings")
        
        temp_col1, temp_col2 = st.columns(2)
        
        with temp_col1:
            st.markdown("##### Tank Temperature")
            tank_temp_unit = st.selectbox("Unit", ["°C", "°F"], index=0, key="tank_temp_unit")
            tank_temp_val = _temperature_input(
                f"Temperature ({tank_temp_unit})",
                tank_temp_unit,
                "tank_temp_val",
            )
            
            if tank_temp_unit == "°C":
                tank_temp_c = tank_temp_val
                tank_temp_f = c_to_f(tank_temp_val)
            else:
                tank_temp_f = tank_temp_val
                tank_temp_c = f_to_c(tank_temp_val)
        
        with temp_col2:
            st.markdown("##### Sample Temperature")
            sample_temp_unit = st.selectbox("Unit", ["°F", "°C"], index=0, key="sample_temp_unit")
            sample_temp_val = _temperature_input(
                f"Temperature ({sample_temp_unit})",
                sample_temp_unit,
                "sample_temp_val",
            )
            
            if sample_temp_unit == "°C":
                sample_temp_c = sample_temp_val
                sample_temp_f = c_to_f(sample_temp_val)
            else:
                sample_temp_f = sample_temp_val
                sample_temp_c = f_to_c(sample_temp_val)
        
        st.markdown("---")
        
        # -------- OBSERVED PROPERTY --------
        st.markdown("#### Quality Parameters")
        
        obs_col1, obs_col2 = st.columns([0.3, 0.7])
        
        with obs_col1:
            obs_mode = st.selectbox(
                "Input Type",
                options=["Observed API", "Observed Density"],
                index=0,
                key="obs_mode"
            )
        
        with obs_col2:
            if obs_mode == "Observed API":
                api_observed = _bounded_number_input(
                    "Observed API *",
                    "api_obs",
                    API_MIN,
                    API_MAX,
                )
                density_observed = density_from_api(api_observed) if api_observed > 0 else 0.0
                st.caption(f"? Density: {density_observed:.2f} kg/m3")
            else:
                density_observed = _bounded_number_input(
                    "Observed Density (kg/m3) *",
                    "density_obs",
                    DENSITY_MIN,
                    DENSITY_MAX,
                )
                api_observed = api_from_density(density_observed) if density_observed > 0 else 0.0
                st.caption(f"? API: {api_observed:.2f}")
        
        st.markdown("---")
        
        # -------- SEAL NUMBERS --------
        st.markdown("#### Seal Numbers")
        
        seal_col1, seal_col2, seal_col3, seal_col4 = st.columns(4)
        
        with seal_col1:
            seal_c1 = st.text_input("C1", placeholder="SC1-12345", key="seal_c1")
        
        with seal_col2:
            seal_c2 = st.text_input("C2", placeholder="SC2-12345", key="seal_c2")
        
        with seal_col3:
            seal_m1 = st.text_input("M1", placeholder="SM1-12345", key="seal_m1")
        
        with seal_col4:
            seal_m2 = st.text_input("M2", placeholder="SM2-12345", key="seal_m2")
        
        st.markdown("---")
        
        # -------- REMARKS --------
        remarks = st.text_area("Remarks (Optional)", key="tanker_remarks")
        
        # -------- SUBMIT BUTTON --------
        submit = st.form_submit_button("💾 Save Tanker Transaction", type="primary", use_container_width=True)
        
        if submit:
            # Validate time
            try:
                from datetime import datetime
                import math
                tx_time_obj = datetime.strptime(tx_time_str, "%H:%M").time()
            except:
                st.error("Invalid time format. Use HH:MM (24-hour)")
                tx_time_obj = None
            
            # Validate required fields
            errors = []
            if not convoy_no.strip():
                errors.append("Convoy Number is required")
            if total_dip_cm <= 0:
                errors.append("Total dip must be greater than 0")
            if api_observed <= 0 and density_observed <= 0:
                errors.append("Either API or Density must be provided")
            
            if errors:
                for err in errors:
                    st.error(f"? {err}")
            elif tx_time_obj:
                try:
                    # Calculate API@60
                    if obs_mode == "Observed API":
                        api60 = convert_api_to_60_from_api(
                            api_observed, 
                            sample_temp_val, 
                            sample_temp_unit
                        )
                    else:
                        api60 = convert_api_to_60_from_density(
                            density_observed, 
                            sample_temp_val, 
                            sample_temp_unit
                        )
                    
                    # Calculate VCF
                    input_mode = "density" if obs_mode == "Observed Density" else "api"
                    vcf_val = vcf_from_api60_and_temp(api60, tank_temp_val, tank_temp_unit, input_mode)
                    
                    # Calculate volumes
                    gsv_bbl = gov_bbl * vcf_val
                    bsw_vol_bbl = gsv_bbl * (bsw_pct / 100.0)
                    nsv_bbl = gsv_bbl - bsw_vol_bbl
                    
                    # Get LT Factor
                    with get_session() as s:
                        lt = lookup_lt(s, api60)
                    
                    # Calculate LT and MT
                    lt_val = nsv_bbl * lt
                    mt_val = lt_val * 1.01605
                    
                    # Save transaction
                    from models import TankerTransaction
                    
                    with get_session() as s:
                        new_tx = TankerTransaction(
                            location_id=active_location_id,
                            tanker_name=tanker_name,
                            chassis_no=chassis_no.strip() if chassis_no else None,
                            convoy_no=convoy_no.strip(),
                            transaction_date=tx_date,
                            transaction_time=tx_time_obj,
                            cargo=cargo,
                            destination=destination,
                            loading_bay=loading_bay if loading_bay != "N/A" else None,
                            compartment=compartment,
                            manhole=manhole,
                            total_dip_cm=float(total_dip_cm),
                            total_dip_mm=float(total_dip_mm),
                            water_dip_cm=float(water_dip_cm),
                            water_dip_mm=float(water_dip_mm),
                            tank_temp_c=float(tank_temp_c),
                            tank_temp_f=float(tank_temp_f),
                            sample_temp_c=float(sample_temp_c),
                            sample_temp_f=float(sample_temp_f),
                            api_observed=float(api_observed),
                            density_observed=float(density_observed),
                            bsw_pct=float(bsw_pct),
                            total_volume_bbl=float(total_vol_bbl),
                            water_volume_bbl=float(water_vol_bbl),
                            gov_bbl=float(gov_bbl),
                            api60=float(api60),
                            vcf=float(vcf_val),
                            gsv_bbl=float(gsv_bbl),
                            bsw_vol_bbl=float(bsw_vol_bbl),
                            nsv_bbl=float(nsv_bbl),
                            lt=float(lt),
                            mt=float(mt_val),
                            seal_c1=seal_c1.strip() if seal_c1 else None,
                            seal_c2=seal_c2.strip() if seal_c2 else None,
                            seal_m1=seal_m1.strip() if seal_m1 else None,
                            seal_m2=seal_m2.strip() if seal_m2 else None,
                            remarks=remarks.strip() if remarks else None,
                            created_by=user["username"]
                        )
                        
                        s.add(new_tx)
                        s.commit()
                        
                        st.success(f"? Saved! NSV: {nsv_bbl:,.2f} bbls | MT: {mt_val:,.2f}")
                        
                        # Log audit
                        from security import SecurityManager
                        SecurityManager.log_audit(
                            s, user["username"], "CREATE",
                            resource_type="TankerTransaction",
                            resource_id=f"{tanker_name}-{convoy_no}",
                            details=f"Tanker dispatch: {nsv_bbl:.2f} bbls",
                            user_id=user["id"],
                            location_id=active_location_id
                        )
                        
                        import time
                        time.sleep(1)
                        _st_safe_rerun()
                        
                except Exception as ex:
                    log_error(f"Failed to save transaction: {ex}", exc_info=True)
                    st.error(f"Failed to save: {ex}")
                    import traceback
                    st.code(traceback.format_exc())
    
    # ============ END OF FORM ============

# ========================= TOA-YADE =========================
elif page == "TOA-Yade":
    import os, base64
    from io import BytesIO
    from pathlib import Path
    from datetime import datetime as _dt
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.units import mm
    from reportlab.lib import colors
    from reportlab.pdfgen import canvas
    from reportlab.lib.utils import ImageReader

    header("TOA � YADE")
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("TOA-Yade") is False:
                st.error("🚫 TOA-Yade page is disabled for this location.")
                st.stop()
    except Exception:
        pass
    
    # ============ LOCATION ACCESS CHECK ============
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("⚠️ No active location selected.")
        st.stop()
    
    user = st.session_state.get("auth_user")
    if user:
        from auth import AuthManager
        if not AuthManager.can_access_location(user, active_location_id):
            st.error("🚫 You do not have access to this location.")
            st.stop()
    
    # Apply location-based page visibility: hide page if disabled in config (non-admin)
    try:
        if user:
            with get_session() as _s_cfg:
                from location_config import LocationConfig
                _cfg = LocationConfig.get_config(_s_cfg, active_location_id)
            # Use show_toa_yade flag to determine visibility
            if not _cfg.get("page_visibility", {}).get("show_toa_yade", False) and (user.get("role", "").lower() not in ["admin-operations", "manager"]):
                st.error("🚫 TOA-Yade page is disabled for this location.")
                st.stop()
    except Exception:
        pass

    # ========== CHECK PERMISSIONS (FOLLOWS YADE PERMISSIONS) ==========
    from permission_manager import PermissionManager
    
    with get_session() as s:
        from location_manager import LocationManager
        
        # Get location info
        loc = LocationManager.get_location_by_id(s, active_location_id)
        if not loc:
            st.error("? Location not found.")
            st.stop()
        
        st.info(f"📍 **Active Location:** {loc.name} ({loc.code})")
        
        # TOA-Yade uses YADE permissions (Admin can access everywhere)
        if not PermissionManager.can_access_feature(s, active_location_id, "yade_transactions", user["role"]):
            st.error("🚫 **Access Denied**")
            st.warning(f"**TOA-Yade** is not available at **{loc.name}**")
            st.info("🚫 TOA-Yade reports require YADE Transactions permission")
            
            # Show where it's available
            allowed_locs = PermissionManager.get_allowed_locations_for_feature(s, "yade_transactions")
            if allowed_locs:
                st.info(f"? This feature is available at: **{', '.join(allowed_locs)}**")
            
            st.markdown("---")
            st.caption(f"Current Location: **{loc.name} ({loc.code})**")
            st.caption("TOA-Yade Access: **? Denied** (YADE permission required)")
            st.stop()
    
    # ============ TOA-YADE ENABLED ============
    st.success(f"? TOA-Yade enabled at {loc.name}")

    # ---------- small helpers ----------
    def _kind_text(x):
        try:
            return x.value if hasattr(x, "value") else (str(x) if x is not None else "")
        except Exception:
            return str(x or "")

    def _fmt_date(d):
        try:    return d.strftime("%d/%m/%Y")
        except: return str(d or "")

    def _fmt_time(t):
        try:    return t.strftime("%H:%M")
        except: return str(t or "")

    # ---------- PDF builder ----------
    def _pdf_support_ok():
        try:
            import reportlab
            return True
        except ImportError:
            return False

    def _mk_pdf_bytes(sess, voyage_id: int) -> bytes | None:
        """Builds the TOA PDF"""
        if not _pdf_support_ok():
            return None

        try:
            from reportlab.lib.pagesizes import A4
            from reportlab.lib.units import mm
            from reportlab.lib import colors
            from reportlab.pdfgen import canvas
            from reportlab.lib.utils import ImageReader
            from io import BytesIO
            from pathlib import Path

            v   = sess.query(YadeVoyage).filter(YadeVoyage.id == voyage_id).one()
            stB = sess.query(TOAYadeStage).filter(TOAYadeStage.voyage_id==voyage_id, TOAYadeStage.stage=="before").one_or_none()
            stA = sess.query(TOAYadeStage).filter(TOAYadeStage.voyage_id==voyage_id, TOAYadeStage.stage=="after").one_or_none()
            sm  = sess.query(TOAYadeSummary).filter(TOAYadeSummary.voyage_id==voyage_id).one_or_none()

            def g(o, k): return float(getattr(o, k) or 0.0) if o else 0.0

            buf = BytesIO()
            c   = canvas.Canvas(buf, pagesize=A4)
            W, H = A4
            LM, RM, TM, BM = 15*mm, 15*mm, 15*mm, 15*mm
            x = LM
            y = H - TM

            # ---- Section 1: Header bar + logos + title ----
            bar_h = 22*mm
            c.setFillColorRGB(0.98, 0.98, 0.98)
            c.setStrokeColorRGB(0.85, 0.85, 0.85)
            c.roundRect(x, y - bar_h, W - LM - RM, bar_h, 4, fill=1, stroke=1)
            c.setFillColor(colors.black)
            c.setStrokeColor(colors.black)

            Lx, Ly, Lw, Lh = x + 6*mm, y - bar_h + 3*mm, 26*mm, bar_h - 6*mm
            Rx, Ry, Rw, Rh = x + (W - LM - RM) - 26*mm - 6*mm, Ly, 26*mm, Lh

            def _draw_img_or_box(path: Path | None, x0, y0, w0, h0, label):
                try:
                    if path and path.exists():
                        img = ImageReader(str(path))
                        iw, ih = img.getSize()
                        if iw > 0 and ih > 0:
                            scale = min(w0/iw, h0/ih)
                            dw, dh = iw*scale, ih*scale
                            ox = x0 + (w0 - dw)/2.0
                            oy = y0 + (h0 - dh)/2.0
                            c.drawImage(img, ox, oy, dw, dh, preserveAspectRatio=True, mask='auto')
                            return
                except Exception:
                    pass
                c.setStrokeColor(colors.black)
                c.rect(x0, y0, w0, h0, stroke=1, fill=0)
                c.setFont("Helvetica", 7)
                c.drawCentredString(x0 + w0/2, y0 - 10, label)

            def _first_existing(paths):
                for p in paths:
                    pth = Path(p)
                    if pth.exists():
                        return pth
                return None

            COMPANY_LOGO = _first_existing([
                "assets/logos/company_logo.png",
                "assets/icons/company_logo.png",
                "assets/company_logo.png",
            ])
            YADE_LOGO = _first_existing([
                "assets/logos/yade_logo.png",
                "assets/icons/yade_logo.png",
                "assets/yade_logo.png",
            ])

            _draw_img_or_box(COMPANY_LOGO, Lx, Ly, Lw, Lh, "Company Logo")
            _draw_img_or_box(YADE_LOGO,    Rx, Ry, Rw, Rh, "YADE Logo")

            c.setFont("Helvetica-Bold", 13)
            c.drawCentredString(LM + (W - LM - RM)/2, y - 7*mm, "TRANSHIPMENT ORDER & ADVICE")
            c.setFont("Helvetica", 9)
            c.drawCentredString(LM + (W - LM - RM)/2, y - 13*mm, f"Report for {v.yade_name} � Voyage {v.voyage_no}")
            y -= (bar_h + 6*mm)

            # ---- Section 2: metadata box ----
            meta_h = 34*mm
            c.setStrokeColor(colors.black)
            c.rect(LM, y - meta_h, W - LM - RM, meta_h, stroke=1, fill=0)
            c.setFont("Helvetica-Bold", 10)
            c.setFillColor(colors.black)
            c.drawString(LM + 4*mm, y - 7*mm, "Voyage Details")
            c.setFont("Helvetica", 9)
            mrow = y - 14*mm
            meta_items = [
                ("Date",          _fmt_date(v.date)),
                ("Time",          _fmt_time(v.time)),
                ("YADE No",       v.yade_name),
                ("Voyage No",     v.voyage_no),
                ("Convoy No",     v.convoy_no),
                ("Cargo",         _kind_text(v.cargo)),
                ("Destination",   _kind_text(v.destination)),
                ("Loading Berth", _kind_text(v.loading_berth)),
            ]
            left = meta_items[:4]
            right = meta_items[4:]
            xL = LM + 6*mm
            xR = LM + (W - LM - RM)/2 + 6*mm
            for (k,vv) in left:  c.drawString(xL, mrow, f"{k}:  {vv}"); mrow -= 6*mm
            mrow = y - 14*mm
            for (k,vv) in right: c.drawString(xR, mrow, f"{k}:  {vv}"); mrow -= 6*mm
            y -= (meta_h + 10*mm)

            # ---- Section 3: quantities table ----
            B_GOV = g(stB, "gov_bbl"); B_GSV = g(stB, "gsv_bbl"); B_FW = g(stB, "fw_bbl")
            A_GOV = g(stA, "gov_bbl"); A_GSV = g(stA, "gsv_bbl"); A_FW = g(stA, "fw_bbl")
            B_NSV = g(stB, "nsv_bbl"); A_NSV = g(stA, "nsv_bbl")
            B_LTF = g(stB, "lt");      A_LTF = g(stA, "lt")

            L_GOV = (A_GOV or 0.0) - (B_GOV or 0.0)
            L_GSV = (A_GSV or 0.0) - (B_GSV or 0.0)
            L_FW  = (A_FW  or 0.0) - (B_FW  or 0.0)
            L_NSV = (A_NSV or 0.0) - (B_NSV or 0.0)

            B_LT_TONS = (B_NSV or 0.0) * (B_LTF or 0.0)
            A_LT_TONS = (A_NSV or 0.0) * (A_LTF or 0.0)
            L_LT_TONS = A_LT_TONS - B_LT_TONS

            B_MT = B_LT_TONS * 1.01605
            A_MT = A_LT_TONS * 1.01605
            L_MT = A_MT - B_MT

            rows = [
                ("Total Volume (bbl)", (B_GOV or 0.0) + (B_FW or 0.0), (A_GOV or 0.0) + (A_FW or 0.0), (L_GOV or 0.0) + (L_FW or 0.0)),
                ("Free Water (bbl)",   B_FW,  A_FW,  L_FW),
                ("GOV (bbl)",          B_GOV, A_GOV, L_GOV),
                ("GSV (bbl)",          B_GSV, A_GSV, L_GSV),
                ("NSV (bbl)",          B_NSV, A_NSV, L_NSV),
                ("Long Tons (LT)",     B_LT_TONS, A_LT_TONS, L_LT_TONS),
                ("MT",                 B_MT,  A_MT,  L_MT),
            ]

            table_h = 7 * 18 + 28
            col_w   = (W - LM - RM) / 4.0
            x_before = LM + 1.2*col_w - 6
            x_after  = LM + 2.3*col_w - 6
            x_loaded = LM + 3.5*col_w - 6

            c.setFont("Helvetica-Bold", 10)
            c.drawString(LM + 4*mm, y - 7*mm, "Certified Quantity loaded in the Barge")
            y -= 10*mm

            c.setFont("Helvetica-Bold", 9)
            c.drawString(LM + 6, y - 12, "Quantity")
            c.drawRightString(x_before, y - 12, "Before")
            c.drawRightString(x_after,  y - 12, "After")
            c.drawRightString(x_loaded, y - 12, "Loaded")

            c.setStrokeColor(colors.black)
            c.rect(LM, y - (table_h + 18), (W - LM - RM), (table_h + 18), stroke=1, fill=0)

            c.setFont("Helvetica", 9)
            ry = y - 28
            def _fmt(v): 
                try: return f"{(v or 0):,.2f}"
                except: return "0.00"
            for name, vb, va, vl in rows:
                c.line(LM, ry + 6, W - RM, ry + 6)
                c.drawString(LM + 6, ry - 6, str(name))
                c.drawRightString(x_before, ry - 6, "" if vb is None else _fmt(vb))
                c.drawRightString(x_after,  ry - 6, "" if va is None else _fmt(va))
                c.drawRightString(x_loaded, ry - 6, "" if vl is None else _fmt(vl))
                ry -= 18
            y -= (table_h + 30)

            # ---- Section 4: Seal details and dips ----
            seal_h = 32*mm
            c.setFont("Helvetica-Bold", 10)
            c.setFillColor(colors.black)
            c.drawString(LM + 4*mm, y - 5*mm, "Seal & Dip Details")

            seals = sess.query(YadeSealDetail).filter(YadeSealDetail.voyage_id == voyage_id).one_or_none()
            dips_after = sess.query(YadeDip).filter(YadeDip.voyage_id == voyage_id, YadeDip.stage == "after").all()
            dips_map = {d.tank_id: d for d in dips_after}

            tanks = ["C1","C2","P1","P2","S1","S2"] if str(v.design) == "6" else ["P1","P2","S1","S2"]

            row_height = 8*mm
            col_widths = [20*mm, 24*mm, 24*mm, 28*mm, 28*mm, 28*mm, 28*mm]
            table_left_x = LM 
            table_top_y = y - 7*mm
            table_width = sum(col_widths)
            table_height = (len(tanks) + 1) * row_height

            c.setLineWidth(1)
            c.rect(table_left_x, table_top_y - table_height, table_width, table_height, stroke=1, fill=0)

            # Vertical lines
            current_x = table_left_x
            for w in col_widths:
                c.line(current_x, table_top_y, current_x, table_top_y - table_height)
                current_x += w
            c.line(table_left_x + table_width, table_top_y, table_left_x + table_width, table_top_y - table_height)

            # Horizontal lines
            for i in range(len(tanks) + 2):
                row_y = table_top_y - i * row_height
                c.line(table_left_x, row_y, table_left_x + table_width, row_y)

            # Header
            hdrs = ["Tank", "Total Dip (cm)", "Water Dip (cm)", "Manhole-1", "Manhole-2", "Lock No", "Dip Hatch"]
            c.setFont("Helvetica-Bold", 9)
            header_y = table_top_y - row_height/2 + 3
            current_x = table_left_x
            for i, h in enumerate(hdrs):
                c.drawCentredString(current_x + col_widths[i]/2, header_y, h)
                current_x += col_widths[i]

            # Data rows
            c.setFont("Helvetica", 8)
            for r, t in enumerate(tanks):
                k = t.upper()
                dip_row = dips_map.get(k)
                total_dip = f"{dip_row.total_cm:.2f}" if dip_row else ""
                water_dip = f"{dip_row.water_cm:.2f}" if dip_row else ""

                seals_k = t.lower()
                mh1 = getattr(seals, f"{seals_k}_mh1", "") if seals else ""
                mh2 = getattr(seals, f"{seals_k}_mh2", "") if seals else ""
                lk  = getattr(seals, f"{seals_k}_lock", "") if seals else ""
                dh  = getattr(seals, f"{seals_k}_diphatch", "") if seals else ""

                vals = [t, total_dip, water_dip, mh1, mh2, lk, dh]
                row_y = table_top_y - (r + 1) * row_height - row_height/2 + 3
                current_x = table_left_x
                for i, vv in enumerate(vals):
                    c.drawCentredString(current_x + col_widths[i]/2, row_y, str(vv or ""))
                    current_x += col_widths[i]

            y -= (table_height + 12*mm)

            # ---- Section 5: Authorized Signatory ----
            sig_h = 40*mm
            sig_y = BM + 5*mm
            c.rect(LM, sig_y, W - LM - RM, sig_h, stroke=1, fill=0)
            c.setFont("Helvetica-Bold", 10)
            c.drawString(LM + 4*mm, sig_y + sig_h - 6*mm, "Authorized Signatory")
            c.setFont("Helvetica", 9)
            c.drawString(LM + 4*mm, sig_y + 6*mm,  "For SEEPCO                                                         For Yade Barge Operators Ltd")
            c.drawRightString(W - RM - 4*mm, sig_y + 6*mm, f"For Barge Master of {v.yade_name}")

            c.showPage()
            c.save()
            out = buf.getvalue()
            buf.close()
            return out

        except Exception as e:
            import traceback
            st.error(f"PDF generation error: {e}")
            st.write("Traceback:", traceback.format_exc())
            return None

    # ---------- Listing UI ----------
    try:
        from models import TOAYadeSummary
        import pandas as pd

        with get_session() as s:
            rows = (
                s.query(TOAYadeSummary)
                 .join(YadeVoyage, TOAYadeSummary.voyage_id == YadeVoyage.id)
                 .filter(YadeVoyage.location_id == active_location_id)
                 .order_by(TOAYadeSummary.date.desc(), TOAYadeSummary.time.desc())
                 .limit(500)
                 .all()
            )

        rows = [r for r in rows if (r and r.yade_name and r.date and r.time)]

        if not rows:
            st.info("🚫 No TOA/YADE summaries yet. Save a YADE voyage first.")
        else:
            df = pd.DataFrame([{
                "Voyage ID":          r.voyage_id,
                "YADE No":            r.yade_name or "",
                "Convoy No":          r.convoy_no or "",
                "Date":               r.date,
                "Time":               r.time,
                "Destination":        _kind_text(r.destination),
                "Loading Berth":      _kind_text(r.loading_berth),
                "Before GSV (bbl)":   float(r.gsv_before_bbl or 0.0),
                "After GSV (bbl)":    float(r.gsv_after_bbl  or 0.0),
                "Loaded GSV (bbl)":   float(r.gsv_loaded_bbl or 0.0),
            } for r in rows])

            st.caption(f"📊 {len(df)} TOA/YADE reports available")

            headers = [
                "YADE No","Convoy No","Date","Time",
                "Destination","Loading Berth",
                "Before GSV (bbl)","After GSV (bbl)","Loaded GSV (bbl)","Create TOA"
            ]
            widths  = [0.10, 0.10, 0.08, 0.07, 0.14, 0.14, 0.10, 0.10, 0.10, 0.07]
            hcols = st.columns(widths)
            for c,h in zip(hcols, headers):
                c.markdown(f"**{h}**")

            import streamlit.components.v1 as components
            for _, r in df.iterrows():
                cols = st.columns(widths)
                cols[0].write(r["YADE No"])
                cols[1].write(r["Convoy No"])
                cols[2].write(_fmt_date(r["Date"]))
                cols[3].write(_fmt_time(r["Time"]))
                cols[4].write(r["Destination"])
                cols[5].write(r["Loading Berth"])
                cols[6].write(f'{r["Before GSV (bbl)"]:.2f}')
                cols[7].write(f'{r["After GSV (bbl)"]:.2f}')
                cols[8].write(f'{r["Loaded GSV (bbl)"]:.2f}')

                vid = int(r["Voyage ID"])
                if cols[9].button("Create TOA", key=f"toa_btn_{vid}"):
                    with get_session() as s:
                        pdf_bytes = _mk_pdf_bytes(s, vid)

                    if not pdf_bytes:
                        st.error("? PDF export failed. Please ensure reportlab is installed.")
                    else:
                        b64 = base64.b64encode(pdf_bytes).decode("utf-8")
                        components.html(
                            f"""
                            <script>
                            (function(){{
                              const b64="{b64}";
                              const byteChars=atob(b64);
                              const byteNums=new Array(byteChars.length);
                              for (let i=0;i<byteChars.length;i++) byteNums[i]=byteChars.charCodeAt(i);
                              const blob=new Blob([new Uint8Array(byteNums)],{{type:'application/pdf'}});
                              const url=URL.createObjectURL(blob);
                              window.open(url,'_blank');
                              setTimeout(()=>URL.revokeObjectURL(url),60000);
                            }})();
                            </script>
                            """,
                            height=0
                        )
                        st.success("? TOA PDF opened in new tab!")
        
        # Show ReportLab status
        try:
            import reportlab
            st.caption("? PDF export available (ReportLab installed)")
        except Exception:
            st.warning("⚠️ To export PDFs, install: `pip install reportlab`")

    except Exception as ex:
        st.error(f"❌ Failed to load TOA-Yade: {ex}")
        log_error(f"Failed to load TOA-Yade: {ex}", exc_info=True)
        import traceback
        with st.expander("⚠️ Error Details"):
            st.code(traceback.format_exc())

# ========================= VIEW TRANSACTIONS =========================
elif page == "View Transactions":
    header("View Transactions")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()
    st.markdown("### Transaction History")
    
    # ============ LOCATION ACCESS CHECK ============
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("⚠️ No active location selected.")
        st.stop()
    
    user = st.session_state.get("auth_user")
    if user:
        from auth import AuthManager
        if not AuthManager.can_access_location(user, active_location_id):
            st.error("🚫 You do not have access to this location.")
            st.stop()
    
    # Display current location
    is_bfs_location = False
    active_location_code = ""
    with get_session() as s:
        from location_manager import LocationManager
        from permission_manager import PermissionManager
        
        loc = LocationManager.get_location_by_id(s, active_location_id)
        if loc:
            active_location_code = (loc.code or "").upper()
            loc_name_upper = (loc.name or "").upper()
            is_bfs_location = (
                "BFS" in active_location_code
                or "BFS" in loc_name_upper
                or "BENEKU" in loc_name_upper
            )
            st.info(f"📍 **Viewing Transactions for:** {loc.name} ({loc.code})")
        
        # Check which transaction types are enabled for this location
        show_yade = PermissionManager.can_access_feature(s, active_location_id, "yade_transactions", user["role"])
        show_tanker = PermissionManager.can_access_feature(s, active_location_id, "tanker_transactions", user["role"])
    
    # ============ BUILD SCOPE OPTIONS BASED ON LOCATION ============
    scope_options = ["Tank Transactions"]
    if show_yade:
        scope_options.append("YADE Voyages")
    if show_tanker:
        scope_options.append("Tanker Transactions")
    if is_bfs_location:
        scope_options.append("Condensate Receipts")
    
    # ---------------- Selector ----------------
    scope = st.selectbox(
        "Select data to view",
        scope_options,
        index=0,
        key="vt_scope"
    )
    st.markdown("---")

    def _date_series(s):
        """Return a Series[datetime.date] regardless of input dtype."""
        return pd.to_datetime(s, errors="coerce").dt.date

    def _fmt_date(x):
        try:
            return pd.to_datetime(x).strftime("%d/%m/%Y")
        except Exception:
            return ""

    def _fmt_time(x):
        try:
            return pd.to_datetime(str(x)).strftime("%H:%M")
        except Exception:
            return ""

    from models import CalibrationTank

    def _calc_tov_from_calibration(session, tank_name: str, dip_cm_val: float, location_id: int) -> float | None:
        """Return interpolated volume (bbl) for a tank dip."""
        if not tank_name or dip_cm_val is None:
            return None
        rows = (
            session.query(CalibrationTank)
            .filter(
                CalibrationTank.tank_name == tank_name,
                CalibrationTank.location_id == location_id,
            )
            .order_by(CalibrationTank.dip_cm.asc())
            .all()
        )
        if not rows:
            return None
        xs = [float(r.dip_cm or 0.0) for r in rows]
        ys = [float(r.volume_bbl or 0.0) for r in rows]
        if dip_cm_val <= xs[0]:
            return ys[0]
        if dip_cm_val >= xs[-1]:
            return ys[-1]
        import bisect

        idx = bisect.bisect_left(xs, dip_cm_val)
        x1, y1 = xs[idx - 1], ys[idx - 1]
        x2, y2 = xs[idx], ys[idx]
        if x2 == x1:
            return y1
        frac = (dip_cm_val - x1) / (x2 - x1)
        return y1 + frac * (y2 - y1)

    import math
    WAT60_CONST = 999.012

    def convert_api_to_60_from_api(api_obs: float, sample_temp_val: float, temp_unit: str) -> float:
        if not api_obs or api_obs <= 0:
            return 0.0
        tf = sample_temp_val if temp_unit == "°F" else (sample_temp_val * 1.8) + 32.0
        temp_diff = tf - 60.0
        rho_obs = (141.5 * WAT60_CONST / (131.5 + float(api_obs))) * (
            (1.0 - 0.00001278 * temp_diff) - (0.0000000062 * temp_diff * temp_diff)
        )
        rho = rho_obs
        for _ in range(10):
            alfa = 341.0957 / (rho * rho)
            vcf = math.exp(-alfa * temp_diff - 0.8 * alfa * alfa * temp_diff * temp_diff)
            rho = rho_obs / vcf
        api60 = 141.5 * WAT60_CONST / rho - 131.5
        return round(api60, 2)

    def convert_api_to_60_from_density(dens_obs_kgm3: float, sample_temp_val: float, temp_unit: str) -> float:
        if not dens_obs_kgm3 or dens_obs_kgm3 <= 0:
            return 0.0
        tc = sample_temp_val if temp_unit == "°C" else (sample_temp_val - 32.0) / 1.8
        temp_diff = tc - 15.0
        hyc = 1.0 - 0.000023 * temp_diff - 0.00000002 * temp_diff * temp_diff
        rho_obs_corrected = float(dens_obs_kgm3) * hyc
        rho15 = rho_obs_corrected
        for _ in range(17):
            K = 613.9723 / (rho15 * rho15)
            vcf = math.exp(-K * temp_diff * (1.0 + 0.8 * K * temp_diff))
            rho15 = rho_obs_corrected / vcf
        sg60 = rho15 / WAT60_CONST
        if sg60 <= 0:
            return 0.0
        api60 = 141.5 / sg60 - 131.5
        return round(api60, 2)

    def vcf_from_api60_and_temp(api60: float, tank_temp: float, tank_temp_unit: str, input_mode: str = "api") -> float:
        if not api60 or api60 <= 0:
            return 1.00000
        tank_temp_f = tank_temp if tank_temp_unit == "°F" else (tank_temp * 1.8) + 32.0
        delta_t = tank_temp_f - 60.0
        if abs(delta_t) < 0.01:
            return 1.00000
        sg60 = 141.5 / (api60 + 131.5)
        rho60 = sg60 * WAT60_CONST
        K0 = 341.0957
        alpha = K0 / (rho60 * rho60)
        vcf = math.exp(-alpha * delta_t * (1.0 + 0.8 * alpha * delta_t))
        return round(float(vcf), 5)

    def lookup_lt_factor(session, api60: float) -> float:
        from models import Table11

        rows = session.query(Table11).order_by(Table11.api60).all()
        if not rows:
            return 0.0
        xs = [float(r.api60) for r in rows]
        ys = [float(r.lt_factor) for r in rows]
        if api60 <= xs[0]:
            return ys[0]
        if api60 >= xs[-1]:
            return ys[-1]
        import bisect

        idx = bisect.bisect_left(xs, api60)
        x1, y1 = xs[idx - 1], ys[idx - 1]
        x2, y2 = xs[idx], ys[idx]
        if x2 == x1:
            return y1
        frac = (api60 - x1) / (x2 - x1)
        return y1 + frac * (y2 - y1)

    from uuid import uuid4
    import hashlib

    def _uniq_key(*parts) -> str:
        raw = "||".join(str(p) for p in parts)
        return hashlib.md5(raw.encode("utf-8")).hexdigest()

    # ===========================================================
    # =============== TANK TRANSACTIONS VIEWER ==================
    # ===========================================================
    if scope == "Tank Transactions":
        st.markdown("### Tank Transactions")

        # -------- load rows - FILTERED BY LOCATION --------
        try:
            with get_session() as s:
                rows = (
                    s.query(TankTransaction)
                    .filter(TankTransaction.location_id == active_location_id)
                    .order_by(TankTransaction.date.desc(), TankTransaction.time.desc())
                    .limit(1000)
                    .all()
                )
        except Exception as ex:
            st.error(f"Failed to load transactions: {ex}")
            rows = []

        if not rows:
            st.info("No tank transactions saved yet for this location.")
            st.stop()

        rows = [r for r in rows if not _is_condensate_tx(r)]

        tx_dates = [r.date for r in rows if isinstance(r.date, date)]
        tx_min_date, tx_max_date = _derive_filter_bounds(tx_dates)
        tx_from_default = _ensure_date_key_in_bounds(
            "vt_tk_date_from", tx_min_date, tx_max_date, tx_min_date
        )
        tx_to_default = _ensure_date_key_in_bounds(
            "vt_tk_date_to", tx_min_date, tx_max_date, tx_max_date
        )

        # -------- live filters (tank) --------
        with st.container(border=True):
            st.caption("Live filters")
            c1, c2, c3, c4, c5, c6 = st.columns([0.22, 0.18, 0.18, 0.16, 0.16, 0.10])
            with c1:
                f_ticket = st.text_input("Ticket ID", key="vt_tk_ticket")
            with c2:
                f_tank = st.text_input("Tank", key="vt_tk_tank")
            with c3:
                op_options = [
                    "(All)",
                    "Opening Stock", "Receipt", "Receipt from Agu", "Receipt from OFS",
                    "OKW Receipt", "ANZ Receipt", "Other Receipts","Dispatch",
                    "Dispatch to barge", "Other Dispatch",
                    "ITT - Receipt", "ITT - Dispatch", "Settling", "Draining"
                ]
                f_op = st.selectbox("Operation", op_options, index=0, key="vt_tk_f_op")
            with c4:
                f_date_from = st.date_input(
                    "From date",
                    value=tx_from_default,
                    min_value=tx_min_date,
                    max_value=tx_max_date,
                    key="vt_tk_date_from",
                )
            with c5:
                f_date_to = st.date_input(
                    "To date",
                    value=tx_to_default,
                    min_value=tx_min_date,
                    max_value=tx_max_date,
                    key="vt_tk_date_to",
                )
            with c6:
                f_api_min = st.number_input("Obs API =", value=0.0, step=0.1, key="vt_tk_api_min")
        
        with get_session() as s2:
            otr_map = {
                o.ticket_id: o.nsv_bbl
                for o in s2.query(OTRRecord).filter(
                    OTRRecord.location_id == active_location_id,
                    OTRRecord.ticket_id.in_([r.ticket_id for r in rows])
                ).all()
            }
            meta_map = { 
                r.ticket_id: (r.created_by, r.updated_by, r.updated_at) 
                for r in rows 
            }
        # to DataFrame for easy filtering & display (preserve columns even when no non-condensate rows)
        df_columns = [
            "Ticket ID", "Operation", "Tank", "Date", "Time",
            "Dip (cm)", "Water (cm)", "Tank Temp A?C", "Tank Temp A?F",
            "Obs API", "Obs Density", "Sample Temp A?C", "Sample Temp A?F",
            "BS&W %", "Qty (bbls)", "NSV (bbl)", "Remarks",
            "Created By", "Updated By", "Updated At",
        ]
        df_rows = [
            {
                "Ticket ID": r.ticket_id,
                "Operation": (r.operation.value if hasattr(r.operation, "value") else (str(r.operation) if r.operation else None)),
                "Tank": r.tank_name or (r.tank.name if getattr(r, "tank", None) else None),
                "Date": r.date,
                "Time": r.time,
                "Dip (cm)": r.dip_cm,
                "Water (cm)": r.water_cm,
                "Tank Temp A?C": r.tank_temp_c,
                "Tank Temp A?F": r.tank_temp_f,
                "Obs API": r.api_observed,
                "Obs Density": r.density_observed,
                "Sample Temp A?C": r.sample_temp_c,
                "Sample Temp A?F": r.sample_temp_f,
                "BS&W %": getattr(r, "bsw_pct", None),
                "Qty (bbls)": r.qty_bbls,
                "NSV (bbl)": round(otr_map.get(r.ticket_id, 0.0) or 0.0, 2),
                "Remarks": r.remarks,
                # include audit information for caution display
                "Created By": getattr(r, "created_by", None),
                "Updated By": getattr(r, "updated_by", None),
                "Updated At": getattr(r, "updated_at", None),
            }
            for r in rows
        ]
        df = pd.DataFrame(df_rows, columns=df_columns)
        # apply filters
        fdf = df.copy()
        if f_ticket:
            fdf = fdf[fdf["Ticket ID"].astype(str).str.contains(f_ticket.strip(), case=False, na=False)]
        if f_tank:
            fdf = fdf[fdf["Tank"].astype(str).str.contains(f_tank.strip(), case=False, na=False)]
        if f_op != "(All)":
            fdf = fdf[fdf["Operation"] == f_op]

        dser = _date_series(fdf["Date"])
        if f_date_from:
            fdf = fdf[dser >= f_date_from]
        if f_date_to:
            fdf = fdf[dser <= f_date_to]

        if f_api_min and f_api_min > 0:
            fdf = fdf[(fdf["Obs API"].fillna(0) >= f_api_min)]

        st.caption(f"{len(fdf)} / {len(df)} rows")

        fdf = fdf.reset_index(drop=True)

        # Display with borders and buttons
        with st.container(border=True):
            # Header now includes User column for audit/caution display
            hdr = [
                "Ticket ID", "Tank", "Date", "Time", "Operation", "Stock (bbls)", "User", "Actions"
            ]
            # Adjust column widths to accommodate the new "User" column. The sum should be ~1.0.
            widths = [0.14, 0.14, 0.12, 0.12, 0.12, 0.12, 0.14, 0.10]
            hcols = st.columns(widths)
            for c, h in zip(hcols, hdr):
                c.markdown(f"**{h}**")

            for i, row in fdf.iterrows():
                cols = st.columns(widths)
                cols[0].write(str(row.get("Ticket ID", "")))
                cols[1].write(str(row.get("Tank", "")))
                cols[2].write(_fmt_date(row.get("Date", "")))
                cols[3].write(_fmt_time(row.get("Time", "")))
                tid = str(row["Ticket ID"])
                created_by, updated_by, updated_at = meta_map.get(tid, (None, None, None))
                badge = ""
                if updated_by:
                    ts = updated_at.strftime("%d-%m-%Y %H:%M") if updated_at else "-"
                    badge = f' <span title="Edited by {updated_by} on {ts}"⚠️</span>'
                cols[4].markdown(f'{row["Operation"]}{badge}', unsafe_allow_html=True)

                cols[5].write(str(row.get("NSV (bbl)","")))

                # Construct User cell with caution icon if record has been edited
                created_by = row.get("Created By") or "-"
                updated_by = row.get("Updated By")
                updated_at = row.get("Updated At")
                if updated_by:
                    # format updated_at if available
                    try:
                        # convert to string like YYYY-MM-DD HH:MM
                        ts_str = ""
                        if updated_at:
                            # some DBs store datetimes as strings or datetime objects
                            try:
                                ts_obj = pd.to_datetime(updated_at)
                                ts_str = ts_obj.strftime("%Y-%m-%d %H:%M")
                            except Exception:
                                ts_str = str(updated_at)
                        tooltip = f"Edited by {updated_by}, {ts_str}" if ts_str else f"Edited by {updated_by}"
                    except Exception:
                        tooltip = f"Edited by {updated_by}"
                    user_html = f"{created_by} <span style=\"color: #f59e0b;\" title=\"{tooltip}\">⚠️</span>"
                else:
                    user_html = created_by
                cols[6].markdown(user_html, unsafe_allow_html=True)

                # Actions column
                act_c1, act_c2 = cols[7].columns([0.5, 0.5])
                tid_str = str(row.get("Ticket ID", f"row{i}"))
                k_view = f"tt_view_{_uniq_key('tt', tid_str, i)}"
                k_del  = f"tt_del_{_uniq_key('tt', tid_str, i)}"

                if act_c1.button("🔍", key=k_view, help="View / Edit this transaction"):
                    st.session_state["tt_view_tid"] = tid_str
                    st.session_state["tt_edit_mode"] = False
                    st.session_state.pop("tt_delete_tid_pending", None)
                    _st_safe_rerun()
                if act_c2.button("🗑️", key=k_del, help="Delete this transaction"):
                    st.session_state["tt_delete_tid_pending"] = tid_str
                    _st_safe_rerun()

    elif scope == "Condensate Receipts":
        st.markdown("### Condensate Receipts")

        if not is_bfs_location:
            st.info("Condensate receipts are only configured for BFS/Beneku.")
            st.stop()

        cond_df_records, meta_map = load_condensate_transactions(active_location_id)

        if not cond_df_records:
            st.info("No condensate receipts captured yet.")
        else:
            cond_df = pd.DataFrame(cond_df_records)
            if not cond_df.empty:
                cond_df["Date"] = pd.to_datetime(cond_df["Date"]).dt.date
            cond_dates = cond_df["Date"].tolist() if not cond_df.empty else []
            cond_min_date, cond_max_date = _derive_filter_bounds(cond_dates)
            cond_from_default = _ensure_date_key_in_bounds(
                "vt_cond_from", cond_min_date, cond_max_date, cond_min_date
            )
            cond_to_default = _ensure_date_key_in_bounds(
                "vt_cond_to", cond_min_date, cond_max_date, cond_max_date
            )

            with st.container(border=True):
                st.caption("Live filters")
                c1, c2, c3 = st.columns([0.3, 0.35, 0.35])
                with c1:
                    f_ticket = st.text_input("Ticket ID", key="vt_cond_ticket")
                with c2:
                    f_date_from = st.date_input(
                        "From date",
                        value=cond_from_default,
                        min_value=cond_min_date,
                        max_value=cond_max_date,
                        key="vt_cond_from",
                    )
                with c3:
                    f_date_to = st.date_input(
                        "To date",
                        value=cond_to_default,
                        min_value=cond_min_date,
                        max_value=cond_max_date,
                        key="vt_cond_to",
                    )

            fdf = cond_df.copy()
            if f_ticket:
                fdf = fdf[fdf["Ticket ID"].astype(str).str.contains(f_ticket.strip(), case=False, na=False)]
            dser = _date_series(fdf["Date"])
            if f_date_from:
                fdf = fdf[dser >= f_date_from]
            if f_date_to:
                fdf = fdf[dser <= f_date_to]

            st.caption(f"{len(fdf)} / {len(cond_df)} records")
            fdf = fdf.reset_index(drop=True)

            hdr = [
                "Ticket ID", "Date", "Opening (m3)", "Closing (m3)",
                "Net Receipt (m3)", "GOV (bbls)", "API @ 60",
                "VCF", "GSV (bbls)", "LT", "MT", "User", "Actions"
            ]
            widths = [0.12, 0.09, 0.11, 0.11, 0.11, 0.09, 0.08, 0.08, 0.09, 0.06, 0.06, 0.07, 0.09]
            hcols = st.columns(widths)
            for c, h in zip(hcols, hdr):
                c.markdown(f"**{h}**")

            for i, row in fdf.iterrows():
                cols = st.columns(widths)
                cols[0].write(str(row.get("Ticket ID", "")))
                cols[1].write(_fmt_date(row.get("Date", "")))
                cols[2].write(f"{row.get('Opening (m3)', 0.0):,.3f}")
                cols[3].write(f"{row.get('Closing (m3)', 0.0):,.3f}")
                cols[4].write(f"{row.get('Net Receipt (m3)', 0.0):,.3f}")
                cols[5].write(f"{row.get('GOV (bbls)', 0.0):,.2f}")
                cols[6].write(f"{row.get('API @ 60', 0.0):,.2f}")
                cols[7].write(f"{row.get('VCF', 0.0):,.5f}")
                cols[8].write(f"{row.get('GSV (bbls)', 0.0):,.2f}")
                cols[9].write(f"{row.get('LT', 0.0):,.2f}")
                cols[10].write(f"{row.get('MT', 0.0):,.2f}")

                tid = str(row.get("Ticket ID", ""))
                created_by, updated_by, updated_at = meta_map.get(tid, (None, None, None))
                badge = ""
                if updated_by:
                    ts = updated_at.strftime("%d-%m-%Y %H:%M") if updated_at else "-"
                    badge = f' <span title="Edited by {updated_by} on {ts}">?⚠️,?</span>'
                cols[11].markdown(f"{created_by or '-'}{badge}", unsafe_allow_html=True)

                act_c1, act_c2 = cols[12].columns([0.5, 0.5])
                k_view = f"cond_view_{_uniq_key('cond', tid, i)}"
                k_del = f"cond_del_{_uniq_key('cond', tid, i)}"
                if act_c1.button("🔍", key=k_view, help="View / Edit this receipt"):
                    st.session_state["tt_view_tid"] = tid
                    st.session_state["tt_edit_mode"] = False
                    st.session_state.pop("tt_delete_tid_pending", None)
                    _st_safe_rerun()
                if act_c2.button("🗑️", key=k_del, help="Delete this receipt"):
                    st.session_state["tt_delete_tid_pending"] = tid
                    _st_safe_rerun()

    # ===========================================================
    # ================== YADE VOYAGES VIEWER ====================
    # ===========================================================
    elif scope == "YADE Voyages":
        st.markdown("### YADE Voyages")

        # -------- load rows + summaries - FILTERED BY LOCATION --------
        try:
            from models import YadeVoyage, YadeDip, YadeSampleParam, YadeSealDetail, TOAYadeSummary

            def _enum_text(x):
                if hasattr(x, "value"):
                    return x.value
                return str(x)

            vdf_rows = []
            with get_session() as s:
                vrows = (
                    s.query(YadeVoyage)
                    .filter(YadeVoyage.location_id == active_location_id)
                    .order_by(YadeVoyage.date.desc(), YadeVoyage.time.desc())
                    .limit(200)
                    .all()
                )

                if not vrows:
                    summaries = {}
                else:
                    v_ids = [v.id for v in vrows]
                    summaries = {
                        r.voyage_id: r
                        for r in s.query(TOAYadeSummary).filter(TOAYadeSummary.voyage_id.in_(v_ids)).all()
                    }

                for v in vrows:
                    summ = summaries.get(v.id)
                    vdf_rows.append({
                        "YADE No": v.yade_name,
                        "Voyage No": v.voyage_no,
                        "Convoy No": v.convoy_no,
                        "Date": v.date,
                        "Time": v.time,
                        "Destination": _enum_text(v.destination),
                        "Loading Berth": _enum_text(v.loading_berth),
                        "Before Qty (bbl)": float(getattr(summ, "gsv_before_bbl", 0.0) or 0.0),
                        "After Qty (bbl)":  float(getattr(summ, "gsv_after_bbl",  0.0) or 0.0),
                        "Loaded Qty (bbl)": float(getattr(summ, "gsv_loaded_bbl", 0.0) or 0.0),
                        "ID": v.id,
                        # audit fields for caution display
                        "Created By": getattr(v, "created_by", None),
                        "Updated By": getattr(v, "updated_by", None),
                        "Updated At": getattr(v, "updated_at", None),
                    })
                    yade_meta = { v.id: (v.created_by, v.updated_by, v.updated_at) for v in vrows }
        except Exception as ex:
            st.error(f"Failed to load YADE Voyages: {ex}")
            vdf_rows = []

        if not vdf_rows:
            st.info("No YADE Voyages yet for this location.")
            st.stop()

        vdf = pd.DataFrame(vdf_rows)
        if not vdf.empty:
            vdf["Date"] = pd.to_datetime(vdf["Date"]).dt.date
        yade_dates = vdf["Date"].tolist() if not vdf.empty else []
        yade_min_date, yade_max_date = _derive_filter_bounds(yade_dates)
        yade_from_default = _ensure_date_key_in_bounds(
            "vt_yd_from", yade_min_date, yade_max_date, yade_min_date
        )
        yade_to_default = _ensure_date_key_in_bounds(
            "vt_yd_to", yade_min_date, yade_max_date, yade_max_date
        )

        # -------- live filters --------
        with st.container(border=True):
            st.caption("Live filters")
            y1, y2, y3, y4, y5, y6 = st.columns([0.15, 0.12, 0.14, 0.14, 0.20, 0.25])
            with y1:
                f_yade = st.text_input("YADE No", key="vt_yd_name")
            with y2:
                f_voy = st.text_input("Voyage No", key="vt_yd_voy")
            with y3:
                f_date_from = st.date_input(
                    "From date",
                    value=yade_from_default,
                    min_value=yade_min_date,
                    max_value=yade_max_date,
                    key="vt_yd_from",
                )
            with y4:
                f_date_to = st.date_input(
                    "To date",
                    value=yade_to_default,
                    min_value=yade_min_date,
                    max_value=yade_max_date,
                    key="vt_yd_to",
                )
            
            dest_opts = ["(All)"] + sorted([x for x in vdf["Destination"].dropna().unique().tolist()])
            berth_opts = ["(All)"] + sorted([x for x in vdf["Loading Berth"].dropna().unique().tolist()])

            with y5:
                f_dest = st.selectbox("Destination", dest_opts, index=0, key="vt_yd_dest")
            with y6:
                f_berth = st.selectbox("Loading Berth", berth_opts, index=0, key="vt_yd_berth")

        # apply filters
        f_vdf = vdf.copy()
        if f_yade:
            f_vdf = f_vdf[f_vdf["YADE No"].astype(str).str.contains(f_yade.strip(), case=False, na=False)]
        if f_voy:
            f_vdf = f_vdf[f_vdf["Voyage No"].astype(str).str.contains(f_voy.strip(), case=False, na=False)]

        vser = _date_series(f_vdf["Date"])
        if f_date_from:
            f_vdf = f_vdf[vser >= f_date_from]
        if f_date_to:
            f_vdf = f_vdf[vser <= f_date_to]
        if f_dest != "(All)":
            f_vdf = f_vdf[f_vdf["Destination"] == f_dest]
        if f_berth != "(All)":
            f_vdf = f_vdf[f_vdf["Loading Berth"] == f_berth]

        st.caption(f"{len(f_vdf)} / {len(vdf)} rows")

        f_vdf = f_vdf.reset_index(drop=True)

        # Display with borders and buttons
        with st.container(border=True):
            # Header now includes User column for audit/caution display
            hdr = [
                "YADE No", "Voyage No", "Convoy No", "Date", "Time", "Destination", "Loading Berth",
                "Before Qty (bbl)", "After Qty (bbl)", "Loaded Qty (bbl)", "User", "Actions"
            ]
            # Define column widths; sum should be ~1.0
            widths = [0.09, 0.08, 0.08, 0.07, 0.06, 0.12, 0.12, 0.08, 0.08, 0.10, 0.10, 0.10]
            hcols = st.columns(widths)
            for c, h in zip(hcols, hdr):
                c.markdown(f"**{h}**")

            for i, row in f_vdf.iterrows():
                cols = st.columns(widths)
                cols[0].write(row["YADE No"])
                cb, ub, ut = yade_meta.get(int(row["ID"]), (None, None, None))
                badge = ""
                if ub:
                    ts = ut.strftime("%d-%m-%Y %H:%M") if ut else "-"
                    badge = f' <span title="Edited by {ub} on {ts}"⚠️</span>'
                cols[1].markdown(f'{row["Voyage No"]}{badge}', unsafe_allow_html=True)
                cols[2].write(row["Convoy No"])
                cols[3].write(_fmt_date(row["Date"]))
                cols[4].write(_fmt_time(row["Time"]))
                cols[5].write(row["Destination"])
                cols[6].write(row["Loading Berth"])
                cols[7].write(f'{row["Before Qty (bbl)"]:.2f}')
                cols[8].write(f'{row["After Qty (bbl)"]:.2f}')
                cols[9].write(f'{row["Loaded Qty (bbl)"]:.2f}')

                # User cell: show created_by and caution if updated
                created_by = row.get("Created By") or "-"
                updated_by = row.get("Updated By")
                updated_at = row.get("Updated At")
                if updated_by:
                    # Build tooltip
                    try:
                        ts_str = ""
                        if updated_at:
                            try:
                                ts_obj = pd.to_datetime(updated_at)
                                ts_str = ts_obj.strftime("%Y-%m-%d %H:%M")
                            except Exception:
                                ts_str = str(updated_at)
                        tooltip = f"Edited by {updated_by}, {ts_str}" if ts_str else f"Edited by {updated_by}"
                    except Exception:
                        tooltip = f"Edited by {updated_by}"
                    user_html = f"{created_by} <span style=\"color: #f59e0b;\" title=\"{tooltip}\">⚠️</span>"
                else:
                    user_html = created_by
                cols[10].markdown(user_html, unsafe_allow_html=True)

                # Actions
                act_c1, act_c2 = cols[11].columns([0.5, 0.5])
                vid = int(row["ID"])
                k_view = f"yv_view_{_uniq_key('yv', vid, i)}"
                k_del  = f"yv_del_{_uniq_key('yv', vid, i)}"

                if act_c1.button("🔍", key=k_view, help="View / Edit this voyage"):
                    st.session_state["yade_view_id"] = vid
                    st.session_state["yade_edit_mode"] = False
                    st.session_state.pop("yade_delete_id_pending", None)
                    _st_safe_rerun()
                if act_c2.button("🗑️", key=k_del, help="Delete this voyage"):
                    st.session_state["yade_delete_id_pending"] = vid
                    _st_safe_rerun()

        # -------- delete flow (yade) --------
        if st.session_state.get("yade_delete_id_pending"):
            vid = st.session_state["yade_delete_id_pending"]
            st.markdown("---")
            with st.container(border=True):
                st.markdown(f"### Delete YADE Voyage � ID {vid}")

                user_info = st.session_state.get("auth_user") or {"username": "unknown", "role": "operator"}
                role = user_info.get("role", "operator")
                username = user_info.get("username", "unknown")

                def _execute_yade_delete(approver_label: str):
                    try:
                        with get_session() as s:
                            rec = s.query(YadeVoyage).filter(YadeVoyage.id == vid).one_or_none()
                            extra_payload: Dict[str, Any] = {}
                            if rec:
                                dips_snapshot = [
                                    RecycleBinManager.snapshot_record(d)
                                    for d in s.query(YadeDip).filter(YadeDip.voyage_id == vid).all()
                                ]
                                samples_snapshot = [
                                    RecycleBinManager.snapshot_record(d)
                                    for d in s.query(YadeSampleParam).filter(YadeSampleParam.voyage_id == vid).all()
                                ]
                                seals_snapshot = [
                                    RecycleBinManager.snapshot_record(d)
                                    for d in s.query(YadeSealDetail).filter(YadeSealDetail.voyage_id == vid).all()
                                ]
                                summary_snapshot = [
                                    RecycleBinManager.snapshot_record(d)
                                    for d in s.query(TOAYadeSummary).filter(TOAYadeSummary.voyage_id == vid).all()
                                ]
                                stages_snapshot = [
                                    RecycleBinManager.snapshot_record(d)
                                    for d in s.query(TOAYadeStage).filter(TOAYadeStage.voyage_id == vid).all()
                                ]
                                extra_payload = {
                                    "dips": dips_snapshot,
                                    "samples": samples_snapshot,
                                    "seals": seals_snapshot,
                                    "summaries": summary_snapshot,
                                    "stages": stages_snapshot,
                                }
                                _archive_record_for_delete(
                                    s,
                                    rec,
                                    "YadeVoyage",
                                    reason=f"Marked YADE voyage {vid} for deletion. Approved by {approver_label}.",
                                    label=f"Voyage {vid}",
                                    extra_payload=extra_payload,
                                )

                            dips_deleted = s.query(YadeDip).filter(
                                YadeDip.voyage_id == vid
                            ).delete(synchronize_session=False)
                            samples_deleted = s.query(YadeSampleParam).filter(
                                YadeSampleParam.voyage_id == vid
                            ).delete(synchronize_session=False)
                            seals_deleted = s.query(YadeSealDetail).filter(
                                YadeSealDetail.voyage_id == vid
                            ).delete(synchronize_session=False)
                            summary_deleted = s.query(TOAYadeSummary).filter(
                                TOAYadeSummary.voyage_id == vid
                            ).delete(synchronize_session=False)
                            stages_deleted = s.query(TOAYadeStage).filter(
                                TOAYadeStage.voyage_id == vid
                            ).delete(synchronize_session=False)

                            if not rec:
                                username_a, user_id, location_id = _current_user_audit_context()
                                SecurityManager.log_audit(
                                    s,
                                    username_a,
                                    "DELETE",
                                    resource_type="YadeVoyage",
                                    resource_id=str(vid),
                                    details=(
                                        f"Cleaned orphan YADE voyage {vid} "
                                        f"(dips={dips_deleted}, samples={samples_deleted}, "
                                        f"seals={seals_deleted}, TOA summary={summary_deleted}, "
                                        f"stages={stages_deleted}). "
                                        f"Approved by {approver_label}."
                                    ),
                                    user_id=user_id,
                                    location_id=location_id,
                                )

                        TaskManager.complete_tasks_for_resource(
                            "YadeVoyage",
                            vid,
                            username,
                            notes=f"Approved by {approver_label}",
                        )
                        st.success(f"Deleted voyage {vid}. Approved by {approver_label}.")
                    except Exception as ex:
                        st.error(f"Failed to delete: {ex}")
                    finally:
                        st.session_state.pop("yade_delete_id_pending", None)
                        _st_safe_rerun()

                if role in ("admin-operations", "supervisor"):
                    approver = f"{username} ({role})"
                    st.info(f"Approval: {approver}")
                    # Show confirm and cancel buttons with appropriate icons
                    do_del = st.button("✅ Confirm Delete", key=f"yv_del_confirm_{vid}", type="primary")
                    cancel = st.button("✖️ Cancel", key=f"yv_del_cancel_{vid}")

                    if do_del:
                        _execute_yade_delete(approver)

                    if cancel:
                        st.session_state.pop("yade_delete_id_pending", None)
                        st.success("Deletion cancelled.")
                        _st_safe_rerun()
                else:
                    remote_task = _render_remote_delete_request_ui(
                        "YadeVoyage",
                        vid,
                        f"YADE voyage {vid}",
                        "Yade Transactions",
                    )
                    if remote_task and remote_task.get("status") == TaskStatus.APPROVED.value:
                        remote_approver = remote_task.get("approved_by") or "Supervisor"
                        if st.button(
                            "Delete with approved request",
                            key=f"yv_remote_delete_{vid}",
                            type="primary",
                        ):
                            _execute_yade_delete(f"{remote_approver} (remote)")

                    with st.form(f"yv_delete_approval_{vid}"):
                        st.warning("Supervisor approval required.")
                        sup_username, sup_label = _supervisor_dropdown(
                            "Supervisor",
                            f"yv_delete_sup_{vid}",
                            active_location_id,
                        )
                        code = st.text_input(
                            "Supervisor Code",
                            type="password",
                            key=f"yv_delete_code_{vid}",
                        )
                        ok = st.form_submit_button("✅ Approve & Delete", type="primary")

                    cancel = st.button("✖️ Cancel", key=f"yv_del_cancel_{vid}")

                    if ok:
                        if not sup_username:
                            st.error("No supervisor available for approval.")
                        elif SecurityManager.verify_supervisor_code(code, sup_username):
                            display_name = sup_label or sup_username
                            _execute_yade_delete(f"{display_name} (supervisor)")
                        else:
                            st.error("Invalid supervisor code.")

                    if cancel:
                        st.session_state.pop("yade_delete_id_pending", None)
                        st.success("Deletion cancelled.")
                        _st_safe_rerun()

        # -------- view / edit prompt (yade) --------
        if st.session_state.get("yade_view_id"):
            vid = st.session_state["yade_view_id"]

            with get_session() as s:
                voyage = s.query(YadeVoyage).filter(YadeVoyage.id == vid).one_or_none()
                
                # Get dips
                before_dips = {d.tank_id: d for d in s.query(YadeDip).filter(
                    YadeDip.voyage_id == vid, YadeDip.stage == "before"
                ).all()}
                
                after_dips = {d.tank_id: d for d in s.query(YadeDip).filter(
                    YadeDip.voyage_id == vid, YadeDip.stage == "after"
                ).all()}
                
                # Get sample params
                before_params = s.query(YadeSampleParam).filter(
                    YadeSampleParam.voyage_id == vid, YadeSampleParam.stage == "before"
                ).first()
                
                after_params = s.query(YadeSampleParam).filter(
                    YadeSampleParam.voyage_id == vid, YadeSampleParam.stage == "after"
                ).first()
                
                # Get seals
                seals = s.query(YadeSealDetail).filter(YadeSealDetail.voyage_id == vid).first()
                
                # Get TOA
                toa = s.query(TOAYadeSummary).filter(TOAYadeSummary.voyage_id == vid).first()

            st.markdown("---")
            with st.container(border=True):
            # Use an em dash instead of a replacement character in the heading
                st.markdown(f"### YADE Voyage — {voyage.yade_name if voyage else 'N/A'}")

                if not voyage:
                    st.info("Voyage not found.")
                else:
                    ns = "yv" + hashlib.md5(str(vid).encode("utf-8")).hexdigest()[:8]
                    editing = st.session_state.get("yade_edit_mode", False)

                    # Action buttons
                    left_actions, right_actions = st.columns([0.7, 0.3])
                    with left_actions:
                        if not editing:
                            if st.button("✏️ Edit", key=f"{ns}_edit_open", help="Edit this voyage"):
                                if not _deny_edit_for_lock(voyage, "YadeVoyage", f"{voyage.yade_name}-{voyage.voyage_no}"):
                                    st.session_state["yade_edit_mode"] = True
                                    _st_safe_rerun()
                        else:
                            save_clicked = st.button("💾 Save", key=f"{ns}_save", help="Save changes")
                            cancel_clicked = st.button("✖️ Cancel edit", key=f"{ns}_cancel", help="Cancel editing")

                    with right_actions:
                        if st.button("🗑️ Delete", key=f"{ns}_del", help="Delete this voyage"):
                            st.session_state["yade_delete_id_pending"] = vid
                            _st_safe_rerun()

                    # Get tank IDs based on design
                    tank_ids = ["C1", "C2", "P1", "P2", "S1", "S2"] if str(voyage.design) == "6" else ["P1", "P2", "S1", "S2"]

                    # ============ BASIC INFO ============
                    st.markdown("#### Basic Information")
                    basic_col1, basic_col2, basic_col3, basic_col4 = st.columns(4)
                    
                    with basic_col1:
                        st.text_input("YADE Name", value=voyage.yade_name, disabled=True, key=f"{ns}_yade_name")
                        voyage_no_val = st.text_input("Voyage No", value=voyage.voyage_no, disabled=not editing, key=f"{ns}_voyage_no")
                    
                    with basic_col2:
                        convoy_no_val = st.text_input("Convoy No", value=voyage.convoy_no, disabled=not editing, key=f"{ns}_convoy_no")
                        st.text_input("Design", value=voyage.design, disabled=True, key=f"{ns}_design")
                    
                    with basic_col3:
                        date_val = st.date_input("Date", value=voyage.date, disabled=not editing, key=f"{ns}_date")
                        time_val = st.time_input("Time", value=voyage.time, disabled=not editing, key=f"{ns}_time")
                    
                    with basic_col4:
                        from models import CargoKind, DestinationKind, LoadingBerthKind
                        cargo_opts = [c.value for c in CargoKind]
                        cargo_val = st.selectbox("Cargo", cargo_opts, 
                                                index=cargo_opts.index(_enum_text(voyage.cargo)) if _enum_text(voyage.cargo) in cargo_opts else 0,
                                                disabled=not editing, key=f"{ns}_cargo")
                        
                        dest_opts = [d.value for d in DestinationKind]
                        dest_val = st.selectbox("Destination", dest_opts,
                                            index=dest_opts.index(_enum_text(voyage.destination)) if _enum_text(voyage.destination) in dest_opts else 0,
                                            disabled=not editing, key=f"{ns}_dest")

                    berth_col1, berth_col2 = st.columns(2)
                    with berth_col1:
                        berth_opts = [b.value for b in LoadingBerthKind]
                        berth_val = st.selectbox("Loading Berth", berth_opts,
                                                index=berth_opts.index(_enum_text(voyage.loading_berth)) if _enum_text(voyage.loading_berth) in berth_opts else 0,
                                                disabled=not editing, key=f"{ns}_berth")

                    # ============ GAUGE TIMES ============
                    st.markdown("#### Gauge Times")
                    gauge_col1, gauge_col2 = st.columns(2)
                    
                    with gauge_col1:
                        st.markdown("**Before Gauge**")
                        before_gauge_date_val = st.date_input("Date", value=voyage.before_gauge_date, disabled=not editing, key=f"{ns}_before_gauge_date")
                        before_gauge_time_val = st.time_input("Time", value=voyage.before_gauge_time, disabled=not editing, key=f"{ns}_before_gauge_time")
                    
                    with gauge_col2:
                        st.markdown("**After Gauge**")
                        after_gauge_date_val = st.date_input("Date", value=voyage.after_gauge_date, disabled=not editing, key=f"{ns}_after_gauge_date")
                        after_gauge_time_val = st.time_input("Time", value=voyage.after_gauge_time, disabled=not editing, key=f"{ns}_after_gauge_time")

                    # ============ DIP READINGS ============
                    st.markdown("#### Dip Readings")
                    dip_col1, dip_col2 = st.columns(2)
                    
                    before_dip_vals = {}
                    after_dip_vals = {}
                    
                    with dip_col1:
                        st.markdown("**Before Loading/Unloading**")
                        for tank_id in tank_ids:
                            dip_obj = before_dips.get(tank_id)
                            st.markdown(f"**Tank {tank_id}**")
                            d1, d2 = st.columns(2)
                            with d1:
                                before_dip_vals[f"{tank_id}_total"] = st.number_input(
                                    f"Total (cm)", 
                                    value=float(dip_obj.total_cm if dip_obj else 0.0),
                                    step=0.1, disabled=not editing, 
                                    key=f"{ns}_before_{tank_id}_total"
                                )
                            with d2:
                                before_dip_vals[f"{tank_id}_water"] = st.number_input(
                                    f"Water (cm)", 
                                    value=float(dip_obj.water_cm if dip_obj else 0.0),
                                    step=0.1, disabled=not editing, 
                                    key=f"{ns}_before_{tank_id}_water"
                                )
                    
                    with dip_col2:
                        st.markdown("**After Loading/Unloading**")
                        for tank_id in tank_ids:
                            dip_obj = after_dips.get(tank_id)
                            st.markdown(f"**Tank {tank_id}**")
                            d1, d2 = st.columns(2)
                            with d1:
                                after_dip_vals[f"{tank_id}_total"] = st.number_input(
                                    f"Total (cm)", 
                                    value=float(dip_obj.total_cm if dip_obj else 0.0),
                                    step=0.1, disabled=not editing, 
                                    key=f"{ns}_after_{tank_id}_total"
                                )
                            with d2:
                                after_dip_vals[f"{tank_id}_water"] = st.number_input(
                                    f"Water (cm)", 
                                    value=float(dip_obj.water_cm if dip_obj else 0.0),
                                    step=0.1, disabled=not editing, 
                                    key=f"{ns}_after_{tank_id}_water"
                                )

                    # ============ SAMPLE PARAMETERS ============
                    st.markdown("#### Sample Parameters")
                    param_col1, param_col2 = st.columns(2)
                    
                    before_param_vals = {}
                    after_param_vals = {}
                    
                    with param_col1:
                        st.markdown("**Before**")
                        before_param_vals["obs_mode"] = st.selectbox(
                            "Observation Mode",
                            ["Observed API", "Observed Density"],
                            index=0 if not before_params or "API" in before_params.obs_mode else 1,
                            disabled=not editing,
                            key=f"{ns}_before_obs_mode"
                        )
                        before_obs_min, before_obs_max = _observed_value_bounds(before_param_vals["obs_mode"])
                        before_param_vals["obs_val"] = _bounded_number_input(
                            "Observed Value",
                            key=f"{ns}_before_obs_val",
                            min_value=before_obs_min,
                            max_value=before_obs_max,
                            value=float(before_params.obs_val if before_params else 0.0),
                            step=0.1,
                            disabled=not editing,
                        )
                        before_param_vals["sample_unit"] = st.selectbox(
                            "Temperature Unit",
                            ["°C", "°F"],
                            index=0 if not before_params or before_params.sample_unit == "°C" else 1,
                            disabled=not editing,
                            key=f"{ns}_before_sample_unit"
                        )
                        before_param_vals["sample_temp"] = _temperature_input(
                            "Sample Temperature",
                            before_param_vals["sample_unit"],
                            key=f"{ns}_before_sample_temp",
                            value=float(before_params.sample_temp if before_params else 0.0),
                            disabled=not editing,
                        )
                        before_param_vals["tank_temp"] = _temperature_input(
                            "Tank Temperature",
                            before_param_vals["sample_unit"],
                            key=f"{ns}_before_tank_temp",
                            value=float(before_params.tank_temp if before_params else 0.0),
                            disabled=not editing,
                        )
                        before_param_vals["ccf"] = st.number_input(
                            "CCF",
                            value=float(before_params.ccf if before_params else 1.0),
                            step=0.0001, disabled=not editing,
                            key=f"{ns}_before_ccf"
                        )
                        before_param_vals["bsw_pct"] = st.number_input(
                            "BS&W %",
                            value=float(before_params.bsw_pct if before_params else 0.0),
                            step=0.01, disabled=not editing,
                            key=f"{ns}_before_bsw"
                        )
                    
                    with param_col2:
                        st.markdown("**After**")
                        after_param_vals["obs_mode"] = st.selectbox(
                            "Observation Mode",
                            ["Observed API", "Observed Density"],
                            index=0 if not after_params or "API" in after_params.obs_mode else 1,
                            disabled=not editing,
                            key=f"{ns}_after_obs_mode"
                        )
                        after_obs_min, after_obs_max = _observed_value_bounds(after_param_vals["obs_mode"])
                        after_param_vals["obs_val"] = _bounded_number_input(
                            "Observed Value",
                            key=f"{ns}_after_obs_val",
                            min_value=after_obs_min,
                            max_value=after_obs_max,
                            value=float(after_params.obs_val if after_params else 0.0),
                            step=0.1,
                            disabled=not editing,
                        )
                        after_param_vals["sample_unit"] = st.selectbox(
                            "Temperature Unit",
                            ["°C", "°F"],
                            index=0 if not after_params or after_params.sample_unit == "°C" else 1,
                            disabled=not editing,
                            key=f"{ns}_after_sample_unit"
                        )
                        after_param_vals["sample_temp"] = _temperature_input(
                            "Sample Temperature",
                            after_param_vals["sample_unit"],
                            key=f"{ns}_after_sample_temp",
                            value=float(after_params.sample_temp if after_params else 0.0),
                            disabled=not editing,
                        )
                        after_param_vals["tank_temp"] = _temperature_input(
                            "Tank Temperature",
                            after_param_vals["sample_unit"],
                            key=f"{ns}_after_tank_temp",
                            value=float(after_params.tank_temp if after_params else 0.0),
                            disabled=not editing,
                        )
                        after_param_vals["ccf"] = st.number_input(
                            "CCF",
                            value=float(after_params.ccf if after_params else 1.0),
                            step=0.0001, disabled=not editing,
                            key=f"{ns}_after_ccf"
                        )
                        after_param_vals["bsw_pct"] = st.number_input(
                            "BS&W %",
                            value=float(after_params.bsw_pct if after_params else 0.0),
                            step=0.01, disabled=not editing,
                            key=f"{ns}_after_bsw"
                        )

                    # ============ SEAL DETAILS ============
                    st.markdown("#### Seal Details")
                    
                    seal_vals = {}
                    seal_header = st.columns([0.10, 0.225, 0.225, 0.225, 0.225])
                    seal_header[0].markdown("**Tank**")
                    seal_header[1].markdown("**Manhole-1**")
                    seal_header[2].markdown("**Manhole-2**")
                    seal_header[3].markdown("**Lock No**")
                    seal_header[4].markdown("**Dip Hatch**")
                    
                    for tank_id in tank_ids:
                        seal_row = st.columns([0.10, 0.225, 0.225, 0.225, 0.225])
                        seal_row[0].write(tank_id)
                        
                        tank_lower = tank_id.lower()
                        seal_vals[f"{tank_id}_mh1"] = seal_row[1].text_input(
                            "MH1", value=getattr(seals, f"{tank_lower}_mh1", "") if seals else "",
                            disabled=not editing, key=f"{ns}_seal_{tank_id}_mh1",
                            label_visibility="collapsed"
                        )
                        seal_vals[f"{tank_id}_mh2"] = seal_row[2].text_input(
                            "MH2", value=getattr(seals, f"{tank_lower}_mh2", "") if seals else "",
                            disabled=not editing, key=f"{ns}_seal_{tank_id}_mh2",
                            label_visibility="collapsed"
                        )
                        seal_vals[f"{tank_id}_lock"] = seal_row[3].text_input(
                            "Lock", value=getattr(seals, f"{tank_lower}_lock", "") if seals else "",
                            disabled=not editing, key=f"{ns}_seal_{tank_id}_lock",
                            label_visibility="collapsed"
                        )
                        seal_vals[f"{tank_id}_diphatch"] = seal_row[4].text_input(
                            "Diphatch", value=getattr(seals, f"{tank_lower}_diphatch", "") if seals else "",
                            disabled=not editing, key=f"{ns}_seal_{tank_id}_diphatch",
                            label_visibility="collapsed"
                        )

                    # ============ TOA SUMMARY ============
                    if toa:
                        st.markdown("#### TOA Summary")
                        toa_col1, toa_col2, toa_col3 = st.columns(3)
                        
                        with toa_col1:
                            st.metric("GSV Before", f"{toa.gsv_before_bbl:,.2f} bbls")
                        
                        with toa_col2:
                            st.metric("GSV After", f"{toa.gsv_after_bbl:,.2f} bbls")
                        
                        with toa_col3:
                            st.metric("GSV Loaded", f"{toa.gsv_loaded_bbl:,.2f} bbls", delta=f"{toa.gsv_loaded_bbl:,.2f}")

                    # ============ SAVE LOGIC ============
                    if editing and save_clicked:
                        try:
                            with get_session() as s:
                                # Update voyage
                                db_voyage = s.query(YadeVoyage).filter(YadeVoyage.id == vid).one_or_none()
                                if db_voyage:
                                    db_voyage.voyage_no = voyage_no_val
                                    db_voyage.convoy_no = convoy_no_val
                                    db_voyage.date = date_val
                                    db_voyage.time = time_val
                                    db_voyage.cargo = cargo_val
                                    db_voyage.destination = dest_val
                                    db_voyage.loading_berth = berth_val
                                    db_voyage.before_gauge_date = before_gauge_date_val
                                    db_voyage.before_gauge_time = before_gauge_time_val
                                    db_voyage.after_gauge_date = after_gauge_date_val
                                    db_voyage.after_gauge_time = after_gauge_time_val
                                
                                # Update dips
                                for tank_id in tank_ids:
                                    # Before dips
                                    before_dip = s.query(YadeDip).filter(
                                        YadeDip.voyage_id == vid,
                                        YadeDip.tank_id == tank_id,
                                        YadeDip.stage == "before"
                                    ).first()
                                    if before_dip:
                                        before_dip.total_cm = before_dip_vals[f"{tank_id}_total"]
                                        before_dip.water_cm = before_dip_vals[f"{tank_id}_water"]
                                    
                                    # After dips
                                    after_dip = s.query(YadeDip).filter(
                                        YadeDip.voyage_id == vid,
                                        YadeDip.tank_id == tank_id,
                                        YadeDip.stage == "after"
                                    ).first()
                                    if after_dip:
                                        after_dip.total_cm = after_dip_vals[f"{tank_id}_total"]
                                        after_dip.water_cm = after_dip_vals[f"{tank_id}_water"]
                                
                                # Update sample params
                                db_before_params = s.query(YadeSampleParam).filter(
                                    YadeSampleParam.voyage_id == vid,
                                    YadeSampleParam.stage == "before"
                                ).first()
                                if db_before_params:
                                    db_before_params.obs_mode = before_param_vals["obs_mode"]
                                    db_before_params.obs_val = before_param_vals["obs_val"]
                                    db_before_params.sample_unit = before_param_vals["sample_unit"]
                                    db_before_params.sample_temp = before_param_vals["sample_temp"]
                                    db_before_params.tank_temp = before_param_vals["tank_temp"]
                                    db_before_params.ccf = before_param_vals["ccf"]
                                    db_before_params.bsw_pct = before_param_vals["bsw_pct"]
                                
                                db_after_params = s.query(YadeSampleParam).filter(
                                    YadeSampleParam.voyage_id == vid,
                                    YadeSampleParam.stage == "after"
                                ).first()
                                if db_after_params:
                                    db_after_params.obs_mode = after_param_vals["obs_mode"]
                                    db_after_params.obs_val = after_param_vals["obs_val"]
                                    db_after_params.sample_unit = after_param_vals["sample_unit"]
                                    db_after_params.sample_temp = after_param_vals["sample_temp"]
                                    db_after_params.tank_temp = after_param_vals["tank_temp"]
                                    db_after_params.ccf = after_param_vals["ccf"]
                                    db_after_params.bsw_pct = after_param_vals["bsw_pct"]
                                
                                # Update seals
                                db_seals = s.query(YadeSealDetail).filter(YadeSealDetail.voyage_id == vid).first()
                                if db_seals:
                                    for tank_id in tank_ids:
                                        tank_lower = tank_id.lower()
                                        setattr(db_seals, f"{tank_lower}_mh1", seal_vals[f"{tank_id}_mh1"])
                                        setattr(db_seals, f"{tank_lower}_mh2", seal_vals[f"{tank_id}_mh2"])
                                        setattr(db_seals, f"{tank_lower}_lock", seal_vals[f"{tank_id}_lock"])
                                        setattr(db_seals, f"{tank_lower}_diphatch", seal_vals[f"{tank_id}_diphatch"])

                                if db_voyage:
                                    _persist_toa_from_current_inputs(
                                        s,
                                        db_voyage,
                                        db_voyage.yade_name,
                                        tank_ids,
                                        len(tank_ids),
                                    )

                                from datetime import datetime, timezone
                                editor = (st.session_state.get("auth_user") or {}).get("username", "unknown")
                                if db_voyage is not None:
                                    if hasattr(db_voyage, "updated_by"):
                                        db_voyage.updated_by = editor
                                    if hasattr(db_voyage, "updated_at"):
                                        db_voyage.updated_at = datetime.now(timezone.utc)
                                s.commit()
                                # ----------------------- Audit log for YADE voyage update -----------------------
                                try:
                                    from security import SecurityManager  # type: ignore
                                    user_ctx = st.session_state.get("auth_user") or {}
                                    username = user_ctx.get("username", "unknown")
                                    user_id = user_ctx.get("id")
                                    resource_id = str(getattr(db_voyage, "id", "")) or f"{db_voyage.yade_name}-{getattr(db_voyage, 'voyage_no', '')}"
                                    SecurityManager.log_audit(
                                        None,
                                        username,
                                        "UPDATE",
                                        resource_type="YadeVoyage",
                                        resource_id=resource_id,
                                        details=f"Updated YADE voyage {db_voyage.yade_name} - {getattr(db_voyage, 'voyage_no', '')}",
                                        user_id=user_id,
                                        location_id=active_location_id,
                                    )
                                except Exception:
                                    pass
                            st.success("? Changes saved successfully!")
                            st.session_state["yade_edit_mode"] = False
                            _st_safe_rerun()
                        
                        except Exception as ex:
                            st.error(f"? Failed to save: {ex}")
                            import traceback
                            st.code(traceback.format_exc())

                    if editing and cancel_clicked:
                        st.session_state["yade_edit_mode"] = False
                        _st_safe_rerun()

                st.divider()
                if st.button("⬅️ Close", key=f"{ns}_close", help="Close viewer"):
                    st.session_state.pop("yade_view_id", None)
                    st.session_state.pop("yade_edit_mode", None)
                    _st_safe_rerun()

    # ===========================================================
    # ============== TANKER TRANSACTIONS VIEWER =================
    # ===========================================================
    elif scope == "Tanker Transactions":
        st.markdown("### Tanker Transactions")
        
        # [Keep your existing tanker code - it already has the table structure]
        # Just add the view/delete prompt windows similar to YADE above
        
        st.info("Tanker viewer - Add view/delete prompts if needed")
        
    if scope in ("Tank Transactions", "Condensate Receipts"):
        if st.session_state.get("tt_delete_tid_pending"):
            tid = st.session_state["tt_delete_tid_pending"]
            st.markdown("---")
            with st.container(border=True):
                st.markdown(f"### Delete Transaction � {tid}")

                user_info = st.session_state.get("auth_user") or {"username": "unknown", "role": "operator"}
                role = user_info.get("role", "operator")
                username = user_info.get("username", "unknown")
                user_id = user_info.get("id")
                loc_id = active_location_id

                def _execute_tank_delete(approver_label: str):
                    try:
                        with get_session() as s:
                            rec = (
                                s.query(TankTransaction)
                                .filter(
                                    TankTransaction.ticket_id == tid,
                                    TankTransaction.location_id == loc_id,
                                )
                                .first()
                            )

                            rec_id = rec.id if rec else None
                            rec_created_by = getattr(rec, "created_by", None) if rec else None
                            otr_rows = (
                                s.query(OTRRecord)
                                .filter(
                                    OTRRecord.ticket_id == tid,
                                    OTRRecord.location_id == loc_id,
                                )
                                .all()
                            )
                            deleted_otr = len(otr_rows)
                            otr_payload = {"otr_rows": [RecycleBinManager.snapshot_record(o) for o in otr_rows]}

                            if rec:
                                _archive_record_for_delete(
                                    s,
                                    rec,
                                    "TankTransaction",
                                    reason=(
                                        f"Marked tank transaction {tid} for deletion "
                                        f"(created_by={rec_created_by}, scope={scope}, OTR={deleted_otr}). "
                                        f"Approved by {approver_label}."
                                    ),
                                    label=tid,
                                    extra_payload=otr_payload,
                                )
                            if deleted_otr:
                                for otr in otr_rows:
                                    _archive_payload_for_delete(
                                        s,
                                        "OTRRecord",
                                        str(otr.id),
                                        payload=RecycleBinManager.snapshot_record(otr),
                                        reason=f"Mirrored OTR record for tank ticket {tid}.",
                                        label=tid,
                                    )
                                    s.delete(otr)

                            s.commit()

                        TaskManager.complete_tasks_for_resource(
                            "TankTransaction",
                            tid,
                            username,
                            notes=f"Approved by {approver_label}",
                        )
                        st.success(f"Deleted {tid}. Approved by {approver_label}.")
                    except Exception as ex:
                        st.error(f"Failed to delete: {ex}")
                    finally:
                        st.session_state.pop("tt_delete_tid_pending", None)
                        _st_safe_rerun()

                if role in ("admin", "supervisor"):
                    approver = f"{username} ({role})"
                    st.info(f"Approval: {approver}")
                    do_del = st.button("Confirm Delete", key=f"tt_del_confirm_{tid}", type="primary")
                    cancel = st.button("Cancel", key=f"tt_del_cancel_{tid}")

                    if do_del:
                        _execute_tank_delete(approver)

                    if cancel:
                        st.session_state.pop("tt_delete_tid_pending", None)
                        st.success("Deletion cancelled.")
                        _st_safe_rerun()
                else:
                    remote_task = _render_remote_delete_request_ui(
                        "TankTransaction",
                        tid,
                        f"Tank ticket {tid}",
                        "Tank Transactions",
                        metadata={"scope": scope},
                    )
                    if remote_task and remote_task.get("status") == TaskStatus.APPROVED.value:
                        remote_approver = remote_task.get("approved_by") or "Supervisor"
                        if st.button(
                            "Delete with approved request",
                            key=f"tt_remote_delete_{tid}",
                            type="primary",
                        ):
                            _execute_tank_delete(f"{remote_approver} (remote)")

                    with st.form(f"tt_delete_approval_{tid}"):
                        st.warning("Supervisor approval required.")
                        sup_username, sup_label = _supervisor_dropdown(
                            "Supervisor",
                            f"tt_delete_sup_{tid}",
                            active_location_id,
                        )
                        code = st.text_input(
                            "Supervisor Code",
                            type="password",
                            key=f"tt_sup_code_{tid}",
                        )
                        ok = st.form_submit_button("Approve & Delete", type="primary")

                    cancel = st.button("Cancel", key=f"tt_del_cancel_{tid}")

                    if ok:
                        if not sup_username:
                            st.error("No supervisor available for approval.")
                        elif SecurityManager.verify_supervisor_code(code, sup_username):
                            _execute_tank_delete(f"{sup_label or sup_username} (supervisor)")
                        else:
                            st.error("Invalid supervisor code.")

                    if cancel:
                        st.session_state.pop("tt_delete_tid_pending", None)
                        st.success("Deletion cancelled.")
                        _st_safe_rerun()


        # -------- shared view / edit prompt --------
        if st.session_state.get("tt_view_tid"):
            tid = st.session_state["tt_view_tid"]

            with get_session() as s:
                rec = s.query(TankTransaction).filter(TankTransaction.ticket_id == tid).first()

            st.markdown("---")
            with st.container(border=True):
                st.markdown(f"### Tank Transaction 📝\" {tid}")
                ns = "tt" + hashlib.md5(tid.encode("utf-8")).hexdigest()[:8]
                editing = st.session_state.get("tt_edit_mode", False)

                left_actions, right_actions = st.columns([0.7, 0.3])
                with left_actions:
                    if not editing:
                        if st.button("Edit", key=f"{ns}_edit_open", help="Edit this transaction"):
                            if not _deny_edit_for_lock(rec, "TankTransaction", tid):
                                st.session_state["tt_edit_mode"] = True
                                _st_safe_rerun()
                    else:
                        save_clicked   = st.button("Save", key=f"{ns}_save", help="Save edited")
                        cancel_clicked = st.button("Cancel edit", key=f"{ns}_cancel", help="Cancel edit")

                with right_actions:
                    if st.button("Delete", key=f"{ns}_del", help="Delete this transaction"):
                        st.session_state["tt_delete_tid_pending"] = tid
                        _st_safe_rerun()

                if not rec:
                    st.info("Record not found.")
                else:
                    op_label = (
                        rec.operation.value
                        if hasattr(rec.operation, "value")
                        else str(rec.operation or "")
                    )
                    is_condensate = _is_condensate_tx(rec)

                    dip_val = float(rec.dip_cm or 0.0)
                    water_val = float(rec.water_cm or 0.0)
                    tank_temp_c_val = float(rec.tank_temp_c or 0.0)
                    tank_temp_f_val = float(rec.tank_temp_f or 0.0)
                    api_val = float(rec.api_observed or 0.0)
                    dens_val = float(rec.density_observed or 0.0)
                    bsw_val = float(getattr(rec, "bsw_pct", 0.0) or 0.0)
                    sample_temp_c_val = float(rec.sample_temp_c or 0.0)
                    sample_temp_f_val = float(rec.sample_temp_f or 0.0)
                    qty_val = float(rec.qty_bbls or 0.0)
                    opening_meter_val = float(rec.opening_meter_reading or 0.0)
                    closing_meter_val = float(rec.closing_meter_reading or 0.0)

                    if is_condensate:
                        meter_cols = st.columns(2)
                        with meter_cols[0]:
                            opening_meter_val = st.number_input(
                                "Opening Meter (m�)",
                                value=opening_meter_val,
                                step=0.001,
                                disabled=not editing,
                                key=f"{ns}_cond_open"
                            )
                        with meter_cols[1]:
                            closing_meter_val = st.number_input(
                                "Closing Meter (m�)",
                                value=closing_meter_val,
                                step=0.001,
                                disabled=not editing,
                                key=f"{ns}_cond_close"
                            )

                        temp_cols = st.columns(2)
                        with temp_cols[0]:
                            tank_temp_c_val = _temperature_input(
                                "Tank Temp (°C)",
                                "°C",
                                key=f"{ns}_cond_ttc",
                                value=tank_temp_c_val,
                                disabled=not editing,
                            )
                            sample_temp_c_val = _temperature_input(
                                "Sample Temp (°C)",
                                "°C",
                                key=f"{ns}_cond_stc",
                                value=sample_temp_c_val,
                                disabled=not editing,
                            )
                        with temp_cols[1]:
                            tank_temp_f_val = _temperature_input(
                                "Tank Temp (°F)",
                                "°F",
                                key=f"{ns}_cond_ttf",
                                value=tank_temp_f_val,
                                disabled=not editing,
                            )
                            sample_temp_f_val = _temperature_input(
                                "Sample Temp (°F)",
                                "°F",
                                key=f"{ns}_cond_stf",
                                value=sample_temp_f_val,
                                disabled=not editing,
                            )

                        prop_cols = st.columns(2)
                        with prop_cols[0]:
                            api_val = _bounded_number_input(
                                "Observed API",
                                key=f"{ns}_cond_api",
                                min_value=API_MIN,
                                max_value=API_MAX,
                                value=api_val,
                                step=0.1,
                                disabled=not editing,
                            )
                        with prop_cols[1]:
                            dens_val = _bounded_number_input(
                                "Observed Density (kg/m3)",
                                key=f"{ns}_cond_dens",
                                min_value=DENSITY_MIN,
                                max_value=DENSITY_MAX,
                                value=dens_val,
                                step=0.1,
                                disabled=not editing,
                            )
                        bsw_val = 0.0
                        dip_val = 0.0
                        water_val = 0.0
                    else:
                        c1, c2, c3, c4 = st.columns(4)
                        with c1:
                            dip_val = st.number_input(
                                "Dip (cm)",
                                value=dip_val,
                                step=0.1,
                                disabled=not editing,
                                key=f"{ns}_dip"
                            )
                            water_val = st.number_input(
                                "Water (cm)",
                                value=water_val,
                                step=0.1,
                                disabled=not editing,
                                key=f"{ns}_water"
                            )
                        with c2:
                            tank_temp_c_val = _temperature_input(
                                "Tank Temp (degC)",
                                "°C",
                                key=f"{ns}_ttc",
                                value=tank_temp_c_val,
                                disabled=not editing,
                            )
                            tank_temp_f_val = _temperature_input(
                                "Tank Temp (degF)",
                                "°F",
                                key=f"{ns}_ttf",
                                value=tank_temp_f_val,
                                disabled=not editing,
                            )
                        with c3:
                            api_val = _bounded_number_input(
                                "Observed API",
                                key=f"{ns}_api",
                                min_value=API_MIN,
                                max_value=API_MAX,
                                value=api_val,
                                step=0.1,
                                disabled=not editing,
                            )
                            dens_val = _bounded_number_input(
                                "Observed Density (kg/m3)",
                                key=f"{ns}_den",
                                min_value=DENSITY_MIN,
                                max_value=DENSITY_MAX,
                                value=dens_val,
                                step=0.1,
                                disabled=not editing,
                            )
                            bsw_val = st.number_input(
                                "BS&W %",
                                value=bsw_val,
                                step=0.01,
                                disabled=not editing,
                                key=f"{ns}_bsw"
                            )
                        with c4:
                            sample_temp_c_val = _temperature_input(
                                "Sample Temp (degC)",
                                "°C",
                                key=f"{ns}_stc",
                                value=sample_temp_c_val,
                                disabled=not editing,
                            )
                            sample_temp_f_val = _temperature_input(
                                "Sample Temp (degF)",
                                "°F",
                                key=f"{ns}_stf",
                                value=sample_temp_f_val,
                                disabled=not editing,
                            )

                    remarks_col, extra_col = st.columns([0.6, 0.4])
                    with remarks_col:
                        remarks = st.text_area(
                            "Remarks",
                            value=rec.remarks or "",
                            disabled=not editing,
                            key=f"{ns}_remarks"
                        )
                    with extra_col:
                        extra = st.text_area(
                            "Additional Notes",
                            value="",
                            disabled=not editing,
                            key=f"{ns}_extra"
                        )

                    tank_name_for_calc = rec.tank_name
                    if not tank_name_for_calc and rec.tank_id:
                        with get_session() as s_lookup:
                            tank_obj = s_lookup.query(Tank).filter(Tank.id == rec.tank_id).one_or_none()
                            if tank_obj:
                                tank_name_for_calc = tank_obj.name

                    if is_condensate:
                        opening_meter = float(opening_meter_val or 0.0)
                        closing_meter = float(closing_meter_val or opening_meter)
                        condensate_qty_m3 = max(closing_meter - opening_meter, 0.0)
                        tov_bbl = round(condensate_qty_m3 * CONDENSATE_M3_TO_BBL, 2)
                        fw_bbl = 0.0
                        gov_bbl = tov_bbl

                        sample_temp_c_used = sample_temp_c_val or (
                            (sample_temp_f_val - 32.0) / 1.8 if sample_temp_f_val else 0.0
                        )
                        sample_temp_f_used = sample_temp_f_val or (
                            (sample_temp_c_val * 1.8) + 32.0 if sample_temp_c_val else 0.0
                        )
                        tank_temp_c_used = tank_temp_c_val or (
                            (tank_temp_f_val - 32.0) / 1.8 if tank_temp_f_val else 0.0
                        )

                        if api_val > 0:
                            sample_unit = "°F" if sample_temp_f_used else "°C"
                            sample_temp_for_api = sample_temp_f_used if sample_unit == "°F" else sample_temp_c_used
                            api60_val = convert_api_to_60_from_api(api_val, sample_temp_for_api or 0.0, sample_unit)
                        elif dens_val > 0:
                            sample_temp_for_density = sample_temp_c_used or 15.0
                            api60_val = convert_api_to_60_from_density(dens_val, sample_temp_for_density or 0.0, "°C")
                        else:
                            api60_val = 0.0

                        input_mode = "api" if api_val > 0 else ("density" if dens_val > 0 else "api")
                        vcf_val = vcf_from_api60_and_temp(api60_val, tank_temp_c_used, "°C", input_mode)
                        gsv_bbl = round(gov_bbl * vcf_val, 2)
                        bsw_vol = 0.0
                        nsv_bbl = gsv_bbl
                        try:
                            with get_session() as s_lt:
                                lt_factor = lookup_lt_factor(s_lt, api60_val) if api60_val > 0 else 0.0
                        except Exception:
                            lt_factor = 0.0
                        lt_val = round(nsv_bbl * lt_factor, 2)
                        mt_val = round(lt_val * 1.01605, 2)
                    else:
                        with get_session() as s_cal:
                            tov_bbl = _calc_tov_from_calibration(s_cal, tank_name_for_calc, dip_val, rec.location_id) if tank_name_for_calc else None
                            fw_bbl = (
                                _calc_tov_from_calibration(s_cal, tank_name_for_calc, water_val, rec.location_id)
                                if tank_name_for_calc and water_val > 0 else 0.0
                            )
                        if tov_bbl is None:
                            tov_bbl = float(qty_val or 0.0)
                        else:
                            tov_bbl = float(tov_bbl)
                        fw_bbl = float(fw_bbl or 0.0)
                        gov_bbl = max(tov_bbl - fw_bbl, 0.0)

                        if not sample_temp_f_val and sample_temp_c_val:
                            sample_temp_f_val = (sample_temp_c_val * 1.8) + 32.0
                        if not sample_temp_c_val and sample_temp_f_val:
                            sample_temp_c_val = (sample_temp_f_val - 32.0) / 1.8

                        sample_temp_unit = "°F"
                        sample_temp_for_api = sample_temp_f_val or 60.0
                        if api_val > 0:
                            api60_val = convert_api_to_60_from_api(api_val, sample_temp_for_api, sample_temp_unit)
                        elif dens_val > 0:
                            sample_temp_for_density = sample_temp_c_val or 15.0
                            api60_val = convert_api_to_60_from_density(dens_val, sample_temp_for_density, "°C")
                        else:
                            api60_val = 0.0

                        tank_temp_for_vcf = tank_temp_c_val or ((tank_temp_f_val - 32.0) / 1.8 if tank_temp_f_val else 0.0)
                        tank_temp_unit = "°C"
                        input_mode = "density" if (api_val <= 0 and dens_val > 0) else "api"
                        vcf_val = vcf_from_api60_and_temp(api60_val, tank_temp_for_vcf, tank_temp_unit, input_mode)

                        gsv_bbl = round(gov_bbl * vcf_val, 2)
                        bsw_vol = round(gsv_bbl * (bsw_val / 100.0), 2)
                        nsv_bbl = round(gsv_bbl - bsw_vol, 2)
                        if api60_val and api60_val > 0:
                            with get_session() as s_lt:
                                lt_factor = lookup_lt_factor(s_lt, api60_val)
                        else:
                            lt_factor = 0.0
                        lt_val = round(nsv_bbl * lt_factor, 2)
                        mt_val = round(lt_val * 1.01605, 2)

                    st.caption(f"TOV: {tov_bbl:.2f} bbl | GOV: {gov_bbl:.2f} bbl | GSV: {gsv_bbl:.2f} bbl | NSV: {nsv_bbl:.2f} bbl")

                    if editing and save_clicked:
                        try:
                            with get_session() as s:
                                dbrec = s.query(TankTransaction).filter(TankTransaction.ticket_id == tid).first()
                                if not dbrec:
                                    st.error("Record not found in database.")
                                else:
                                    if is_condensate:
                                        dbrec.dip_cm = None
                                        dbrec.water_cm = None
                                        dbrec.opening_meter_reading = float(opening_meter)
                                        dbrec.closing_meter_reading = float(closing_meter)
                                        dbrec.condensate_qty_m3 = float(condensate_qty_m3)
                                    else:
                                        dbrec.dip_cm = dip_val
                                        dbrec.water_cm = water_val
                                        dbrec.opening_meter_reading = None
                                        dbrec.closing_meter_reading = None
                                        dbrec.condensate_qty_m3 = None

                                    dbrec.tank_temp_c = tank_temp_c_val
                                    dbrec.tank_temp_f = tank_temp_f_val
                                    dbrec.api_observed = api_val
                                    dbrec.density_observed = dens_val
                                    dbrec.sample_temp_c = sample_temp_c_val
                                    dbrec.sample_temp_f = sample_temp_f_val
                                    dbrec.bsw_pct = bsw_val
                                    dbrec.qty_bbls = float(round(tov_bbl, 2))
                                    editor_name = (st.session_state.get("auth_user") or {}).get("username", "unknown")
                                    edit_time = datetime.now()
                                    audit = f"edited by {editor_name}, {edit_time.strftime('%Y-%m-%d %H:%M')}"
                                    if extra:
                                        audit = f"{audit} | {extra}"
                                    dbrec.remarks = ((dbrec.remarks or "") + " | " + audit).strip(" |")
                                    dbrec.updated_by = editor_name
                                    dbrec.updated_at = edit_time

                                    if not is_condensate:
                                        otr = s.query(OTRRecord).filter(OTRRecord.ticket_id == tid).one_or_none()
                                        if not otr:
                                            otr = OTRRecord(
                                                location_id=dbrec.location_id,
                                                ticket_id=tid,
                                                tank_id=dbrec.tank_name or (str(dbrec.tank_id) if dbrec.tank_id else None),
                                                date=dbrec.date,
                                                time=dbrec.time,
                                                operation=op_label,
                                            )
                                            s.add(otr)

                                        otr.dip_cm = dip_val
                                        otr.total_volume_bbl = float(round(tov_bbl, 2))
                                        otr.water_cm = water_val
                                        otr.free_water_bbl = float(round(fw_bbl, 2))
                                        otr.gov_bbl = float(round(gov_bbl, 2))
                                        otr.api60 = float(api60_val)
                                        otr.vcf = float(vcf_val)
                                        otr.gsv_bbl = float(gsv_bbl)
                                        otr.bsw_vol_bbl = float(bsw_vol)
                                        otr.nsv_bbl = float(nsv_bbl)
                                        otr.lt = float(lt_val)
                                        otr.mt = float(mt_val)

                                    s.commit()
                                    # ----------------------- Audit log for tank transaction edit -----------------------
                                    try:
                                        from security import SecurityManager  # type: ignore
                                        user_ctx = st.session_state.get("auth_user") or {}
                                        username = user_ctx.get("username", "unknown")
                                        user_id = user_ctx.get("id")
                                        location_id = st.session_state.get("active_location_id") or user_ctx.get("location_id")
                                        # Determine record ID: use dbrec.id if available, otherwise fallback to tid
                                        rec_id = str(dbrec.id) if 'dbrec' in locals() and getattr(dbrec, 'id', None) else str(tid)
                                        SecurityManager.log_audit(
                                            None,
                                            username,
                                            "UPDATE",
                                            resource_type="TankTransaction",
                                            resource_id=rec_id,
                                            details=f"Updated tank transaction (ticket {tid})",
                                            user_id=user_id,
                                            location_id=location_id,
                                        )
                                    except Exception:
                                        # Do not interrupt the user flow if audit logging fails
                                        pass

                            st.success("Changes saved.")
                            st.session_state["tt_edit_mode"] = False
                            _st_safe_rerun()
                        except Exception as ex:
                            st.error(f"Failed to save: {ex}")

                    if editing and cancel_clicked:
                        st.session_state["tt_edit_mode"] = False
                        _st_safe_rerun()

                st.divider()
                if st.button("Close", key=f"{ns}_close", help="Close viewer"):
                    st.session_state.pop("tt_view_tid", None)
                    st.session_state.pop("tt_edit_mode", None)
                    _st_safe_rerun()
# OTR � placeholder
elif page == "OTR":
    header("Out-Turn Report")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()
    
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("OTR") is False:
                st.error("🚫 OTR page is disabled for this location.")
                st.stop()
    except Exception:
        pass

    # ============ LOCATION ACCESS CHECK ============
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("⚠️ No active location selected. Please select a location from the Home page.")
        st.stop()

    # Verify user has access to this location
    user = st.session_state.get("auth_user")
    if user:
        from auth import AuthManager
        if not AuthManager.can_access_location(user, active_location_id):
            st.error("🚫 You do not have access to this location.")
            st.stop()

    # Display current location and load config
    with get_session() as s:
        from location_manager import LocationManager
        from location_config import LocationConfig
        
        loc = LocationManager.get_location_by_id(s, active_location_id)
        if loc:
            st.info(f"📍 **Active Location:** {loc.name} ({loc.code})")
        
        # Load location-specific configuration
        config = LocationConfig.get_config(s, active_location_id)
        tank_config = config.get("tank_transactions", {})

    # Models (safe imports)
    try:
        from models import Tank, OTRRecord
    except Exception:
        pass

    # Get configured operations for this location
    location_operations = tank_config.get("enabled_operations", [
        "Opening Stock","Receipt - Commingled","Receipt - Condensate", "Receipt", "Receipt from Agu", "Receipt from OFS",
        "OKW Receipt", "ANZ Receipt", "Other Receipts","Dispatch",
        "Dispatch to barge", "Other Dispatch",
        "ITT - Receipt", "ITT - Dispatch", "Settling", "Draining"
    ])

    # Determine earliest/latest OTR entry dates for default filter bounds
    otr_first_date = None
    otr_last_date = None
    with get_session() as s_first:
        first_entry = (
            s_first.query(OTRRecord.date)
            .filter(OTRRecord.location_id == active_location_id)
            .order_by(OTRRecord.date.asc())
            .first()
        )
        if first_entry and first_entry[0]:
            otr_first_date = first_entry[0]
        last_entry = (
            s_first.query(OTRRecord.date)
            .filter(OTRRecord.location_id == active_location_id)
            .order_by(OTRRecord.date.desc())
            .first()
        )
        if last_entry and last_entry[0]:
            otr_last_date = last_entry[0]
    if otr_first_date is None:
        otr_first_date = date.today()
    if otr_last_date is None:
        otr_last_date = date.today()
    otr_last_date = min(otr_last_date, date.today())
    if otr_first_date > otr_last_date:
        otr_first_date = otr_last_date

    otr_from_default = _ensure_date_key_in_bounds(
        "otr_f_from", otr_first_date, otr_last_date, otr_first_date
    )
    otr_to_default = _ensure_date_key_in_bounds(
        "otr_f_to", otr_first_date, otr_last_date, otr_last_date
    )

    # --- Filters (with Tank dropdown as requested) ---
    with st.container(border=True):
        st.caption("Live filters")
        c1, c2, c3, c4, c5 = st.columns([0.20, 0.20, 0.18, 0.21, 0.21])

        # Tank list - FILTERED BY LOCATION (names)
        with get_session() as s:
            tanks_all = s.query(Tank).filter(
                Tank.location_id == active_location_id
            ).order_by(Tank.name).all()
        tank_name_list = [t.name for t in tanks_all]
        tank_opts = ["(All Tanks)"] + tank_name_list

        with c1:
            f_tank = st.selectbox("Tank", tank_opts, index=0, key="otr_f_tank")
        with c2:
            f_ticket = st.text_input("Ticket ID", key="otr_f_ticket")
        with c3:
            # Operation filter - ONLY SHOW LOCATION-CONFIGURED OPERATIONS
            operation_opts = ["(All)"] + location_operations
            f_op = st.selectbox("Operation", operation_opts, index=0, key="otr_f_op")
        with c4:
            f_from = st.date_input(
                "From date",
                value=otr_from_default,
                min_value=otr_first_date,
                max_value=otr_last_date,
                key="otr_f_from",
            )
        with c5:
            f_to = st.date_input(
                "To date",
                value=otr_to_default,
                min_value=otr_first_date,
                max_value=otr_last_date,
                key="otr_f_to",
            )

    # --- Load OTR from DB - FILTERED BY LOCATION ---
    with get_session() as s:
        rows = s.query(OTRRecord).filter(
            OTRRecord.location_id == active_location_id  # LOCATION FILTER
        ).order_by(OTRRecord.date.asc(), OTRRecord.time.asc()).all()

    if not rows:
        st.info(f"No OTR records yet for {loc.name}.")
        st.stop()

    # --- All OTR records as dataframe (unfiltered) ---
    # Use tank_name for "Tank" (so Tank filter works), and stringify Operation safely
    def _safe_str(x):
        try:
            return str(x) if x is not None else ""
        except Exception:
            return ""

    df = pd.DataFrame([{
        "Ticket ID": r.ticket_id,
        "Tank": getattr(r, "tank_name", None) or getattr(r, "tank_id", None),  # prefer name
        "Date": r.date,
        "Time": r.time,
        "Operation": _safe_str(getattr(r, "operation", None)),
        "Dip (cm)": r.dip_cm,
        "Total Volume (bbl)": r.total_volume_bbl,
        "Water (cm)": r.water_cm,
        "Free Water (bbl)": r.free_water_bbl,
        "GOV (bbl)": r.gov_bbl,
        "API @ 60°F": r.api60,
        "VCF": r.vcf,
        "GSV (bbl)": r.gsv_bbl,
        "BS&W Vol (bbl)": r.bsw_vol_bbl,
        "NSV (bbl)": r.nsv_bbl,
        "LT": r.lt,
        "MT": r.mt,
        "Operation Enum": getattr(r, "operation", None),
    } for r in rows])

    # Build a proper timestamp column for correct per-tank ordering
    # Date is date, Time may be string/time; coerce both then combine
    _date = pd.to_datetime(df["Date"], errors="coerce")
    _time = pd.to_datetime(df["Time"].astype(str), errors="coerce").dt.time
    df["DT"] = [
        (datetime.combine(d.date(), t) if (pd.notna(d) and t is not pd.NaT and t is not None) else pd.NaT)
        for d, t in zip(_date, _time)
    ]

    # --- Apply filters ---
    fdf = df.copy()
    if f_tank and f_tank != "(All Tanks)":
        fdf = fdf[fdf["Tank"] == f_tank]
    if f_ticket:
        fdf = fdf[fdf["Ticket ID"].astype(str).str.contains(f_ticket.strip(), case=False, na=False)]
    if f_op and f_op != "(All)":
        fdf = fdf[fdf["Operation"].astype(str) == str(f_op)]
    if f_from:
        fdf = fdf[pd.to_datetime(fdf["Date"], errors="coerce").dt.date >= f_from]
    if f_to:
        fdf = fdf[pd.to_datetime(fdf["Date"], errors="coerce").dt.date <= f_to]

    st.caption(f"📊 Showing {len(fdf)} / {len(df)} records for **{loc.name}**")
    st.markdown("### Out-Turn Report (OTR)")
    
    columns_2dec = [
        "Dip (cm)", "Total Volume (bbl)", "Water (cm)", "Free Water (bbl)",
        "GOV (bbl)", "API @ 60°F", "GSV (bbl)", "BS&W Vol (bbl)",
        "NSV (bbl)", "LT", "MT", "Net Rece/Disp (bbls)", "Net Water Rece/Disp (bbls)"
    ]
    column_5dec = "VCF"

    # Cast/round numeric columns for display
    for col in columns_2dec:
        if col in fdf.columns:
            fdf[col] = pd.to_numeric(fdf[col], errors="coerce").round(2)
    if column_5dec in fdf.columns:
        fdf[column_5dec] = pd.to_numeric(fdf[column_5dec], errors="coerce").round(5)
    
    # --- Chronological sort (global for display) ---
    # Keep your current UI sort; net calcs will use per-tank DT order below.
    fdf = fdf.sort_values(["Date", "Time"], ascending=[True, True]).reset_index(drop=True)

    # ---------------- Tank-aware net calculations for OTR ----------------
    import numpy as np

    # Ensure source numeric columns exist
    if "NSV (bbl)" not in fdf.columns:
        fdf["NSV (bbl)"] = 0.0
    if "Free Water (bbl)" not in fdf.columns:
        fdf["Free Water (bbl)"] = 0.0

    # Cast numerics safely
    fdf["NSV (bbl)"] = pd.to_numeric(fdf["NSV (bbl)"], errors="coerce").fillna(0.0)
    fdf["Free Water (bbl)"] = pd.to_numeric(fdf["Free Water (bbl)"], errors="coerce").fillna(0.0)

    # Sort by Tank + DT so "previous" truly means previous entry of the same tank
    # If DT is NaT, use index order to keep stability
    sort_key = pd.Series(pd.to_datetime(fdf["DT"], errors="coerce"))
    orig_index = fdf.index
    fdf_sorted = fdf.assign(__sort_time=sort_key).sort_values(
        by=["Tank", "__sort_time", orig_index.name or "__sort_time"],
        kind="mergesort"
    )

    # Per-tank previous values using groupby+shift
    prev_nsv = fdf_sorted.groupby("Tank")["NSV (bbl)"].shift(1)
    prev_fw  = fdf_sorted.groupby("Tank")["Free Water (bbl)"].shift(1)

    # Deltas = current - previous
    net_nsv  = fdf_sorted["NSV (bbl)"] - prev_nsv
    net_fw   = fdf_sorted["Free Water (bbl)"] - prev_fw

    # First entries per tank ? blank (keep your �Opening/blank� behavior)
    first_of_tank_mask = prev_nsv.isna()
    net_nsv  = net_nsv.mask(first_of_tank_mask, np.nan)
    net_fw   = net_fw.mask(first_of_tank_mask, np.nan)

    # Align back to original order
    net_nsv_aligned = pd.Series(net_nsv.values, index=fdf_sorted.index).reindex(orig_index)
    net_fw_aligned  = pd.Series(net_fw.values,  index=fdf_sorted.index).reindex(orig_index)

    # Write columns; blank string for first-of-tank rows, else float (2dp formatting already set above)
    def _fmt_net(s):
        return s.where(~s.isna(), "")

    fdf["Net Rece/Disp (bbls)"]       = _fmt_net(pd.to_numeric(net_nsv_aligned, errors="coerce").round(2))
    fdf["Net Water Rece/Disp (bbls)"] = _fmt_net(pd.to_numeric(net_fw_aligned,  errors="coerce").round(2))

    # Cleanup helper column
    if "__sort_time" in fdf.columns:
        fdf.drop(columns="__sort_time", inplace=True, errors="ignore")

    # --- Display ---
    st.dataframe(fdf, use_container_width=True, hide_index=True)
    
    # --- PDF Generation Function ---
    def generate_otr_pdf(dataframe, selected_tank, filter_text, location_name, location_code):
        from reportlab.lib.pagesizes import A4, landscape
        from reportlab.pdfgen import canvas
        from reportlab.lib.units import cm, mm
        from reportlab.lib import colors
        from reportlab.lib.utils import ImageReader
        from io import BytesIO
        from pathlib import Path

        buf = BytesIO()
        c = canvas.Canvas(buf, pagesize=landscape(A4))
        width, height = landscape(A4)

        # Margins
        margin = 0.5 * cm
        usable_width = width - 2 * margin
        usable_height = height - 2 * margin

        # -- Company Logo (top left) --
        logo_path = Path("assets/logo.png")
        logo_x = margin
        logo_y = height - margin - 14*mm
        logo_w = 28 * mm
        logo_h = 18 * mm
        if logo_path.exists():
            img = ImageReader(str(logo_path))
            c.drawImage(img, logo_x, logo_y, width=logo_w, height=logo_h, preserveAspectRatio=True, mask='auto')

        # -- Title (centered) --
        title_y = height - margin - 3*mm
        c.setFont("Helvetica-Bold", 22)
        c.drawCentredString(width/2, title_y, "Out-Turn Report")

        # -- Location subtitle --
        subtitle_y = title_y - 7*mm
        c.setFont("Helvetica-Bold", 12)
        c.drawCentredString(width/2, subtitle_y, f"{location_name} ({location_code})")
        
        # -- Filter subtitle, just below location --
        filter_y = subtitle_y - 6*mm
        c.setFont("Helvetica", 10)
        c.drawCentredString(width/2, filter_y, f"Filter: {filter_text}")
        
        # Clean dataframe for PDF (drop helper/enum/ids)
        df_pdf = dataframe.copy()
        for drop_col in ["Operation Enum", "Ticket ID", "DT"]:
            if drop_col in df_pdf.columns:
                df_pdf = df_pdf.drop(columns=[drop_col])
        
        # -- Table layout --
        cols = list(df_pdf.columns)
        n_cols = len(cols)
        base_col_width = (usable_width) / (n_cols + 1.0)
        col_widths = []
        for idx in range(n_cols):
            if idx == 0 or idx == n_cols - 1:
                col_widths.append(base_col_width * 1.5)
            else:
                col_widths.append(base_col_width)
        total_width = sum(col_widths)
        table_left = margin
        table_top = filter_y - 8*mm  # Table after logo/title/location/filter
        row_height = 9*mm
        max_rows = min(len(df_pdf), 22)

        # -- Table headers (bold, wrap if needed) --
        c.setFont("Helvetica-Bold", 6.5)
        for i, col in enumerate(cols):
            header_text = str(col)
            x_center = table_left + sum(col_widths[:i]) + col_widths[i]/2
            y_header = table_top
            if len(header_text) > 10 and " " in header_text:
                parts = header_text.split(" ")
                first_line = " ".join(parts[:len(parts)//2])
                second_line = " ".join(parts[len(parts)//2:])
                c.drawCentredString(x_center, y_header-12, first_line)
                c.drawCentredString(x_center, y_header-19, second_line)
            else:
                c.drawCentredString(x_center, y_header-12, header_text)

        # --- Table Borders: horizontal line below header ---
        c.setLineWidth(1)
        header_line_y = table_top - row_height
        c.line(table_left, header_line_y, table_left + total_width, header_line_y)

        # --- Table Rows/Content ---
        c.setFont("Helvetica", 7)
        for r in range(max_rows):
            y = header_line_y - (r+1)*row_height
            for i, col in enumerate(cols):
                txt = str(df_pdf.iloc[r][col])
                x_center = table_left + sum(col_widths[:i]) + col_widths[i]/2

                if col == "Operation":
                    # Wrap text to fit cell width
                    wrapped_lines = []
                    max_chars_per_line = int(col_widths[i] // 5)
                    while txt:
                        if len(txt) <= max_chars_per_line:
                            wrapped_lines.append(txt)
                            break
                        else:
                            split_idx = txt.rfind(" ", 0, max_chars_per_line)
                            if split_idx == -1:
                                split_idx = max_chars_per_line
                            wrapped_lines.append(txt[:split_idx])
                            txt = txt[split_idx:].lstrip()
                    for j, line in enumerate(wrapped_lines):
                        c.drawCentredString(x_center, y + row_height/2 - 2 - (j*8), line)
                else:
                    max_chars = int(col_widths[i] // 3.2)
                    if len(txt) > max_chars:
                        txt = txt[:max_chars-3] + "..."
                    c.drawCentredString(x_center, y + row_height/2 - 2, txt)

        # --- Draw Table Cell Borders ---
        from reportlab.lib import colors as _colors
        c.setStrokeColor(_colors.black)
        x = table_left
        for w in col_widths:
            c.line(x, table_top, x, (header_line_y - (max_rows+1)*row_height)+25)
            x += w
        c.line(x, table_top, x, (header_line_y - (max_rows+1)*row_height)+25)  # last border
        for r in range(max_rows+2):
            y = table_top - r*row_height
            c.line(table_left, y, table_left + total_width, y)

        c.save()
        return buf.getvalue()

    # --- Export controls (CSV / XLSX / PDF) ---
    st.markdown("---")
    st.markdown("#### Export Options")
    
    ec1, ec2, ec3 = st.columns([0.25, 0.25, 0.5])

    # CSV / XLSX using a single button with option
    with ec1:
        fmt = st.selectbox("Download as", ["CSV", "XLSX"], index=0, key="otr_dl_fmt")
        if fmt == "CSV":
            data_bytes = fdf.to_csv(index=False).encode("utf-8")
            filename = f"OTR_{loc.code}_{f_from}_{f_to}.csv"
            st.download_button("Download", data=data_bytes, file_name=filename, mime="text/csv", key="otr_dl_csv")
        else:
            from io import BytesIO
            bio = BytesIO()
            with pd.ExcelWriter(bio, engine="xlsxwriter") as writer:
                fdf.to_excel(writer, sheet_name="OTR", index=False)
            filename = f"OTR_{loc.code}_{f_from}_{f_to}.xlsx"
            st.download_button("Download", data=bio.getvalue(), file_name=filename,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key="otr_dl_xlsx")

    # PDF export respects filters
    from io import BytesIO
    import base64
    import streamlit.components.v1 as components

    with ec2:
        selected_tank = f_tank if f_tank and f_tank != "(All Tanks)" else "All Tanks"
        filter_text_parts = []
        filter_text_parts.append(f"Tank: {selected_tank}")
        if f_op and f_op != "(All)": 
            filter_text_parts.append(f"Operation: {f_op}")
        if f_from: 
            filter_text_parts.append(f"From: {f_from}")
        if f_to: 
            filter_text_parts.append(f"To: {f_to}")
        if f_ticket: 
            filter_text_parts.append(f"Ticket: {f_ticket}")
        filter_text = ", ".join(filter_text_parts) if filter_text_parts else "No filters applied"

        if st.button("Download PDF", key="otr_pdf_dl"):
            pdf_bytes = generate_otr_pdf(fdf, selected_tank, filter_text, loc.name, loc.code)
            filename = f"OTR_{loc.code}_{f_from}_{f_to}.pdf"
            st.download_button("Download PDF", data=pdf_bytes, file_name=filename,
                            mime="application/pdf", key="otr_pdf_dl_real")
        
        if st.button("View PDF", key="otr_pdf_view"):
            pdf_bytes = generate_otr_pdf(fdf, selected_tank, filter_text, loc.name, loc.code)
            b64 = base64.b64encode(pdf_bytes).decode("utf-8")
            components.html(
                f"""
                <script>
                (function(){{
                const b64="{b64}";
                const byteChars=atob(b64);
                const byteNums=new Array(byteChars.length);
                for (let i=0;i<byteChars.length;i++) byteNums[i]=byteChars.charCodeAt(i);
                const blob=new Blob([new Uint8Array(byteNums)],{{type:'application/pdf'}});
                const url=URL.createObjectURL(blob);
                window.open(url,'_blank');
                setTimeout(()=>URL.revokeObjectURL(url),60000);
                }})();
                </script>
                """,
                height=0
            )
    
    # --- Summary Statistics ---
    st.markdown("---")
    st.markdown("#### Summary Statistics")
    
    sum_col1, sum_col2, sum_col3, sum_col4, sum_col5 = st.columns(5)
    
    sum_col1.metric("Total Records", len(fdf))
    sum_col2.metric("Total GOV (bbl)", f"{pd.to_numeric(fdf['GOV (bbl)'], errors='coerce').sum():,.2f}")
    sum_col3.metric("Total GSV (bbl)", f"{pd.to_numeric(fdf['GSV (bbl)'], errors='coerce').sum():,.2f}")
    sum_col4.metric("Total NSV (bbl)", f"{pd.to_numeric(fdf['NSV (bbl)'], errors='coerce').sum():,.2f}")
    sum_col5.metric("Avg API @ 60°F", f"{pd.to_numeric(fdf['API @ 60°F'], errors='coerce').mean():.2f}")

# BCCR page
elif page == "BCCR":
    import re
    header("BCCR")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()
    
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("BCCR") is False:
                st.error("🚫 BCCR page is disabled for this location.")
                st.stop()
    except Exception:
        pass

    active_location_id = st.session_state.get("active_location_id")
    user = st.session_state.get("auth_user")
    if not active_location_id:
        st.error("⚠️ No active location selected. Please choose a location from the Home page.")
        st.stop()
    if not user:
        st.error("⚠️ User session expired. Please log in again.")
        st.stop()

    user_role = (user.get("role") or "").lower()

    def _canon(txt: str | None) -> str:
        return re.sub(r"[^A-Z0-9]", "", str(txt or "").upper())

    allowed_loc_tokens = {"JETTY", "ASEMOKU", "ASEMOKUJETTY", "NDONI"}
    lagos_tokens = {"LAGOSHO"}

    with get_session() as s:
        from location_manager import LocationManager
        from models import Location

        current_loc = LocationManager.get_location_by_id(s, active_location_id)
        if not current_loc:
            st.error("Location not found.")
            st.stop()

        current_tokens = {_canon(current_loc.code), _canon(current_loc.name)}
        is_allowed_location = bool(current_tokens & allowed_loc_tokens)
        is_lagos_viewer = bool(current_tokens & lagos_tokens)
        is_admin = user_role in ["admin-operations", "manager"]

        if not (is_allowed_location or is_admin or is_lagos_viewer):
            st.error("⚠️ BCCR is only available for Asemoku Jetty or Ndoni.")
            st.stop()

        def _eligible_location(loc_obj) -> bool:
            tokens = {_canon(loc_obj.code), _canon(loc_obj.name)}
            return bool(tokens & allowed_loc_tokens)

        eligible_locations = [
            loc for loc in s.query(Location).order_by(Location.name).all()
            if _eligible_location(loc)
        ]

    can_select_location = is_admin or is_lagos_viewer
    target_location_id = active_location_id

    if "bccr_target_location_id" not in st.session_state:
        st.session_state["bccr_target_location_id"] = active_location_id

    if can_select_location and eligible_locations:
        options = {loc.id: f"{loc.name} ({loc.code})" for loc in eligible_locations}
        default_id = st.session_state.get("bccr_target_location_id", active_location_id)
        if default_id not in options:
            default_id = eligible_locations[0].id
        target_location_id = st.selectbox(
            "📍 Select BCCR Location",
            options=sorted(options.items(), key=lambda item: item[1]),
            format_func=lambda opt: opt[1],
            index=[idx for idx, (loc_id, _) in enumerate(sorted(options.items(), key=lambda item: item[1]))
                   if loc_id == default_id][0],
            key="bccr_location_selector"
        )[0]
        st.session_state["bccr_target_location_id"] = target_location_id
    else:
        st.session_state["bccr_target_location_id"] = active_location_id

    if not can_select_location and not is_allowed_location:
        st.error("⚠️ BCCR is only available for Asemoku Jetty or Ndoni.")
        st.stop()

    with get_session() as s_target:
        from location_manager import LocationManager
        target_location = LocationManager.get_location_by_id(s_target, target_location_id)
        if not target_location:
            st.error("Target location not found.")
            st.stop()
        target_location_name = target_location.name or "Unknown"
        target_location_code = target_location.code or ""

    st.info(f"📍 **Viewing Location:** {target_location_name} ({target_location_code})")

    if "bccr_selected_yade" not in st.session_state:
        st.session_state["bccr_selected_yade"] = {}
    if "bccr_selected_otr" not in st.session_state:
        st.session_state["bccr_selected_otr"] = {}
    if "bccr_pending" not in st.session_state:
        st.session_state["bccr_pending"] = {}
    if "bccr_records" not in st.session_state:
        st.session_state["bccr_records"] = {}

    def _get_selection(store_key: str) -> set[int]:
        store = st.session_state.setdefault(store_key, {})
        if target_location_id not in store:
            store[target_location_id] = set()
        return store[target_location_id]

    def _set_selection(store_key: str, values: set[int]) -> None:
        st.session_state.setdefault(store_key, {})[target_location_id] = values

    def _get_pending():
        return st.session_state["bccr_pending"].get(target_location_id)

    def _set_pending(data):
        st.session_state["bccr_pending"][target_location_id] = data

    def _get_records() -> list[dict]:
        store = st.session_state["bccr_records"].setdefault(target_location_id, [])
        return store

    def _set_records(records: list[dict]):
        st.session_state["bccr_records"][target_location_id] = records

    def _generate_bccr_pdf(df: pd.DataFrame, location_name: str, location_code: str, filters_text: str) -> bytes:
        """Create a compact PDF table for the BCCR export."""
        from io import BytesIO
        from reportlab.lib import colors
        from reportlab.lib.enums import TA_CENTER, TA_LEFT
        from reportlab.lib.pagesizes import landscape, A4
        from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet
        from reportlab.platypus import Paragraph, SimpleDocTemplate, Spacer, Table, TableStyle
        import numbers

        buffer = BytesIO()
        doc = SimpleDocTemplate(
            buffer,
            pagesize=landscape(A4),
            leftMargin=25,
            rightMargin=25,
            topMargin=35,
            bottomMargin=25,
        )

        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            "BCCRTitle",
            parent=styles["Title"],
            alignment=TA_CENTER,
            fontSize=18,
        )
        subtitle_style = ParagraphStyle(
            "BCCRSubtitle",
            parent=styles["Heading3"],
            alignment=TA_CENTER,
            fontSize=12,
        )
        filter_style = ParagraphStyle(
            "BCCRFilters",
            parent=styles["BodyText"],
            alignment=TA_CENTER,
            fontSize=10,
        )
        table_text_style = ParagraphStyle(
            "BCCRTable",
            parent=styles["BodyText"],
            alignment=TA_LEFT,
            fontSize=9,
        )

        elements = [
            Paragraph("BCCR Report", title_style),
            Paragraph(f"{location_name} ({location_code})", subtitle_style),
            Paragraph(filters_text, filter_style),
            Spacer(1, 12),
        ]

        if df.empty:
            elements.append(Paragraph("No records available for the selected filters.", table_text_style))
        else:
            table_data = [list(df.columns)]
            for _, row in df.iterrows():
                row_values = []
                for col in df.columns:
                    value = row[col]
                    if value is None:
                        row_values.append("")
                    elif isinstance(value, numbers.Integral):
                        row_values.append(str(int(value)))
                    elif isinstance(value, numbers.Number):
                        row_values.append(f"{float(value):,.2f}")
                    else:
                        row_values.append(str(value))
                table_data.append(row_values)

            table = Table(table_data, repeatRows=1)
            table.setStyle(
                TableStyle(
                    [
                        ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#003366")),
                        ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
                        ("ALIGN", (0, 0), (-1, -1), "CENTER"),
                        ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
                        ("FONTSIZE", (0, 0), (-1, 0), 10),
                        ("FONTSIZE", (0, 1), (-1, -1), 9),
                        ("GRID", (0, 0), (-1, -1), 0.3, colors.grey),
                        ("ROWBACKGROUNDS", (0, 1), (-1, -1), [colors.whitesmoke, colors.lightgrey]),
                        ("VALIGN", (0, 0), (-1, -1), "MIDDLE"),
                    ]
                )
            )
            elements.append(table)

        doc.build(elements)
        return buffer.getvalue()

    def _load_yade_transactions(location_id: int) -> list[dict]:
        with get_session() as s_load:
            from models import TOAYadeSummary, TOAYadeStage, YadeVoyage

            summaries = (
                s_load.query(TOAYadeSummary, YadeVoyage)
                .join(YadeVoyage, TOAYadeSummary.voyage_id == YadeVoyage.id)
                .filter(YadeVoyage.location_id == location_id)
                .order_by(TOAYadeSummary.date.desc(), TOAYadeSummary.time.desc())
                .limit(200)
                .all()
            )
            if not summaries:
                return []

            voyage_ids = [summary.voyage_id for summary, _ in summaries]
            stages = (
                s_load.query(TOAYadeStage)
                .filter(TOAYadeStage.voyage_id.in_(voyage_ids))
                .all()
            )

            stage_map: dict[int, dict[str, TOAYadeStage]] = {}
            for stage in stages:
                stage_map.setdefault(stage.voyage_id, {})[(stage.stage or "").strip().lower()] = stage

            rows = []
            for summary, voyage in summaries:
                per_stage = stage_map.get(summary.voyage_id, {})
                before = per_stage.get("before")
                after = per_stage.get("after")
                rob_qty = float(getattr(before, "nsv_bbl", 0.0) or 0.0)
                rob_water = float(getattr(before, "fw_bbl", 0.0) or 0.0)
                tob_qty = float(getattr(after, "nsv_bbl", 0.0) or 0.0)
                tob_water = float(getattr(after, "fw_bbl", 0.0) or 0.0)
                net_loaded = float(summary.gsv_loaded_bbl or (tob_qty - rob_qty))
                net_water = float(tob_water - rob_water)
                rows.append(
                    {
                        "id": summary.id,
                        "Date": summary.date,
                        "Convoy No": summary.convoy_no or "",
                        "Yade No": summary.yade_name or "",
                        "ROB Qty": round(rob_qty, 2),
                        "ROB Water": round(rob_water, 2),
                        "TOB Qty": round(tob_qty, 2),
                        "TOB Water": round(tob_water, 2),
                        "Net Loaded": round(net_loaded, 2),
                        "Net Water": round(net_water, 2),
                    }
                )
            return rows

    def _load_dispatch_rows(location_id: int) -> list[dict]:
        with get_session() as s_load:
            records = (
                s_load.query(OTRRecord)
                .filter(OTRRecord.location_id == location_id)
                .order_by(OTRRecord.date.asc(), OTRRecord.time.asc())
                .all()
            )
            if not records:
                return []

            data = []
            for rec in records:
                tank_label = getattr(rec, "tank_name", None) or (rec.tank_id or "")
                dt_val = rec.date
                tm_val = rec.time
                data.append(
                    {
                        "id": rec.id,
                        "Ticket ID": rec.ticket_id,
                        "Tank": tank_label,
                        "Date": rec.date,
                        "Time": tm_val,
                        "Operation": rec.operation or "",
                        "NSV (bbl)": float(rec.nsv_bbl or 0.0),
                        "Free Water (bbl)": float(rec.free_water_bbl or 0.0),
                    }
                )

            if not data:
                return []

            df = pd.DataFrame(data)
            df["Tank"] = df["Tank"].fillna("")
            df["DT"] = pd.to_datetime(df["Date"]) + pd.to_timedelta(
                df["Time"].astype(str).replace("None", "00:00:00")
            )
            df.sort_values(["Tank", "DT"], inplace=True)

            df["Prev NSV"] = df.groupby("Tank")["NSV (bbl)"].shift(1)
            df["Prev FW"] = df.groupby("Tank")["Free Water (bbl)"].shift(1)
            df["Net Rece/Disp (bbls)"] = df["NSV (bbl)"] - df["Prev NSV"]
            df["Net Water Rece/Disp (bbls)"] = df["Free Water (bbl)"] - df["Prev FW"]

            df = df[df["Operation"].str.strip().str.lower() == "dispatch to barge"]
            df = df.sort_values("Date", ascending=False).head(200)

            df["Net Rece/Disp (bbls)"] = df["Net Rece/Disp (bbls)"].round(2)
            df["Net Water Rece/Disp (bbls)"] = df["Net Water Rece/Disp (bbls)"].round(2)

            rows = df[
                [
                    "id",
                    "Date",
                    "Ticket ID",
                    "Tank",
                    "Operation",
                    "Net Rece/Disp (bbls)",
                    "Net Water Rece/Disp (bbls)",
                ]
            ].to_dict(orient="records")
            return rows

    yade_rows = _load_yade_transactions(target_location_id)
    otr_rows = _load_dispatch_rows(target_location_id)
    yade_lookup = {row["id"]: row for row in yade_rows}
    otr_lookup = {row["id"]: row for row in otr_rows}

    tab_map, tab_report = st.tabs(["Mapping", "BCCR Report"])

    def _render_selectable_table(rows: list[dict], key_prefix: str, column_order: list[str], column_labels: dict[str, str]):
        if not rows:
            st.info("No records available.")
            return set()

        df = pd.DataFrame(rows).reset_index(drop=True)
        if "Date" in df.columns:
            df["Date"] = pd.to_datetime(df["Date"], errors="coerce").dt.strftime("%d-%b-%Y")
        df = df[column_order].copy()
        selection_key = f"{key_prefix}_selected"
        selected_ids = set(_get_selection(f"bccr_{selection_key}"))
        df.insert(0, "Select", df[column_order[0]].index.map(lambda idx: rows[idx]["id"] in selected_ids))
        df.insert(1, "Item ID", [rows[idx]["id"] for idx in range(len(rows))])

        editor_key = f"{key_prefix}_editor_{target_location_id}"
        edited = st.data_editor(
            df,
            hide_index=True,
            use_container_width=True,
            key=editor_key,
            column_config={
                "Select": st.column_config.CheckboxColumn("Select"),
                "Item ID": st.column_config.Column("ID", help="Internal reference", disabled=True),
                **{field: st.column_config.Column(column_labels.get(field, field)) for field in column_order}
            },
            disabled=[col for col in df.columns if col not in {"Select"}],
        )

        if isinstance(edited, pd.DataFrame):
            new_selected = set(
                edited.loc[edited["Select"], "Item ID"].astype(int).tolist()
            )
        else:
            edited_df = pd.DataFrame(edited)
            new_selected = set(
                edited_df.loc[edited_df["Select"], "Item ID"].astype(int).tolist()
            )

        _set_selection(f"bccr_{selection_key}", new_selected)
        return new_selected

    with tab_map:
        st.markdown("### Mapping")
        st.caption("Select YADE and Dispatch entries to compare and map them into BCCR records.")

        map_col1, map_col2 = st.columns(2)

        with map_col1:
            st.subheader("YADE Transactions (TOA)")
            yc1, yc2 = st.columns(2)
            with yc1:
                yade_convoy_filter = st.text_input(
                    "Convoy No",
                    key=f"bccr_yade_convoy_{target_location_id}"
                )
                yade_no_filter = st.text_input(
                    "Yade No",
                    key=f"bccr_yade_yade_{target_location_id}"
                )
            with yc2:
                yade_date_filter = st.date_input(
                    "Date",
                    value=None,
                    key=f"bccr_yade_date_{target_location_id}"
                )

            def _matches_yade(row):
                if yade_convoy_filter and yade_convoy_filter.strip():
                    if yade_convoy_filter.strip().lower() not in (row.get("Convoy No") or "").lower():
                        return False
                if yade_no_filter and yade_no_filter.strip():
                    if yade_no_filter.strip().lower() not in (row.get("Yade No") or "").lower():
                        return False
                if yade_date_filter and row.get("Date"):
                    if row["Date"] != yade_date_filter:
                        return False
                return True

            filtered_yade_rows = [r for r in yade_rows if _matches_yade(r)]

            yade_selected = _render_selectable_table(
                filtered_yade_rows,
                "yade",
                ["Date", "Convoy No", "Yade No", "ROB Qty", "ROB Water", "TOB Qty", "TOB Water", "Net Loaded", "Net Water"],
                {
                    "Date": "Date",
                    "Convoy No": "Convoy No",
                    "Yade No": "Yade No",
                    "ROB Qty": "ROB Qty (bbls)",
                    "ROB Water": "ROB Water (bbls)",
                    "TOB Qty": "TOB Qty (bbls)",
                    "TOB Water": "TOB Water (bbls)",
                    "Net Loaded": "Net Loaded (bbls)",
                    "Net Water": "Net Water (bbls)",
                }
            )

        with map_col2:
            st.subheader("Dispatch to Barge (OTR)")
            oc1, oc2 = st.columns(2)
            with oc1:
                otr_date_filter = st.date_input(
                    "Date",
                    value=None,
                    key=f"bccr_otr_date_{target_location_id}"
                )
            with oc2:
                otr_tank_filter = st.text_input(
                    "Tank",
                    key=f"bccr_otr_tank_{target_location_id}"
                )

            def _matches_otr(row):
                if otr_date_filter and row.get("Date"):
                    if row["Date"] != otr_date_filter:
                        return False
                if otr_tank_filter and otr_tank_filter.strip():
                    if otr_tank_filter.strip().lower() not in (row.get("Tank") or "").lower():
                        return False
                return True

            filtered_otr_rows = [r for r in otr_rows if _matches_otr(r)]

            otr_selected = _render_selectable_table(
                filtered_otr_rows,
                "otr",
                ["Date", "Ticket ID", "Tank", "Operation", "Net Rece/Disp (bbls)", "Net Water Rece/Disp (bbls)"],
                {
                    "Date": "Date",
                    "Ticket ID": "Ticket",
                    "Tank": "Tank",
                    "Operation": "Operation",
                    "Net Rece/Disp (bbls)": "Net Rece/Disp (bbls)",
                    "Net Water Rece/Disp (bbls)": "Net Water Rece/Disp (bbls)",
                }
            )

        can_map = bool(yade_selected and otr_selected)
        if st.button("MAP Selected Rows", disabled=not can_map, type="primary"):
            if not can_map:
                st.warning("Please select at least one YADE record and one Dispatch record.")
            else:
                selected_yade_rows = [yade_lookup[row_id] for row_id in yade_selected if row_id in yade_lookup]
                selected_otr_rows = [otr_lookup[row_id] for row_id in otr_selected if row_id in otr_lookup]

                if not selected_yade_rows or not selected_otr_rows:
                    st.warning("Unable to locate selected rows. Please try again.")
                else:
                    pending_payload = {
                        "yade_ids": list(yade_selected),
                        "otr_ids": list(otr_selected),
                        "rob_qty": round(sum(r["ROB Qty"] for r in selected_yade_rows), 2),
                        "rob_water": round(sum(r["ROB Water"] for r in selected_yade_rows), 2),
                        "tob_qty": round(sum(r["TOB Qty"] for r in selected_yade_rows), 2),
                        "tob_water": round(sum(r["TOB Water"] for r in selected_yade_rows), 2),
                        "net_yade": round(sum(r["Net Loaded"] for r in selected_yade_rows), 2),
                        "net_water": round(sum(r["Net Water"] for r in selected_yade_rows), 2),
                        "bccr_qty": round(sum(r["Net Rece/Disp (bbls)"] for r in selected_otr_rows if isinstance(r["Net Rece/Disp (bbls)"], (int, float))), 2),
                    }
                    _set_pending(pending_payload)
                    _set_selection("bccr_yade_selected", set())
                    _set_selection("bccr_otr_selected", set())
                    st.session_state.pop(f"yade_editor_{target_location_id}", None)
                    st.session_state.pop(f"otr_editor_{target_location_id}", None)
                    st.success("Selections mapped. Review and finalize in the BCCR Report tab.")

    with tab_report:
        st.markdown("### BCCR Report")
        pending_data = _get_pending()
        records = _get_records()

        rep_col1, rep_col2 = st.columns(2)
        with rep_col1:
            report_date_filter = st.date_input(
                "Filter by Date",
                value=None,
                key=f"bccr_report_date_{target_location_id}"
            )
        with rep_col2:
            report_convoy_filter = st.text_input(
                "Filter by Convoy No",
                key=f"bccr_report_convoy_{target_location_id}"
            )

        export_container = st.container()

        if pending_data:
            st.info("Pending mapping detected. Review the values below and save to BCCR report.")
            default_sno = max([rec["sno"] for rec in records], default=0) + 1
            with st.form(f"bccr_add_form_{target_location_id}"):
                col1, col2 = st.columns(2)
                with col1:
                    new_sno = st.number_input("S.No", min_value=1, value=default_sno, step=1)
                    new_date = st.date_input("Date", value=date.today())
                    new_convoy = st.text_input("Convoy No", value="")
                    new_rob_qty = st.number_input("ROB Qty (bbls)", value=float(pending_data["rob_qty"]), format="%.2f")
                    new_rob_water = st.number_input("ROB Water (bbls)", value=float(pending_data["rob_water"]), format="%.2f")
                    new_tob_qty = st.number_input("TOB Qty (bbls)", value=float(pending_data["tob_qty"]), format="%.2f")
                with col2:
                    new_tob_water = st.number_input("TOB Water (bbls)", value=float(pending_data["tob_water"]), format="%.2f")
                    new_net_yade = st.number_input("Net YADE Receipt (bbls)", value=float(pending_data["net_yade"]), format="%.2f")
                    new_net_water = st.number_input("Net Water (bbls)", value=float(pending_data["net_water"]), format="%.2f")
                    new_bccr_qty = st.number_input("BCCR Quantity (bbls)", value=float(pending_data["bccr_qty"]), format="%.2f")
                    difference_value = new_bccr_qty - new_net_yade
                    st.metric("Difference (BCCR - YADE)", f"{difference_value:,.2f} bbls")
                new_remarks = st.text_area("Remarks", value="")

                if st.form_submit_button("Save BCCR Mapping", type="primary"):
                    record = {
                        "id": str(uuid4()),
                        "sno": int(new_sno),
                        "date": new_date.strftime("%Y-%m-%d"),
                        "convoy": new_convoy,
                        "rob_qty": round(new_rob_qty, 2),
                        "rob_water": round(new_rob_water, 2),
                        "tob_qty": round(new_tob_qty, 2),
                        "tob_water": round(new_tob_water, 2),
                        "net_yade": round(new_net_yade, 2),
                        "net_water": round(new_net_water, 2),
                        "bccr_qty": round(new_bccr_qty, 2),
                        "difference": round(difference_value, 2),
                        "remarks": new_remarks.strip(),
                    }
                    records.append(record)
                    _set_records(records)
                    _set_pending(None)
                    st.success("Mapping saved.")
        else:
            st.caption("Select records in the Mapping tab and click MAP to create a pending entry.")

        def _record_matches(rec: dict) -> bool:
            if report_date_filter:
                try:
                    rec_date = datetime.strptime(rec["date"], "%Y-%m-%d").date()
                    if rec_date != report_date_filter:
                        return False
                except Exception:
                    return False
            if report_convoy_filter and report_convoy_filter.strip():
                if report_convoy_filter.strip().lower() not in (rec.get("convoy") or "").lower():
                    return False
            return True

        filtered_records = [rec for rec in records if _record_matches(rec)]
        column_map = {
            "sno": "S.No",
            "date": "Date",
            "convoy": "Convoy No",
            "rob_qty": "ROB Qty",
            "rob_water": "ROB Water",
            "tob_qty": "TOB Qty",
            "tob_water": "TOB Water",
            "net_yade": "Net YADE Receipt",
            "net_water": "Net Water",
            "bccr_qty": "BCCR Quantity",
            "difference": "Difference Yade vs BCCR",
            "remarks": "Remarks",
        }
        download_df = pd.DataFrame()
        if filtered_records:
            records_df_sorted = pd.DataFrame(filtered_records).sort_values("sno")
            renamed_df = records_df_sorted.rename(columns=column_map)
            download_df = renamed_df.drop(columns=["id"], errors="ignore")

        export_disabled = download_df.empty
        filter_parts = []
        if report_date_filter:
            filter_parts.append(f"Date: {report_date_filter.strftime('%d %b %Y')}")
        if report_convoy_filter and report_convoy_filter.strip():
            filter_parts.append(f"Convoy: {report_convoy_filter.strip()}")
        filter_description = " | ".join(filter_parts) if filter_parts else "No filters applied"

        date_token = report_date_filter.strftime("%Y%m%d") if report_date_filter else "ALL"
        convoy_raw = (report_convoy_filter or "").strip()
        convoy_token = re.sub(r"[^A-Za-z0-9]+", "_", convoy_raw).strip("_") or "ALL"
        location_token = _canon(target_location_code) or _canon(target_location_name) or "LOCATION"
        base_filename = f"BCCR_{location_token}_{date_token}_{convoy_token}"

        from io import BytesIO

        csv_bytes = download_df.to_csv(index=False).encode("utf-8") if not export_disabled else b""
        xlsx_bytes = b""
        if not export_disabled:
            xlsx_buffer = BytesIO()
            with pd.ExcelWriter(xlsx_buffer, engine="xlsxwriter") as writer:
                download_df.to_excel(writer, sheet_name="BCCR", index=False)
            xlsx_bytes = xlsx_buffer.getvalue()

        pdf_bytes = b""
        pdf_error_message = None
        if not export_disabled:
            try:
                pdf_bytes = _generate_bccr_pdf(download_df, target_location_name, target_location_code, filter_description)
            except Exception as exc:
                pdf_error_message = str(exc)
                pdf_bytes = b""

        with export_container:
            st.markdown("#### Export & Downloads")
            col_csv, col_xlsx, col_pdf, col_view = st.columns(4)
            with col_csv:
                st.download_button(
                    "📥 CSV",
                    data=csv_bytes,
                    file_name=f"{base_filename}.csv",
                    mime="text/csv",
                    disabled=export_disabled,
                    key=f"bccr_csv_{target_location_id}",
                )
            with col_xlsx:
                st.download_button(
                    "📥 XLSX",
                    data=xlsx_bytes,
                    file_name=f"{base_filename}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    disabled=export_disabled,
                    key=f"bccr_xlsx_{target_location_id}",
                )
            with col_pdf:
                st.download_button(
                    "📥 PDF",
                    data=pdf_bytes,
                    file_name=f"{base_filename}.pdf",
                    mime="application/pdf",
                    disabled=export_disabled or pdf_error_message is not None,
                    key=f"bccr_pdf_{target_location_id}",
                )
            with col_view:
                if st.button(
                    "👁️ View PDF",
                    key=f"bccr_pdf_view_{target_location_id}",
                    disabled=export_disabled or pdf_error_message is not None,
                ):
                    import base64
                    import streamlit.components.v1 as components

                    b64 = base64.b64encode(pdf_bytes).decode("utf-8")
                    components.html(
                        f"""
                        <script>
                            const pdfData = "{b64}";
                            const byteCharacters = atob(pdfData);
                            const byteNumbers = new Array(byteCharacters.length);
                            for (let i = 0; i < byteCharacters.length; i++) {{
                                byteNumbers[i] = byteCharacters.charCodeAt(i);
                            }}
                            const byteArray = new Uint8Array(byteNumbers);
                            const file = new Blob([byteArray], {{ type: "application/pdf" }});
                            const fileURL = URL.createObjectURL(file);
                            window.open(fileURL, "_blank");
                        </script>
                        """,
                        height=0,
                    )
                    st.success("BCCR PDF opened in a new tab.")

            if pdf_error_message:
                st.warning(f"PDF export unavailable: {pdf_error_message}")

        if filtered_records:
            st.subheader("Mapped Records")
            st.dataframe(download_df, use_container_width=True, hide_index=True)

            for rec in filtered_records:
                if st.button(f"Delete S.No {rec['sno']}", key=f"bccr_delete_{rec['id']}"):
                    records = [r for r in records if r["id"] != rec["id"]]
                    _set_records(records)
                    st.success(f"Deleted mapping S.No {rec['sno']}")
                    break

        else:
            st.info("No BCCR mappings found for the current filters.")

# MATERIAL BALANCE � placeholder reports
elif page == "Material Balance":
    header("Material Balance")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("Material Balance") is False:
                st.error("⚠️ Material Balance page is disabled for this location.")
                st.stop()
    except Exception:
        pass
    
    from datetime import datetime, date, time, timedelta
    from io import BytesIO
    import pandas as pd
    import base64
    from reportlab.pdfgen import canvas
    from reportlab.lib.pagesizes import A4, landscape
    from reportlab.lib import colors
    from reportlab.lib.units import cm, mm
    from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.enums import TA_CENTER
    from reportlab.lib.utils import ImageReader
    from pathlib import Path
    import streamlit.components.v1 as components
    
    # Import material balance modules
    from material_balance_config import MaterialBalanceConfig
    from material_balance_calculator import MaterialBalanceCalculator
    
    # ============ LOCATION ACCESS CHECK ============
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("⚠️ No active location selected. Please select a location from the Home page.")
        st.stop()

    # Verify user has access to this location
    user = st.session_state.get("auth_user")
    if user:
        from auth import AuthManager
        if not AuthManager.can_access_location(user, active_location_id):
            st.error("🚫 You do not have access to this location.")
            st.stop()

    # Get location details
    with get_session() as s:
        from location_manager import LocationManager
        from models import Location
        
        loc = LocationManager.get_location_by_id(s, active_location_id)
        if not loc:
            st.error("? Location not found.")
            st.stop()
        
        location_code = loc.code
        location_name = loc.name
        
        st.info(f"📍 **Active Location:** {location_name} ({location_code})")
    
    st.markdown("### 📊 Material Balance Report")
    st.caption("Auto-calculated from OTR records (06:01 - 06:00)")
    
    # Check if material balance is configured for this location
    config = MaterialBalanceConfig.get_config(location_code)
    
    if not config:
        st.warning(f"⚠️ Material Balance is not configured for {location_name}")
        st.info("Please contact administrator to configure material balance for this location.")
        
        with st.expander("🐞 Debug Info"):
            st.write(f"Location Code: '{location_code}'")
            st.write(f"Available Configs: {list(MaterialBalanceConfig.LOCATION_COLUMNS.keys())}")
        
        st.stop()
    
    # Display location-specific configuration
    st.success(f"Material Balance configured for {config['name']}")
    
    # ============ FILTERS ============
    st.markdown("#### Filters")
    
    filter_col1, filter_col2, filter_col3 = st.columns([1, 1, 1])
    
    otr_first_date = None
    with get_session() as s_otr_min:
        try:
            otr_first_date = (
                s_otr_min.query(func.min(OTRRecord.date))
                .filter(OTRRecord.location_id == active_location_id)
                .scalar()
            )
        except Exception:
            otr_first_date = None
    default_mb_from = otr_first_date or (date.today() - timedelta(days=7))

    with filter_col1:
        mb_date_from = st.date_input(
            "From Date",
            value=st.session_state.get("mb_from", default_mb_from),
            min_value=otr_first_date or default_mb_from,
            key="mb_from"
        )

    with filter_col2:
        mb_date_to = st.date_input(
            "To Date",
            value=date.today(),
            key="mb_to"
        )
    
    with filter_col3:
        # Tank filter (optional)
        with get_session() as s:
            from models import Tank
            tanks_all = s.query(Tank).filter(
                Tank.location_id == active_location_id
            ).order_by(Tank.name).all()
        
        tank_opts = ["All Tanks"] + [t.name for t in tanks_all]
        f_tank = st.selectbox("Tank", tank_opts, index=0, key="mb_tank")
    
    st.markdown("---")
    # Determine earliest OTR date for this location (for proper opening stock continuity)
    earliest_otr_date = None
    with get_session() as s:
        try:
            earliest_otr_date = s.query(func.min(OTRRecord.date)).filter(OTRRecord.location_id == active_location_id).scalar()
        except Exception:
            earliest_otr_date = None

    # ============ CALCULATE MATERIAL BALANCE ============
    try:
        # ? Calculate material balance using OTR data (location_id based)
        calc_from = mb_date_from
        if earliest_otr_date:
            if earliest_otr_date < calc_from:
                calc_from = earliest_otr_date
        mb_data = MaterialBalanceCalculator.calculate_material_balance(
            entries=None,                         # let the calculator fetch from DB
            location_code=location_code,
            date_from=calc_from,
            date_to=mb_date_to,
            location_id=active_location_id        # <-- important
        )

        
        if not mb_data:
            st.info("ℹ️ No data available for material balance calculation.")
            st.info("ℹ️ Add transactions in Tank Transactions to see material balance here.")
        else:

            # Create DataFrame

            mb_df = pd.DataFrame(mb_data)



            if mb_df.empty:

                st.info("dY\"- No data available for material balance calculation.")

                st.info("dY'? Add transactions in Tank Transactions to see material balance here.")

                st.stop()



            mb_df["Date"] = pd.to_datetime(mb_df["Date"], errors="coerce")

            mb_df = mb_df.dropna(subset=["Date"]).sort_values("Date").reset_index(drop=True)



            if mb_df.empty:

                st.info("dY\"- No data available for material balance calculation.")

                st.stop()



            mb_df_full = mb_df.copy()
            prev_rows = mb_df_full[mb_df_full["Date"].dt.date < mb_date_from]

            def _anchor_value(series, default=0.0):
                try:
                    raw = series
                    if isinstance(raw, str):
                        raw = raw.replace(",", "")
                    return float(raw if raw not in (None, "") else default)
                except Exception:
                    try:
                        return float(raw)
                    except Exception:
                        return float(default)

            if not prev_rows.empty and "Closing Stock" in prev_rows.columns:
                opening_anchor = _anchor_value(prev_rows["Closing Stock"].iloc[-1])
            elif "Opening Stock" in mb_df_full.columns:
                opening_anchor = _anchor_value(mb_df_full["Opening Stock"].iloc[0])
            else:
                opening_anchor = 0.0

            if "Closing Stock" in mb_df_full.columns:
                closing_anchor = _anchor_value(mb_df_full["Closing Stock"].iloc[-1])
            else:
                closing_anchor = 0.0

            view_mask = (
                (mb_df_full["Date"].dt.date >= mb_date_from) &
                (mb_df_full["Date"].dt.date <= mb_date_to)
            )

            mb_df = mb_df_full.loc[view_mask].copy()



            if mb_df.empty:

                st.info("dY\"- No material balance rows within the selected filter range.")

                st.stop()



            mb_df["Date"] = mb_df["Date"].dt.strftime("%Y-%m-%d")

            total_days = len(mb_df)

            st.markdown(f"#### 📊 Material Balance - {config['name']} ({total_days} days)")
            st.caption("? Auto-calculated from OTR records")
            
            # ============ SUMMARY STATISTICS ============
            st.markdown("---")
            st.markdown("#### 📊 Summary")
            
            # Calculate totals based on location-specific columns
            total_opening = opening_anchor
            total_closing = closing_anchor
            
            # Calculate total receipts (sum of all receipt columns)
            receipt_columns = [col for col in mb_df.columns if 'Receipt' in col and col not in ['Book Closing Stock']]
            total_receipts = sum(mb_df[col].sum() for col in receipt_columns)
            
            # Calculate total dispatches (sum of all dispatch columns)
            dispatch_columns = [col for col in mb_df.columns if 'Dispatch' in col or 'dispatch' in col]
            total_dispatches = sum(mb_df[col].sum() for col in dispatch_columns)
            
            # Total loss/gain
            total_loss_gain = mb_df["Loss/Gain"].sum() if "Loss/Gain" in mb_df.columns else 0.0
            
            # Calculate loss/gain percentage
            loss_gain_pct = (total_loss_gain / total_receipts * 100.0) if total_receipts > 0 else 0.0
            
            sum_col1, sum_col2, sum_col3, sum_col4, sum_col5 = st.columns(5)
            
            with sum_col1:
                st.metric("Opening Stock", f"{total_opening:,.0f} bbls")
            
            with sum_col2:
                st.metric("Total Receipts", f"{total_receipts:,.0f} bbls")
            
            with sum_col3:
                st.metric("Total Dispatches", f"{total_dispatches:,.0f} bbls")
            
            with sum_col4:
                st.metric("Closing Stock", f"{total_closing:,.0f} bbls")
            
            with sum_col5:
                st.metric(
                    "Total Loss/Gain",
                    f"{total_loss_gain:,.2f} bbls",
                    delta=f"{loss_gain_pct:.2f}%",
                    delta_color="normal" if total_loss_gain >= 0 else "inverse"
                )

            st.caption("Opening/Closing stocks always reflect the full data range; other metrics follow the active filters.")
            
            st.markdown("---")
            
            # ============ DATA TABLE WITH TOTALS ============
            # Calculate totals row
            totals_row = {"Date": "TOTAL"}
            
            for col in mb_df.columns:
                if col == "Date":
                    continue
                elif col in ["Opening Stock", "Closing Stock", "Book Closing Stock"]:
                    totals_row[col] = ""  # Don't sum these
                elif col == "Loss/Gain":
                    totals_row[col] = round(mb_df[col].sum(), 2)
                else:
                    totals_row[col] = round(mb_df[col].sum(), 2)
            
            # Add totals row to dataframe
            mb_df_with_totals = pd.concat([mb_df, pd.DataFrame([totals_row])], ignore_index=True)
            
            # Display table
            st.dataframe(
                mb_df_with_totals,
                use_container_width=True,
                hide_index=True,
                column_config={
                    col: st.column_config.NumberColumn(
                        col,
                        format="%.2f" if col != "Date" else None
                    ) for col in mb_df_with_totals.columns
                }
            )
            
            # ============ EXPORT OPTIONS ============
            st.markdown("---")
            st.markdown("#### 📤 Export Options")
            
            ec1, ec2, ec3 = st.columns(3)
            
            # CSV/Excel Download
            with ec1:
                fmt = st.selectbox("Download as", ["CSV", "XLSX"], index=0, key="mb_dl_fmt")
                
                if fmt == "CSV":
                    data_bytes = mb_df.to_csv(index=False).encode("utf-8")
                    st.download_button(
                        "⬇️ Download",
                        data=data_bytes,
                        file_name=f"MaterialBalance_{location_code}_{mb_date_from}_{mb_date_to}.csv",
                        mime="text/csv",
                        key="mb_dl_csv",
                        use_container_width=True
                    )
                else:
                    bio = BytesIO()
                    with pd.ExcelWriter(bio, engine="xlsxwriter") as writer:
                        mb_df.to_excel(writer, sheet_name="MaterialBalance", index=False)
                    st.download_button(
                        "⬇️ Download",
                        data=bio.getvalue(),
                        file_name=f"MaterialBalance_{location_code}_{mb_date_from}_{mb_date_to}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key="mb_dl_xlsx",
                        use_container_width=True
                    )
            
            # PDF Generation Function
            def generate_mb_pdf(dataframe, df_with_totals, filter_info, location_name, username):
                """Generate professional Material Balance PDF report"""
                buffer = BytesIO()
                
                # Create document with 0.5cm margins
                doc = SimpleDocTemplate(
                    buffer, 
                    pagesize=landscape(A4),
                    leftMargin=0.5*cm,
                    rightMargin=0.5*cm,
                    topMargin=0.5*cm,
                    bottomMargin=0.5*cm
                )
                
                elements = []
                styles = getSampleStyleSheet()
                
                # Custom styles
                title_style = ParagraphStyle(
                    'CustomTitle',
                    parent=styles['Heading1'],
                    fontSize=16,
                    textColor=colors.HexColor('#1f4788'),
                    spaceAfter=8,
                    alignment=TA_CENTER,
                    fontName='Helvetica-Bold'
                )
                
                subtitle_style = ParagraphStyle(
                    'CustomSubtitle',
                    parent=styles['Normal'],
                    fontSize=10,
                    textColor=colors.HexColor('#666666'),
                    spaceAfter=6,
                    alignment=TA_CENTER
                )
                
                # Title
                title = Paragraph(f"<b>MATERIAL BALANCE REPORT</b><br/><font size=14>{location_name}</font>", title_style)
                elements.append(title)
                elements.append(Spacer(1, 0.3*cm))
                
                # Subtitle
                subtitle = Paragraph(f"{filter_info}<br/>Generated: {datetime.now().strftime('%d-%b-%Y %H:%M')}", subtitle_style)
                elements.append(subtitle)
                elements.append(Spacer(1, 0.4*cm))
                
                # Calculate available width
                page_width = landscape(A4)[0] - (1.0*cm)
                table_width = page_width
                
                # Dynamic column widths based on number of columns
                num_cols = len(df_with_totals.columns)
                col_widths = [table_width / num_cols for _ in range(num_cols)]
                
                # Custom paragraph style for centered headers
                header_style = ParagraphStyle(
                    'HeaderStyle',
                    parent=styles['Normal'],
                    fontSize=7,
                    leading=9,
                    alignment=TA_CENTER,
                    fontName='Helvetica-Bold'
                )
                
                # Table headers
                table_data = [[
                    Paragraph(f"<b><font color='white'>{col}</font></b>", header_style)
                    for col in df_with_totals.columns
                ]]
                
                # Custom cell style
                cell_style = ParagraphStyle(
                    'CellStyle',
                    parent=styles['Normal'],
                    fontSize=6,
                    leading=8,
                    alignment=TA_CENTER
                )
                
                # Add data rows
                for idx, row in df_with_totals.iterrows():
                    row_cells = []
                    for col in df_with_totals.columns:
                        val = row[col]
                        
                        # Format value
                        if col == "Date":
                            cell_text = str(val)
                        elif col == "Loss/Gain" and val != "" and val != "TOTAL":
                            # Color code loss/gain
                            try:
                                numeric_val = float(val)
                                color = '#28a745' if numeric_val >= 0 else '#dc3545'
                                cell_text = f"<font color='{color}'><b>{numeric_val:,.2f}</b></font>"
                            except:
                                cell_text = str(val)
                        elif val == "" or val == "TOTAL":
                            cell_text = str(val)
                        else:
                            try:
                                cell_text = f"{float(val):,.2f}"
                            except:
                                cell_text = str(val)
                        
                        # Make totals row bold
                        if idx == len(df_with_totals) - 1 and val != "":
                            cell_text = f"<b>{cell_text}</b>"
                        
                        row_cells.append(Paragraph(cell_text, cell_style))
                    
                    table_data.append(row_cells)
                
                # Create table
                table = Table(table_data, colWidths=col_widths, repeatRows=1)
                table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1f4788')),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, 0), 7),
                    ('BOTTOMPADDING', (0, 0), (-1, 0), 5),
                    ('TOPPADDING', (0, 0), (-1, 0), 5),
                    ('BACKGROUND', (0, 1), (-1, -2), colors.HexColor('#f8f9fa')),
                    ('ROWBACKGROUNDS', (0, 1), (-1, -2), [colors.white, colors.HexColor('#f8f9fa')]),
                    ('BACKGROUND', (0, -1), (-1, -1), colors.HexColor('#e9ecef')),  # Totals row
                    ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
                    ('FONTSIZE', (0, 1), (-1, -1), 6),
                    ('TEXTCOLOR', (0, 1), (-1, -1), colors.HexColor('#333333')),
                    ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
                    ('BOX', (0, 0), (-1, -1), 1, colors.HexColor('#1f4788')),
                    ('LEFTPADDING', (0, 0), (-1, -1), 2),
                    ('RIGHTPADDING', (0, 0), (-1, -1), 2),
                    ('TOPPADDING', (0, 1), (-1, -1), 3),
                    ('BOTTOMPADDING', (0, 1), (-1, -1), 3),
                ]))
                
                elements.append(table)
                
                # Footer
                elements.append(Spacer(1, 0.3*cm))
                footer_text = f"<font size=7 color='#666666'>Generated by: {username} | OTMS - Oil Terminal Management System | {datetime.now().strftime('%d-%b-%Y %H:%M:%S')}</font>"
                elements.append(Paragraph(footer_text, subtitle_style))
                
                doc.build(elements)
                pdf_data = buffer.getvalue()
                buffer.close()
                
                return pdf_data
            
            # Filter info for PDF
            filter_info = f"Tank: {f_tank} | Period: {mb_date_from} to {mb_date_to}"
            
            # PDF Download
            with ec2:
                if st.button("📥 Download PDF", key="mb_pdf_dl", use_container_width=True):
                    pdf_bytes = generate_mb_pdf(
                        mb_df, 
                        mb_df_with_totals, 
                        filter_info, 
                        location_name,
                        user['username']
                    )
                    st.download_button(
                        "💾 Save PDF",
                        data=pdf_bytes,
                        file_name=f"MaterialBalance_{location_code}_{mb_date_from}_{mb_date_to}.pdf",
                        mime="application/pdf",
                        key="mb_pdf_dl_real",
                        use_container_width=True
                    )

            # PDF View
            with ec3:
                if st.button("👁️ View PDF", key="mb_pdf_view_mb", use_container_width=True):
                    pdf_bytes = generate_mb_pdf(
                        mb_df, 
                        mb_df_with_totals, 
                        filter_info, 
                        location_name,
                        user['username']
                    )
                    b64 = base64.b64encode(pdf_bytes).decode("utf-8")
                    components.html(
                        f"""
                        <script>
                        (function(){{
                        const b64="{b64}";
                        const byteChars=atob(b64);
                        const byteNums=new Array(byteChars.length);
                        for (let i=0;i<byteChars.length;i++) byteNums[i]=byteChars.charCodeAt(i);
                        const blob=new Blob([new Uint8Array(byteNums)],{{type:'application/pdf'}});
                        const url=URL.createObjectURL(blob);
                        window.open(url,'_blank');
                        setTimeout(()=>URL.revokeObjectURL(url),60000);
                        }})();
                        </script>
                        """,
                        height=0
                    )
                    st.success("? PDF opened in new tab!")
    
    except Exception as ex:
        st.error(f"? Failed to calculate material balance: {ex}")
        import traceback
        with st.expander("⚠️ Error Details"):
            st.code(traceback.format_exc())
            
# =================================== ADD ASSET - admin only =============================
elif page == "Add Asset":
    from sqlalchemy.exc import IntegrityError

    if st.session_state.get("auth_user", {}).get("role") != "admin-operations":
        header("Add Asset")
        st.subheader("Assets")
        st.error("You do not have permission to access this page. Admin-Operations only.")
        st.stop()

    header("Add Asset")
    st.subheader("Assets")

    # ============ LOCATION CONTEXT ============
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.warning("⚠️ Please select a location from the Home page first.")
        st.stop()

    # Display current location
    with get_session() as s:
        from location_manager import LocationManager
        loc = LocationManager.get_location_by_id(s, active_location_id)
        if loc:
            st.info(f"📍 **Adding assets to Location:** {loc.name} ({loc.code})")

    # ------------------------ Shared helpers (once) ------------------------
    def _read_table(file) -> pd.DataFrame:
        """Read CSV/XLSX to DataFrame and lowercase headers."""
        name = (getattr(file, "name", "") or "").lower()
        try:
            if name.endswith(".csv"):
                df = pd.read_csv(file)
            else:
                try:
                    import openpyxl
                except Exception:
                    st.error("XLSX support needs 'openpyxl'. Install: pip install openpyxl")
                    raise
                df = pd.read_excel(file)
        except Exception as e:
            st.error(f"Failed to read file: {e}")
            raise
        df.columns = [str(c).strip().lower() for c in df.columns]
        return df

    def _require_cols(df: pd.DataFrame, required: set):
        miss = list(required - set(df.columns))
        if miss:
            raise ValueError(f"Missing required columns: {', '.join(miss)}")

    def _numeric(df: pd.DataFrame, cols: list) -> pd.DataFrame:
        """Coerce numeric columns; drop rows with invalid numbers (warn)."""
        for c in cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors="coerce")
        need = [c for c in cols if c in df.columns]
        if need:
            bad = df[df[need].isna().any(axis=1)]
            if not bad.empty:
                st.warning(f"{len(bad)} row(s) have invalid numbers and will be skipped.")
                df = df.dropna(subset=need)
        return df

    # UPDATE TABS TO INCLUDE TANKER MASTER AND TANKER CALIBRATION
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "Tank Master",
        "ASTM Table 11",
        "YADE Barges",
        "Tanker Master & Calibration",  # NEW - Combined
        "Vessels",
    ])

    # ============================== TAB 1: Tank Master ==============================
    with tab1:
        st.markdown("#### Add / Edit Tank")
        
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            tank_name = st.text_input("Tank Name *", placeholder="e.g., OST-A", key="asset_tank_name")
        with c2:
            capacity_bbl = st.number_input("Capacity (bbl)", min_value=0.0, step=1.0, key="asset_capacity")
        with c3:
            product = st.text_input("Product", value="CRUDE", key="asset_product")
        with c4:
            status = st.selectbox("Status", ["ACTIVE", "INACTIVE"], key="asset_status")

        bL, bR = st.columns([0.50, 0.50])

        # --------- Left: Upload Tank Calibration with overwrite protection ---------
        with bL:
            with st.expander("📤 Upload Calibration Chart (CSV/XLSX)", expanded=False):
                st.caption("Required columns in file: **dip_cm, volume_bbl**. "
                           "The **tank_name** is taken from the input box above.")
                up_tank_cal = st.file_uploader("Select file", type=["csv", "xlsx"], key="tank_cal_upl")

                df_preview = None
                if up_tank_cal is not None:
                    try:
                        df = _read_table(up_tank_cal)
                        _require_cols(df, {"dip_cm", "volume_bbl"})
                        df = _numeric(df, ["dip_cm", "volume_bbl"]).sort_values("dip_cm").reset_index(drop=True)

                        st.markdown("**Preview (first 50 rows)**")
                        st.dataframe(df.head(50), use_container_width=True, hide_index=True)
                        df_preview = df
                    except Exception as ex:
                        st.error(f"Upload error: {ex}")

                if df_preview is not None:
                    if not tank_name.strip():
                        st.info("Enter **Tank Name** above to continue.")
                    else:
                        # Show overwrite status against DB for this tank + location
                        try:
                            from models import CalibrationTank
                            with get_session() as s:
                                exist_cnt = s.query(CalibrationTank).filter(
                                    CalibrationTank.location_id == active_location_id,
                                    CalibrationTank.tank_name == tank_name.strip()
                                ).count()
                            if exist_cnt > 0:
                                st.warning(
                                    f"Existing calibration found for **{tank_name.strip()}** at this location "
                                    f"({exist_cnt} row(s)). Importing will overwrite."
                                )
                                overwrite_ok = st.checkbox(
                                    f"I confirm to overwrite calibration for {tank_name.strip()}",
                                    key=f"tankcal_overwrite_{tank_name.strip()}"
                                )
                            else:
                                st.success("No existing calibration found. A fresh set will be saved.")
                                overwrite_ok = True
                        except Exception as ex:
                            overwrite_ok = False
                            st.error(f"Can't check existing calibration: {ex}")

                        if st.button("Import Calibration to DB", key="tank_cal_import_btn"):
                            if not overwrite_ok:
                                st.error("Please tick the overwrite confirmation to proceed.")
                            else:
                                try:
                                    from models import CalibrationTank
                                    with get_session() as s:
                                        # delete previous rows for this tank + location
                                        s.query(CalibrationTank).filter(
                                            CalibrationTank.location_id == active_location_id,
                                            CalibrationTank.tank_name == tank_name.strip()
                                        ).delete()
                                        # bulk insert new
                                        s.bulk_save_objects([
                                            CalibrationTank(
                                                location_id=active_location_id,
                                                tank_name=tank_name.strip(),
                                                dip_cm=float(r["dip_cm"]),
                                                volume_bbl=float(r["volume_bbl"])
                                            ) for _, r in df_preview.iterrows()
                                        ])
                                        s.commit()
                                        # ----------------------- Audit log for calibration import -----------------------
                                        try:
                                            from security import SecurityManager  # type: ignore
                                            user_ctx = st.session_state.get("auth_user") or {}
                                            username = user_ctx.get("username", "unknown")
                                            user_id = user_ctx.get("id")
                                            location_id = st.session_state.get("active_location_id") or user_ctx.get("location_id")
                                            SecurityManager.log_audit(
                                                None,
                                                username,
                                                "IMPORT",
                                                resource_type="CalibrationTank",
                                                resource_id=tank_name.strip(),
                                                details=f"Imported {len(df_preview)} calibration rows for tank {tank_name.strip()}",
                                                user_id=user_id,
                                                location_id=location_id,
                                            )
                                        except Exception:
                                            # Do not interrupt user flow if logging fails
                                            pass
                                    st.success(
                                        f"Calibration imported for **{tank_name.strip()}** "
                                        f"({len(df_preview)} rows)."
                                    )
                                except Exception as ex:
                                    st.error(f"Failed to import calibration: {ex}")

        # --------- Right: Save Tank master record ---------
        with bR:
            if st.button("Save Tank", key="asset_save_tank"):
                errs = []
                if not tank_name.strip():
                    errs.append("Tank Name is required.")
                if errs:
                    for e in errs:
                        st.error(e)
                else:
                    try:
                        from models import Tank, TankStatus
                        with get_session() as s:
                            existing = s.query(Tank).filter(
                                Tank.location_id == active_location_id,
                                Tank.name == tank_name.strip()
                            ).one_or_none()
                            
                            if existing:
                                existing.capacity_bbl = capacity_bbl
                                existing.product = product.strip()
                                existing.status = TankStatus[status]
                            else:
                                s.add(Tank(
                                    location_id=active_location_id,
                                    name=tank_name.strip(),
                                    capacity_bbl=capacity_bbl,
                                    product=product.strip(),
                                    status=TankStatus[status]
                                ))
                            s.commit()
                            # ----------------------- Audit log for tank save -----------------------
                            try:
                                from security import SecurityManager  # type: ignore
                                user_ctx = st.session_state.get("auth_user") or {}
                                username = user_ctx.get("username", "unknown")
                                user_id = user_ctx.get("id")
                                # Determine action based on existence of tank
                                action_type = "UPDATE" if existing else "CREATE"
                                SecurityManager.log_audit(
                                    None,
                                    username,
                                    action_type,
                                    resource_type="Tank",
                                    resource_id=tank_name.strip(),
                                    details=f"{action_type.title()} tank {tank_name.strip()}",
                                    user_id=user_id,
                                    location_id=active_location_id,
                                )
                            except Exception:
                                pass
                        st.success("Tank saved.")
                    except Exception as ex:
                        st.error(f"Failed to save tank: {ex}")

        st.markdown("##### Tanks (from DB)")
        try:
            from models import Tank
            with get_session() as s:
                rows = s.query(Tank).filter(
                    Tank.location_id == active_location_id
                ).order_by(Tank.name).all()
            if rows:
                st.dataframe(
                    pd.DataFrame([{
                        "Name": r.name,
                        "Capacity (bbl)": r.capacity_bbl,
                        "Product": r.product,
                        "Status": r.status.value if r.status else None
                    } for r in rows]),
                    use_container_width=True, hide_index=True
                )
            else:
                st.info("No tanks yet for this location. Add one above.")
        except Exception as ex:
            st.error(f"Failed to load tanks: {ex}")

        st.markdown("##### Delete Tank (Admin)")
        try:
            from models import Tank
            with get_session() as s:
                tank_list = s.query(Tank).filter(
                    Tank.location_id == active_location_id
                ).order_by(Tank.name).all()
            
            if tank_list:
                del_col1, del_col2, del_col3 = st.columns([0.4, 0.4, 0.2])
                with del_col1:
                    del_tank_name = st.selectbox(
                        "Select Tank to delete",
                        [t.name for t in tank_list],
                        key="asset_del_tank_select"
                    )
                with del_col2:
                    confirm_text = st.text_input(
                        "Type the tank name to confirm",
                        key="asset_del_tank_confirm"
                    )
                with del_col3:
                    if st.button("Delete Tank", key="asset_del_tank_btn"):
                        if not del_tank_name:
                            st.error("Please select a tank.")
                        elif confirm_text.strip() != del_tank_name:
                            st.error("Confirmation text does not match the selected tank name.")
                        else:
                            try:
                                with get_session() as s:
                                    obj = s.query(Tank).filter(
                                        Tank.location_id == active_location_id,
                                        Tank.name == del_tank_name
                                    ).one_or_none()
                                    if not obj:
                                        st.warning("Tank not found (maybe already deleted).")
                                    else:
                                        _archive_record_for_delete(
                                            s,
                                            obj,
                                            "Tank",
                                            reason=f"Marked tank {del_tank_name} for deletion.",
                                            label=del_tank_name,
                                        )
                                        s.commit()
                                st.success(f"Deleted tank: {del_tank_name}")
                                _st_safe_rerun()
                            except IntegrityError:
                                st.error("Cannot delete: this tank is referenced by existing transactions.")
                            except Exception as ex:
                                st.error(f"Failed to delete tank: {ex}")
            else:
                st.info("No tanks to delete for this location.")
        except Exception as ex:
            st.error(f"Delete UI error (tanks): {ex}")

    # ============================== TAB 2: ASTM Table 11 ==============================
    with tab2:
        st.markdown("#### ASTM Table 11 � Import (.xlsx)")
        st.info("ℹ️ **Note:** ASTM Table 11 is shared across ALL locations (not location-specific).")
        
        st.caption("""
        Upload an Excel file (.xlsx) with exactly **two columns** (case-insensitive):
        1) **API @ 60°F** (variants like `API_60`, `api 60f`, `api @60 f` handled)
        2) **LT factor** (variants like `lt`, `lt_factor`)
        We'll normalize headers automatically and store to the **table11** dataset.
        """)

        def _read_xlsx(file) -> pd.DataFrame:
            try:
                import openpyxl
            except Exception:
                st.error("XLSX support needs 'openpyxl'. Install: pip install openpyxl")
                raise
            df = pd.read_excel(file)
            df.columns = [str(c).strip().lower() for c in df.columns]
            return df

        def _normalize_table11(df: pd.DataFrame) -> pd.DataFrame:
            colmap = {}
            for c in df.columns:
                cl = c.lower().strip()
                cl = cl.replace("�", "�").replace("deg", "�").replace("degrees", "�")
                cl = cl.replace("@60f", "@ 60°F").replace("@ 60 f", "@ 60°F").replace("@60 °F", "@ 60°F")
                cl = " ".join(cl.split())
                if cl in {"api @ 60°F","api@60°F","api 60°F","api @60°F","api @ 60°F","api_60","api60","api 60f","api @60 f"}:
                    colmap[c] = "api60"
                elif cl in {"lt factor","lt","ltf","lt_factor"}:
                    colmap[c] = "lt_factor"

            if "api60" not in colmap.values() or "lt_factor" not in colmap.values():
                raise ValueError("Could not detect both required columns: API @ 60°F and LT factor.")

            df = df.rename(columns=colmap)[["api60", "lt_factor"]]
            df["api60"] = pd.to_numeric(df["api60"], errors="coerce")
            df["lt_factor"] = pd.to_numeric(df["lt_factor"], errors="coerce")
            bad = df[df[["api60","lt_factor"]].isna().any(axis=1)]
            if not bad.empty:
                st.warning(f"{len(bad)} row(s) have invalid numbers and will be skipped.")
                df = df.dropna(subset=["api60","lt_factor"])
            return df.sort_values("api60").reset_index(drop=True)

        up_tbl11 = st.file_uploader("Select ASTM Table 11 (.xlsx only)", type=["xlsx"], key="astm11_upl")

        df11_preview = None
        if up_tbl11 is not None:
            try:
                df11 = _read_xlsx(up_tbl11)
                df11 = _normalize_table11(df11)

                st.markdown("**Preview (first 100 rows)**")
                st.dataframe(df11.head(100), use_container_width=True, hide_index=True)
                df11_preview = df11
            except Exception as ex:
                st.error(f"Upload error: {ex}")

        if df11_preview is not None:
            try:
                from models import Table11
                with get_session() as s:
                    existing = s.query(Table11).count()
                if existing > 0:
                    st.warning(f"Existing ASTM Table 11 has **{existing}** row(s). Importing will overwrite.")
                    astm_overwrite_ok = st.checkbox("I confirm to overwrite ASTM Table 11", key="astm11_overwrite_ck")
                else:
                    st.success("No existing ASTM Table 11 found. A fresh dataset will be saved.")
                    astm_overwrite_ok = True
            except Exception as ex:
                st.error(f"Can't check existing ASTM Table 11: {ex}")
                astm_overwrite_ok = False

            if st.button("Import ASTM Table 11 to DB", key="astm11_import_btn"):
                if not astm_overwrite_ok:
                    st.error("Please tick the overwrite confirmation to proceed.")
                else:
                    try:
                        from models import Table11
                        with get_session() as s:
                            s.query(Table11).delete()
                            s.bulk_save_objects([
                                Table11(api60=float(r["api60"]), lt_factor=float(r["lt_factor"]))
                                for _, r in df11_preview.iterrows()
                            ])
                            s.commit()
                            # ----------------------- Audit log for ASTM Table 11 import -----------------------
                            try:
                                from security import SecurityManager  # type: ignore
                                user_ctx = st.session_state.get("auth_user") or {}
                                username = user_ctx.get("username", "unknown")
                                user_id = user_ctx.get("id")
                                SecurityManager.log_audit(
                                    None,
                                    username,
                                    "IMPORT",
                                    resource_type="ASTMTable11",
                                    resource_id="Table11",
                                    details=f"Imported ASTM Table 11 with {len(df11_preview)} rows",
                                    user_id=user_id,
                                    location_id=None,
                                )
                            except Exception:
                                pass
                        st.success(f"ASTM Table 11 imported: {len(df11_preview)} rows.")
                    except Exception as ex:
                        st.error(f"Failed to import ASTM Table 11: {ex}")
        else:
            st.info("Choose an .xlsx file to preview and import.")

    # ============================== TAB 3: YADE Barges ==============================
    with tab3:
        st.markdown("#### Add / Edit YADE Barge")
        st.info("ℹ️ **Note:** YADE barges are shared across ALL locations (same barges travel between terminals).")
        
        y1, y2 = st.columns(2)
        with y1:
            yade_name = st.text_input("YADE No *", placeholder="e.g., YADE-001", key="yade_name")
        with y2:
            design = st.selectbox("Tank Design *", ["6", "4"], index=0, key="yade_design")

        ybL, ybR = st.columns([0.50, 0.50])

        # --------- Left: Upload YADE Calibration ---------
        with ybL:
            with st.expander("📤 Upload YADE Calibration (CSV/XLSX)", expanded=False):
                st.caption("""Required columns:
    **yade_name, tank_id, dip_mm, vol_bbl** and (optionally) **mm1..mm9**.
    - `yade_name` must match the YADE No field (or will be overwritten by it if filled above).
    - `tank_id` must be C1,C2,P1,P2,S1,S2 (6-tank) or P1,P2,S1,S2 (4-tank).
    - **Calibration is shared globally** - same for all locations.""")

                up_yade_cal = st.file_uploader("Select file", type=["csv", "xlsx"], key="yade_cal_upl")

                dfy_preview = None
                if up_yade_cal is not None:
                    try:
                        dfy = _read_table(up_yade_cal)
                        _require_cols(dfy, {"yade_name", "tank_id", "dip_mm", "vol_bbl"})

                        dfy["tank_id"] = dfy["tank_id"].astype(str).str.upper().str.strip()
                        dfy["yade_name"] = dfy["yade_name"].astype(str).str.strip()

                        if yade_name.strip():
                            dfy["yade_name"] = yade_name.strip()

                        num_cols = ["dip_mm", "vol_bbl", "mm1","mm2","mm3","mm4","mm5","mm6","mm7","mm8","mm9"]
                        dfy = _numeric(dfy, num_cols)
                        dfy = dfy.sort_values(["yade_name", "tank_id", "dip_mm"]).reset_index(drop=True)

                        st.markdown("**Preview (first 60 rows)**")
                        st.dataframe(dfy.head(60), use_container_width=True, hide_index=True)
                        dfy_preview = dfy
                    except Exception as ex:
                        st.error(f"Upload error: {ex}")

                if dfy_preview is not None:
                    affected_yades = sorted(dfy_preview["yade_name"].unique().tolist())
                    affected_pairs = sorted(dfy_preview[["yade_name","tank_id"]].drop_duplicates().itertuples(index=False, name=None))

                    st.info("**Will import calibration for:**")
                    st.write(", ".join([f"{yn}" for yn in affected_yades]))
                    st.caption("Pairs (YADE, Tank): " + ", ".join([f"({yn},{tk})" for yn, tk in affected_pairs]))

                    try:
                        from models import YadeCalibration
                        with get_session() as s:
                            existing_rows = (
                                s.query(YadeCalibration.yade_name, YadeCalibration.tank_id)
                                .filter(YadeCalibration.yade_name.in_(affected_yades))
                                .all()
                            )
                        if existing_rows:
                            existing_set = sorted(set(existing_rows))
                            st.warning(
                                "Existing calibration found for the following pairs (will be overwritten):\n" +
                                ", ".join([f"({yn},{tk})" for yn, tk in existing_set])
                            )
                            yade_overwrite_ok = st.checkbox(
                                "I confirm to overwrite the existing YADE calibration for the pairs listed above",
                                key="yade_overwrite_ck"
                            )
                        else:
                            st.success("No existing calibration found for these YADE(s). A fresh set will be saved.")
                            yade_overwrite_ok = True
                    except Exception as ex:
                        yade_overwrite_ok = False
                        st.error(f"Can't check existing YADE calibration: {ex}")

                    if st.button("Import YADE Calibration to DB", key="yade_cal_import_btn"):
                        if not yade_overwrite_ok:
                            st.error("Please tick the overwrite confirmation to proceed.")
                        else:
                            try:
                                from models import YadeCalibration
                                with get_session() as s:
                                    s.query(YadeCalibration).filter(
                                        YadeCalibration.yade_name.in_(affected_yades)
                                    ).delete(synchronize_session=False)

                                    objs = []
                                    has_mm = [c for c in ["mm1","mm2","mm3","mm4","mm5","mm6","mm7","mm8","mm9"] if c in dfy_preview.columns]
                                    for _, r in dfy_preview.iterrows():
                                        kwargs = dict(
                                            yade_name=r["yade_name"],
                                            tank_id=r["tank_id"],
                                            dip_mm=float(r["dip_mm"]),
                                            vol_bbl=float(r["vol_bbl"]),
                                        )
                                        for mm in has_mm:
                                            val = r.get(mm, None)
                                            kwargs[mm] = float(val) if pd.notna(val) else None
                                        objs.append(YadeCalibration(**kwargs))

                                    s.bulk_save_objects(objs)
                                    s.commit()
                                    # ----------------------- Audit log for YADE calibration import -----------------------
                                    try:
                                        from security import SecurityManager  # type: ignore
                                        user_ctx = st.session_state.get("auth_user") or {}
                                        username = user_ctx.get("username", "unknown")
                                        user_id = user_ctx.get("id")
                                        SecurityManager.log_audit(
                                            None,
                                            username,
                                            "IMPORT",
                                            resource_type="YadeCalibration",
                                            resource_id="*",
                                            details=f"Imported {len(dfy_preview)} YADE calibration rows for {len(affected_yades)} YADE(s)",
                                            user_id=user_id,
                                            location_id=None,
                                        )
                                    except Exception:
                                        pass

                                st.success(
                                    f"YADE calibration imported for {len(affected_yades)} YADE(s), "
                                    f"{len(dfy_preview)} row(s) total (shared globally)."
                                )
                            except Exception as ex:
                                st.error(f"Failed to import YADE calibration: {ex}")

        # --------- Right: Save YADE Barge master ---------
        with ybR:
            if st.button("Save YADE Barge", key="yade_save_btn"):
                if not yade_name.strip():
                    st.error("YADE No is required.")
                else:
                    try:
                        from models import YadeBarge
                        with get_session() as s:
                            existing = s.query(YadeBarge).filter(
                                YadeBarge.name == yade_name.strip()
                            ).one_or_none()
                            
                            if existing:
                                existing.design = design
                                st.info(f"Updated existing YADE barge '{yade_name.strip()}' (shared globally).")
                            else:
                                s.add(YadeBarge(
                                    name=yade_name.strip(),
                                    design=design
                                ))
                                st.success(f"Created new YADE barge '{yade_name.strip()}' (available to all locations).")
                            s.commit()
                            # ----------------------- Audit log for YADE barge save -----------------------
                            try:
                                from security import SecurityManager  # type: ignore
                                user_ctx = st.session_state.get("auth_user") or {}
                                username = user_ctx.get("username", "unknown")
                                user_id = user_ctx.get("id")
                                action_type = "UPDATE" if existing else "CREATE"
                                SecurityManager.log_audit(
                                    None,
                                    username,
                                    action_type,
                                    resource_type="YadeBarge",
                                    resource_id=yade_name.strip(),
                                    details=f"{action_type.title()} YADE barge {yade_name.strip()}",
                                    user_id=user_id,
                                    location_id=None,
                                )
                            except Exception:
                                pass
                    except Exception as ex:
                        st.error(f"Failed to save YADE barge: {ex}")

        st.markdown("##### YADE Barges (All - Shared Globally)")
        try:
            from models import YadeBarge
            with get_session() as s:
                rows = s.query(YadeBarge).order_by(YadeBarge.name).all()
            if rows:
                st.dataframe(
                    pd.DataFrame([{"YADE No": r.name, "Design": r.design} for r in rows]),
                    use_container_width=True, hide_index=True
                )
                st.caption(f"🔢 Total: {len(rows)} YADE barge(s) (shared across all locations)")
            else:
                st.info("No YADE barges yet. Add one above.")
        except Exception as ex:
            st.error(f"Failed to load YADE barges: {ex}")

        st.markdown("##### Delete YADE Barge (Admin)")
        st.warning("⚠️ Deleting a YADE barge affects ALL locations!")
                
        try:
            from models import YadeBarge
            with get_session() as s:
                barge_list = s.query(YadeBarge).order_by(YadeBarge.name).all()
            
            if barge_list:
                yd1, yd2, yd3 = st.columns([0.4, 0.4, 0.2])
                with yd1:
                    del_yade_name = st.selectbox(
                        "Select YADE to delete",
                        [b.name for b in barge_list],
                        key="asset_del_yade_select"
                    )
                with yd2:
                    yade_confirm = st.text_input(
                        "Type the YADE No to confirm",
                        key="asset_del_yade_confirm"
                    )
                with yd3:
                    if st.button("Delete YADE Barge", key="asset_del_yade_btn"):
                        if not del_yade_name:
                            st.error("Please select a YADE barge.")
                        elif yade_confirm.strip() != del_yade_name:
                            st.error("Confirmation text does not match the selected YADE No.")
                        else:
                            try:
                                with get_session() as s:
                                    obj = s.query(YadeBarge).filter(
                                        YadeBarge.name == del_yade_name
                                    ).one_or_none()
                                    if not obj:
                                        st.warning("YADE barge not found (maybe already deleted).")
                                    else:
                                        _archive_record_for_delete(
                                            s,
                                            obj,
                                            "YadeBarge",
                                            reason=f"Marked YADE barge '{del_yade_name}' for deletion (affects all locations).",
                                            label=del_yade_name,
                                        )

                                st.success(f"Deleted YADE barge: {del_yade_name} (from all locations)")
                                _st_safe_rerun()
                            except IntegrityError:
                                st.error("Cannot delete: this YADE is referenced by existing YADE records.")
                            except Exception as ex:
                                st.error(f"Failed to delete YADE barge: {ex}")
            else:
                st.info("No YADE barges to delete.")
        except Exception as ex:
            st.error(f"Delete UI error (YADE): {ex}")

    
    # ============================== TAB 4: Tanker Master & Calibration (COMBINED) ==============================
    with tab4:
        st.markdown("#### Tanker Master & Calibration")
        st.info("ℹ️ **Note:** Tankers and their calibration are shared across ALL locations (same tankers travel between terminals).")
        
        # ========== SECTION 1: Add New Tanker ==========
        with st.expander("? Add New Tanker", expanded=False):
            with st.form("add_tanker_form"):
                st.markdown("##### Tanker Details")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    tanker_name = st.text_input(
                        "Tanker Name/ID *",
                        placeholder="e.g., TKR-001",
                        key="tanker_name",
                        help="Unique identifier for the tanker"
                    )
                    
                    chassis_no = st.text_input(
                        "Chassis Number",
                        placeholder="e.g., ABC-1234-XYZ",
                        key="tanker_chassis",
                        help="Vehicle chassis number"
                    )
                
                with col2:
                    capacity = st.number_input(
                        "Capacity (Litres)",
                        min_value=0.0,
                        step=100.0,
                        key="tanker_capacity",
                        help="Total tanker capacity in litres"
                    )
                    
                    tanker_status = st.selectbox(
                        "Status",
                        options=["ACTIVE", "INACTIVE"],
                        key="tanker_status"
                    )
                
                submit_tanker = st.form_submit_button("➕ Add Tanker", type="primary")
                
                if submit_tanker:
                    if not tanker_name.strip():
                        st.error("? Tanker name is required")
                    else:
                        try:
                            from models import Tanker, TankStatus
                            with get_session() as s:
                                # Check if tanker already exists
                                existing = s.query(Tanker).filter(
                                    Tanker.name == tanker_name.strip()
                                ).one_or_none()
                                
                                if existing:
                                    st.error(f"? Tanker '{tanker_name}' already exists")
                                else:
                                    new_tanker = Tanker(
                                        name=tanker_name.strip(),
                                        registration_no=chassis_no.strip() if chassis_no else None,  # Stored as registration_no in DB
                                        capacity_litres=float(capacity) if capacity else None,
                                        status=TankStatus.ACTIVE if tanker_status == "ACTIVE" else TankStatus.INACTIVE
                                    )
                                    s.add(new_tanker)
                                    s.commit()
                                    
                                    st.success(f"? Tanker '{tanker_name}' added successfully!")
                                    
                                    # Log audit
                                    user = st.session_state.get("auth_user")
                                    if user:
                                        from security import SecurityManager
                                        SecurityManager.log_audit(
                                            s, user["username"], "CREATE",
                                            resource_type="Tanker",
                                            resource_id=tanker_name,
                                            details=f"Added tanker: {tanker_name} (Chassis: {chassis_no})",
                                            user_id=user["id"]
                                        )
                                    
                                    import time
                                    time.sleep(1)
                                    _st_safe_rerun()
                        except Exception as ex:
                            st.error(f"? Failed to add tanker: {ex}")
        
        st.markdown("---")
        
        # ========== SECTION 2: List Existing Tankers ==========
        st.markdown("##### Existing Tankers (All - Shared Globally)")
        
        try:
            from models import Tanker
            with get_session() as s:
                tankers = s.query(Tanker).order_by(Tanker.name).all()
            
            if tankers:
                import pandas as pd
                df = pd.DataFrame([{
                    "Name": t.name,
                    "Chassis No": t.registration_no or "�",  # Display as "Chassis No"
                    "Capacity (L)": f"{t.capacity_litres:,.0f}" if t.capacity_litres else "�",
                    "Status": t.status.value if hasattr(t.status, 'value') else t.status,
                    "Created": t.created_at.strftime("%d/%m/%Y") if t.created_at else "�"
                } for t in tankers])
                
                st.dataframe(df, use_container_width=True, hide_index=True)
                st.caption(f"🔢 Total tankers: {len(tankers)} (shared across all locations)")
            else:
                st.info("No tankers added yet. Add your first tanker above.")
        except Exception as ex:
            st.error(f"? Failed to load tankers: {ex}")
        
        st.markdown("---")
        
        # ========== SECTION 3: Upload Tanker Calibration ==========
        st.markdown("##### Upload Tanker Calibration")
        
        try:
            from models import Tanker, TankStatus
            with get_session() as s:
                tankers = s.query(Tanker).filter(Tanker.status == TankStatus.ACTIVE).order_by(Tanker.name).all()
            
            if not tankers:
                st.warning("⚠️ No active tankers available. Please add tankers first.")
            else:
                tanker_names = [t.name for t in tankers]
                
                cal_col1, cal_col2 = st.columns([0.4, 0.6])
                
                with cal_col1:
                    selected_tanker = st.selectbox(
                        "Select Tanker",
                        options=tanker_names,
                        key="tanker_cal_select"
                    )
                    
                    compartment = st.selectbox(
                        "Compartment",
                        options=["C1", "C2"],
                        key="tanker_compartment",
                        help="Which compartment to calibrate"
                    )
                
                with cal_col2:
                    st.caption("**Required columns:** dip_mm, volume_litres")
                    uploaded_file = st.file_uploader(
                        "Upload Calibration CSV",
                        type=["csv"],
                        key="tanker_cal_upload",
                        help="CSV should have columns: dip_mm, volume_litres"
                    )
                
                if uploaded_file:
                    try:
                        import pandas as pd
                        df = pd.read_csv(uploaded_file)
                        
                        # Normalize column names
                        df.columns = [c.strip().lower() for c in df.columns]
                        
                        # Validate columns
                        required_cols = ["dip_mm", "volume_litres"]
                        if not all(col in df.columns for col in required_cols):
                            st.error(f"? CSV must have columns: {', '.join(required_cols)}")
                        else:
                            # Convert to numeric
                            df["dip_mm"] = pd.to_numeric(df["dip_mm"], errors="coerce")
                            df["volume_litres"] = pd.to_numeric(df["volume_litres"], errors="coerce")
                            
                            # Drop invalid rows
                            df = df.dropna(subset=required_cols)
                            
                            # Sort by dip
                            df = df.sort_values("dip_mm").reset_index(drop=True)
                            
                            st.success(f"? Loaded {len(df)} calibration points")
                            
                            # Preview
                            with st.expander("🔎 Preview Calibration Data", expanded=True):
                                st.dataframe(df.head(20), use_container_width=True, hide_index=True)
                            
                            if st.button("💾 Save Calibration Data", key="save_tanker_cal", type="primary"):
                                try:
                                    from models import TankerCalibration
                                    with get_session() as s:
                                        # Delete existing calibration for this tanker-compartment
                                        deleted = s.query(TankerCalibration).filter(
                                            TankerCalibration.tanker_name == selected_tanker,
                                            TankerCalibration.compartment == compartment
                                        ).delete()
                                        
                                        # Add new calibration points
                                        for _, row in df.iterrows():
                                            cal = TankerCalibration(
                                                tanker_name=selected_tanker,
                                                compartment=compartment,
                                                dip_mm=float(row['dip_mm']),
                                                volume_litres=float(row['volume_litres'])
                                            )
                                            s.add(cal)
                                        
                                        s.commit()
                                        
                                        st.success(f"? Saved {len(df)} calibration points for {selected_tanker} - {compartment}")
                                        if deleted > 0:
                                            st.info(f"🔄 Replaced {deleted} existing calibration points")
                                        
                                        # Log audit
                                        user = st.session_state.get("auth_user")
                                        if user:
                                            from security import SecurityManager
                                            with get_session() as s2:
                                                SecurityManager.log_audit(
                                                    s2, user["username"], "CREATE",
                                                    resource_type="TankerCalibration",
                                                    resource_id=f"{selected_tanker}-{compartment}",
                                                    details=f"Uploaded {len(df)} calibration points",
                                                    user_id=user["id"]
                                                )
                                        
                                        import time
                                        time.sleep(1)
                                        _st_safe_rerun()
                                except Exception as ex:
                                    st.error(f"? Failed to save calibration: {ex}")
                                    import traceback
                                    st.code(traceback.format_exc())
                    
                    except Exception as ex:
                        st.error(f"? Failed to read CSV: {ex}")
                
                # ========== SECTION 4: View Existing Calibration ==========
                st.markdown("---")
                st.markdown(f"##### Current Calibration: {selected_tanker} - {compartment}")
                
                try:
                    from models import TankerCalibration
                    with get_session() as s:
                        cal_data = s.query(TankerCalibration).filter(
                            TankerCalibration.tanker_name == selected_tanker,
                            TankerCalibration.compartment == compartment
                        ).order_by(TankerCalibration.dip_mm).all()
                    
                    if cal_data:
                        import pandas as pd
                        df_cal = pd.DataFrame([{
                            "Dip (mm)": c.dip_mm,
                            "Volume (Litres)": f"{c.volume_litres:,.2f}"
                        } for c in cal_data])
                        
                        st.dataframe(df_cal, use_container_width=True, hide_index=True)
                        st.caption(f"🔢 Total calibration points: {len(cal_data)}")
                        
                        # Export and Delete buttons
                        exp_col, del_col = st.columns([0.5, 0.5])
                        
                        with exp_col:
                            # Export existing calibration
                            csv_data = df_cal.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                "⬇️ Download Current Calibration",
                                data=csv_data,
                                file_name=f"{selected_tanker}_{compartment}_calibration.csv",
                                mime="text/csv",
                                key="download_tanker_cal"
                            )
                        
                        with del_col:
                            # Delete calibration
                            if st.button(f"🗑️ Delete Calibration", key="delete_tanker_cal"):
                                try:
                                    from models import TankerCalibration
                                    with get_session() as s:
                                        deleted = s.query(TankerCalibration).filter(
                                            TankerCalibration.tanker_name == selected_tanker,
                                            TankerCalibration.compartment == compartment
                                        ).delete()
                                        s.commit()
                                    
                                    st.success(f"? Deleted {deleted} calibration points")
                                    
                                    # ----------------------- Audit log for tanker calibration deletion -----------------------
                                    try:
                                        from security import SecurityManager  # type: ignore
                                        user_ctx = st.session_state.get("auth_user") or {}
                                        username = user_ctx.get("username", "unknown")
                                        user_id = user_ctx.get("id")
                                        SecurityManager.log_audit(
                                            None,
                                            username,
                                            "DELETE",
                                            resource_type="TankerCalibration",
                                            resource_id=f"{selected_tanker}-{compartment}",
                                            details=f"Deleted {deleted} calibration points",
                                            user_id=user_id,
                                            location_id=active_location_id,
                                        )
                                    except Exception:
                                        pass
                                    
                                    import time
                                    time.sleep(1)
                                    _st_safe_rerun()
                                except Exception as ex:
                                    st.error(f"? Failed to delete calibration: {ex}")
                    else:
                        st.info(f"ℹ️ No calibration data for {selected_tanker} - {compartment}. Upload CSV above.")
                except Exception as ex:
                    st.error(f"? Failed to load calibration: {ex}")
        
        except Exception as ex:
            st.error(f"? Failed to load tankers: {ex}")
        
        st.markdown("---")
        
        # ========== SECTION 5: Delete Tanker ==========
        st.markdown("##### Delete Tanker (Admin)")
        st.warning("⚠️ Deleting a tanker affects ALL locations and removes all its calibration data!")
        
        try:
            from models import Tanker
            with get_session() as s:
                tanker_list = s.query(Tanker).order_by(Tanker.name).all()
            
            if tanker_list:
                td1, td2, td3 = st.columns([0.4, 0.4, 0.2])
                with td1:
                    del_tanker_name = st.selectbox(
                        "Select Tanker to delete",
                        [t.name for t in tanker_list],
                        key="asset_del_tanker_select"
                    )
                with td2:
                    tanker_confirm = st.text_input(
                        "Type the tanker name to confirm",
                        key="asset_del_tanker_confirm"
                    )
                with td3:
                    if st.button("🗑️ Delete", key="asset_del_tanker_btn"):
                        if not del_tanker_name:
                            st.error("? Please select a tanker.")
                        elif tanker_confirm.strip() != del_tanker_name:
                            st.error("? Confirmation text does not match the selected tanker name.")
                        else:
                            try:
                                with get_session() as s:
                                    obj = s.query(Tanker).filter(
                                        Tanker.name == del_tanker_name
                                    ).one_or_none()
                                    if not obj:
                                        st.warning("⚠️ Tanker not found (maybe already deleted).")
                                    else:
                                        _archive_record_for_delete(
                                            s,
                                            obj,
                                            "Tanker",
                                            reason=f"Marked tanker {del_tanker_name} for deletion.",
                                            label=del_tanker_name,
                                        )
                                        s.commit()
                                st.success(f"? Deleted tanker: {del_tanker_name}")
                                _st_safe_rerun()
                            except IntegrityError:
                                st.error("? Cannot delete: this tanker is referenced by existing transactions.")
                            except Exception as ex:
                                st.error(f"? Failed to delete tanker: {ex}")
            else:
                st.info("ℹ️ No tankers to delete.")
        except Exception as ex:
            st.error(f"? Delete UI error (tankers): {ex}")

# ============================== TAB 5: Vessel Assets ==============================
    with tab5:
        st.markdown("#### Vessel Assets")
        st.caption("Add or edit vessel master records and assign them to locations.")

        try:
            from models import Vessel, Location, LocationVessel
            with get_session() as s:
                vessel_rows = s.query(Vessel).order_by(Vessel.name).all()
                location_rows = s.query(Location).order_by(Location.name).all()
                if vessel_rows:
                    assignment_rows = (
                        s.query(LocationVessel)
                        .filter(LocationVessel.is_active == True)
                        .filter(LocationVessel.vessel_id.in_([v.id for v in vessel_rows]))
                        .all()
                    )
                else:
                    assignment_rows = []
        except Exception as ex:
            vessel_rows = []
            location_rows = []
            assignment_rows = []
            st.error(f"Failed to load vessel data: {ex}")

        vessel_lookup = {v.id: v for v in vessel_rows}
        location_labels = {
            loc.id: f"{loc.name} ({loc.code})" if loc.code else loc.name for loc in location_rows
        }

        vessel_select_items = ["? Add New Vessel"] + [f"{v.name} (#{v.id})" for v in vessel_rows]
        selected_label = st.selectbox(
            "Select Vessel to Edit",
            vessel_select_items,
            key="asset_vessel_selector",
        )
        selected_vessel_id = 0
        if selected_label != "? Add New Vessel":
            for vessel in vessel_rows:
                if f"{vessel.name} (#{vessel.id})" == selected_label:
                    selected_vessel_id = vessel.id
                    break

        vessel_state_key = "asset_vessel_selected_id"
        if vessel_state_key not in st.session_state:
            st.session_state[vessel_state_key] = 0
        if st.session_state[vessel_state_key] != selected_vessel_id:
            st.session_state[vessel_state_key] = selected_vessel_id
            if selected_vessel_id and selected_vessel_id in vessel_lookup:
                vessel_obj = vessel_lookup[selected_vessel_id]
                st.session_state["asset_vessel_name"] = vessel_obj.name
                st.session_state["asset_vessel_code"] = vessel_obj.registration_no or ""
                st.session_state["asset_vessel_capacity"] = vessel_obj.capacity_bbl or 0.0
                default_loc = None
                for link in assignment_rows:
                    if link.vessel_id == selected_vessel_id and link.is_active:
                        default_loc = link.location_id
                        break
                st.session_state["asset_vessel_location"] = default_loc
            else:
                st.session_state["asset_vessel_name"] = ""
                st.session_state["asset_vessel_code"] = ""
                st.session_state["asset_vessel_capacity"] = 0.0
                st.session_state["asset_vessel_location"] = active_location_id

        if st.session_state.pop("asset_vessel_reset_flag", False):
            st.session_state[vessel_state_key] = 0
            st.session_state["asset_vessel_name"] = ""
            st.session_state["asset_vessel_code"] = ""
            st.session_state["asset_vessel_capacity"] = 0.0
            st.session_state["asset_vessel_location"] = None

        with st.form("asset_vessel_form"):
            col_a, col_b = st.columns(2)
            with col_a:
                vessel_name = st.text_input(
                    "Vessel Name *",
                    value=st.session_state.get("asset_vessel_name", ""),
                    key="asset_vessel_name",
                )
            with col_b:
                vessel_code = st.text_input(
                    "Vessel ID / Registration *",
                    value=st.session_state.get("asset_vessel_code", ""),
                    key="asset_vessel_code",
                )

            col_c, col_d = st.columns(2)
            with col_c:
                vessel_capacity = st.number_input(
                    "Capacity (bbl)",
                    min_value=0.0,
                    step=1.0,
                    value=float(st.session_state.get("asset_vessel_capacity", 0.0) or 0.0),
                    key="asset_vessel_capacity",
                )
            location_options = [None] + [loc.id for loc in location_rows]
            loc_labels = {None: "-- Select Location --"}
            loc_labels.update(location_labels)
            with col_d:
                assigned_location = st.selectbox(
                    "Assign to Location (optional)",
                    options=location_options,
                    index=(
                        location_options.index(st.session_state.get("asset_vessel_location"))
                        if st.session_state.get("asset_vessel_location") in location_options
                        else 0
                    ),
                    format_func=lambda opt: loc_labels.get(opt, "-- Select Location --"),
                    key="asset_vessel_location",
                )

            action_cols = st.columns([0.3, 0.3, 0.4])
            save_vessel = action_cols[0].form_submit_button("Save Vessel", type="primary")
            reset_form = action_cols[1].form_submit_button("Reset", type="secondary")

            if reset_form:
                st.session_state["asset_vessel_reset_flag"] = True
                _st_safe_rerun()

            if save_vessel:
                errors = []
                clean_name = (vessel_name or "").strip()
                clean_code = (vessel_code or "").strip()
                if not clean_name:
                    errors.append("Vessel name is required.")
                if not clean_code:
                    errors.append("Vessel ID / Registration is required.")
                if errors:
                    for err in errors:
                        st.error(err)
                else:
                    try:
                        with get_session() as s:
                            if selected_vessel_id:
                                vessel_obj = (
                                    s.query(Vessel)
                                    .filter(Vessel.id == selected_vessel_id)
                                    .one_or_none()
                                )
                                if not vessel_obj:
                                    st.error("Selected vessel no longer exists.")
                                    st.stop()
                                duplicate = (
                                    s.query(Vessel)
                                    .filter(Vessel.name == clean_name, Vessel.id != selected_vessel_id)
                                    .first()
                                )
                                if duplicate:
                                    st.error("Another vessel already uses that name.")
                                    st.stop()
                            else:
                                duplicate = s.query(Vessel).filter(Vessel.name == clean_name).first()
                                if duplicate:
                                    st.error("A vessel with that name already exists. Select it above to edit.")
                                    st.stop()
                                vessel_obj = Vessel(name=clean_name)
                                s.add(vessel_obj)
                                s.flush()
                                selected_vessel_id = vessel_obj.id

                            vessel_obj.name = clean_name
                            vessel_obj.registration_no = clean_code
                            vessel_obj.capacity_bbl = float(vessel_capacity or 0.0)
                            vessel_obj.status = "ACTIVE"
                            s.flush()

                            if assigned_location:
                                existing_link = (
                                    s.query(LocationVessel)
                                    .filter(
                                        LocationVessel.location_id == assigned_location,
                                        LocationVessel.vessel_id == vessel_obj.id,
                                    )
                                    .one_or_none()
                                )
                                if existing_link:
                                    existing_link.is_active = True
                                else:
                                    s.add(
                                        LocationVessel(
                                            location_id=assigned_location,
                                            vessel_id=vessel_obj.id,
                                            is_active=True,
                                        )
                                    )

                            s.commit()
                            st.success("Vessel saved successfully.")
                            _st_safe_rerun()
                    except IntegrityError as ex:
                        st.error(f"Database error: {ex}")
                    except Exception as ex:
                        st.error(f"Failed to save vessel: {ex}")

        if vessel_rows:
            st.markdown("##### Existing Vessels")
            assignment_map: Dict[int, List[str]] = {}
            for link in assignment_rows:
                assignment_map.setdefault(link.vessel_id, []).append(
                    location_labels.get(link.location_id, f"Location #{link.location_id}")
                )
            vessel_data = []
            for vessel in vessel_rows:
                vessel_data.append(
                    {
                        "Vessel": vessel.name,
                        "Vessel ID": vessel.registration_no or "-",
                        "Capacity (bbl)": vessel.capacity_bbl or "-",
                        "Assigned Locations": ", ".join(assignment_map.get(vessel.id, [])) or "-",
                    }
                )
            st.dataframe(
                pd.DataFrame(vessel_data),
                use_container_width=True,
                hide_index=True,
            )
            vessel_display_map = {v.id: f"{v.name} (#{v.id})" for v in vessel_rows}
            location_option_ids = [None] + [loc.id for loc in location_rows]
            formatted_locations = {None: "-- No Location --"}
            formatted_locations.update(location_labels)

            st.markdown("##### Transfer Existing Vessel")
            with st.form("asset_vessel_transfer_form"):
                transfer_vessel_id = st.selectbox(
                    "Select vessel",
                    options=list(vessel_display_map.keys()),
                    format_func=lambda vid: vessel_display_map.get(vid, f"Vessel #{vid}"),
                )
                transfer_location_id = st.selectbox(
                    "Assign to Location",
                    options=location_option_ids,
                    format_func=lambda opt: formatted_locations.get(opt, "-- No Location --"),
                )
                transfer_submit = st.form_submit_button("Update Assignment", type="primary")
                if transfer_submit:
                    try:
                        with get_session() as s:
                            vessel_obj = (
                                s.query(Vessel)
                                .filter(Vessel.id == transfer_vessel_id)
                                .one_or_none()
                            )
                            if not vessel_obj:
                                st.error("Selected vessel could not be found.")
                            else:
                                links = (
                                    s.query(LocationVessel)
                                    .filter(LocationVessel.vessel_id == vessel_obj.id)
                                    .all()
                                )
                                row_map = {row.location_id: row for row in links}
                                # deactivate all existing links
                                for row in links:
                                    row.is_active = False
                                # activate or create selected assignment
                                if transfer_location_id:
                                    existing = row_map.get(transfer_location_id)
                                    if existing:
                                        existing.is_active = True
                                    else:
                                        s.add(
                                            LocationVessel(
                                                location_id=transfer_location_id,
                                                vessel_id=vessel_obj.id,
                                                is_active=True,
                                            )
                                        )
                                s.commit()
                                st.success("Vessel assignment updated.")
                                import time as _t

                                _t.sleep(1)
                                _st_safe_rerun()
                    except Exception as ex:
                        st.error(f"Failed to update assignment: {ex}")

            st.markdown("##### Delete Vessel")
            with st.form("asset_vessel_delete_form"):
                delete_vessel_id = st.selectbox(
                    "Select vessel to delete",
                    options=list(vessel_display_map.keys()),
                    format_func=lambda vid: vessel_display_map.get(vid, f"Vessel #{vid}"),
                )
                confirm_text = st.text_input(
                    "Type DELETE to confirm removal",
                    value="",
                )
                delete_submit = st.form_submit_button("Delete Vessel", type="secondary")
                if delete_submit:
                    if confirm_text.strip().upper() != "DELETE":
                        st.error("Please type DELETE to confirm.")
                    else:
                        try:
                            with get_session() as s:
                                vessel_obj = (
                                    s.query(Vessel)
                                    .filter(Vessel.id == delete_vessel_id)
                                    .one_or_none()
                                )
                                if not vessel_obj:
                                    st.error("Selected vessel does not exist.")
                                else:
                                    s.query(LocationVessel).filter(
                                        LocationVessel.vessel_id == vessel_obj.id
                                    ).delete(synchronize_session=False)
                                    s.delete(vessel_obj)
                                    s.commit()
                                    st.success("Vessel deleted. Please re-add with updated details if needed.")
                                    import time as _t

                                    _t.sleep(1)
                                    _st_safe_rerun()
                        except IntegrityError as ex:
                            st.error(
                                "Unable to delete vessel because it is referenced by existing records. "
                                "Please remove related transactions first."
                            )
                        except Exception as ex:
                            st.error(f"Failed to delete vessel: {ex}")
        else:
            st.info("No vessels available yet. Add a vessel using the form above.")

# ================== NEW PAGE: Location Settings (admin only) ==================
elif page == "Location Settings":
    if st.session_state.get("auth_user", {}).get("role") != "admin-operations":
        header("Location Settings")
        st.error("You do not have permission to access this page. Admin-Operations only.")
        st.stop()

    header("Location Settings")
    st.markdown("### Configure Location-Specific Settings")
    
    from location_config import LocationConfig
    from location_manager import LocationManager
    import json
    
    # Select location
    with get_session() as s:
        locations = LocationManager.get_all_locations(s, active_only=True)
    
    if not locations:
        st.warning("No locations found. Add a location first.")
        st.stop()
    
    loc_options = {f"{loc.name} ({loc.code})": loc.id for loc in locations}
    
    selected_loc = st.selectbox(
        "Select Location to Configure",
        options=list(loc_options.keys()),
        key="config_location_select"
    )
    
    if selected_loc:
        location_id = loc_options[selected_loc]
        
        # Get current config
        with get_session() as s:
            current_config = LocationConfig.get_config(s, location_id)
        
        st.markdown("---")
        
        tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
            "🧭 Page Access",
            "🛢️ Tank Transactions",
            "⛴️ YADE Transactions",
            "⚙️ OTR Settings",
            "🎨 UI Customization",
            "⛴️ Vessel Assignments",
            "📑 Report Builder"
        ])
        
        with tab2:
            st.markdown("#### Tank Transaction Configuration")
            
            with st.form("tank_tx_config_form"):
                st.markdown("##### Enabled Operations")
                
                all_operations = [
                    "Opening Stock",
                    "Receipt",  # NEW
                    "Receipt from Agu",  # NEW
                    "Receipt from OFS",  # NEW
                    "OKW Receipt",
                    "ANZ Receipt",
                    "Other Receipts",
                    "ITT - Receipt",
                    "Dispatch to barge",
                    "Other Dispatch",
                    "ITT - Dispatch",
                    "Settling",
                    "Draining"
                ]
                
                enabled_ops = current_config["tank_transactions"]["enabled_operations"]
                
                selected_ops = st.multiselect(
                    "Select Enabled Operations",
                    options=all_operations,
                    default=enabled_ops,
                    key="config_tank_ops"
                )
                
                st.markdown("##### Product Types")
                
                all_products = ["CRUDE", "CONDENSATE", "DPK", "AGO", "PMS", "LPFO", "HPFO"]
                enabled_products = current_config["tank_transactions"]["product_types"]
                
                selected_products = st.multiselect(
                    "Select Product Types",
                    options=all_products,
                    default=enabled_products,
                    key="config_products"
                )
                
                st.markdown("##### Validation Rules")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    max_days = st.number_input(
                        "Max Days Backward Entry",
                        min_value=1,
                        max_value=365,
                        value=current_config["tank_transactions"]["max_days_backward"],
                        key="config_max_days"
                    )
                    
                    allow_future = st.checkbox(
                        "Allow Future Dates",
                        value=current_config["tank_transactions"]["allow_future_dates"],
                        key="config_allow_future"
                    )
                
                with col2:
                    auto_ticket = st.checkbox(
                        "Auto-Generate Ticket ID",
                        value=current_config["tank_transactions"]["auto_generate_ticket_id"],
                        key="config_auto_ticket"
                    )
                    
                    ticket_prefix = st.text_input(
                        "Ticket ID Prefix (if auto-generate)",
                        value=current_config["tank_transactions"]["ticket_id_prefix"],
                        placeholder="e.g., PHT-",
                        key="config_ticket_prefix"
                    )
                
                save_tank_config = st.form_submit_button("💾 Save Tank Transaction Settings", type="primary")
                
                if save_tank_config:
                    # Update config
                    new_config = current_config.copy()
                    new_config["tank_transactions"]["enabled_operations"] = selected_ops
                    new_config["tank_transactions"]["product_types"] = selected_products
                    new_config["tank_transactions"]["max_days_backward"] = max_days
                    new_config["tank_transactions"]["allow_future_dates"] = allow_future
                    new_config["tank_transactions"]["auto_generate_ticket_id"] = auto_ticket
                    new_config["tank_transactions"]["ticket_id_prefix"] = ticket_prefix
                    
                    try:
                        with get_session() as s:
                            LocationConfig.save_config(s, location_id, new_config)
                        
                        st.success("? Tank Transaction settings saved!")
                        
                        # Log audit
                        user = st.session_state.get("auth_user")
                        if user:
                            from security import SecurityManager
                            with get_session() as s:
                                SecurityManager.log_audit(
                                    s, user["username"], "UPDATE_LOCATION_CONFIG",
                                    resource_type="Location",
                                    resource_id=str(location_id),
                                    details="Updated tank transaction config",
                                    user_id=user["id"]
                                )
                        
                        import time
                        time.sleep(1)
                        _st_safe_rerun()
                    except Exception as ex:
                        st.error(f"Failed to save: {ex}")
        
        with tab3:
            st.markdown("#### YADE Transaction Configuration")
            
            with st.form("yade_config_form"):
                st.markdown("##### Enabled Cargo Types")
                
                all_cargo = ["OKW", "ANZ", "CONDENSATE", "CRUDE", "OTHER"]
                enabled_cargo = current_config["yade_transactions"]["enabled_cargo_types"]
                
                selected_cargo = st.multiselect(
                    "Select Cargo Types",
                    options=all_cargo,
                    default=enabled_cargo,
                    key="config_cargo"
                )
                
                st.markdown("##### Enabled Destinations")
                
                all_dest = [
                    "NEMBE CK", "BONNY", "BRASS", "FORCADOS",
                    "ESCRAVOS", "WARRI", "PORT HARCOURT", "OTHER"
                ]
                enabled_dest = current_config["yade_transactions"]["enabled_destinations"]
                
                selected_dest = st.multiselect(
                    "Select Destinations",
                    options=all_dest,
                    default=enabled_dest,
                    key="config_dest"
                )
                
                st.markdown("##### Loading Berths")
                
                all_berths = ["BERTH 1", "BERTH 2", "BERTH 3", "BERTH 4", "BERTH 5"]
                enabled_berths = current_config["yade_transactions"]["enabled_loading_berths"]
                
                selected_berths = st.multiselect(
                    "Select Loading Berths",
                    options=all_berths,
                    default=enabled_berths,
                    key="config_berths"
                )
                
                st.markdown("##### Options")
                
                enable_seals = st.checkbox(
                    "Enable Seal Tracking",
                    value=current_config["yade_transactions"]["enable_seal_tracking"],
                    key="config_seals"
                )
                
                auto_voyage = st.checkbox(
                    "Auto-Generate Voyage Numbers",
                    value=current_config["yade_transactions"]["auto_generate_voyage_no"],
                    key="config_auto_voyage"
                )
                
                save_yade_config = st.form_submit_button("💾 Save YADE Settings", type="primary")
                
                if save_yade_config:
                    new_config = current_config.copy()
                    new_config["yade_transactions"]["enabled_cargo_types"] = selected_cargo
                    new_config["yade_transactions"]["enabled_destinations"] = selected_dest
                    new_config["yade_transactions"]["enabled_loading_berths"] = selected_berths
                    new_config["yade_transactions"]["enable_seal_tracking"] = enable_seals
                    new_config["yade_transactions"]["auto_generate_voyage_no"] = auto_voyage
                    
                    try:
                        with get_session() as s:
                            LocationConfig.save_config(s, location_id, new_config)
                        
                        st.success("? YADE settings saved!")
                        
                        # Log audit
                        user = st.session_state.get("auth_user")
                        if user:
                            from security import SecurityManager
                            with get_session() as s:
                                SecurityManager.log_audit(
                                    s, user["username"], "UPDATE_LOCATION_CONFIG",
                                    resource_type="Location",
                                    resource_id=str(location_id),
                                    details="Updated YADE transaction config",
                                    user_id=user["id"]
                                )
                        
                        import time
                        time.sleep(1)
                        _st_safe_rerun()
                    except Exception as ex:
                        st.error(f"Failed to save: {ex}")
        
        with tab4:
            st.markdown("#### OTR Calculation Settings")
            
            with st.form("otr_config_form"):
                col1, col2 = st.columns(2)
                
                with col1:
                    auto_calc = st.checkbox(
                        "Auto-Calculate Volumes",
                        value=current_config["otr"]["auto_calculate_volumes"],
                        key="config_auto_calc"
                    )
                    
                    require_cal = st.checkbox(
                        "Require Calibration Data",
                        value=current_config["otr"]["require_calibration_data"],
                        key="config_req_cal"
                    )
                    
                    temp_corr = st.checkbox(
                        "Enable Temperature Correction",
                        value=current_config["otr"]["enable_temperature_correction"],
                        key="config_temp_corr"
                    )
                
                with col2:
                    decimal_precision = st.number_input(
                        "Decimal Precision",
                        min_value=0,
                        max_value=4,
                        value=current_config["otr"]["decimal_precision"],
                        key="config_decimal"
                    )
                    
                    volume_unit = st.selectbox(
                        "Volume Unit",
                        options=["BBL", "M3"],
                        index=0 if current_config["otr"]["volume_unit"] == "BBL" else 1,
                        key="config_vol_unit"
                    )
                    
                    temp_unit = st.selectbox(
                        "Temperature Unit",
                        options=["C", "F"],
                        index=0 if current_config["otr"]["temperature_unit"] == "C" else 1,
                        key="config_temp_unit"
                    )
                
                save_otr_config = st.form_submit_button("💾 Save OTR Settings", type="primary")
                
                if save_otr_config:
                    new_config = current_config.copy()
                    new_config["otr"]["auto_calculate_volumes"] = auto_calc
                    new_config["otr"]["require_calibration_data"] = require_cal
                    new_config["otr"]["enable_temperature_correction"] = temp_corr
                    new_config["otr"]["decimal_precision"] = decimal_precision
                    new_config["otr"]["volume_unit"] = volume_unit
                    new_config["otr"]["temperature_unit"] = temp_unit
                    
                    try:
                        with get_session() as s:
                            LocationConfig.save_config(s, location_id, new_config)
                        
                        st.success("? OTR settings saved!")
                        
                        import time
                        time.sleep(1)
                        _st_safe_rerun()
                    except Exception as ex:
                        st.error(f"Failed to save: {ex}")

            st.markdown("#### OTR-Vessel Dropdown Control")
            try:
                from models import Vessel
                with get_session() as s:
                    vessel_rows = (
                        s.query(Vessel)
                        .filter(Vessel.status == "ACTIVE")
                        .order_by(Vessel.name)
                        .all()
                    )
            except Exception as ex:
                vessel_rows = []
                st.error(f"Failed to load vessel list: {ex}")

            vessel_lookup = {v.id: v.name for v in vessel_rows}
            existing_ids = current_config.get("otr_vessel", {}).get("preferred_vessel_ids", [])

            if not vessel_rows:
                st.info("No active vessels found. Add vessels in Asset Management first.")
            else:
                with st.form("otr_vessel_list_form"):
                    selected_vessels = st.multiselect(
                        "Vessels available in OTR-Vessel dropdown",
                        options=list(vessel_lookup.keys()),
                        default=[vid for vid in existing_ids if vid in vessel_lookup],
                        format_func=lambda vid: vessel_lookup.get(vid, f"Vessel #{vid}"),
                        help="Admins can add or remove vessels that appear in the OTR entry form.",
                    )
                    save_custom_vessels = st.form_submit_button("💾 Save Vessel List", type="secondary")
                    if save_custom_vessels:
                        new_config = current_config.copy()
                        otr_vessel_conf = new_config.get("otr_vessel", {}).copy()
                        otr_vessel_conf["preferred_vessel_ids"] = selected_vessels
                        new_config["otr_vessel"] = otr_vessel_conf
                        try:
                            with get_session() as s:
                                LocationConfig.save_config(s, location_id, new_config)
                            st.success("? Vessel dropdown updated.")
                            user = st.session_state.get("auth_user")
                            import time
                            if user:
                                with get_session() as s_audit:
                                    SecurityManager.log_audit(
                                        s_audit,
                                        user["username"],
                                        "UPDATE_LOCATION_CONFIG",
                                        resource_type="Location",
                                        resource_id=str(location_id),
                                        details="Updated OTR vessel dropdown list",
                                        user_id=user["id"],
                                    )
                            time.sleep(1)
                            _st_safe_rerun()
                        except Exception as ex:
                            st.error(f"Failed to update vessel list: {ex}")
        
        with tab5:
            st.markdown("#### UI Customization")
            
            with st.form("ui_config_form"):
                quick_entry = st.checkbox(
                    "Show Quick Entry Mode",
                    value=current_config["ui_customization"]["show_quick_entry_mode"],
                    key="config_quick_entry"
                )
                
                bulk_upload = st.checkbox(
                    "Enable Bulk Upload",
                    value=current_config["ui_customization"]["enable_bulk_upload"],
                    key="config_bulk_upload"
                )
                
                default_date = st.selectbox(
                    "Default Date Selection",
                    options=["today", "manual"],
                    index=0 if current_config["ui_customization"]["default_date"] == "today" else 1,
                    key="config_default_date"
                )
                
                save_ui_config = st.form_submit_button("💾 Save UI Settings", type="primary")
                
                if save_ui_config:
                    new_config = current_config.copy()
                    new_config["ui_customization"]["show_quick_entry_mode"] = quick_entry
                    new_config["ui_customization"]["enable_bulk_upload"] = bulk_upload
                    new_config["ui_customization"]["default_date"] = default_date
                    
                    try:
                        with get_session() as s:
                            LocationConfig.save_config(s, location_id, new_config)
                        
                        st.success("? UI settings saved!")
                        
                        import time
                        time.sleep(1)
                        _st_safe_rerun()
                    except Exception as ex:
                        st.error(f"Failed to save: {ex}")

        with tab1:
            st.markdown("#### Page Access Permissions")
            with st.form("page_access_form"):
                page_vis = current_config.get("page_visibility", {})
                existing_access = current_config.get("page_access", {})
                management_pages = {
                    "Home",
                    "Add Asset",
                    "Manage Locations",
                    "Manage Users",
                    "Audit Log",
                    "Recycle Bin",
                    "Backup & Recovery",
                    "Location Settings",
                    "My Tasks",
                    "2FA Settings",
                    "Login History",
                    "View Transactions",
                }
                all_pages = [p for p in ICONS.keys() if p not in management_pages]
                cols = st.columns(3)
                toggled = {}
                for idx, p in enumerate(all_pages):
                    with cols[idx % 3]:
                        toggled[p] = st.checkbox(
                            f"Allow {p}",
                            value=existing_access.get(p, True),
                            key=f"page_access_{p}"
                        )
                st.markdown("##### Tab Access Controls")
                tabs_access = current_config.get("tabs_access", {})
                with st.expander("Tank Transactions", expanded=False):
                    tt_tabs = [
                        "Tank Transactions",
                        "Meter Transactions",
                        "River Draft",
                        "Produced Water",
                        "Condensate Records",
                        "Production",
                    ]
                    tt_cols = st.columns(3)
                    tt_toggled = {}
                    for i, t in enumerate(tt_tabs):
                        with tt_cols[i % 3]:
                            tt_toggled[t] = st.checkbox(
                                t,
                                value=tabs_access.get("Tank Transactions", {}).get(t, True),
                                key=f"tabs_tt_{t}"
                            )
                with st.expander("FSO-Operations", expanded=False):
                    fso_tabs = ["🧾 OTR", "📊 Material Balance"]
                    fso_cols = st.columns(2)
                    fso_toggled = {}
                    for i, t in enumerate(fso_tabs):
                        with fso_cols[i % 2]:
                            fso_toggled[t] = st.checkbox(
                                t,
                                value=tabs_access.get("FSO-Operations", {}).get(t, True),
                                key=f"tabs_fso_{t}"
                            )
                with st.expander("BCCR", expanded=False):
                    bccr_tabs = ["Mapping", "BCCR Report"]
                    bccr_cols = st.columns(2)
                    bccr_toggled = {}
                    for i, t in enumerate(bccr_tabs):
                        with bccr_cols[i % 2]:
                            bccr_toggled[t] = st.checkbox(
                                t,
                                value=tabs_access.get("BCCR", {}).get(t, True),
                                key=f"tabs_bccr_{t}"
                            )
                with st.expander("Yade-Vessel Mapping", expanded=False):
                    yvm_tabs = ["Mapping", "Comparison"]
                    yvm_cols = st.columns(2)
                    yvm_toggled = {}
                    for i, t in enumerate(yvm_tabs):
                        with yvm_cols[i % 2]:
                            yvm_toggled[t] = st.checkbox(
                                t,
                                value=tabs_access.get("Yade-Vessel Mapping", {}).get(t, True),
                                key=f"tabs_yvm_{t}"
                            )
                save_page_access = st.form_submit_button("💾 Save Access Settings", type="primary")
                if save_page_access:
                    new_config = current_config.copy()
                    new_config["page_access"] = toggled
                    new_page_vis = page_vis.copy()
                    new_page_vis["show_tank_transactions"] = toggled.get("Tank Transactions", True)
                    new_page_vis["show_tanker_transactions"] = toggled.get("Tanker Transactions", True)
                    new_page_vis["show_yade_transactions"] = toggled.get("Yade Transactions", True)
                    new_page_vis["show_toa_yade"] = toggled.get("TOA-Yade", True)
                    new_config["page_visibility"] = new_page_vis
                    new_tabs_access = tabs_access.copy()
                    new_tabs_access["Tank Transactions"] = tt_toggled
                    new_tabs_access["FSO-Operations"] = fso_toggled
                    new_tabs_access["BCCR"] = bccr_toggled
                    new_tabs_access["Yade-Vessel Mapping"] = yvm_toggled
                    new_config["tabs_access"] = new_tabs_access
                    try:
                        with get_session() as s:
                            LocationConfig.save_config(s, location_id, new_config)
                        st.success("? Access settings saved!")
                        user = st.session_state.get("auth_user")
                        if user:
                            from security import SecurityManager
                            with get_session() as s_a:
                                SecurityManager.log_audit(
                                    s_a,
                                    user["username"],
                                    "UPDATE_LOCATION_CONFIG",
                                    resource_type="Location",
                                    resource_id=str(location_id),
                                    details="Updated page/tab access config",
                                    user_id=user.get("id"),
                                )
                        import time
                        time.sleep(1)
                        _st_safe_rerun()
                    except Exception as ex:
                        st.error(f"Failed to save: {ex}")

        # ========== TAB 6: Vessel Assignments ==========
        with tab6:
            st.markdown("#### Vessel Assignments for this Location")
            try:
                from models import Vessel, LocationVessel
                with get_session() as s:
                    vessels = s.query(Vessel).order_by(Vessel.name).all()
                    existing_links = (
                        s.query(LocationVessel)
                        .filter(LocationVessel.location_id == location_id)
                        .all()
                    )
            except Exception as ex:
                vessels = []
                existing_links = []
                st.error(f"Failed to load vessels: {ex}")

            if not vessels:
                st.info("No vessels available. Add vessels from the Asset page first.")
            else:
                vessel_options = {v.id: v.name for v in vessels}
                active_ids = [
                    link.vessel_id for link in existing_links if link.is_active
                ]
                with st.form("location_vessel_assign_form"):
                    selected_vessels = st.multiselect(
                        "Select vessels to make available at this location",
                        options=list(vessel_options.keys()),
                        default=active_ids,
                        format_func=lambda vid: vessel_options.get(vid, f"Vessel #{vid}"),
                        help="Selected vessels appear in the OTR-Vessel dropdown for this location.",
                    )
                    save_assignments = st.form_submit_button(" Save Vessel Assignments", type="primary")
                    if save_assignments:
                        try:
                            with get_session() as s:
                                rows = (
                                    s.query(LocationVessel)
                                    .filter(LocationVessel.location_id == location_id)
                                    .all()
                                )
                                row_map = {row.vessel_id: row for row in rows}
                                selected_set = set(selected_vessels)

                                for vessel_id in selected_set:
                                    if vessel_id in row_map:
                                        row_map[vessel_id].is_active = True
                                    else:
                                        s.add(
                                            LocationVessel(
                                                location_id=location_id,
                                                vessel_id=vessel_id,
                                                is_active=True,
                                            )
                                        )

                                for vessel_id, row in row_map.items():
                                    if vessel_id not in selected_set and row.is_active:
                                        row.is_active = False

                                s.commit()
                            st.success("Vessel assignments updated.")
                            import time as _t
                            _t.sleep(1)
                            _st_safe_rerun()
                        except Exception as ex:
                            st.error(f"Failed to update assignments: {ex}")

        # ========== TAB 7: Report Builder ==========
        with tab7:
            import json
            import pandas as pd
            from datetime import date, timedelta, datetime
            from sqlalchemy import or_
            from models import ReportDefinition
            from material_balance_calculator import MaterialBalanceCalculator as MBC
            st.markdown("#### Report Tabs")
            try:
                with get_session() as s:
                    report_rows = (
                        s.query(ReportDefinition)
                        .filter(
                            or_(ReportDefinition.location_id == location_id, ReportDefinition.location_id.is_(None)),
                            ReportDefinition.is_active == True,
                        )
                        .order_by(ReportDefinition.name)
                        .all()
                    )
                st.dataframe(
                    pd.DataFrame(
                        [
                            {
                                "Name": r.name,
                                "Slug": r.slug,
                                "Scope": "Location" if r.location_id else "Global",
                            }
                            for r in report_rows
                        ]
                    ),
                    use_container_width=True,
                    hide_index=True,
                )
            except Exception as ex:
                st.info("No report tabs found.")

            st.markdown("#### Create Report Tab")
            # Build location selectors (target + source)
            try:
                from models import Location
                with get_session() as s_loc:
                    _locs = s_loc.query(Location).order_by(Location.name).all()
                location_label_to_id = {f"{loc.name} ({loc.code})": loc.id for loc in _locs}
            except Exception:
                location_label_to_id = {f"(Current) {location_id}": location_id}
            if not location_label_to_id:
                location_label_to_id = {f"(Current) {location_id}": location_id}
            location_id_to_label = {vid: lbl for lbl, vid in location_label_to_id.items()}
            location_labels = list(location_label_to_id.keys())

            def _loc_index_for_id(loc_id: Optional[int]) -> int:
                lbl = location_id_to_label.get(loc_id)
                if lbl and lbl in location_labels:
                    return location_labels.index(lbl)
                return 0

            report_loc_key = st.selectbox(
                "Report Location",
                location_labels,
                index=_loc_index_for_id(location_id),
                key="rb_report_loc",
            )
            report_location_id = location_label_to_id.get(report_loc_key, location_id)
            source_loc_key = st.selectbox(
                "Source Location",
                location_labels,
                index=_loc_index_for_id(report_location_id),
                key="rb_source_loc",
            )
            src_location_id = location_label_to_id.get(source_loc_key, report_location_id)

            with st.form("report_builder_create"):
                r_name = st.text_input("Name", key="rb_name")
                r_slug = st.text_input("Slug", key="rb_slug")
                r_scope = st.selectbox("Scope", ["Location", "Global"], index=0, key="rb_scope")
                source_options = _available_primary_source_keys()
                mode_opt = st.radio("Mode", ["Single Source", "Date-Merge"], index=0, key="rb_mode")
                primary_source = None
                source_fields: list[str] = []
                if mode_opt == "Single Source":
                    primary_source = st.selectbox(
                        "Primary Source",
                        source_options,
                        index=0,
                        key="rb_source",
                        format_func=_format_source_option,
                    )
                    source_fields = _discover_source_fields(primary_source, src_location_id)

                if mode_opt == "Single Source":
                    editor_df = pd.DataFrame([
                        {"Column Label": "Date", "Source Field": (source_fields[0] if source_fields else "")},
                    ])
                    edited = st.data_editor(
                        editor_df,
                        num_rows="dynamic",
                        use_container_width=True,
                        key=f"rb_columns_{primary_source}_{src_location_id}",
                        column_config={
                            "Source Field": st.column_config.SelectboxColumn(options=source_fields),
                        },
                    )
                else:
                    location_options = location_labels or [""]
                    location_name_to_id = location_label_to_id
                    map_editor = st.data_editor(
                        pd.DataFrame([
                            {
                                "Column Label": "Agge Receipt",
                                "Source": (source_options[0] if source_options else ""),
                                "Source Location": location_options[0] if location_options else "",
                                "Source Field": "qty_bbls",
                                "Date Field": "date",
                                "Aggregate": "sum",
                                "Operation Filter": "Receipt",
                            },
                            {
                                "Column Label": "Asemoku Dispatch",
                                "Source": (source_options[0] if source_options else ""),
                                "Source Location": location_options[0] if location_options else "",
                                "Source Field": "qty_bbls",
                                "Date Field": "date",
                                "Aggregate": "sum",
                                "Operation Filter": "Dispatch",
                            },
                        ]),
                        num_rows="dynamic",
                        use_container_width=True,
                        key="rb_mappings_editor",
                        column_config={
                            "Source": st.column_config.SelectboxColumn(options=source_options, format_func=_format_source_option),
                            "Source Location": st.column_config.SelectboxColumn(options=location_options),
                            "Aggregate": st.column_config.SelectboxColumn(options=["sum", "last", "first"]),
                        },
                    )
                    calc_editor = st.data_editor(
                        pd.DataFrame([
                            {"Result Label": "", "Expression": ""},
                        ]),
                        num_rows="dynamic",
                        use_container_width=True,
                        key="rb_calc_editor",
                    )
                    st.caption("Use expressions like Column 3 - Column 2 or wrap names in [brackets] to create calculated columns.")
                save_btn = st.form_submit_button("💾 Save Report Tab", type="primary")
                if save_btn:
                    if mode_opt == "Single Source":
                        cols = []
                        for _, row in edited.iterrows():
                            label = str(row.get("Column Label") or "").strip()
                            field = str(row.get("Source Field") or "").strip()
                            if label and field:
                                cols.append({"label": label, "field": field})
                        resolved_primary = _resolve_source_key(primary_source) or primary_source
                        cfg = {"mode": "single_source", "primary_source": resolved_primary, "columns": cols}
                    else:
                        mappings = []
                        for _, row in map_editor.iterrows():
                            label = str(row.get("Column Label") or "").strip()
                            source_raw = str(row.get("Source") or "").strip()
                            source = _resolve_source_key(source_raw) or source_raw
                            loc_name = str(row.get("Source Location") or "").strip()
                            field = str(row.get("Source Field") or "").strip()
                            date_field = str(row.get("Date Field") or "date").strip()
                            agg = str(row.get("Aggregate") or "sum").strip()
                            op_filter = str(row.get("Operation Filter") or "").strip()
                            if label and source and field and date_field:
                                mappings.append({
                                    "label": label,
                                    "source": source,
                                    "location_id": location_name_to_id.get(loc_name),
                                    "field": field,
                                    "date_field": date_field,
                                    "aggregate": agg,
                                    "operation_filter": op_filter,
                                })
                        calcs = []
                        for _, row in calc_editor.iterrows():
                            lbl = str(row.get("Result Label") or "").strip()
                            expr = str(row.get("Expression") or "").strip()
                            if lbl and expr:
                                calcs.append({"label": lbl, "expression": expr})
                        cfg = {"mode": "date_merge", "mappings": mappings, "calculations": calcs}
                    try:
                        with get_session() as s:
                            scope_loc_id = report_location_id if r_scope == "Location" else None
                            rd = ReportDefinition(
                                location_id=scope_loc_id,
                                name=r_name.strip(),
                                slug=r_slug.strip(),
                                config_json=json.dumps(cfg | ({"source_location_id": src_location_id} if (mode_opt == "Single Source") else {})),
                                is_active=True,
                                created_by=(st.session_state.get("auth_user") or {}).get("username"),
                            )
                            s.add(rd)
                            s.commit()
                        st.success("? Report tab saved")
                        import time as _t
                        _t.sleep(1)
                        _st_safe_rerun()
                    except Exception as _ex:
                        st.error(f"Failed to save: {_ex}")
                    try:
                        with get_session() as s:
                            scope_loc_id = report_location_id if r_scope == "Location" else None
                            rd = ReportDefinition(
                                location_id=scope_loc_id,
                                name=r_name.strip(),
                                slug=r_slug.strip(),
                                config_json=json.dumps(cfg),
                                is_active=True,
                                created_by=(st.session_state.get("auth_user") or {}).get("username"),
                            )
                            s.add(rd)
                            s.commit()
                        st.success("? Report tab saved")
                        import time as _t
                        _t.sleep(1)
                        _st_safe_rerun()
                    except Exception as _ex:
                        st.error(f"Failed to save: {_ex}")

            st.markdown("#### Manage Existing Tabs")
            try:
                with get_session() as s:
                    m_rows = (
                        s.query(ReportDefinition)
                        .filter(or_(ReportDefinition.location_id == location_id, ReportDefinition.location_id.is_(None)))
                        .order_by(ReportDefinition.name)
                        .all()
                    )
                if m_rows:
                    m_labels = [f"{r.name} ({'Location' if r.location_id else 'Global'})" for r in m_rows]
                    m_sel = st.selectbox("Select", options=m_labels, index=0, key="rb_manage_select")
                    m_idx = m_labels.index(m_sel)
                    rd = m_rows[m_idx]
                    try:
                        m_cfg = json.loads(rd.config_json or "{}")
                    except Exception:
                        m_cfg = {}
                    m_name = st.text_input("Name", value=rd.name or "", key=f"rb_m_name_{rd.id}")
                    m_slug = st.text_input("Slug", value=rd.slug or "", key=f"rb_m_slug_{rd.id}")
                    m_scope = st.selectbox("Scope", ["Location", "Global"], index=(0 if rd.location_id else 1), key=f"rb_m_scope_{rd.id}")
                    m_active = st.checkbox("Active", value=bool(rd.is_active), key=f"rb_m_active_{rd.id}")
                    m_mode = st.radio("Mode", ["Single Source", "Date-Merge"], index=(0 if (m_cfg.get("mode") == "single_source" or not m_cfg.get("mode")) else 1), key=f"rb_m_mode_{rd.id}")
                    if m_scope == "Location":
                        default_report_label = location_id_to_label.get(rd.location_id) or location_labels[0]
                        m_report_loc_key = st.selectbox(
                            "Report Location",
                            location_labels,
                            index=(location_labels.index(default_report_label) if default_report_label in location_labels else 0),
                            key=f"rb_m_report_loc_{rd.id}",
                        )
                        m_report_location_id = location_label_to_id.get(m_report_loc_key)
                    else:
                        m_report_location_id = None
                    base_source_options = _available_primary_source_keys()
                    selected_source_loc_id = m_cfg.get("source_location_id") or src_location_id
                    if m_mode == "Single Source":
                        current_source_raw = m_cfg.get("primary_source")
                        if not current_source_raw:
                            current_source_raw = base_source_options[0] if base_source_options else ""
                        select_options = list(base_source_options)
                        if current_source_raw and current_source_raw not in select_options:
                            select_options.append(current_source_raw)
                        stored_source_loc_id = m_cfg.get("source_location_id") or src_location_id
                        default_source_label = location_id_to_label.get(stored_source_loc_id) or location_labels[0]
                        m_source_loc_key = st.selectbox(
                            "Source Location",
                            location_labels,
                            index=(location_labels.index(default_source_label) if default_source_label in location_labels else 0),
                            key=f"rb_m_source_loc_{rd.id}",
                        )
                        m_source_location_id = location_label_to_id.get(m_source_loc_key, stored_source_loc_id)
                        selected_source_loc_id = m_source_location_id
                        m_src = st.selectbox(
                            "Primary Source",
                            select_options,
                            index=(select_options.index(current_source_raw) if current_source_raw in select_options else 0),
                            key=f"rb_m_src_{rd.id}",
                            format_func=_format_source_option,
                        )
                        m_fields = _discover_source_fields(m_src, m_source_location_id)
                        preset_cols = m_cfg.get("columns") or []
                        m_df = pd.DataFrame([{ "Column Label": c.get("label"), "Source Field": c.get("field") } for c in preset_cols] or [{"Column Label": "Date", "Source Field": (m_fields[0] if m_fields else "")}])
                        m_edited = st.data_editor(
                            m_df,
                            num_rows="dynamic",
                            use_container_width=True,
                            key=f"rb_m_cols_{rd.id}_{_resolve_source_key(m_src) or m_src}_{m_source_location_id}",
                            column_config={
                                "Source Field": st.column_config.SelectboxColumn(options=m_fields),
                            },
                        )
                    else:
                        e_loc_name_to_id = location_label_to_id
                        preset_maps = m_cfg.get("mappings") or []
                        map_source_options = list(base_source_options)
                        for m in preset_maps:
                            src_val = str(m.get("source") or "").strip()
                            if src_val and src_val not in map_source_options:
                                map_source_options.append(src_val)
                        m_map_df = pd.DataFrame([
                            {
                                "Column Label": m.get("label"),
                                "Source": m.get("source"),
                                "Source Location": [k for k,v in e_loc_name_to_id.items() if v == m.get("location_id")][0] if m.get("location_id") in e_loc_name_to_id.values() else "",
                                "Source Field": m.get("field"),
                                "Date Field": m.get("date_field"),
                                "Aggregate": m.get("aggregate"),
                                "Operation Filter": m.get("operation_filter"),
                            }
                            for m in preset_maps
                        ] or [
                            {
                                "Column Label": "Column",
                                "Source": (base_source_options[0] if base_source_options else ""),
                                "Source Location": [k for k,v in e_loc_name_to_id.items() if v == src_location_id][0] if src_location_id in e_loc_name_to_id.values() else "",
                                "Source Field": "qty_bbls",
                                "Date Field": "date",
                                "Aggregate": "sum",
                                "Operation Filter": "",
                            }
                        ])
                        m_map_editor = st.data_editor(
                            m_map_df,
                            num_rows="dynamic",
                            use_container_width=True,
                            key=f"rb_m_maps_{rd.id}",
                            column_config={
                                "Source": st.column_config.SelectboxColumn(options=map_source_options, format_func=_format_source_option),
                                "Aggregate": st.column_config.SelectboxColumn(options=["sum", "last", "first"]),
                            },
                        )
                        m_calc_df = pd.DataFrame([
                            {"Result Label": c.get("label"), "Expression": c.get("expression")}
                            for c in (m_cfg.get("calculations") or [])
                        ])
                        if m_calc_df.empty:
                            m_calc_df = pd.DataFrame([{"Result Label": "", "Expression": ""}])
                        m_calc_editor = st.data_editor(
                            m_calc_df,
                            num_rows="dynamic",
                            use_container_width=True,
                            key=f"rb_m_calc_{rd.id}",
                        )
                        st.caption("For calculations, you can reference columns by label in [brackets] or by saying Column 3 - Column 2.")
                    b_save, b_delete = st.columns(2)
                    with b_save:
                        if st.button("Save Changes", key=f"rb_m_save_{rd.id}"):
                            try:
                                with get_session() as s:
                                    rd.name = m_name.strip()
                                    rd.slug = m_slug.strip()
                                    rd.is_active = bool(m_active)
                                    rd.location_id = (m_report_location_id if m_scope == "Location" else None)
                                    if m_mode == "Single Source":
                                        new_cols = []
                                        for _, row in m_edited.iterrows():
                                            label = str(row.get("Column Label") or "").strip()
                                            field = str(row.get("Source Field") or "").strip()
                                            if label and field:
                                                new_cols.append({"label": label, "field": field})
                                        resolved_m_src = _resolve_source_key(m_src) or m_src
                                        rd.config_json = json.dumps({"mode": "single_source", "primary_source": resolved_m_src, "columns": new_cols, "source_location_id": selected_source_loc_id})
                                    else:
                                        new_maps = []
                                        for _, row in m_map_editor.iterrows():
                                            label = str(row.get("Column Label") or "").strip()
                                            source_raw = str(row.get("Source") or "").strip()
                                            source = _resolve_source_key(source_raw) or source_raw
                                            loc_name = str(row.get("Source Location") or "").strip()
                                            field = str(row.get("Source Field") or "").strip()
                                            date_field = str(row.get("Date Field") or "date").strip()
                                            agg = str(row.get("Aggregate") or "sum").strip()
                                            op_filter = str(row.get("Operation Filter") or "").strip()
                                            if label and source and field and date_field:
                                                new_maps.append({
                                                    "label": label,
                                                    "source": source,
                                                    "location_id": e_loc_name_to_id.get(loc_name),
                                                    "field": field,
                                                    "date_field": date_field,
                                                    "aggregate": agg,
                                                    "operation_filter": op_filter,
                                                })
                                        new_calcs = []
                                        for _, row in m_calc_editor.iterrows():
                                            lbl = str(row.get("Result Label") or "").strip()
                                            expr = str(row.get("Expression") or "").strip()
                                            if lbl and expr:
                                                new_calcs.append({"label": lbl, "expression": expr})
                                        rd.config_json = json.dumps({"mode": "date_merge", "mappings": new_maps, "calculations": new_calcs})
                                    s.add(rd)
                                    s.commit()
                                st.success("Saved")
                                import time as _t
                                _t.sleep(1)
                                _st_safe_rerun()
                            except Exception as ex:
                                st.error(f"Failed: {ex}")
                    with b_delete:
                        if st.button("Delete", key=f"rb_m_del_{rd.id}"):
                            try:
                                with get_session() as s:
                                    obj = s.query(ReportDefinition).filter(ReportDefinition.id == rd.id).one_or_none()
                                    if obj:
                                        s.delete(obj)
                                        s.commit()
                                st.success("Deleted")
                                import time as _t
                                _t.sleep(1)
                                _st_safe_rerun()
                            except Exception as ex:
                                st.error(f"Failed: {ex}")
                else:
                    st.info("No report tabs found.")
            except Exception:
                pass

            st.markdown("#### Source Tables Preview")
            prev_cols = st.columns(2)
            prev_from = prev_cols[0].date_input("From date", value=date.today() - timedelta(days=30), key="rb_prev_from")
            prev_to = prev_cols[1].date_input("To date", value=date.today(), key="rb_prev_to")
            preview_keys = _available_primary_source_keys()
            if not preview_keys:
                st.info('No primary sources configured.')
            else:
                preview_labels = [_format_source_label(k) for k in preview_keys]
                src_tabs = st.tabs(preview_labels)
                try:
                    with get_session() as s:
                        for idx, src_key in enumerate(preview_keys):
                            with src_tabs[idx]:
                                meta = _get_source_meta(src_key)
                                if not meta:
                                    st.info('No metadata available for this source.')
                                    continue
                                if meta.get("type") == "fso_material_balance":
                                    st.info("Preview not available for FSO Material Balance. Select an FSO vessel in the single-source builder to see this data.")
                                    continue
                                rows = _fetch_source_rows(src_key, s, src_location_id, prev_from, prev_to)
                                if not rows:
                                    st.info('No records within the selected range.')
                                    continue
                                limit = 500
                                sample_rows = rows[:limit]
                                if sample_rows and isinstance(sample_rows[0], dict):
                                    df = pd.DataFrame(sample_rows)
                                else:
                                    col_names = _get_model_columns(src_key)
                                    if not col_names:
                                        st.info('No column metadata available for this source.')
                                        continue
                                    df = pd.DataFrame([{col: getattr(r, col, None) for col in col_names} for r in sample_rows])
                                if df.empty:
                                    st.info('No records within the selected range.')
                                else:
                                    st.caption(f'Showing up to {min(limit, len(rows))} rows for this source.')
                                    st.dataframe(df, use_container_width=True, hide_index=True)
                except Exception as ex:
                    st.error(f'Failed to load previews: {ex}')


        st.markdown("---")

        # ========== RESET TO DEFAULT ==========
        st.markdown("### 🔄 Reset Configuration")
        
        with st.expander("Reset to Default Settings", expanded=False):
            st.warning("This will reset all configuration to system defaults.")
            
            if st.button("🔄 Reset to Default", key="reset_config_btn"):
                try:
                    with get_session() as s:
                        LocationConfig.reset_to_default(s, location_id)
                    
                    st.success("? Configuration reset to default!")
                    
                    # Log audit
                    user = st.session_state.get("auth_user")
                    if user:
                        from security import SecurityManager
                        with get_session() as s:
                            SecurityManager.log_audit(
                                s, user["username"], "RESET_LOCATION_CONFIG",
                                resource_type="Location",
                                resource_id=str(location_id),
                                details="Reset to default configuration",
                                user_id=user["id"]
                            )
                    
                    import time
                    time.sleep(1)
                    _st_safe_rerun()
                except Exception as ex:
                    st.error(f"Failed to reset: {ex}")
        
        # ========== VIEW RAW JSON ==========
        st.markdown("---")
        st.markdown("### 🛠️ Advanced: View Raw Configuration")
        
        with st.expander("View JSON Configuration", expanded=False):
            st.json(current_config)

# ============================= Recycle Bin (admin only) ==========================
elif page == "Recycle Bin":
    if st.session_state.get("auth_user", {}).get("role") != "admin-operations":
        header("Recycle Bin")
        st.error("You do not have permission to access this page. Admin-Operations only.")
        st.stop()

    header("Recycle Bin")
    st.caption("View soft-deleted records stored in the recycle bin.")

    with get_session() as s:
        type_rows = s.query(RecycleBinEntry.resource_type).distinct().all()
        resource_types = ["(All)"] + sorted(
            {row[0] for row in type_rows if row and row[0]}
        )
        from location_manager import LocationManager

        loc_objs = LocationManager.get_all_locations(s, active_only=False)
        location_options = {"(All locations)": None}
        for loc in loc_objs:
            key = f"{loc.name} ({loc.code})"
            location_options[key] = loc.id

    filter_col1, filter_col2 = st.columns(2)
    with filter_col1:
        selected_type = st.selectbox("Resource Type", resource_types, index=0)
    with filter_col2:
        selected_location = st.selectbox("Location", list(location_options.keys()), index=0)

    filter_col3, filter_col4 = st.columns(2)
    with filter_col3:
        from_date = st.date_input(
            "From Date",
            value=date.today() - timedelta(days=7),
            key="recycle_from_date",
        )
    with filter_col4:
        to_date = st.date_input(
            "To Date",
            value=date.today(),
            key="recycle_to_date",
        )

    search_text = st.text_input(
        "Search (resource id, label or reason)", key="recycle_search"
    ).strip()
    max_records = st.slider("Max records", min_value=50, max_value=500, value=200, step=25)

    with get_session() as s:
        query = s.query(RecycleBinEntry).order_by(RecycleBinEntry.deleted_at.desc())
        if selected_type != "(All)":
            query = query.filter(RecycleBinEntry.resource_type == selected_type)
        loc_filter_id = location_options.get(selected_location)
        if loc_filter_id:
            query = query.filter(RecycleBinEntry.location_id == loc_filter_id)
        if from_date:
            from_dt = datetime.combine(from_date, datetime.min.time())
            query = query.filter(RecycleBinEntry.deleted_at >= from_dt)
        if to_date:
            to_dt = datetime.combine(to_date, datetime.max.time())
            query = query.filter(RecycleBinEntry.deleted_at <= to_dt)
        if search_text:
            pattern = f"%{search_text}%"
            query = query.filter(
                or_(
                    RecycleBinEntry.resource_label.ilike(pattern),
                    RecycleBinEntry.resource_id.ilike(pattern),
                    RecycleBinEntry.reason.ilike(pattern),
                )
            )
        entries = query.limit(int(max_records)).all()

    if not entries:
        st.info("No archived records match your criteria.")
    else:
        import pandas as pd

        location_lookup = {loc.id: f"{loc.name} ({loc.code})" for loc in loc_objs}
        table_rows = []
        for entry in entries:
            table_rows.append(
                {
                    "Deleted At": format_local_datetime(entry.deleted_at),
                    "Type": entry.resource_type,
                    "Resource": entry.resource_label or entry.resource_id,
                    "Location": location_lookup.get(entry.location_id, "-"),
                    "Deleted By": entry.deleted_by,
                    "Reason": entry.reason or "",
                }
            )
        st.dataframe(pd.DataFrame(table_rows), use_container_width=True, hide_index=True)

        for entry in entries:
            header_label = f"{entry.resource_type} � {entry.resource_label or entry.resource_id} ({format_local_datetime(entry.deleted_at)})"
            with st.expander(header_label, expanded=False):
                st.write(
                    {
                        "Deleted By": entry.deleted_by,
                        "User ID": entry.deleted_by_id,
                        "Location": location_lookup.get(entry.location_id, "-"),
                        "Reason": entry.reason or "-",
                        "Record ID": entry.resource_id,
                    }
                )
                try:
                    payload = json.loads(entry.payload_json)
                    st.json(payload)
                except Exception:
                    st.code(entry.payload_json)

# ============================= Audit Log (admin only) ==========================
elif page == "Audit Log":
    if st.session_state.get("auth_user", {}).get("role") not in ["admin-operations", "admin-it"]:
        header("Audit Log")
        st.error("You do not have permission to access this page. Admin-Operations or Admin-IT only.")
        st.stop()

    header("Audit Log")
    st.markdown("### 📜 System Audit Trail")
    
    from datetime import date, timedelta, datetime
    from security import SecurityManager
    import pandas as pd
    from models import AuditLog
    
    # Import timezone utilities
    try:
        from timezone_utils import utc_to_local, format_local_datetime, get_local_time
        TIMEZONE_AVAILABLE = True
    except ImportError:
        TIMEZONE_AVAILABLE = False
        st.warning("⚠️ Timezone utilities not found. Install pytz: `pip install pytz`")
    
    # Show current time for reference
    if TIMEZONE_AVAILABLE:
        current_time = get_local_time()
        st.caption(f"? Current Time: **{current_time.strftime('%Y-%m-%d %H:%M:%S')}** (Nigeria Time - WAT, UTC+1)")
    else:
        st.caption(f"? Current Time: **{datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}** (UTC)")
    
    # Filters
    with st.container(border=True):
        st.markdown("#### 🔎 Filters")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            f_username = st.text_input("Username", placeholder="Search username...", key="audit_username")
        
        with col2:
            f_action = st.selectbox(
                "Action", 
                ["(All)", "LOGIN", "LOGOUT", "CREATE", "UPDATE", "DELETE", "EXPORT", "VIEW"], 
                key="audit_action"
            )
        
        with col3:
            f_from = st.date_input(
                "From Date", 
                value=date.today() - timedelta(days=7), 
                key="audit_from"
            )
        
        with col4:
            f_to = st.date_input(
                "To Date", 
                value=date.today(), 
                key="audit_to"
            )
    
    # Additional filters
    with st.container(border=True):
        st.markdown("#### ⚙️ Advanced Filters")
        col5, col6, col7 = st.columns(3)
        
        with col5:
            f_resource_type = st.selectbox(
                "Resource Type",
                ["(All)", "TankTransaction", "YadeVoyage", "TankerTransaction", "OTRVessel", "User", "Location"],
                key="audit_resource_type"
            )
        
        with col6:
            f_success = st.selectbox(
                "Status",
                ["(All)", "Success", "Failed"],
                key="audit_success"
            )
        
        with col7:
            # Get locations for filter (admin only)
            with get_session() as s:
                from models import Location
                locations = s.query(Location).filter(Location.is_active == True).all()
                location_names = ["(All)"] + [loc.name for loc in locations]
            
            f_location = st.selectbox(
                "Location",
                location_names,
                key="audit_location"
            )
    
    # Fetch audit logs
    try:
        with get_session() as s:
            query = s.query(AuditLog).order_by(AuditLog.timestamp.desc())
            
            # Apply filters
            if f_username:
                query = query.filter(AuditLog.username.like(f"%{f_username}%"))
            
            if f_action != "(All)":
                query = query.filter(AuditLog.action == f_action)
            
            if f_resource_type != "(All)":
                query = query.filter(AuditLog.resource_type == f_resource_type)
            
            if f_success == "Success":
                query = query.filter(AuditLog.success == True)
            elif f_success == "Failed":
                query = query.filter(AuditLog.success == False)
            
            if f_location != "(All)":
                # Find location ID
                location_obj = next((loc for loc in locations if loc.name == f_location), None)
                if location_obj:
                    query = query.filter(AuditLog.location_id == location_obj.id)
            
            # Date range filter
            query = query.filter(AuditLog.timestamp >= datetime.combine(f_from, datetime.min.time()))
            query = query.filter(AuditLog.timestamp <= datetime.combine(f_to, datetime.max.time()))
            
            logs = query.limit(500).all()
        
        if logs:
            # ========== STATISTICS ==========
            st.markdown("---")
            
            total_logs = len(logs)
            success_logs = sum(1 for log in logs if getattr(log, 'success', True))
            failed_logs = total_logs - success_logs
            unique_users = len(set(log.username for log in logs if log.username))
            
            stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
            
            with stat_col1:
                st.metric("Total Actions", total_logs)
            
            with stat_col2:
                st.metric("Successful", success_logs)
            
            with stat_col3:
                st.metric("Failed", failed_logs, delta_color="inverse")
            
            with stat_col4:
                st.metric("Unique Users", unique_users)
            
            st.markdown("---")
            
            # Show timezone info
            if TIMEZONE_AVAILABLE:
                st.caption("? Showing times in **Nigeria Time (WAT - UTC+1)**")
            else:
                st.caption("? Showing times in **UTC** (install pytz for local time)")
            
            # Prepare display data
            display_data = []
            
            for log in logs:
                # Format timestamp in local time
                if log.timestamp:
                    if TIMEZONE_AVAILABLE:
                        timestamp_str = format_local_datetime(
                            log.timestamp,
                            "%Y-%m-%d %H:%M:%S",
                            naive_is_local=True
                        )
                    else:
                        timestamp_str = log.timestamp.strftime("%Y-%m-%d %H:%M:%S UTC")
                else:
                    timestamp_str = "N/A"
                
                # Get location name
                location_name = "�"
                if log.location_id:
                    location_obj = next((loc for loc in locations if loc.id == log.location_id), None)
                    if location_obj:
                        location_name = location_obj.code
                
                # Format resource
                resource_str = ""
                if log.resource_type:
                    resource_str = log.resource_type
                    if log.resource_id:
                        resource_str += f" #{log.resource_id}"
                else:
                    resource_str = "�"
                
                display_data.append({
                    "Timestamp": timestamp_str,
                    "Username": log.username or "�",
                    "Action": log.action or "�",
                    "Resource": resource_str,
                    "Location": location_name,
                    "Details": log.details or "�",
                    "IP Address": log.ip_address or "�",
                    "Status": "? Success" if getattr(log, 'success', True) else "? Failed"
                })
            
            df = pd.DataFrame(display_data)
            
            # Display table
            st.dataframe(
                df, 
                use_container_width=True, 
                hide_index=True,
                height=600,
                column_config={
                    "Timestamp": st.column_config.TextColumn("Timestamp", width="medium"),
                    "Username": st.column_config.TextColumn("Username", width="small"),
                    "Action": st.column_config.TextColumn("Action", width="small"),
                    "Resource": st.column_config.TextColumn("Resource", width="medium"),
                    "Location": st.column_config.TextColumn("Location", width="small"),
                    "Details": st.column_config.TextColumn("Details", width="large"),
                    "IP Address": st.column_config.TextColumn("IP Address", width="medium"),
                    "Status": st.column_config.TextColumn("Status", width="small"),
                }
            )
            
            st.caption(f"🔢 Showing **{len(logs)}** records (max 500)")
            
            # ========== ACTIVITY BREAKDOWN ==========
            st.markdown("---")
            st.markdown("#### 📊 Activity Breakdown")
            
            breakdown_col1, breakdown_col2 = st.columns(2)
            
            with breakdown_col1:
                st.markdown("##### 🛠️ Actions")
                action_counts = {}
                for log in logs:
                    action = log.action or "Unknown"
                    action_counts[action] = action_counts.get(action, 0) + 1
                
                sorted_actions = sorted(action_counts.items(), key=lambda x: x[1], reverse=True)
                for action, count in sorted_actions[:10]:
                    st.caption(f"� {action}: {count}")
            
            with breakdown_col2:
                st.markdown("##### 👥 Top Users")
                user_counts = {}
                for log in logs:
                    username = log.username or "Unknown"
                    user_counts[username] = user_counts.get(username, 0) + 1
                
                sorted_users = sorted(user_counts.items(), key=lambda x: x[1], reverse=True)
                for username, count in sorted_users[:10]:
                    st.caption(f"� {username}: {count} actions")
            
            st.markdown("---")
            
            # ========== EXPORT OPTIONS ==========
            export_col1, export_col2, export_col3 = st.columns([0.4, 0.4, 0.2])
            
            with export_col1:
                # CSV Export
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "📥 Download CSV",
                    data=csv,
                    file_name=f"audit_log_{f_from.strftime('%Y%m%d')}_{f_to.strftime('%Y%m%d')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            with export_col2:
                # Excel Export
                try:
                    from io import BytesIO
                    excel_buffer = BytesIO()
                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                        df.to_excel(writer, index=False, sheet_name='Audit Log')
                    
                    st.download_button(
                        "⬇️ Download Excel",
                        data=excel_buffer.getvalue(),
                        file_name=f"audit_log_{f_from.strftime('%Y%m%d')}_{f_to.strftime('%Y%m%d')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
                except ImportError:
                    st.button("⬇️ Download Excel", disabled=True, help="Install openpyxl", use_container_width=True)
            
            with export_col3:
                if st.button("🔄 Refresh", use_container_width=True):
                    _st_safe_rerun()
        
        else:
            st.info("ℹ️ No audit records found for the selected filters.")
            st.caption("Try adjusting your filters or expanding the date range.")
    
    except Exception as ex:
        st.error(f"? Failed to load audit log: {ex}")
        import traceback
        with st.expander("⚠️ Error Details"):
            st.code(traceback.format_exc())

# =============================== Backup & Recovery (admin only) =============================
elif page == "Backup & Recovery":
    if st.session_state.get("auth_user", {}).get("role") not in ["admin-operations", "admin-it"]:
        header("Backup & Recovery")
        st.error("You do not have permission to access this page. Admin-Operations or Admin-IT only.")
        st.stop()

    header("Backup & Recovery")
    st.markdown("### Database Backup & Recovery Management")
    
    from backup_manager import BackupManager
    from datetime import datetime
    import pandas as pd
    
    tab1, tab2, tab3 = st.tabs(["🗄️ Backups", "🗄️ Create Backup", "📤 Export Location"])
    
    # ========== TAB 1: Manage Backups ==========
    with tab1:
        st.markdown("#### Available Backups")
        
        try:
            backups = BackupManager.list_backups()
            
            if backups:
                # Display backups table
                df = pd.DataFrame([{
                    "Timestamp": datetime.fromisoformat(b["datetime"]).strftime("%Y-%m-%d %H:%M:%S"),
                    "Type": b["type"].title(),
                    "Description": b["description"],
                    "Size (MB)": b["size_mb"],
                    "File": b["filename"]
                } for b in backups])
                
                st.dataframe(df, use_container_width=True, hide_index=True)
                st.caption(f"Total backups: {len(backups)}")
                
                # -------- Restore Section --------
                st.markdown("---")
                st.markdown("#### Restore from Backup")
                
                col1, col2 = st.columns([0.6, 0.4])
                
                with col1:
                    backup_options = {
                        f"{datetime.fromisoformat(b['datetime']).strftime('%Y-%m-%d %H:%M:%S')} - {b['description']} ({b['size_mb']} MB)": b["timestamp"]
                        for b in backups
                    }
                    
                    selected_backup = st.selectbox(
                        "Select backup to restore",
                        options=list(backup_options.keys()),
                        key="restore_backup_select"
                    )
                    
                    if selected_backup:
                        backup_ts = backup_options[selected_backup]
                        
                        # Show backup details
                        backup_info = BackupManager.get_backup_info(backup_ts)
                        if backup_info and backup_info.get("tables"):
                            st.markdown("##### Backup Contents:")
                            tables_data = []
                            for table, count in backup_info["tables"].items():
                                tables_data.append({"Table": table.title(), "Records": count})
                            st.table(pd.DataFrame(tables_data))
                        
                        st.warning("⚠️ **WARNING:** Restoring will replace your current database!")
                        st.caption("A backup of the current database will be created before restoration.")
                        
                        confirm_restore = st.text_input(
                            'Type "RESTORE" to confirm',
                            key="restore_confirm"
                        )
                        
                        if st.button("♻️ Restore Database", key="restore_btn", type="primary"):
                            if confirm_restore == "RESTORE":
                                try:
                                    result = BackupManager.restore_backup(backup_ts, create_backup_before=True)
                                    
                                    st.success(f"? Database restored successfully from {backup_ts}")
                                    if result.get("pre_restore_backup"):
                                        st.info(f"Pre-restore backup created: {result['pre_restore_backup']['filename']}")
                                    
                                    st.warning("⚠️ Please restart the application for changes to take effect.")
                                    
                                    # Log audit
                                    user = st.session_state.get("auth_user")
                                    if user:
                                        from security import SecurityManager
                                        with get_session() as s:
                                            SecurityManager.log_audit(
                                                s, user["username"], "RESTORE_BACKUP",
                                                details=f"Restored from {backup_ts}",
                                                user_id=user["id"]
                                            )
                                    
                                except Exception as ex:
                                    st.error(f"Restore failed: {ex}")
                            else:
                                st.error('Please type "RESTORE" to confirm.')
                
                with col2:
                    st.markdown("##### Delete Backup")
    
                    delete_backup = st.selectbox(
                        "Select backup to delete",
                        options=list(backup_options.keys()),
                        key="delete_backup_select"
                    )
                    
                    if delete_backup:
                        backup_ts = backup_options[delete_backup]
                        
                        # Show backup details for confirmation
                        st.caption(f"Selected: {delete_backup}")
                        
                        # Two-step confirmation
                        if "delete_backup_step" not in st.session_state:
                            st.session_state.delete_backup_step = 0
                        if "delete_backup_pending" not in st.session_state:
                            st.session_state.delete_backup_pending = None
                        
                        # Step 1: Initial delete button
                        if st.session_state.delete_backup_step == 0:
                            if st.button("🗑️ Delete Backup", key="delete_backup_btn_step1"):
                                st.session_state.delete_backup_step = 1
                                st.session_state.delete_backup_pending = backup_ts
                                _st_safe_rerun()
                        
                        # Step 2: Confirmation with typed verification
                        elif st.session_state.delete_backup_step == 1:
                            st.warning("⚠️ **Are you sure you want to delete this backup?**")
                            st.caption("This action cannot be undone!")
                            
                            # Extract just the timestamp for confirmation
                            confirm_text = backup_ts  # e.g., "20250106_143022"
                            
                            st.info(f"Type **{confirm_text}** to confirm deletion")
                            
                            user_input = st.text_input(
                                "Confirmation",
                                key="delete_backup_confirm_input",
                                placeholder=confirm_text
                            )
                            
                            col_confirm, col_cancel = st.columns(2)
                            
                            with col_confirm:
                                if st.button("? Confirm Delete", key="delete_backup_btn_step2", type="primary"):
                                    if user_input.strip() == confirm_text:
                                        try:
                                            BackupManager.delete_backup(st.session_state.delete_backup_pending)
                                            
                                            # Log audit
                                            user = st.session_state.get("auth_user")
                                            if user:
                                                from security import SecurityManager
                                                with get_session() as s:
                                                    SecurityManager.log_audit(
                                                        s, user["username"], "DELETE_BACKUP",
                                                        details=f"Deleted backup {st.session_state.delete_backup_pending}",
                                                        user_id=user["id"]
                                                    )
                                            
                                            st.success(f"? Backup deleted: {st.session_state.delete_backup_pending}")
                                            
                                            # Reset state
                                            st.session_state.delete_backup_step = 0
                                            st.session_state.delete_backup_pending = None
                                            
                                            import time
                                            time.sleep(1)
                                            _st_safe_rerun()
                                            
                                        except Exception as ex:
                                            st.error(f"Failed to delete: {ex}")
                                    else:
                                        st.error("? Confirmation text does not match. Please try again.")
                            
                            with col_cancel:
                                if st.button("❌ Cancel", key="delete_backup_cancel"):
                                    st.session_state.delete_backup_step = 0
                                    st.session_state.delete_backup_pending = None
                                    st.info("Deletion cancelled.")
                                    _st_safe_rerun()
                
                # -------- Cleanup Old Backups --------
                st.markdown("---")
                st.markdown("#### Cleanup Old Backups")
                
                cleanup_col1, cleanup_col2 = st.columns(2)
                
                with cleanup_col1:
                    days = st.number_input("Delete backups older than (days)", min_value=1, value=30, step=1, key="cleanup_days")
                    keep_min = st.number_input("Always keep minimum", min_value=1, value=5, step=1, key="cleanup_keep_min")
                
                with cleanup_col2:
                    if st.button("🧹 Run Cleanup", key="cleanup_btn"):
                        try:
                            result = BackupManager.cleanup_old_backups(days=days, keep_minimum=keep_min)
                            st.success(f"? Cleanup complete! Deleted: {result['deleted']}, Kept: {result['kept']}")
                            if result['deleted'] > 0:
                                _st_safe_rerun()
                        except Exception as ex:
                            st.error(f"Cleanup failed: {ex}")
            else:
                st.info("No backups found. Create your first backup in the 'Create Backup' tab.")
        
        except Exception as ex:
            st.error(f"Failed to load backups: {ex}")
    
    # ========== TAB 2: Create Backup ==========
    with tab2:
        st.markdown("#### Create Manual Backup")
        
        with st.form("create_backup_form"):
            description = st.text_input(
                "Backup Description",
                placeholder="e.g., Before data migration, End of month backup, etc.",
                key="backup_description"
            )
            
            submitted = st.form_submit_button("🗄️ Create Backup Now", type="primary")
            
            if submitted:
                try:
                    backup_info = BackupManager.create_backup(
                        description=description or "Manual backup",
                        backup_type="manual"
                    )
                    
                    st.success(f"? Backup created successfully!")
                    
                    col1, col2 = st.columns(2)
                    col1.metric("Filename", backup_info['filename'])
                    col2.metric("Size", f"{backup_info['size_mb']} MB")
                    
                    st.info(f"📁 Location: backups/{backup_info['filename']}")
                    
                    # Log audit
                    user = st.session_state.get("auth_user")
                    if user:
                        from security import SecurityManager
                        with get_session() as s:
                            SecurityManager.log_audit(
                                s, user["username"], "CREATE_BACKUP",
                                details=description or "Manual backup",
                                user_id=user["id"]
                            )
                    
                    import time
                    time.sleep(2)
                    _st_safe_rerun()
                    
                except Exception as ex:
                    st.error(f"Backup creation failed: {ex}")
        
        st.markdown("---")
        st.markdown("#### Current Database Statistics")
        
        try:
            from models import (
                Location, User, Tank, YadeBarge, 
                TankTransaction, YadeVoyage, OTRRecord
            )
            
            with get_session() as s:
                stats = {
                    "Locations": s.query(Location).count(),
                    "Users": s.query(User).count(),
                    "Tanks": s.query(Tank).count(),
                    "YADE Barges": s.query(YadeBarge).count(),
                    "Tank Transactions": s.query(TankTransaction).count(),
                    "YADE Voyages": s.query(YadeVoyage).count(),
                    "OTR Records": s.query(OTRRecord).count(),
                }
            
            col1, col2, col3, col4 = st.columns(4)
            cols = [col1, col2, col3, col4]
            
            for i, (key, value) in enumerate(stats.items()):
                cols[i % 4].metric(key, f"{value:,}")
        
        except Exception as ex:
            st.error(f"Failed to load stats: {ex}")
    
    # ========== TAB 3: Export Location ==========
    with tab3:
        st.markdown("#### Export Location Data")
        st.caption("Export all data for a specific location to a ZIP file")
        
        # Get locations
        try:
            from location_manager import LocationManager
            with get_session() as s:
                locations = LocationManager.get_all_locations(s, active_only=False)
            
            if locations:
                loc_options = {f"{loc.name} ({loc.code})": loc.id for loc in locations}
                
                selected_loc = st.selectbox(
                    "Select Location to Export",
                    options=list(loc_options.keys()),
                    key="export_location_select"
                )
                
                if st.button("📤 Export Location Data", key="export_location_btn", type="primary"):
                    if selected_loc:
                        loc_id = loc_options[selected_loc]
                        
                        with st.spinner("Exporting location data..."):
                            try:
                                export_path = BackupManager.export_location_data(loc_id)
                                
                                st.success(f"? Location data exported successfully!")
                                st.info(f"📄 File: {export_path.name}")
                                
                                # Provide download button
                                with open(export_path, 'rb') as f:
                                    st.download_button(
                                        "⬇️ Download Export",
                                        data=f.read(),
                                        file_name=export_path.name,
                                        mime="application/zip"
                                    )
                                
                                # Log audit
                                user = st.session_state.get("auth_user")
                                if user:
                                    from security import SecurityManager
                                    with get_session() as s:
                                        SecurityManager.log_audit(
                                            s, user["username"], "EXPORT_LOCATION",
                                            resource_type="Location",
                                            resource_id=str(loc_id),
                                            details=f"Exported {selected_loc}",
                                            user_id=user["id"]
                                        )
                                
                            except Exception as ex:
                                st.error(f"Export failed: {ex}")
            else:
                st.warning("No locations found.")
        
        except Exception as ex:
            st.error(f"Failed to load locations: {ex}")

# ========================= 2FA VERIFICATION PAGE =========================
elif page == "2FA Verify":
    header("Two-Factor Authentication")
    
    # Check if user is pending 2FA
    pending_user = st.session_state.get("pending_2fa_user")
    
    if not pending_user:
        st.error("No pending login. Please login first.")
        st.session_state["page"] = "Home"
        _st_safe_rerun()
        st.stop()
    
    st.markdown("### 🔐 Enter Verification Code")
    
    col1, col2, col3 = st.columns([0.3, 0.4, 0.3])
    
    with col2:
        st.info(f"**User:** {pending_user.get('username')}")
        st.caption("Enter the 6-digit code from your authenticator app")
        
        with st.form("2fa_verify_form"):
            token = st.text_input(
                "Verification Code",
                max_chars=10,
                placeholder="000000 or XXXX-XXXX",
                key="2fa_token_input"
            )
            
            col_verify, col_cancel = st.columns(2)
            
            with col_verify:
                verify_btn = st.form_submit_button("? Verify", type="primary", use_container_width=True)
            
            with col_cancel:
                cancel_btn = st.form_submit_button("❌ Cancel", use_container_width=True)
            
            if verify_btn:
                if not token.strip():
                    st.error("Please enter a verification code")
                else:
                    try:
                        from twofa import TwoFactorAuth
                        
                        with get_session() as s:
                            # Verify token
                            is_valid = TwoFactorAuth.verify_token(
                                s, 
                                pending_user["id"], 
                                token.strip().replace("-", "")
                            )
                            
                            if is_valid:
                                # 2FA successful - complete login
                                st.session_state.auth_user = pending_user
                                st.session_state.pop("pending_2fa_user", None)
                                
                                # Set default active location
                                if pending_user["role"] in ["admin-operations", "admin-it", "manager"]:
                                    from location_manager import LocationManager
                                    locations = LocationManager.get_all_locations(s, active_only=True)
                                    if locations:
                                        st.session_state.active_location_id = locations[0].id
                                else:
                                    st.session_state.active_location_id = pending_user["location_id"]
                                
                                # Log successful 2FA
                                from security import SecurityManager
                                SecurityManager.log_audit(
                                    s, pending_user["username"], "2FA_SUCCESS",
                                    user_id=pending_user["id"],
                                    details="2FA verification successful"
                                )
                                
                                st.success("? Verification successful!")
                                st.session_state["page"] = "Home"
                                _st_safe_rerun()
                            else:
                                st.error("? Invalid verification code. Please try again.")
                                
                                # Log failed 2FA
                                from security import SecurityManager
                                with get_session() as s:
                                    SecurityManager.log_audit(
                                        s, pending_user["username"], "2FA_FAILED",
                                        user_id=pending_user["id"],
                                        details="Invalid 2FA token"
                                    )
                    
                    except Exception as ex:
                        st.error(f"Verification failed: {ex}")
            
            if cancel_btn:
                st.session_state.pop("pending_2fa_user", None)
                st.session_state["page"] = "Home"
                st.info("Login cancelled")
                _st_safe_rerun()
        
        st.markdown("---")
        st.caption("ℹ️ Lost your device? Use one of your backup codes")
        st.caption("ℹ️ Need help? Contact your system administrator")

# ========================= 2FA SETTINGS PAGE =========================
# ========================= 2FA SETTINGS PAGE =========================
elif page == "My Tasks":
    header("My Tasks")
    current_user = st.session_state.get("auth_user")
    if not current_user:
        st.info("Please login to access this page.")
        st.stop()

    st.caption("Track pending deletion approvals and error alerts assigned to you.")

    if current_user.get("role") in ("operator", "supervisor"):
        with st.expander("Request Password Reset", expanded=False):
            st.info("Submit a reset request that will be routed to the admin team.")
            reset_reason = st.text_area(
                "Reason (optional)",
                placeholder="Explain why you need a reset�",
                key="pwd_reset_reason",
            )
            if st.button("📧 Send Reset Request", key="pwd_reset_request_btn"):
                try:
                    TaskManager.create_password_reset_request(
                        current_user, reset_reason.strip() or None
                    )
                    st.success("Password reset request sent to admins.")
                except Exception as ex:
                    st.error(f"Failed to submit request: {ex}")

    status_options = {
        "Pending": [TaskStatus.PENDING.value],
        "Approved": [TaskStatus.APPROVED.value],
        "Rejected": [TaskStatus.REJECTED.value],
        "Completed": [TaskStatus.COMPLETED.value],
        "All": None,
    }
    filter_col1, filter_col2 = st.columns([0.5, 0.5])
    selected_status = filter_col1.selectbox("Status", list(status_options.keys()), index=0)
    include_history = filter_col2.checkbox("Include resolved tasks", value=False)
    statuses = status_options[selected_status]

    tasks = TaskManager.fetch_tasks_for_user(
        current_user,
        statuses=statuses,
        include_history=include_history,
    )

    if not tasks:
        st.info("No tasks found for the selected filters.")
    else:
        for task in tasks:
            metadata = task.get("metadata") or {}
            resource_label = metadata.get("resource_label")
            if not resource_label and task.get("resource_type"):
                resource_label = f"{task['resource_type']} #{task.get('resource_id')}" if task.get("resource_id") else None

            with st.container(border=True):
                status_badge = task["status"].title()
                st.markdown(
                    f"**{task['title']}**  \n"
                    f"Status: `{status_badge}` � Type: `{task['task_type']}`"
                )
                st.caption(
                    f"Raised by {task.get('raised_by', 'unknown')} on "
                    f"{_format_task_timestamp(task.get('raised_at'))}"
                )
                if resource_label:
                    st.caption(f"Resource: {resource_label}")
                if task.get("description"):
                    st.write(task["description"])
                context_text = metadata.get("context")
                if context_text:
                    st.code(context_text, language="text")
                if task.get("resolution_notes") and task["status"] in (
                    TaskStatus.REJECTED.value,
                    TaskStatus.COMPLETED.value,
                ):
                    st.caption(f"Notes: {task['resolution_notes']}")

                if task["task_type"] == TaskType.PASSWORD_RESET.value:
                    if (
                        current_user.get("role") in ["admin-operations", "admin-it"]
                        and task["status"] == TaskStatus.PENDING.value
                    ):
                        with st.form(f"pwd_reset_action_{task['id']}"):
                            new_pwd = st.text_input(
                                "New Password",
                                type="password",
                                key=f"pwd_reset_new_{task['id']}",
                            )
                            confirm_pwd = st.text_input(
                                "Confirm Password",
                                type="password",
                                key=f"pwd_reset_confirm_{task['id']}",
                            )
                            submitted = st.form_submit_button(
                                "Reset Password & Complete", type="primary"
                            )
                            if submitted:
                                if not new_pwd:
                                    st.error("Password cannot be empty.")
                                elif new_pwd != confirm_pwd:
                                    st.error("Passwords do not match.")
                                else:
                                    try:
                                        TaskManager.resolve_password_reset(
                                            task["id"],
                                            current_user.get("username", "admin"),
                                            new_pwd,
                                        )
                                        st.success("Password reset and task completed.")
                                        _st_safe_rerun()
                                    except Exception as ex:
                                        st.error(f"Failed to reset password: {ex}")
                    elif (
                        task.get("raised_by") == current_user.get("username")
                        and task["status"] == TaskStatus.PENDING.value
                    ):
                        st.info("? Waiting for an admin to complete this reset request.")

                if (
                    task["task_type"] == TaskType.DELETE_REQUEST.value
                    and task["status"] == TaskStatus.APPROVED.value
                    and current_user.get("role") == "operator"
                ):
                    st.info(
                        "? Remote approval granted. Return to the original page to complete the deletion."
                    )

                acted = False
                if TaskManager.user_can_act_on_task(task, current_user):
                    with st.form(f"task_action_{task['id']}"):
                        notes = st.text_area(
                            "Supervisor notes",
                            key=f"task_notes_{task['id']}",
                            placeholder="Optional notes for audit trail",
                            height=60,
                        )
                        act_col1, act_col2 = st.columns(2)
                        approve = act_col1.form_submit_button("? Approve")
                        reject = act_col2.form_submit_button("? Reject")
                        if approve:
                            TaskManager.update_status(
                                task["id"],
                                TaskStatus.APPROVED.value,
                                current_user.get("username", "unknown"),
                                notes or None,
                            )
                            st.success("Task approved.")
                            acted = True
                        elif reject:
                            if not notes:
                                st.error("Please provide a reason before rejecting.")
                            else:
                                TaskManager.update_status(
                                    task["id"],
                                    TaskStatus.REJECTED.value,
                                    current_user.get("username", "unknown"),
                                    notes,
                                )
                                st.warning("Task rejected.")
                                acted = True
                    if acted:
                        import time

                        time.sleep(1)
                        _st_safe_rerun()

                elif (
                    task["task_type"] == TaskType.ERROR_ALERT.value
                    and task["status"] == TaskStatus.PENDING.value
                    and current_user.get("role") in ["admin-operations", "admin-it"]
                ):
                    with st.form(f"task_error_resolve_{task['id']}"):
                        notes = st.text_area(
                            "Resolution notes",
                            key=f"task_error_notes_{task['id']}",
                            height=60,
                        )
                        resolved = st.form_submit_button("? Mark as resolved")
                        if resolved:
                            TaskManager.update_status(
                                task["id"],
                                TaskStatus.COMPLETED.value,
                                current_user.get("username", "unknown"),
                                notes or "Resolved from My Tasks",
                            )
                            st.success("Task marked as resolved.")
                            import time

                            time.sleep(1)
                            _st_safe_rerun()

                with st.expander("Activity log", expanded=False):
                    activities = task.get("activities") or []
                    if not activities:
                        st.caption("No activity recorded yet.")
                    else:
                        for activity in activities:
                            st.caption(
                                f"{_format_task_timestamp(activity.get('timestamp'))} � "
                                f"{activity.get('username') or 'system'} ? "
                                f"{activity.get('action')}  "
                                f"{activity.get('notes') or ''}"
                            )

elif page == "2FA Settings":
    header("Two-Factor Authentication Settings")
    
    user = st.session_state.get("auth_user")
    
    if not user:
        st.error("Please login to access this page")
        st.stop()
    
    st.markdown("### 🔐 Two-Factor Authentication (2FA)")
    st.caption("Add an extra layer of security to your account")
    
    from twofa import TwoFactorAuth
    
    with get_session() as s:
        is_2fa_enabled = TwoFactorAuth.is_enabled(s, user["id"])
    
    # ========== 2FA Status ==========
    if is_2fa_enabled:
        st.success("? **2FA is ENABLED** for your account")
    else:
        st.warning("⚠️ **2FA is DISABLED** - Your account is less secure")
    
    st.markdown("---")
    
    # ========== Enable 2FA ==========
    if not is_2fa_enabled:
        st.markdown("#### Enable 2FA")
        
        st.info("""
        **How it works:**
        1. **Recommended:** Download **Microsoft Authenticator** app
           - iOS: App Store ? Search "Microsoft Authenticator"
           - Android: Play Store ? Search "Microsoft Authenticator"
        2. Open app ? Tap "+" ? Select "Other account" ? Scan QR code
        3. Enter the 6-digit code to verify
        4. **Save your backup codes** in a safe place!
        
        *Also works with: Google Authenticator, Authy, 1Password, etc.*
        """)
        
        if st.button("🔐 Enable 2FA", key="enable_2fa_btn", type="primary"):
            try:
                with get_session() as s:
                    secret, backup_codes, provisioning_uri = TwoFactorAuth.enable_2fa(s, user["id"])
                
                # Store in session for verification
                st.session_state["2fa_setup"] = {
                    "secret": secret,
                    "backup_codes": backup_codes,
                    "provisioning_uri": provisioning_uri
                }
                
                _st_safe_rerun()
            
            except Exception as ex:
                st.error(f"Failed to enable 2FA: {ex}")
        
        # ========== 2FA Setup Flow ==========
        if st.session_state.get("2fa_setup"):
            setup = st.session_state["2fa_setup"]
            
            st.markdown("---")
            st.markdown("#### Step 1: Scan QR Code")
            
            # Generate and display QR code
            qr_image = TwoFactorAuth.generate_qr_code(setup["provisioning_uri"])
            
            col1, col2, col3 = st.columns([0.2, 0.6, 0.2])
            with col2:
                st.image(qr_image, caption="Scan this with Microsoft Authenticator", width=300)
            
            with st.expander("🔢 Can't scan? Enter manually"):
                st.code(setup["secret"], language=None)
                st.caption(f"Account: {user['username']}")
                st.caption(f"Issuer: {TwoFactorAuth.ISSUER_NAME}")
            
            st.markdown("#### Step 2: Verify Code")
            
            # Form for verification (button only)
            with st.form("verify_2fa_setup"):
                verification_code = st.text_input(
                    "Enter the 6-digit code from your app",
                    max_chars=6,
                    placeholder="000000",
                    key="2fa_verify_code"
                )
                
                verify_btn = st.form_submit_button("? Verify & Enable", type="primary")
            
            # Handle verification OUTSIDE form
            if verify_btn:
                if not verification_code or len(verification_code) != 6:
                    st.error("Please enter a 6-digit code")
                else:
                    try:
                        with get_session() as s:
                            success = TwoFactorAuth.verify_and_enable(s, user["id"], verification_code)
                        
                        if success:
                            st.success("? 2FA enabled successfully!")
                            
                            # Store backup codes in session
                            st.session_state["2fa_backup_codes_ready"] = setup["backup_codes"]
                            st.session_state.pop("2fa_setup", None)
                            
                            # Log audit
                            from security import SecurityManager
                            with get_session() as s:
                                SecurityManager.log_audit(
                                    s, user["username"], "2FA_ENABLED",
                                    user_id=user["id"],
                                    details="User enabled 2FA"
                                )
                            
                            _st_safe_rerun()
                        else:
                            st.error("? Invalid code. Please try again.")
                    
                    except Exception as ex:
                        st.error(f"Verification failed: {ex}")
            
            # Show backup codes after successful setup
            if st.session_state.get("2fa_backup_codes_ready"):
                backup_codes = st.session_state["2fa_backup_codes_ready"]
                
                st.markdown("---")
                st.markdown("#### 🔐 IMPORTANT: Save Your Backup Codes")
                st.warning("Store these codes in a safe place. You'll need them if you lose your device.")
                
                backup_codes_text = "\n".join(backup_codes)
                st.code(backup_codes_text, language=None)
                
                # Download button OUTSIDE form
                st.download_button(
                    "⬇️ Download Backup Codes",
                    data=backup_codes_text,
                    file_name=f"otms_backup_codes_{user['username']}.txt",
                    mime="text/plain",
                    key="download_backup_codes_initial"
                )
                
                if st.button("? I've Saved My Backup Codes - Continue", key="finish_2fa_setup"):
                    st.session_state.pop("2fa_backup_codes_ready", None)
                    st.success("Setup complete! You can now use 2FA to login.")
                    import time
                    time.sleep(2)
                    _st_safe_rerun()
    
    # ========== Manage 2FA (if enabled) ==========
    else:
        st.markdown("#### Manage 2FA")
        
        # ========== TABS FOR MANAGING 2FA ==========
        tab1, tab2, tab3 = st.tabs(["Backup Codes", "Regenerate Codes", "Disable 2FA"])
        
        # ==================== TAB 1: VIEW BACKUP CODES ====================
        with tab1:
            st.markdown("##### Your Backup Codes")
            st.caption("Use these codes if you lose access to your authenticator app")
            
            try:
                with get_session() as s:
                    backup_codes = TwoFactorAuth.get_backup_codes(s, user["id"])
                
                if backup_codes:
                    st.info(f"You have **{len(backup_codes)}** unused backup codes")
                    
                    # Initialize visibility state
                    if "backup_codes_visible" not in st.session_state:
                        st.session_state.backup_codes_visible = False
                    
                    # Toggle visibility
                    if not st.session_state.backup_codes_visible:
                        if st.button("👁️ Show Backup Codes", key="btn_show_backup_codes", type="primary"):
                            st.session_state.backup_codes_visible = True
                            _st_safe_rerun()
                    else:
                        # Display codes
                        st.code("\n".join(backup_codes), language=None)
                        
                        # Download button
                        backup_codes_text = "\n".join(backup_codes)
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.download_button(
                                "⬇️ Download Codes",
                                data=backup_codes_text,
                                file_name=f"otms_backup_codes_{user['username']}.txt",
                                mime="text/plain",
                                key="download_existing_backup_codes",
                                use_container_width=True
                            )
                        
                        with col2:
                            if st.button("🙈 Hide Codes", key="btn_hide_backup_codes", use_container_width=True):
                                st.session_state.backup_codes_visible = False
                                _st_safe_rerun()
                else:
                    st.warning("⚠️ No backup codes remaining. Generate new ones in the next tab.")
            
            except Exception as ex:
                st.error(f"Failed to load backup codes: {ex}")
        
        # ==================== TAB 2: REGENERATE BACKUP CODES ====================
        with tab2:
            st.markdown("##### Regenerate Backup Codes")
            st.warning("⚠️ This will **invalidate** all your old backup codes")
            
            st.markdown("""
            **When should you regenerate backup codes?**
            - You've used most of your backup codes
            - You suspect your codes may have been compromised
            - You want to refresh your codes for security
            """)
            
            # Initialize state
            if "new_backup_codes" not in st.session_state:
                st.session_state.new_backup_codes = None
            
            # Generate button
            if st.session_state.new_backup_codes is None:
                if st.button("🔐 Generate New Backup Codes", key="btn_regen_backup_codes", type="primary"):
                    try:
                        with get_session() as s:
                            new_codes = TwoFactorAuth.regenerate_backup_codes(s, user["id"])
                        
                        st.session_state.new_backup_codes = new_codes
                        
                        # Log audit
                        from security import SecurityManager
                        with get_session() as s:
                            SecurityManager.log_audit(
                                s, user["username"], "2FA_BACKUP_CODES_REGENERATED",
                                user_id=user["id"]
                            )
                        
                        _st_safe_rerun()
                    
                    except Exception as ex:
                        st.error(f"Failed to regenerate codes: {ex}")
            
            # Show newly generated codes
            if st.session_state.new_backup_codes is not None:
                new_codes = st.session_state.new_backup_codes
                
                st.success("? New backup codes generated!")
                st.warning("⚠️ **IMPORTANT:** Save these codes now. Old codes are no longer valid.")
                
                st.code("\n".join(new_codes), language=None)
                
                # Download and clear buttons
                col1, col2 = st.columns(2)
                
                with col1:
                    new_codes_text = "\n".join(new_codes)
                    st.download_button(
                        "⬇️ Download New Codes",
                        data=new_codes_text,
                        file_name=f"otms_backup_codes_{user['username']}_new.txt",
                        mime="text/plain",
                        key="download_new_backup_codes",
                        use_container_width=True
                    )
                
                with col2:
                    if st.button("? Done - Clear", key="btn_clear_new_backup_codes", use_container_width=True):
                        st.session_state.new_backup_codes = None
                        _st_safe_rerun()
        
        # ==================== TAB 3: DISABLE 2FA ====================
        with tab3:
            st.markdown("##### Disable 2FA")
            st.error("⚠️ **Warning:** Disabling 2FA makes your account less secure")
            
            st.markdown("""
            **Why you might disable 2FA:**
            - Switching to a new phone
            - Lost access to authenticator app
            - Technical issues
            
            **Important:** You can re-enable 2FA anytime after disabling.
            """)
            
            st.markdown("---")
            st.markdown("**To disable 2FA, please:**")
            st.markdown("1. Enter your current password")
            st.markdown("2. Confirm by typing your username")
            
            with st.form("disable_2fa_form"):
                current_pwd = st.text_input(
                    "Current Password", 
                    type="password", 
                    key="disable_2fa_pwd",
                    placeholder="Enter your password"
                )
                
                confirm_username = st.text_input(
                    f"Type your username ({user['username']}) to confirm", 
                    key="disable_2fa_username",
                    placeholder="Type username here"
                )
                
                disable_btn = st.form_submit_button("🚫 Disable 2FA", type="primary")
            
            # Handle disable OUTSIDE form
            if disable_btn:
                if not current_pwd:
                    st.error("? Please enter your password")
                elif confirm_username.strip() != user["username"]:
                    st.error(f"? Username confirmation does not match. Expected: {user['username']}")
                else:
                    try:
                        from auth import AuthManager
                        with get_session() as s:
                            u = s.query(User).filter(User.id == user["id"]).one_or_none()
                            
                            if u and AuthManager.verify_password(current_pwd, u.password_hash):
                                # Disable 2FA
                                TwoFactorAuth.disable_2fa(s, user["id"])
                                
                                st.success("? 2FA disabled successfully")
                                
                                # Log audit
                                from security import SecurityManager
                                SecurityManager.log_audit(
                                    s, user["username"], "2FA_DISABLED",
                                    user_id=user["id"],
                                    details="User disabled 2FA"
                                )
                                
                                # Clear any 2FA-related session states
                                st.session_state.pop("backup_codes_visible", None)
                                st.session_state.pop("new_backup_codes", None)
                                
                                import time
                                time.sleep(2)
                                _st_safe_rerun()
                            else:
                                st.error("? Invalid password")
                    
                    except Exception as ex:
                        st.error(f"Failed to disable 2FA: {ex}")

# ========================= LOGIN HISTORY PAGE =========================
elif page == "Login History":
    header("Login History & Security Monitoring")
    
    user = st.session_state.get("auth_user")
    
    if not user:
        st.error("Please login to access this page")
        st.stop()
    
    from ip_service import IPService
    from datetime import datetime, timedelta
    import pandas as pd
    from models import User, LoginAttempt
    
    # Import timezone utilities
    try:
        from timezone_utils import utc_to_local, format_local_datetime
        TIMEZONE_AVAILABLE = True
    except ImportError:
        TIMEZONE_AVAILABLE = False
        st.warning("⚠️ Timezone utilities not found. Install pytz: `pip install pytz`")
    
    st.markdown("### 🔐 Login Activity Monitor")
    
    # ========== FILTERS ==========
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # Get list of users for filter
        with get_session() as s:
            if user["role"] in ["admin-operations", "manager"]:
                all_users = s.query(User).all()
                user_options = ["All"] + [u.username for u in all_users]
            else:
                user_options = [user["username"]]
        
        filter_user = st.selectbox(
            "User",
            user_options,
            key="login_history_user_filter"
        )
    
    with col2:
        filter_success = st.selectbox(
            "Status",
            ["All", "Success", "Failed"],
            key="login_history_status_filter"
        )
    
    with col3:
        filter_days = st.selectbox(
            "Time Period",
            ["Last 7 days", "Last 30 days", "Last 90 days", "All time"],
            key="login_history_days_filter"
        )
    
    with col4:
        filter_2fa = st.selectbox(
            "2FA Used",
            ["All", "Yes", "No"],
            key="login_history_2fa_filter"
        )
    
    # ========== QUERY DATA ==========
    try:
        with get_session() as s:
            query = s.query(LoginAttempt).order_by(LoginAttempt.timestamp.desc())
            
            # Apply filters
            if filter_user != "All":
                query = query.filter(LoginAttempt.username == filter_user)
            
            if filter_success == "Success":
                query = query.filter(LoginAttempt.success == True)
            elif filter_success == "Failed":
                query = query.filter(LoginAttempt.success == False)
            
            if filter_2fa == "Yes":
                query = query.filter(LoginAttempt.two_factor_used == True)
            elif filter_2fa == "No":
                query = query.filter(LoginAttempt.two_factor_used == False)
            
            # Time filter
            if filter_days != "All time":
                days_map = {
                    "Last 7 days": 7,
                    "Last 30 days": 30,
                    "Last 90 days": 90
                }
                days = days_map[filter_days]
                cutoff_date = datetime.utcnow() - timedelta(days=days)
                query = query.filter(LoginAttempt.timestamp >= cutoff_date)
            
            attempts = query.limit(500).all()
    
    except Exception as ex:
        st.error(f"Failed to load login history: {ex}")
        import traceback
        st.code(traceback.format_exc())
        st.stop()
    
    # ========== STATISTICS ==========
    if attempts:
        total_attempts = len(attempts)
        successful_logins = sum(1 for a in attempts if a.success)
        failed_logins = total_attempts - successful_logins
        unique_ips = len(set(a.ip_address for a in attempts if a.ip_address))
        
        # Safely count 2FA logins (handle missing attribute)
        two_fa_logins = sum(1 for a in attempts if getattr(a, 'two_factor_used', False))
        
        st.markdown("---")
        
        metric_col1, metric_col2, metric_col3, metric_col4, metric_col5 = st.columns(5)
        
        with metric_col1:
            st.metric("Total Attempts", total_attempts)
        
        with metric_col2:
            success_pct = (successful_logins/total_attempts*100) if total_attempts > 0 else 0
            st.metric("Successful", successful_logins, delta=f"{success_pct:.1f}%")
        
        with metric_col3:
            fail_pct = (failed_logins/total_attempts*100) if total_attempts > 0 else 0
            st.metric("Failed", failed_logins, delta=f"{fail_pct:.1f}%", delta_color="inverse")
        
        with metric_col4:
            st.metric("Unique IPs", unique_ips)
        
        with metric_col5:
            twofa_pct = (two_fa_logins/successful_logins*100) if successful_logins > 0 else 0
            st.metric("2FA Used", two_fa_logins, delta=f"{twofa_pct:.1f}%")
        
        st.markdown("---")
        
        # ========== LOGIN ATTEMPTS TABLE ==========
        st.markdown("#### 🔐 Recent Login Attempts")
        
        # Show timezone info
        if TIMEZONE_AVAILABLE:
            st.caption("? Showing times in **Nigeria Time (WAT - UTC+1)**")
        else:
            st.caption("? Showing times in **UTC** (install pytz for local time)")
        
        # Prepare data for display
        display_data = []
        
        for attempt in attempts[:100]:  # Show last 100
            # Safely get attributes (handle missing columns)
            ip_country = getattr(attempt, 'ip_country', None) or "Unknown"
            ip_city = getattr(attempt, 'ip_city', None) or "Unknown"
            device_type = getattr(attempt, 'device_type', None) or "Unknown"
            browser = getattr(attempt, 'browser', None) or "Unknown"
            os_name = getattr(attempt, 'os', None) or "Unknown"
            two_factor_used = getattr(attempt, 'two_factor_used', False)
            
            flag = IPService.get_flag_emoji(ip_country)
            
            # Format timestamp in local time
            if attempt.timestamp:
                if TIMEZONE_AVAILABLE:
                    # Convert UTC to local time
                    timestamp_str = format_local_datetime(attempt.timestamp, "%Y-%m-%d %H:%M:%S")
                else:
                    # Show UTC time
                    timestamp_str = attempt.timestamp.strftime("%Y-%m-%d %H:%M:%S UTC")
            else:
                timestamp_str = "N/A"
            
            display_data.append({
                "Timestamp": timestamp_str,
                "User": attempt.username,
                "Status": "? Success" if attempt.success else "? Failed",
                "IP Address": attempt.ip_address or "N/A",
                "Location": f"{flag} {ip_city}, {ip_country}",
                "Device": device_type,
                "Browser": browser,
                "OS": os_name,
                "2FA": "?" if two_factor_used else "?",
                "Reason": attempt.failure_reason or "N/A"
            })
        
        df = pd.DataFrame(display_data)
        
        # Display table
        st.dataframe(
            df,
            use_container_width=True,
            hide_index=True,
            height=600,
            column_config={
                "Timestamp": st.column_config.TextColumn("Timestamp", width="medium"),
                "User": st.column_config.TextColumn("User", width="small"),
                "Status": st.column_config.TextColumn("Status", width="small"),
                "IP Address": st.column_config.TextColumn("IP Address", width="medium"),
                "Location": st.column_config.TextColumn("Location", width="medium"),
                "Device": st.column_config.TextColumn("Device", width="small"),
                "Browser": st.column_config.TextColumn("Browser", width="small"),
                "OS": st.column_config.TextColumn("OS", width="small"),
                "2FA": st.column_config.TextColumn("2FA", width="small"),
                "Reason": st.column_config.TextColumn("Reason", width="medium"),
            }
        )
        
        # ========== SECURITY ALERTS ==========
        # Check for suspicious activity
        recent_failures = [a for a in attempts[:50] if not a.success]
        if len(recent_failures) >= 5:
            st.warning(f"⚠️ **Security Alert:** {len(recent_failures)} failed login attempts in recent history")
        
        # Check for multiple IPs for same user
        if filter_user != "All":
            user_ips = set(a.ip_address for a in attempts[:50] if a.username == filter_user and a.ip_address)
            if len(user_ips) > 3:
                st.warning(f"⚠️ **Multiple IPs Detected:** User '{filter_user}' logged in from {len(user_ips)} different IP addresses")
        
        st.markdown("---")
        
        # ========== DOWNLOAD REPORT ==========
        col_download, col_refresh = st.columns([0.8, 0.2])
        
        with col_download:
            csv_data = df.to_csv(index=False)
            st.download_button(
                "⬇️ Download Login History (CSV)",
                data=csv_data,
                file_name=f"login_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col_refresh:
            if st.button("🔄 Refresh", use_container_width=True):
                _st_safe_rerun()
        
        # ========== ADDITIONAL INSIGHTS ==========
        st.markdown("---")
        st.markdown("#### 🔐 Login Insights")
        
        insight_col1, insight_col2 = st.columns(2)
        
        with insight_col1:
            st.markdown("##### 📍 Top Login Locations")
            location_counts = {}
            for a in attempts[:100]:
                country = getattr(a, 'ip_country', None) or "Unknown"
                flag = IPService.get_flag_emoji(country)
                location_key = f"{flag} {country}"
                location_counts[location_key] = location_counts.get(location_key, 0) + 1
            
            sorted_locations = sorted(location_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            for loc, count in sorted_locations:
                st.caption(f"{loc}: {count} attempts")
        
        with insight_col2:
            st.markdown("##### 💻 Top Devices")
            device_counts = {}
            for a in attempts[:100]:
                device = getattr(a, 'device_type', None) or "Unknown"
                device_counts[device] = device_counts.get(device, 0) + 1
            
            sorted_devices = sorted(device_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            for device, count in sorted_devices:
                st.caption(f"{device}: {count} attempts")
    
    else:
        st.info("ℹ️ No login attempts found matching the filters.")
        
        # Show current time for reference
        if TIMEZONE_AVAILABLE:
            from timezone_utils import get_local_time
            current_time = get_local_time()
            st.caption(f"? Current Time: {current_time.strftime('%Y-%m-%d %H:%M:%S')} (Nigeria Time - WAT)")
        else:
            st.caption(f"? Current Time: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} (UTC)")
            
# ========================= OTR-VESSEL PAGE =========================
elif page == "OTR-Vessel":
    header("OTR-Vessel Operations")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()
    
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("OTR-Vessel") is False:
                st.error("⚠️ OTR-Vessel page is disabled for this location.")
                st.stop()
    except Exception:
        pass
    
    from datetime import datetime, date, timedelta
    import pandas as pd
    import re
    from reportlab.lib.pagesizes import A4, landscape
    from reportlab.lib import colors
    from reportlab.lib.units import cm
    from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.enums import TA_CENTER
    from io import BytesIO
    import base64
    
    # ============ PDF GENERATION FUNCTION ============
    def generate_otr_vessel_pdf(df, date_from, date_to, total_receipts, total_dispatches, total_water_in, total_water_out, username, location_name):
        """Generate OTR-Vessel PDF report"""
        buffer = BytesIO()
        
        # Create document with 0.5cm margins
        doc = SimpleDocTemplate(
            buffer, 
            pagesize=landscape(A4),
            leftMargin=0.5*cm,
            rightMargin=0.5*cm,
            topMargin=0.5*cm,
            bottomMargin=0.5*cm
        )
        
        elements = []
        styles = getSampleStyleSheet()
        
        # Custom styles
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=16,
            textColor=colors.HexColor('#1f4788'),
            spaceAfter=8,
            alignment=TA_CENTER,
            fontName='Helvetica-Bold'
        )
        
        subtitle_style = ParagraphStyle(
            'CustomSubtitle',
            parent=styles['Normal'],
            fontSize=10,
            textColor=colors.HexColor('#666666'),
            spaceAfter=6,
            alignment=TA_CENTER
        )
        
        # Title
        title = Paragraph(f"<b>OTR-VESSEL REPORT</b><br/><font size=14>{location_name}</font>", title_style)
        elements.append(title)
        elements.append(Spacer(1, 0.3*cm))
        
        # Subtitle
        subtitle = Paragraph(f"Period: <b>{date_from}</b> to <b>{date_to}</b><br/>Generated: {datetime.now().strftime('%d-%b-%Y %H:%M')}", subtitle_style)
        elements.append(subtitle)
        elements.append(Spacer(1, 0.4*cm))
        
        # Calculate available width
        page_width = landscape(A4)[0] - (1.0*cm)
        table_width = page_width
        
        # Column widths (12 columns)
        col_widths = [
            table_width * 0.08,   # Date
            table_width * 0.05,   # Time
            table_width * 0.08,   # Shuttle
            table_width * 0.12,   # Vessel
            table_width * 0.10,   # Operation
            table_width * 0.08,   # Opening Stock
            table_width * 0.07,   # Opening Water
            table_width * 0.08,   # Closing Stock
            table_width * 0.07,   # Closing Water
            table_width * 0.08,   # Net R/D
            table_width * 0.07,   # Net Water
            table_width * 0.12    # Remarks
        ]
        
        # Custom paragraph style for centered headers
        header_style = ParagraphStyle(
            'HeaderStyle',
            parent=styles['Normal'],
            fontSize=8,
            leading=9,
            alignment=TA_CENTER,
            fontName='Helvetica-Bold'
        )
        
        # Table headers
        table_data = [[
            Paragraph("<b><font color='white'>Date</font></b>", header_style),
            Paragraph("<b><font color='white'>Time</font></b>", header_style),
            Paragraph("<b><font color='white'>Shuttle<br/>No</font></b>", header_style),
            Paragraph("<b><font color='white'>Vessel<br/>Name</font></b>", header_style),
            Paragraph("<b><font color='white'>Operation</font></b>", header_style),
            Paragraph("<b><font color='white'>Opening<br/>Stock</font></b>", header_style),
            Paragraph("<b><font color='white'>Opening<br/>Water</font></b>", header_style),
            Paragraph("<b><font color='white'>Closing<br/>Stock</font></b>", header_style),
            Paragraph("<b><font color='white'>Closing<br/>Water</font></b>", header_style),
            Paragraph("<b><font color='white'>Net<br/>R/D</font></b>", header_style),
            Paragraph("<b><font color='white'>Net<br/>Water</font></b>", header_style),
            Paragraph("<b><font color='white'>Remarks</font></b>", header_style)
        ]]
        
        # Custom cell style
        cell_style = ParagraphStyle(
            'CellStyle',
            parent=styles['Normal'],
            fontSize=7,
            leading=8,
            alignment=TA_CENTER
        )
        
        # Add data rows
        for _, row in df.iterrows():
            table_data.append([
                Paragraph(row['Date'], cell_style),
                Paragraph(row['Time'], cell_style),
                Paragraph(str(row['Shuttle No']), cell_style),
                Paragraph(str(row['Vessel Name'])[:30], cell_style),
                Paragraph(str(row['Operation'])[:25], cell_style),
                Paragraph(f"{row['Opening Stock']:,.0f}", cell_style),
                Paragraph(f"{row['Opening Water']:,.0f}", cell_style),
                Paragraph(f"{row['Closing Stock']:,.0f}", cell_style),
                Paragraph(f"{row['Closing Water']:,.0f}", cell_style),
                Paragraph(f"<font color='{'#28a745' if row['Net R/D'] >= 0 else '#dc3545'}'>{row['Net R/D']:,.0f}</font>", header_style),
                Paragraph(f"{row['Net Water']:,.0f}", cell_style),
                Paragraph(str(row['Remarks'])[:60] if row['Remarks'] else "-", cell_style)
            ])
        
        # Create table
        table = Table(table_data, colWidths=col_widths, repeatRows=1)
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1f4788')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 7),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 5),
            ('TOPPADDING', (0, 0), (-1, 0), 5),
            ('BACKGROUND', (0, 1), (-1, -1), colors.HexColor('#f8f9fa')),
            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f8f9fa')]),
            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
            ('FONTSIZE', (0, 1), (-1, -1), 6),
            ('TEXTCOLOR', (0, 1), (-1, -1), colors.HexColor('#333333')),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
            ('BOX', (0, 0), (-1, -1), 1, colors.HexColor('#1f4788')),
            ('LEFTPADDING', (0, 0), (-1, -1), 2),
            ('RIGHTPADDING', (0, 0), (-1, -1), 2),
            ('TOPPADDING', (0, 1), (-1, -1), 3),
            ('BOTTOMPADDING', (0, 1), (-1, -1), 3),
        ]))
        
        elements.append(table)
        
        # Summary section
        elements.append(Spacer(1, 0.4*cm))
        
        summary_style = ParagraphStyle(
            'Summary',
            parent=styles['Normal'],
            fontSize=8,
            textColor=colors.HexColor('#333333'),
            spaceAfter=3
        )
        
        summary_header_style = ParagraphStyle(
            'SummaryHeader',
            parent=styles['Normal'],
            fontSize=9,
            textColor=colors.white,
            fontName='Helvetica-Bold',
            alignment=TA_CENTER
        )
        
        summary_data = [
            [
                Paragraph("<b>SUMMARY STATISTICS</b>", summary_header_style),
                "",
                "",
                ""
            ],
            [
                Paragraph(f"<b>Total Receipts:</b> {total_receipts:,.2f} bbls", summary_style),
                Paragraph(f"<b>Total Dispatches:</b> {total_dispatches:,.2f} bbls", summary_style),
                Paragraph(f"<b>Water In:</b> {total_water_in:,.2f} bbls", summary_style),
                Paragraph(f"<b>Water Out:</b> {total_water_out:,.2f} bbls", summary_style)
            ],
            [
                Paragraph(f"<b>Net Movement:</b> {(total_receipts - total_dispatches):,.2f} bbls", summary_style),
                Paragraph(f"<b>Net Water:</b> {(total_water_in - total_water_out):,.2f} bbls", summary_style),
                "",
                Paragraph(f"<b>Total Entries:</b> {len(df)}", summary_style)
            ]
        ]
        
        summary_col_width = table_width / 4
        summary_table = Table(summary_data, colWidths=[summary_col_width] * 4)
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1f4788')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
            ('BACKGROUND', (0, 1), (-1, -1), colors.white),
            ('SPAN', (0, 0), (-1, 0)),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 9),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
            ('BOX', (0, 0), (-1, -1), 1, colors.HexColor('#1f4788')),
            ('LEFTPADDING', (0, 0), (-1, -1), 5),
            ('RIGHTPADDING', (0, 0), (-1, -1), 5),
            ('TOPPADDING', (0, 0), (-1, -1), 4),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 4),
        ]))
        
        elements.append(summary_table)
        
        # Footer
        elements.append(Spacer(1, 0.3*cm))
        footer_text = f"<font size=7 color='#666666'>Generated by: {username} | OTMS - Oil Terminal Management System | {datetime.now().strftime('%d-%b-%Y %H:%M:%S')}</font>"
        elements.append(Paragraph(footer_text, subtitle_style))
        
        doc.build(elements)
        pdf_data = buffer.getvalue()
        buffer.close()
        
        return pdf_data
    
    # ============ MAIN CODE ============
    
    user = st.session_state.get("auth_user")
    
    if not user:
        st.error("Please login to access this page")
        st.stop()
    
    # ========== GET LOCATION ID ==========
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("No active location selected")
        st.stop()
    
    # ========== CHECK PERMISSIONS ==========
    from permission_manager import PermissionManager
    
    preferred_vessel_ids: List[int] = []

    with get_session() as s:
        from location_manager import LocationManager
        from models import Location
        from location_config import LocationConfig
        
        # Get location info
        location = s.query(Location).filter(Location.id == active_location_id).first()
        if not location:
            st.error("? Location not found.")
            st.stop()
        
        location_name = location.name
        st.info(f"📍 **Active Location:** {location.name} ({location.code})")
        
        # Check if feature is allowed at this location
        if not PermissionManager.can_access_feature(s, active_location_id, "otr_vessel", user["role"]):
            st.error("🚫 **Access Denied**")
            st.warning(f"**OTR-Vessel** is not available at **{location.name}**")
            
            allowed_locs = PermissionManager.get_allowed_locations_for_feature(s, "otr_vessel")
            if allowed_locs:
                st.info(f"? This feature is available at: **{', '.join(allowed_locs)}**")
            
            st.markdown("---")
            st.caption(f"Current Location: **{location.name} ({location.code})**")
            st.caption("OTR-Vessel Access: **? Denied**")
            st.stop()
        
        # Check permissions
        can_make_entries = PermissionManager.can_make_entries(s, user["role"], active_location_id)
        can_delete_direct = user["role"].lower() in ["admin-operations", "supervisor"]
        can_delete_with_approval = user["role"].lower() == "operator"
        preferred_vessel_ids = (
            LocationConfig.get_config(s, active_location_id)
            .get("otr_vessel", {})
            .get("preferred_vessel_ids", [])
            or []
        )
    
    # ============ VESSEL ENABLED ============
    st.success(f"? OTR-Vessel enabled at {location_name}")

    from models import OTRVessel, Vessel, VesselOperation, LocationVessel

    st.markdown("### ⛴️ Vessel Operations Tracker")
    st.caption("Direct table entry for vessel operations with live filtering and export")

    # ========== LOAD VESSELS & OPERATIONS ==========
    try:
        with get_session() as s:
            # Get vessels assigned to this location
            assigned_vessels_query = s.query(Vessel).join(
                LocationVessel,
                LocationVessel.vessel_id == Vessel.id
            ).filter(
                LocationVessel.location_id == active_location_id,
                LocationVessel.is_active == True,
                Vessel.status == "ACTIVE"
            ).all()

            if not assigned_vessels_query:
                st.warning(" No vessels assigned to this location. Use Location Settings > Vessel Assignments.")
                st.stop()

            custom_ids = {int(v_id) for v_id in preferred_vessel_ids if isinstance(v_id, int)}
            if custom_ids:
                assigned_vessels_query = [v for v in assigned_vessels_query if v.id in custom_ids]
                if not assigned_vessels_query:
                    st.warning(" No vessels match the location's preferred list. Update Location Settings to include assigned vessels.")
                    st.stop()
            vessel_options = [(v.id, v.name) for v in assigned_vessels_query]
            vessel_dict = {v.id: v.name for v in assigned_vessels_query}
            
            # Get all active operations
            operations_query = s.query(VesselOperation).filter(
                VesselOperation.is_active == True
            ).order_by(VesselOperation.operation_name).all()
            
            operation_options = [(op.id, op.operation_name) for op in operations_query]
            operation_dict = {op.id: op.operation_name for op in operations_query}

    except Exception as ex:
        st.error(f"? Failed to load vessels/operations: {ex}")
        st.stop()

    if not vessel_options:
        st.warning("⚠️ No vessels available. Please add vessels in Asset Management first.")
        st.stop()
    
    if not operation_options:
        st.warning("⚠️ No operations available. Please contact administrator.")
        st.stop()
    
    vessel_id_choices = [v[0] for v in vessel_options]
    operation_id_choices = [op[0] for op in operation_options]

    # ========== LIVE FILTERS ==========
    st.markdown("#### 🔎 Filters")

    filter_col1, filter_col2, filter_col3, filter_col4, filter_col5 = st.columns(5)

    with filter_col1:
        filter_date_from = st.date_input(
            "From Date",
            value=date.today() - timedelta(days=30),
            key="otr_vessel_date_from"
        )

    with filter_col2:
        filter_date_to = st.date_input(
            "To Date",
            value=date.today(),
            key="otr_vessel_date_to"
        )

    with filter_col3:
        filter_shuttle = st.text_input(
            "Shuttle No",
            placeholder="Filter...",
            key="otr_vessel_filter_shuttle"
        )

    with filter_col4:
            filter_vessel_names = [v[1] for v in vessel_options]
            filter_vessel = st.selectbox(
                "Vessel Name",
                ["All"] + filter_vessel_names,
                key="otr_vessel_filter_vessel"
            )

    with filter_col5:
        filter_operation_names = [op[1] for op in operation_options]
        filter_operation = st.selectbox(
            "Operation",
            ["All"] + filter_operation_names,
            key="otr_vessel_filter_operation"
        )

    st.markdown("---")

    # ========== ADD NEW ENTRY FORM WITH WATER COLUMNS ==========
    if can_make_entries:
        with st.expander("? Add New Entry", expanded=False):
            with st.form("add_otr_vessel_form"):
                st.markdown("##### New Vessel Operation Entry")
                
                form_col1, form_col2, form_col3, form_col4 = st.columns(4)
                
                with form_col1:
                    entry_date = st.date_input("Date *", value=date.today(), key="otr_vessel_new_date")
                    entry_time = st.text_input(
                        "Time (HH:MM) *",
                        value=datetime.now().strftime("%H:%M"),
                        placeholder="14:30",
                        key="otr_vessel_new_time",
                        max_chars=5
                    )
                    entry_shuttle = st.text_input(
                        "Shuttle No *",
                        placeholder="SH-001",
                        key="otr_vessel_new_shuttle"
                    )
                
                with form_col2:
                    entry_vessel_id = st.selectbox(
                        "Vessel Name *",
                        options=vessel_id_choices,
                        format_func=lambda x: vessel_dict.get(x, "Unknown"),
                        key="otr_vessel_new_vessel"
                    )
                    
                    entry_operation_id = st.selectbox(
                        "Operation *",
                        options=operation_id_choices,
                        format_func=lambda x: operation_dict.get(x, "Unknown"),
                        key="otr_vessel_new_operation"
                    )
                
                with form_col3:
                    entry_opening = st.number_input(
                        "Opening Stock (bbls) *",
                        min_value=0.0,
                        value=0.0,
                        step=0.01,
                        format="%.2f",
                        key="otr_vessel_new_opening"
                    )
                    entry_opening_water = st.number_input(
                        "Opening Water (bbls)",
                        min_value=0.0,
                        value=0.0,
                        step=0.01,
                        format="%.2f",
                        key="otr_vessel_new_opening_water"
                    )
                    entry_closing = st.number_input(
                        "Closing Stock (bbls) *",
                        min_value=0.0,
                        value=0.0,
                        step=0.01,
                        format="%.2f",
                        key="otr_vessel_new_closing"
                    )
                
                with form_col4:
                    entry_closing_water = st.number_input(
                        "Closing Water (bbls)",
                        min_value=0.0,
                        value=0.0,
                        step=0.01,
                        format="%.2f",
                        key="otr_vessel_new_closing_water"
                    )
                
                entry_remarks = st.text_area(
                    "Remarks",
                    placeholder="Optional remarks...",
                    key="otr_vessel_new_remarks",
                    max_chars=500
                )
                
                # Calculate
                net_stock = entry_closing - entry_opening
                net_water = entry_closing_water - entry_opening_water
                
                calc_col1, calc_col2 = st.columns(2)
                
                with calc_col1:
                    if net_stock >= 0:
                        st.success(f"**Net Stock:** +{net_stock:,.2f} bbls")
                    else:
                        st.info(f"**Net Stock:** {net_stock:,.2f} bbls")
                
                with calc_col2:
                    if net_water >= 0:
                        st.success(f"**Net Water:** +{net_water:,.2f} bbls")
                    else:
                        st.info(f"**Net Water:** {net_water:,.2f} bbls")
                
                submit_btn = st.form_submit_button("💾 Save Entry", type="primary", use_container_width=True)
                
                if submit_btn:
                    if not entry_shuttle.strip():
                        st.error("? Shuttle No is required")
                    elif not entry_time.strip() or not re.match(r'^\d{2}:\d{2}$', entry_time):
                        st.error("? Invalid time format. Use HH:MM")
                    else:
                        try:
                            with get_session() as s:
                                new_entry = OTRVessel(
                                    location_id=active_location_id,
                                    date=entry_date,
                                    time=entry_time,
                                    shuttle_no=entry_shuttle.strip(),
                                    vessel_id=entry_vessel_id,
                                    operation_id=entry_operation_id,
                                    opening_stock=entry_opening,
                                    opening_water=entry_opening_water,
                                    closing_stock=entry_closing,
                                    closing_water=entry_closing_water,
                                    net_receipt_dispatch=net_stock,
                                    net_water=net_water,
                                    remarks=entry_remarks.strip() if entry_remarks else None,
                                    created_by=user["username"],
                                )

                                s.add(new_entry)
                                # Flush so new_entry.id is available before audit log
                                s.flush()
                                new_entry_id = new_entry.id
                                s.commit()

                            # Log audit outside the transaction so we don't reuse the write session
                            from security import SecurityManager
                            vessel_name = vessel_dict.get(entry_vessel_id, "Unknown")
                            operation_name = operation_dict.get(entry_operation_id, "Unknown")

                            SecurityManager.log_audit(
                                None,
                                user["username"],
                                "CREATE",
                                resource_type="OTRVessel",
                                resource_id=str(new_entry_id),
                                location_id=active_location_id,
                                details=f"Added: {vessel_name} - {entry_shuttle} - {operation_name}",
                                user_id=user["id"],
                            )

                            st.success(f"? Entry saved! ID: {new_entry_id}")
                            st.balloons()
                            import time
                            time.sleep(1)
                            _st_safe_rerun()

                        except Exception as ex:
                            st.error(f"? Failed to save: {ex}")
                            import traceback
                            with st.expander("⚠️ Error Details"):
                                st.code(traceback.format_exc())
    else:
        st.info("ℹ️ You don't have permission to add entries")

    st.markdown("---")

    
    # ========== FETCH AND DISPLAY DATA ==========
    try:
        with get_session() as s:
            # Build query with filters
            query = s.query(OTRVessel).filter(
                OTRVessel.location_id == active_location_id,
                OTRVessel.date >= filter_date_from,
                OTRVessel.date <= filter_date_to
            )
            
            if filter_shuttle:
                query = query.filter(OTRVessel.shuttle_no.contains(filter_shuttle))
            
            if filter_vessel != "All":
                vessel_id_for_filter = next((v[0] for v in vessel_options if v[1] == filter_vessel), None)
                if vessel_id_for_filter:
                    query = query.filter(OTRVessel.vessel_id == vessel_id_for_filter)
            
            if filter_operation != "All":
                operation_id_for_filter = next((op[0] for op in operation_options if op[1] == filter_operation), None)
                if operation_id_for_filter:
                    query = query.filter(OTRVessel.operation_id == operation_id_for_filter)
            
            entries = query.order_by(OTRVessel.date.desc(), OTRVessel.time.desc()).all()
            
            if not entries:
                st.info("ℹ️ No vessel entries found. Add your first entry above!")
            else:
                st.markdown(f"#### ⛴️ Vessel Operations ({len(entries)} entries)")
                
                # Create DataFrame for PDF export
                export_data = []
                for entry in entries:
                    vessel_name = vessel_dict.get(entry.vessel_id, "Unknown")
                    operation_name = operation_dict.get(entry.operation_id, "Unknown")
                    
                    export_data.append({
                        "Date": entry.date.strftime("%Y-%m-%d"),
                        "Time": entry.time,
                        "Shuttle No": entry.shuttle_no,
                        "Vessel Name": vessel_name,
                        "Operation": operation_name,
                        "Opening Stock": getattr(entry, 'opening_stock', 0.0),
                        "Opening Water": getattr(entry, 'opening_water', 0.0),
                        "Closing Stock": getattr(entry, 'closing_stock', 0.0),
                        "Closing Water": getattr(entry, 'closing_water', 0.0),
                        "Net R/D": getattr(entry, 'net_receipt_dispatch', 0.0),
                        "Net Water": getattr(entry, 'net_water', 0.0),
                        "Remarks": entry.remarks or "",
                        "Created By": entry.created_by or ""
                    })
                
                df_export = pd.DataFrame(export_data)
                
                # Display compact table (KEEPING YOUR EXISTING TABLE DISPLAY)
                for idx, entry in enumerate(entries):
                    vessel_name = vessel_dict.get(entry.vessel_id, "Unknown")
                    operation_name = operation_dict.get(entry.operation_id, "Unknown")
                    
                    with st.container(border=True):
                        cols = st.columns([0.05, 0.10, 0.07, 0.10, 0.14, 0.13, 0.09, 0.09, 0.09, 0.15, 0.11, 0.12])
                        
                        with cols[0]:
                            st.markdown(f"**{entry.id}**")
                        
                        with cols[1]:
                            st.markdown(f"{entry.date.strftime('%Y-%m-%d')}")
                        
                        with cols[2]:
                            st.markdown(f"{entry.time}")
                        
                        with cols[3]:
                            st.markdown(f"{entry.shuttle_no}")
                        
                        with cols[4]:
                            st.markdown(f"{vessel_name}")
                        
                        with cols[5]:
                            st.markdown(f"{operation_name}")
                        
                        with cols[6]:
                            st.markdown(f"{entry.opening_stock:,.0f}")
                        
                        with cols[7]:
                            st.markdown(f"{entry.closing_stock:,.0f}")
                        
                        with cols[8]:
                            if entry.net_receipt_dispatch >= 0:
                                st.markdown(f"<span style='color: green; font-weight: bold;'>+{entry.net_receipt_dispatch:,.0f}</span>", unsafe_allow_html=True)
                            else:
                                st.markdown(f"<span style='color: red; font-weight: bold;'>{entry.net_receipt_dispatch:,.0f}</span>", unsafe_allow_html=True)
                        
                        with cols[9]:
                            remarks_text = entry.remarks[:35] + "..." if entry.remarks and len(entry.remarks) > 35 else (entry.remarks or "-")
                            st.markdown(f'<small>{remarks_text}</small>', unsafe_allow_html=True)
                        
                        with cols[10]:
                            if entry.updated_by:
                                tip = (
                                    f"Edited by {entry.updated_by} on {entry.updated_at:%d-%m-%Y %H:%M}"
                                    if entry.updated_by else "Not edited"
                                )
                                st.markdown(
                                    f'{entry.created_by} <span style="color:#f59e0b;" title="{tip}">⏱️</span>',
                                    unsafe_allow_html=True
                                )

                            else:
                                st.markdown(entry.created_by or "-")
                        
                        with cols[11]:
                            action_btn_col1, action_btn_col2 = st.columns(2)
                            
                            with action_btn_col1:
                                if st.button("✏️", key=f"otrv_edit_btn_{entry.id}", help="Edit", use_container_width=True):
                                    if not _deny_edit_for_lock(entry, "OTRVessel", f"{entry.id}"):
                                        st.session_state[f"otrv_editing_{entry.id}"] = True
                                        _st_safe_rerun()
                            
                            with action_btn_col2:
                                if can_delete_direct or can_delete_with_approval:
                                    if st.button("🗑️", key=f"otrv_del_btn_{entry.id}", help="Delete", use_container_width=True):
                                        st.session_state[f"otrv_deleting_{entry.id}"] = True
                                        _st_safe_rerun()
                        
                        # Edit form (if editing)
                        if st.session_state.get(f"otrv_editing_{entry.id}", False):
                            st.markdown("---")
                            with st.form(f"otrv_edit_form_{entry.id}"):
                                st.markdown("#### ✏️ Edit Vessel Entry")
                                
                                edit_col1, edit_col2, edit_col3, edit_col4 = st.columns(4)
                                
                                with edit_col1:
                                    edit_date = st.date_input(
                                        "Date",
                                        value=entry.date,
                                        key=f"otrv_edit_date_{entry.id}"
                                    )
                                    edit_time = st.text_input(
                                        "Time (HH:MM)",
                                        value=str(entry.time),
                                        key=f"otrv_edit_time_{entry.id}",
                                        max_chars=5
                                    )
                                    edit_shuttle = st.text_input(
                                        "Shuttle No",
                                        value=entry.shuttle_no,
                                        key=f"otrv_edit_shuttle_{entry.id}"
                                    )
                                
                                with edit_col2:
                                    try:
                                        vessel_index = vessel_id_choices.index(entry.vessel_id)
                                    except ValueError:
                                        vessel_index = 0
                                    edit_vessel_id = st.selectbox(
                                        "Vessel Name",
                                        options=vessel_id_choices,
                                        index=vessel_index,
                                        format_func=lambda x: vessel_dict.get(x, "Unknown"),
                                        key=f"otrv_edit_vessel_{entry.id}"
                                    )
                                    
                                    try:
                                        op_index = operation_id_choices.index(entry.operation_id)
                                    except ValueError:
                                        op_index = 0
                                    edit_operation_id = st.selectbox(
                                        "Operation",
                                        options=operation_id_choices,
                                        index=op_index,
                                        format_func=lambda x: operation_dict.get(x, "Unknown"),
                                        key=f"otrv_edit_operation_{entry.id}"
                                    )
                                
                                with edit_col3:
                                    edit_opening = st.number_input(
                                        "Opening Stock (bbls)",
                                        value=float(getattr(entry, "opening_stock", 0.0)),
                                        key=f"otrv_edit_opening_{entry.id}"
                                    )
                                    edit_opening_water = st.number_input(
                                        "Opening Water (bbls)",
                                        value=float(getattr(entry, "opening_water", 0.0)),
                                        key=f"otrv_edit_opening_water_{entry.id}"
                                    )
                                    edit_closing = st.number_input(
                                        "Closing Stock (bbls)",
                                        value=float(getattr(entry, "closing_stock", 0.0)),
                                        key=f"otrv_edit_closing_{entry.id}"
                                    )
                                
                                with edit_col4:
                                    edit_closing_water = st.number_input(
                                        "Closing Water (bbls)",
                                        value=float(getattr(entry, "closing_water", 0.0)),
                                        key=f"otrv_edit_closing_water_{entry.id}"
                                    )
                                    edit_remarks = st.text_area(
                                        "Remarks",
                                        value=entry.remarks or "",
                                        key=f"otrv_edit_remarks_{entry.id}",
                                        max_chars=500
                                    )
                                
                                edit_net_stock = edit_closing - edit_opening
                                edit_net_water = edit_closing_water - edit_opening_water
                                
                                st.info(
                                    f"Net Stock: {edit_net_stock:,.2f} bbls | Net Water: {edit_net_water:,.2f} bbls"
                                )
                                
                                save_col, cancel_col = st.columns(2)
                                with save_col:
                                    save_edit = st.form_submit_button(
                                        "💾 Save Changes",
                                        type="primary",
                                        use_container_width=True
                                    )
                                with cancel_col:
                                    cancel_edit = st.form_submit_button(
                                        "? Cancel",
                                        use_container_width=True
                                    )
                                
                                if save_edit:
                                    time_text = (edit_time or "").strip()
                                    if not edit_shuttle.strip():
                                        st.error("? Shuttle No is required")
                                    elif not time_text or not re.match(r"^\\d{2}:\\d{2}$", time_text):
                                        st.error("? Enter time in HH:MM format")
                                    else:
                                        try:
                                            with get_session() as s:
                                                entry_to_update = (
                                                    s.query(OTRVessel)
                                                     .filter(OTRVessel.id == entry.id)
                                                     .first()
                                                )
                                                if not entry_to_update:
                                                    st.error("? Entry no longer exists.")
                                                else:
                                                    entry_to_update.date = edit_date
                                                    entry_to_update.time = time_text
                                                    entry_to_update.shuttle_no = edit_shuttle.strip()
                                                    entry_to_update.vessel_id = edit_vessel_id
                                                    entry_to_update.operation_id = edit_operation_id
                                                    entry_to_update.opening_stock = float(edit_opening)
                                                    entry_to_update.opening_water = float(edit_opening_water)
                                                    entry_to_update.closing_stock = float(edit_closing)
                                                    entry_to_update.closing_water = float(edit_closing_water)
                                                    entry_to_update.net_receipt_dispatch = float(edit_net_stock)
                                                    entry_to_update.net_water = float(edit_net_water)
                                                    entry_to_update.remarks = (
                                                        edit_remarks.strip() if edit_remarks else None
                                                    )
                                                    entry_to_update.updated_by = user["username"]
                                                    entry_to_update.updated_at = datetime.now()
                                                    
                                                    from security import SecurityManager
                                                    
                                                    SecurityManager.log_audit(
                                                        s,
                                                        user["username"],
                                                        "UPDATE",
                                                        resource_type="OTRVessel",
                                                        resource_id=str(entry.id),
                                                        location_id=active_location_id,
                                                        details=f"Updated: {vessel_dict.get(edit_vessel_id, 'Unknown')} - {edit_shuttle.strip()}",
                                                        user_id=user.get("id"),
                                                    )
                                                    
                                                    s.commit()
                                                
                                            st.success("? Entry updated!")
                                            del st.session_state[f"otrv_editing_{entry.id}"]
                                            import time
                                            time.sleep(1)
                                            _st_safe_rerun()
                                        except Exception as ex:
                                            st.error(f"? Update failed: {ex}")
                                elif cancel_edit:
                                    del st.session_state[f"otrv_editing_{entry.id}"]
                                    _st_safe_rerun()
                        
                        # Delete confirmation (if deleting)
                        if st.session_state.get(f"otrv_deleting_{entry.id}", False):
                            st.markdown("---")
                            st.warning("⚠️ **Confirm Delete**")

                            def _execute_otrv_delete(approver_label: str):
                                try:
                                    with get_session() as s:
                                        target = (
                                            s.query(OTRVessel)
                                             .filter(OTRVessel.id == entry.id)
                                             .first()
                                        )
                                        if not target:
                                            st.warning("Entry already removed.")
                                            return

                                        _archive_record_for_delete(
                                            s,
                                            target,
                                            "OTRVessel",
                                            reason=(
                                                f"Marked OTR vessel entry #{entry.id} "
                                                f"({vessel_dict.get(target.vessel_id, 'Unknown')} - "
                                                f"{target.shuttle_no}) for deletion. Approved by {approver_label}."
                                            ),
                                            label=f"{entry.id}",
                                        )
                                        s.commit()

                                    TaskManager.complete_tasks_for_resource(
                                        "OTRVessel",
                                        entry.id,
                                        user.get("username", "unknown"),
                                        notes=f"Approved by {approver_label}",
                                    )
                                    st.success("? Entry deleted!")
                                    del st.session_state[f"otrv_deleting_{entry.id}"]
                                    import time

                                    time.sleep(1)
                                    _st_safe_rerun()
                                except Exception as ex:
                                    st.error(f"? Delete failed: {ex}")

                            if can_delete_direct:
                                st.write("Are you sure you want to delete this entry?")
                                del_col1, del_col2 = st.columns(2)

                                with del_col1:
                                    if st.button(
                                        "🗑️ Yes, Delete",
                                        key=f"otrv_delete_confirm_{entry.id}",
                                        type="primary",
                                        use_container_width=True
                                    ):
                                        _execute_otrv_delete(f"{user.get('username', 'admin')} ({user.get('role')})")

                                with del_col2:
                                    if st.button(
                                        "? Cancel",
                                        key=f"otrv_delete_cancel_{entry.id}",
                                        use_container_width=True
                                    ):
                                        del st.session_state[f"otrv_deleting_{entry.id}"]
                                        _st_safe_rerun()

                            elif can_delete_with_approval:
                                remote_task = _render_remote_delete_request_ui(
                                    "OTRVessel",
                                    entry.id,
                                    f"OTR vessel entry #{entry.id}",
                                    "OTR Vessel",
                                    metadata={
                                        "ticket": row.get("Ticket ID"),
                                        "vessel": row["Vessel Name"],
                                        "shuttle": row["Shuttle No"],
                                    },
                                )
                                if remote_task and remote_task.get("status") == TaskStatus.APPROVED.value:
                                    remote_label = remote_task.get("approved_by") or "Supervisor"
                                    if st.button(
                                        "Delete with approved request",
                                        key=f"otrv_remote_delete_{entry.id}",
                                        type="primary",
                                        use_container_width=True
                                    ):
                                        _execute_otrv_delete(f"{remote_label} (remote)")

                                st.write("Operator access detected. Supervisor code required.")
                                with st.form(f"otrv_delete_form_{entry.id}"):
                                    sup_username, sup_label = _supervisor_dropdown(
                                        "Supervisor",
                                        f"otrv_delete_sup_{entry.id}",
                                        active_location_id,
                                    )
                                    supervisor_code = st.text_input(
                                        "Supervisor Code",
                                        type="password",
                                        key=f"otrv_delete_code_{entry.id}"
                                    )
                                    
                                    approver_col1, approver_col2 = st.columns(2)
                                    with approver_col1:
                                        approve_delete = st.form_submit_button(
                                            "🗑️ Confirm Delete",
                                            type="primary",
                                            use_container_width=True
                                        )
                                    with approver_col2:
                                        cancel_delete = st.form_submit_button(
                                            "? Cancel",
                                            use_container_width=True
                                        )
                                    
                                    if approve_delete:
                                        if not supervisor_code.strip():
                                            st.error("? Supervisor code is required")
                                        elif not sup_username:
                                            st.error("? No supervisor available for approval")
                                        elif not SecurityManager.verify_supervisor_code(supervisor_code, sup_username):
                                            st.error("? Invalid supervisor code")
                                        else:
                                            approver = sup_label or sup_username or "Supervisor"
                                            _execute_otrv_delete(f"{approver}")
                                    elif cancel_delete:
                                        del st.session_state[f"otrv_deleting_{entry.id}"]
                                        _st_safe_rerun()

                
                st.markdown("---")
                
                # ========== EXPORT OPTIONS WITH PDF ==========
                st.markdown("#### 📤 Export Data")
                
                export_col1, export_col2, export_col3, export_col4, export_col5 = st.columns(5)
                
                # CSV Export
                with export_col1:
                    csv = df_export.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="📥 CSV",
                        data=csv,
                        file_name=f"otr_vessel_{location_name.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                
                # Excel Export
                with export_col2:
                    excel_buffer = BytesIO()
                    try:
                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                            df_export.to_excel(writer, index=False, sheet_name='OTR Vessel')
                        
                        st.download_button(
                            label="📊 Excel",
                            data=excel_buffer.getvalue(),
                            file_name=f"otr_vessel_{location_name.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
                    except ImportError:
                        st.button("📊 Excel", disabled=True, help="Install openpyxl", use_container_width=True)
                
                # PDF Download
                with export_col3:
                    if st.button("📥 Download PDF", use_container_width=True):
                        try:
                            # Calculate summary
                            total_receipts = sum(e.net_receipt_dispatch for e in entries if e.net_receipt_dispatch > 0)
                            total_dispatches = abs(sum(e.net_receipt_dispatch for e in entries if e.net_receipt_dispatch < 0))
                            total_water_in = sum(getattr(e, 'net_water', 0.0) for e in entries if getattr(e, 'net_water', 0.0) > 0)
                            total_water_out = abs(sum(getattr(e, 'net_water', 0.0) for e in entries if getattr(e, 'net_water', 0.0) < 0))
                            
                            pdf_data = generate_otr_vessel_pdf(
                                df_export,
                                filter_date_from.strftime("%d-%b-%Y"),
                                filter_date_to.strftime("%d-%b-%Y"),
                                total_receipts,
                                total_dispatches,
                                total_water_in,
                                total_water_out,
                                user["username"],
                                location_name
                            )
                            
                            st.download_button(
                                label="💾 Save PDF",
                                data=pdf_data,
                                file_name=f"otr_vessel_{location_name.replace(' ', '_')}_{date.today()}.pdf",
                                mime="application/pdf",
                                key="otrv_save_pdf"
                            )
                        except Exception as ex:
                            st.error(f"? PDF generation failed: {ex}")
                
                # PDF View
                with export_col4:
                    if st.button("👁️ View PDF", key="otr_vessel_pdf_view", use_container_width=True):
                        try:
                            # Calculate summary
                            total_receipts = sum(e.net_receipt_dispatch for e in entries if e.net_receipt_dispatch > 0)
                            total_dispatches = abs(sum(e.net_receipt_dispatch for e in entries if e.net_receipt_dispatch < 0))
                            total_water_in = sum(getattr(e, 'net_water', 0.0) for e in entries if getattr(e, 'net_water', 0.0) > 0)
                            total_water_out = abs(sum(getattr(e, 'net_water', 0.0) for e in entries if getattr(e, 'net_water', 0.0) < 0))
                            
                            pdf_data = generate_otr_vessel_pdf(
                                df_export,
                                filter_date_from.strftime("%d-%b-%Y"),
                                filter_date_to.strftime("%d-%b-%Y"),
                                total_receipts,
                                total_dispatches,
                                total_water_in,
                                total_water_out,
                                user["username"],
                                location_name
                            )
                            
                            base64_pdf = base64.b64encode(pdf_data).decode('utf-8')
                            
                            pdf_html = f"""
                            <script>
                                var pdfWindow = window.open("");
                                pdfWindow.document.write(
                                    '<html><head><title>OTR-Vessel Report - {location_name}</title></head>' +
                                    '<body style="margin:0"><iframe width="100%" height="100%" src="data:application/pdf;base64,{base64_pdf}"></iframe></body></html>'
                                );
                            </script>
                            """
                            
                            import streamlit.components.v1 as components
                            components.html(pdf_html, height=0)
                            st.success("? PDF opened in new tab!")
                            
                        except Exception as ex:
                            st.error(f"? PDF view failed: {ex}")
                
                # Summary Stats
                with export_col5:
                    with st.popover("📊 Summary"):
                        total_opening = sum(e.opening_stock for e in entries)
                        total_closing = sum(e.closing_stock for e in entries)
                        total_net = sum(e.net_receipt_dispatch for e in entries)
                        total_water = sum(getattr(e, 'net_water', 0.0) for e in entries)
                        
                        st.metric("Entries", len(entries))
                        st.metric("Total Opening", f"{total_opening:,.0f} bbls")
                        st.metric("Total Closing", f"{total_closing:,.0f} bbls")
                        st.metric("Total Net Stock", f"{total_net:,.0f} bbls")
                        st.metric("Total Net Water", f"{total_water:,.0f} bbls")
    
    except Exception as ex:
        st.error(f"? Failed to load vessel data: {ex}")
        import traceback
        with st.expander("⚠️ Error Details"):
            st.code(traceback.format_exc())

# ========================= CONVOY STATUS PAGE =========================
elif page == "Convoy Status":
    header("Convoy Status")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()

    user = st.session_state.get("auth_user")
    if not user:
        st.error("Please login to access this page.")
        st.stop()

    user_role = (user.get("role") or "").lower()
    active_location_id = st.session_state.get("active_location_id")
    can_delete_snapshots = user_role not in {"operator"}
    if not active_location_id and user_role != "admin-operations":
        st.error("No active location selected.")
        st.stop()

    from location_manager import LocationManager
    from models import (
        Location,
        YadeBarge,
        YadeVoyage,
        TOAYadeSummary,
        TOAYadeStage,
        OTRVessel,
        LocationVessel,
        Vessel,
        FSOOperation,
        ConvoyStatusYade,
        ConvoyStatusVessel,
    )

    def _norm_txt(value: Optional[str]) -> str:
        return (value or "").strip()

    def _norm_loc_name(value: Optional[str]) -> str:
        return _norm_txt(value).lower()

    # Load location context and allowed options
    with get_session() as s:
        all_locations = s.query(Location).order_by(Location.name).all()
        allowed_location_objs = [
            loc for loc in all_locations if _norm_loc_name(loc.name) in CONVOY_STATUS_ALLOWED_LOCATIONS
        ]
        active_location = (
            LocationManager.get_location_by_id(s, active_location_id) if active_location_id else None
        )
    if user_role != "admin-operations":
        if not active_location:
            st.error("Active location not found.")
            st.stop()
        if _norm_loc_name(active_location.name) not in CONVOY_STATUS_ALLOWED_LOCATIONS:
            st.error("Convoy Status is restricted to Agge, Utapate, Lagos (HO), or administrators.")
            st.stop()

    # Determine which location we are viewing
    target_location_id = active_location.id if active_location else None
    if user_role in ["admin-operations", "manager"]:
        loc_options = {loc.id: f"{loc.name} ({loc.code})" for loc in allowed_location_objs}
        if not loc_options:
            st.error("No eligible locations configured for Convoy Status.")
            st.stop()
        default_loc_id = st.session_state.get("convoy_status_admin_loc") or target_location_id
        if default_loc_id not in loc_options:
            default_loc_id = next(iter(loc_options.keys()))
        option_items = sorted(loc_options.items(), key=lambda item: item[1])
        target_location_id = st.selectbox(
            "Select Location",
            option_items,
            format_func=lambda item: item[1],
            index=[idx for idx, (loc_id, _) in enumerate(option_items) if loc_id == default_loc_id][0],
            key="convoy_status_admin_loc_selector",
        )[0]
        st.session_state["convoy_status_admin_loc"] = target_location_id
        with get_session() as s:
            target_location = LocationManager.get_location_by_id(s, target_location_id)
    else:
        target_location = active_location

    if not target_location:
        st.error("Unable to determine selected location.")
        st.stop()

    target_location_name = target_location.name or "Unknown"
    target_location_code = target_location.code or ""
    target_location_norm = _norm_loc_name(target_location_name)
    st.success(f"Viewing Convoy Status for **{target_location_name} ({target_location_code})**")

    is_agge = target_location_norm == "agge"
    is_utapate = target_location_norm == "utapate"
    show_yade_tab = not is_utapate

    with get_session() as s:
        assigned_rows = (
            s.query(LocationVessel)
            .filter(LocationVessel.location_id == target_location_id, LocationVessel.is_active == True)
            .all()
        )
        assigned_vessel_ids = [row.vessel_id for row in assigned_rows]
        if assigned_vessel_ids:
            _assigned_vessels = (
                s.query(Vessel)
                .filter(Vessel.id.in_(assigned_vessel_ids))
                .order_by(Vessel.name)
                .all()
            )
            active_vessel_names = [v.name for v in _assigned_vessels]
        else:
            active_vessel_names = []

    # Determine if Asemoku Jetty data should be shown
    asemoku_location_id = next(
        (loc.id for loc in all_locations if "asemoku" in _norm_loc_name(loc.name)), None
    )
    include_asemoku = (
        asemoku_location_id is not None and target_location_norm == "agge"
    )
    if include_asemoku:
        st.caption("YADE data from Asemoku Jetty is also available for the dropdown selections.")

    source_location_ids = [target_location_id]
    if include_asemoku:
        source_location_ids.append(asemoku_location_id)

    location_by_norm = {_norm_loc_name(loc.name): loc for loc in all_locations}
    location_by_code_norm = {
        _norm_loc_name(loc.code): loc for loc in all_locations if getattr(loc, "code", None)
    }

    def _extend_loc_mapping(store: Dict[str, Location]) -> None:
        additions = {}
        for key, loc in list(store.items()):
            sanitized = key.replace(" ", "").replace("-", "")
            if sanitized and sanitized not in store:
                additions[sanitized] = loc
        store.update(additions)

    _extend_loc_mapping(location_by_norm)
    _extend_loc_mapping(location_by_code_norm)
    special_vessel_locations: Dict[str, Dict[str, Any]] = {}
    for vessel_name, loc_norms in CONVOY_STATUS_SPECIAL_VESSEL_LOCATIONS.items():
        loc_obj = None
        for candidate in loc_norms:
            candidate_norm = candidate.strip().lower()
            alt_norm = candidate_norm.replace(" ", "").replace("-", "")
            loc_obj = (
                location_by_norm.get(candidate_norm)
                or location_by_norm.get(alt_norm)
                or location_by_code_norm.get(candidate_norm)
                or location_by_code_norm.get(alt_norm)
            )
            if loc_obj:
                break
        if loc_obj:
            special_vessel_locations[vessel_name.upper()] = {
                "location_id": loc_obj.id,
                "location_code": loc_obj.code or "",
                "vessel_name": vessel_name,
            }

    with get_session() as s:
        yade_barges = s.query(YadeBarge).order_by(YadeBarge.name).all()
        if active_vessel_names:
            vessel_rows = s.query(Vessel).filter(Vessel.name.in_(active_vessel_names)).all()
        else:
            vessel_rows = []
    vessel_id_map = {(_norm_txt(v.name)).upper(): v.id for v in vessel_rows}

    def _load_yade_dropdown_data(target_date: date, loc_ids: List[int]):
        convoy_map: Dict[str, List[str]] = defaultdict(list)
        stock_map: Dict[tuple[str, str], List[Dict[str, Any]]] = defaultdict(list)
        if not loc_ids:
            return convoy_map, stock_map
        with get_session() as s:
            location_lookup = {
                loc.id: loc.name for loc in s.query(Location).filter(Location.id.in_(loc_ids)).all()
            }
            query = (
                s.query(
                    YadeVoyage.yade_name,
                    YadeVoyage.convoy_no,
                    YadeVoyage.voyage_no,
                    YadeVoyage.location_id,
                    YadeVoyage.date.label("voyage_date"),
                    TOAYadeSummary.date,
                    TOAYadeSummary.time,
                    TOAYadeStage.nsv_bbl,
                )
                .outerjoin(TOAYadeSummary, TOAYadeSummary.voyage_id == YadeVoyage.id)
                .outerjoin(
                    TOAYadeStage,
                    and_(TOAYadeStage.voyage_id == YadeVoyage.id, TOAYadeStage.stage == "after"),
                )
                .filter(YadeVoyage.location_id.in_(loc_ids))
                .order_by(
                    TOAYadeSummary.date.desc().nullslast(),
                    TOAYadeSummary.time.desc().nullslast(),
                    YadeVoyage.date.desc(),
                )
                .limit(1000)
            )
            rows = query.all()

        for (
            yade_name,
            convoy_no,
            voyage_no,
            loc_id,
            voyage_date,
            sum_date,
            sum_time,
            nsv_bbl,
        ) in rows:
            yade_name = _norm_txt(yade_name)
            convoy_no = _norm_txt(convoy_no)
            if yade_name and convoy_no:
                if convoy_no not in convoy_map[yade_name]:
                    convoy_map[yade_name].append(convoy_no)
            if (
                yade_name
                and convoy_no
                and nsv_bbl is not None
                and isinstance(nsv_bbl, (int, float))
            ):
                time_label = sum_time.strftime("%H:%M") if sum_time else ""
                date_label = None
                if sum_date:
                    date_label = sum_date.strftime("%d-%b-%Y")
                elif voyage_date:
                    date_label = voyage_date.strftime("%d-%b-%Y")
                location_label = location_lookup.get(loc_id)
                parts = [f"{float(nsv_bbl):,.2f} bbls"]
                if voyage_no:
                    parts.append(f"Voy {voyage_no}")
                if time_label:
                    parts.append(f"@ {time_label}")
                if date_label:
                    parts.append(f"on {date_label}")
                if include_asemoku and loc_id != target_location_id and location_label:
                    parts.append(f"� {location_label}")
                label = " ".join(parts)
                stock_map[(yade_name, convoy_no)].append(
                    {"label": label, "value": float(nsv_bbl)}
                )

        for k in convoy_map:
            convoy_map[k] = sorted(convoy_map[k])
        return convoy_map, stock_map

    def _load_vessel_dropdown_data(
        target_date: date, loc_id: int, special_location_map: Dict[str, Dict[str, Any]], allowed_vessel_ids: List[int]
    ):
        shuttle_map: Dict[str, List[str]] = defaultdict(list)
        stock_map: Dict[tuple[str, str], List[Dict[str, Any]]] = defaultdict(list)
        special_stock_map: Dict[str, Dict[str, Any]] = {}
        seen_shuttles: Dict[str, set] = defaultdict(set)

        def _fmt_time(val) -> str:
            if not val:
                return ''
            try:
                return val.strftime('%H:%M')
            except AttributeError:
                return str(val)

        with get_session() as s:
            if not allowed_vessel_ids:
                otr_rows = []
            else:
                query = (
                    s.query(
                        Vessel.name,
                        OTRVessel.shuttle_no,
                        OTRVessel.closing_stock,
                        OTRVessel.time,
                        OTRVessel.date,
                    )
                    .join(Vessel, Vessel.id == OTRVessel.vessel_id)
                    .filter(
                        OTRVessel.location_id == loc_id,
                        OTRVessel.vessel_id.in_(allowed_vessel_ids),
                    )
                    .order_by(OTRVessel.date.desc(), OTRVessel.time.desc().nullslast())
                    .limit(1000)
                )
                otr_rows = query.all()

        for vessel_name, shuttle_no, closing_stock, tx_time, tx_date in otr_rows:
            vessel_name = _norm_txt(vessel_name)
            shuttle_no = _norm_txt(shuttle_no)
            if vessel_name and shuttle_no:
                seen = seen_shuttles[vessel_name]
                if shuttle_no not in seen:
                    seen.add(shuttle_no)
                    shuttle_map[vessel_name].append(shuttle_no)
            if vessel_name and closing_stock is not None:
                label_parts = [f'{float(closing_stock):,.2f} bbls']
                time_label = _fmt_time(tx_time)
                if time_label:
                    label_parts.append(f'@ {time_label}')
                if tx_date:
                    try:
                        label_parts.append(f"on {tx_date.strftime('%d-%b-%Y')}")
                    except AttributeError:
                        label_parts.append(f'on {tx_date}')
                if shuttle_no:
                    label_parts.append(f' {shuttle_no}')
                label = ' '.join(label_parts)
                stock_map[(vessel_name, shuttle_no or '')].append(
                    {'label': label, 'value': float(closing_stock)}
                )

        for vessel_name in shuttle_map:
            shuttle_map[vessel_name] = sorted(shuttle_map[vessel_name])

        for vessel_key, loc_info in special_location_map.items():
            display_value, numeric_value = _convoy_fetch_mb_closing_value(
                target_date, loc_info.get("location_code")
            )
            if numeric_value is None:
                numeric_value = _convoy_fallback_closing_from_ops(
                    target_date, loc_info.get("location_id"), loc_info.get("vessel_name")
                )
                if numeric_value is not None and not display_value:
                    display_value = f"{numeric_value:,.2f}"
            special_stock_map[vessel_key] = {
                "label": display_value,
                "value": numeric_value,
            }

        return shuttle_map, stock_map, special_stock_map



    def _load_saved_yade_records(loc_id: int, target_date: date):
        with get_session() as s:
            rows = (
                s.query(ConvoyStatusYade)
                .filter(
                    ConvoyStatusYade.location_id == loc_id,
                    ConvoyStatusYade.date == target_date,
                )
                .all()
            )
        return {row.yade_barge_id: row for row in rows}

    def _load_saved_vessel_records(loc_id: int, target_date: date):
        with get_session() as s:
            rows = (
                s.query(ConvoyStatusVessel)
                .filter(
                    ConvoyStatusVessel.location_id == loc_id,
                    ConvoyStatusVessel.date == target_date,
                )
                .all()
            )
        return {(row.vessel_name or "").upper(): row for row in rows}

    def _load_saved_dates(model_cls):
        with get_session() as s:
            results = (
                s.query(model_cls.date)
                .filter(model_cls.location_id == target_location_id)
                .distinct()
                .order_by(model_cls.date.desc())
                .all()
            )
        return [row[0] for row in results]

    def _open_pdf(pdf_bytes: bytes, title: str):
        base64_pdf = base64.b64encode(pdf_bytes).decode("utf-8")
        pdf_html = f"""
        <script>
            var pdfWindow = window.open("");
            pdfWindow.document.write(
                '<html><head><title>{title}</title></head>' +
                '<body style="margin:0"><iframe width="100%" height="100%" src="data:application/pdf;base64,{base64_pdf}"></iframe></body></html>'
            );
        </script>
        """
        components.html(pdf_html, height=0)

    def _generate_pdf(title: str, subtitle: str, headers: List[str], rows: List[List[str]]):
        ok, err, _ = ensure_reportlab()
        if not ok:
            raise RuntimeError(err or "reportlab unavailable")
        from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
        from reportlab.lib.styles import getSampleStyleSheet

        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        styles = getSampleStyleSheet()
        elems = [
            Paragraph(f"<b>{title}</b>", styles["Title"]),
            Paragraph(subtitle, styles["Normal"]),
            Spacer(1, 12),
        ]
        table = Table([headers] + rows, repeatRows=1)
        table.setStyle(
            TableStyle(
                [
                    ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
                    ("TEXTCOLOR", (0, 0), (-1, 0), colors.black),
                    ("ALIGN", (0, 0), (-1, -1), "LEFT"),
                    ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
                    ("FONTSIZE", (0, 0), (-1, -1), 9),
                ]
            )
        )
        elems.append(table)
        doc.build(elems)
        pdf_data = buffer.getvalue()
        buffer.close()
        return pdf_data

    def _delete_convoy_snapshot(kind: str, entry_date: date):
        model = ConvoyStatusYade if kind == "yade" else ConvoyStatusVessel
        resource_type = "ConvoyStatusYade" if kind == "yade" else "ConvoyStatusVessel"
        with get_session() as s:
            s.query(model).filter(
                model.location_id == target_location_id,
                model.date == entry_date,
            ).delete(synchronize_session=False)
            s.commit()
        SecurityManager.log_audit(
            None,
            user["username"],
            "DELETE",
            resource_type=resource_type,
            resource_id=f"{target_location_id}:{entry_date.isoformat()}",
            location_id=target_location_id,
            details=f"Deleted {kind.upper()} convoy snapshot for {entry_date.isoformat()}",
            user_id=user.get("id"),
        )

    def _request_convoy_delete(kind: str, entry_date: date):
        resource_type = "ConvoyStatusYade" if kind == "yade" else "ConvoyStatusVessel"
        resource_id = f"{target_location_id}:{entry_date.isoformat()}"
        label = f"{kind.upper()} snapshot {entry_date.strftime('%d-%b-%Y')}"
        TaskManager.create_delete_request(
            resource_type=resource_type,
            resource_id=resource_id,
            resource_label=label,
            raised_by=user.get("username", "operator"),
            raised_by_role=user_role,
            location_id=target_location_id,
            metadata={"date": entry_date.isoformat(), "kind": kind},
        )

    tab_specs: List[Tuple[str, str]] = []
    if show_yade_tab:
        tab_specs.append(("Yade", "yade"))
    tab_specs.append(("Vessel", "vessel"))
    tab_specs.append(("Saved Entries", "saved"))
    tabs = st.tabs([label for label, _ in tab_specs])
    tab_indices = {kind: idx for idx, (_, kind) in enumerate(tab_specs)}

    if show_yade_tab:
        # ---------------------- YADE TAB ----------------------
        with tabs[tab_indices['yade']]:
            if 'convoy_status_yade_date' not in st.session_state:
                st.session_state['convoy_status_yade_date'] = date.today()
            yade_date = st.date_input('Select Date', key='convoy_status_yade_date')
            convoy_map, yade_stock_map = _load_yade_dropdown_data(yade_date, source_location_ids)
            saved_yade_records = _load_saved_yade_records(target_location_id, yade_date)

            st.markdown('#### Yade Convoy Tracker')
            header_cols = st.columns([2.2, 2, 2, 2])
            header_cols[0].markdown('**YADE No**')
            header_cols[1].markdown('**Convoy**')
            header_cols[2].markdown('**Stock (After Loading NSV)**')
            header_cols[3].markdown('**Status**')

            for yade in yade_barges:
                row_cols = st.columns([2.2, 2, 2, 2])
                row_cols[0].markdown(f"**{yade.name}**")
                yade_name_norm = _norm_txt(yade.name)
                saved_record = saved_yade_records.get(yade.id)

                convoy_options = ['N/A'] + convoy_map.get(yade_name_norm, [])
                if saved_record and saved_record.convoy_no and saved_record.convoy_no not in convoy_options:
                    convoy_options.append(saved_record.convoy_no)
                convoy_key = f"convoy_status_yade_{yade_date.isoformat()}_{yade.id}_convoy"
                if (
                    convoy_key not in st.session_state
                    or st.session_state[convoy_key] not in convoy_options
                ):
                    st.session_state[convoy_key] = (
                        saved_record.convoy_no if saved_record and saved_record.convoy_no else 'N/A'
                    )
                selected_convoy = row_cols[1].selectbox(
                    'Convoy',
                    options=convoy_options,
                    key=convoy_key,
                    label_visibility='collapsed',
                )

                stock_candidates = yade_stock_map.get((yade_name_norm, selected_convoy), [])
                stock_labels = ['N/A'] + [opt['label'] for opt in stock_candidates]
                if saved_record and saved_record.stock_display and saved_record.stock_display not in stock_labels:
                    stock_labels.append(saved_record.stock_display)
                stock_key = f"convoy_status_yade_{yade_date.isoformat()}_{yade.id}_stock"
                current_stock = st.session_state.get(stock_key)
                if current_stock not in stock_labels:
                    st.session_state[stock_key] = (
                        saved_record.stock_display if saved_record and saved_record.stock_display else 'N/A'
                    )
                selected_stock = row_cols[2].selectbox(
                    'Stock',
                    options=stock_labels,
                    key=stock_key,
                    label_visibility='collapsed',
                )

                status_options = ['Select status'] + CONVOY_STATUS_YADE_STATUS_OPTIONS
                if saved_record and saved_record.status and saved_record.status not in status_options:
                    status_options.append(saved_record.status)
                status_key = f"convoy_status_yade_{yade_date.isoformat()}_{yade.id}_status"
                current_status = st.session_state.get(status_key)
                if current_status not in status_options:
                    st.session_state[status_key] = saved_record.status if saved_record else 'Select status'
                row_cols[3].selectbox(
                    'Status',
                    options=status_options,
                    key=status_key,
                    label_visibility='collapsed',
                )

            save_key = f"convoy_status_yade_save_{target_location_id}"
            if st.button(' Save YADE Status', key=save_key, use_container_width=True):
                try:
                    with get_session() as s:
                        existing_rows = (
                            s.query(ConvoyStatusYade)
                            .filter(
                                ConvoyStatusYade.location_id == target_location_id,
                                ConvoyStatusYade.date == yade_date,
                            )
                            .all()
                        )
                        existing = {row.yade_barge_id: row for row in existing_rows}
                        changes = 0
                        for yade in yade_barges:
                            yade_name_norm = _norm_txt(yade.name)
                            convoy_key = f"convoy_status_yade_{yade_date.isoformat()}_{yade.id}_convoy"
                            stock_key = f"convoy_status_yade_{yade_date.isoformat()}_{yade.id}_stock"
                            status_key = f"convoy_status_yade_{yade_date.isoformat()}_{yade.id}_status"
                            selected_convoy = st.session_state.get(convoy_key, 'N/A')
                            selected_stock = st.session_state.get(stock_key, 'N/A')
                            selected_status = st.session_state.get(status_key, 'Select status')
                            if selected_status == 'Select status':
                                continue
                            selected_stock_value = None
                            for opt in yade_stock_map.get((yade_name_norm, selected_convoy), []):
                                if opt['label'] == selected_stock:
                                    selected_stock_value = opt['value']
                                    break
                            record = existing.get(yade.id)
                            if not record:
                                record = ConvoyStatusYade(
                                    location_id=target_location_id,
                                    date=yade_date,
                                    yade_barge_id=yade.id,
                                    created_by=user.get('username', 'unknown'),
                                )
                                s.add(record)
                            record.convoy_no = None if selected_convoy == 'N/A' else selected_convoy
                            record.stock_display = None if selected_stock == 'N/A' else selected_stock
                            record.stock_value_bbl = selected_stock_value
                            record.status = selected_status
                            record.updated_by = user.get('username')
                            changes += 1
                        if changes:
                            s.commit()
                        else:
                            s.rollback()
                    if changes:
                        SecurityManager.log_audit(
                            None,
                            user['username'],
                            'UPDATE',
                            resource_type='ConvoyStatusYade',
                            resource_id=f"{target_location_id}:{yade_date.isoformat()}",
                            location_id=target_location_id,
                            details=f"Saved {changes} YADE convoy rows for {yade_date}",
                            user_id=user.get('id'),
                        )
                    st.success('YADE convoy status saved.')
                    import time as _t
                    _t.sleep(1)
                    _st_safe_rerun()
                except Exception as ex:
                    st.error(f'Failed to save YADE status: {ex}')

    # ---------------------- VESSEL TAB ----------------------
    with tabs[tab_indices['vessel']]:
        if 'convoy_status_vessel_date' not in st.session_state:
            st.session_state['convoy_status_vessel_date'] = date.today()
        vessel_date = st.date_input('Select Date', key='convoy_status_vessel_date')
        shuttle_map, vessel_stock_map, special_stock_map = _load_vessel_dropdown_data(
            vessel_date, target_location_id, special_vessel_locations, assigned_vessel_ids
        )
        saved_vessel_records = _load_saved_vessel_records(target_location_id, vessel_date)

        st.markdown('#### Vessel Convoy Tracker')
        header_cols = st.columns([2.2, 2, 2, 2])
        header_cols[0].markdown('**Vessel Name**')
        header_cols[1].markdown('**Shuttle No**')
        header_cols[2].markdown('**Stock (Closing)**')
        header_cols[3].markdown('**Status**')

        special_display_snapshot: Dict[str, Dict[str, Any]] = {}

        for vessel_name in active_vessel_names:
            row_cols = st.columns([2.2, 2, 2, 2])
            row_cols[0].markdown(f"**{vessel_name}**")
            vessel_key = vessel_name.upper()
            saved_record = saved_vessel_records.get(vessel_key)
            is_special = vessel_name in CONVOY_STATUS_SPECIAL_VESSELS

            if is_special:
                row_cols[1].markdown('_N/A_')
                stock_info = special_stock_map.get(vessel_key, {})
                display_label = stock_info.get('label')
                numeric_val = stock_info.get('value')
                if display_label:
                    row_cols[2].markdown(f"**{display_label}**")
                elif numeric_val is not None:
                    display_label = f"{numeric_val:,.2f}"
                    row_cols[2].markdown(f"**{display_label}**")
                else:
                    display_label = None
                    row_cols[2].markdown('_No closing stock for selected date_')
                special_display_snapshot[vessel_key] = {
                    'label': display_label,
                    'value': numeric_val,
                }
            else:
                shuttle_options = ['N/A'] + shuttle_map.get(vessel_name, [])
                if (
                    saved_record
                    and saved_record.shuttle_no
                    and saved_record.shuttle_no not in shuttle_options
                ):
                    shuttle_options.append(saved_record.shuttle_no)
                shuttle_key = f"convoy_status_vessel_{vessel_date.isoformat()}_{vessel_key}_shuttle"
                if (
                    shuttle_key not in st.session_state
                    or st.session_state[shuttle_key] not in shuttle_options
                ):
                    st.session_state[shuttle_key] = (
                        saved_record.shuttle_no if saved_record and saved_record.shuttle_no else 'N/A'
                    )
                selected_shuttle = row_cols[1].selectbox(
                    'Shuttle',
                    options=shuttle_options,
                    key=shuttle_key,
                    label_visibility='collapsed',
                )

                stock_candidates = vessel_stock_map.get((vessel_name, selected_shuttle or ''), [])
                stock_labels = ['N/A'] + [opt['label'] for opt in stock_candidates]
                if (
                    saved_record
                    and saved_record.stock_display
                    and saved_record.stock_display not in stock_labels
                ):
                    stock_labels.append(saved_record.stock_display)
                stock_key = f"convoy_status_vessel_{vessel_date.isoformat()}_{vessel_key}_stock"
                if stock_key not in st.session_state or st.session_state[stock_key] not in stock_labels:
                    st.session_state[stock_key] = (
                        saved_record.stock_display if saved_record and saved_record.stock_display else 'N/A'
                    )
                row_cols[2].selectbox(
                    'Stock',
                    options=stock_labels,
                    key=stock_key,
                    label_visibility='collapsed',
                )

            status_options = ['Select status'] + CONVOY_STATUS_VESSEL_STATUS_OPTIONS
            if saved_record and saved_record.status and saved_record.status not in status_options:
                status_options.append(saved_record.status)
            status_key = f"convoy_status_vessel_{vessel_date.isoformat()}_{vessel_key}_status"
            if status_key not in st.session_state or st.session_state[status_key] not in status_options:
                st.session_state[status_key] = saved_record.status if saved_record else 'Select status'
            row_cols[3].selectbox(
                'Status',
                options=status_options,
                key=status_key,
                label_visibility='collapsed',
            )

        vessel_save_key = f"convoy_status_vessel_save_{target_location_id}"
        if st.button(' Save Vessel Status', key=vessel_save_key, use_container_width=True):
            try:
                with get_session() as s:
                    existing_rows = (
                        s.query(ConvoyStatusVessel)
                        .filter(
                            ConvoyStatusVessel.location_id == target_location_id,
                            ConvoyStatusVessel.date == vessel_date,
                        )
                        .all()
                    )
                    existing = {(row.vessel_name or '').upper(): row for row in existing_rows}
                    changes = 0
                    for vessel_name in active_vessel_names:
                        vessel_key = vessel_name.upper()
                        status_key = f"convoy_status_vessel_{vessel_date.isoformat()}_{vessel_key}_status"
                        selected_status = st.session_state.get(status_key, 'Select status')
                        if selected_status == 'Select status':
                            continue
                        if vessel_name in CONVOY_STATUS_SPECIAL_VESSELS:
                            stock_data = special_display_snapshot.get(vessel_key, {})
                            selected_shuttle = 'N/A'
                            stock_value = stock_data.get('value') if stock_data else None
                            display_label = stock_data.get('label') if stock_data else None
                            if not display_label and stock_value is not None:
                                display_label = f"{stock_value:,.2f}"
                            selected_stock = display_label or 'N/A'
                        else:
                            shuttle_key = f"convoy_status_vessel_{vessel_date.isoformat()}_{vessel_key}_shuttle"
                            stock_key = f"convoy_status_vessel_{vessel_date.isoformat()}_{vessel_key}_stock"
                            selected_shuttle = st.session_state.get(shuttle_key, 'N/A')
                            selected_stock = st.session_state.get(stock_key, 'N/A')
                            stock_value = None
                            record = existing.get(vessel_key)
                            stock_candidates = vessel_stock_map.get((vessel_name, selected_shuttle or ''), [])
                            for opt in stock_candidates:
                                if opt['label'] == selected_stock:
                                    stock_value = opt['value']
                                    break
                            if stock_value is None and record and record.stock_display == selected_stock:
                                stock_value = record.stock_value_bbl
                        record = existing.get(vessel_key)
                        if not record:
                            record = ConvoyStatusVessel(
                                location_id=target_location_id,
                                date=vessel_date,
                                vessel_name=vessel_name,
                                vessel_id=vessel_id_map.get(vessel_key),
                                created_by=user.get('username', 'unknown'),
                            )
                            s.add(record)
                        record.shuttle_no = None if selected_shuttle == 'N/A' else selected_shuttle
                        record.stock_display = None if selected_stock == 'N/A' else selected_stock
                        record.stock_value_bbl = stock_value
                        record.status = selected_status
                        record.updated_by = user.get('username')
                        changes += 1
                    if changes:
                        s.commit()
                    else:
                        s.rollback()
                if changes:
                    SecurityManager.log_audit(
                        None,
                        user['username'],
                        'UPDATE',
                        resource_type='ConvoyStatusVessel',
                        resource_id=f"{target_location_id}:{vessel_date.isoformat()}",
                        location_id=target_location_id,
                        details=f"Saved {changes} vessel convoy rows for {vessel_date}",
                        user_id=user.get('id'),
                    )
                st.success('Vessel convoy status saved.')
                import time as _t
                _t.sleep(1)
                _st_safe_rerun()
            except Exception as ex:
                st.error(f'Failed to save vessel status: {ex}')

    # ---------------------- SAVED ENTRIES TAB ----------------------
    with tabs[tab_indices["saved"]]:
        st.markdown("#### Saved Entries")
        yade_saved_dates = _load_saved_dates(ConvoyStatusYade)
        vessel_saved_dates = _load_saved_dates(ConvoyStatusVessel)

        yade_col, vessel_col = st.columns(2)

        with yade_col:
            st.markdown("**YADE Entries**")
            if not yade_saved_dates:
                st.info("No YADE entries saved yet.")
            else:
                for idx, entry_date in enumerate(yade_saved_dates, start=1):
                    row_cols = st.columns([0.3, 1, 0.35, 0.35])
                    row_cols[0].markdown(f"**{idx}**")
                    row_cols[1].markdown(entry_date.strftime("%d-%b-%Y"))
                    view_key = f"convoy_status_view_yade_{entry_date}"
                    delete_key = f"convoy_status_delete_yade_{entry_date}"
                    confirm_key = f"convoy_status_confirm_delete_yade_{entry_date}"

                    if row_cols[2].button(
                        "👁️",
                        key=view_key,
                        use_container_width=True,
                        help="View PDF",
                    ):
                        with get_session() as s:
                            rows = (
                                s.query(ConvoyStatusYade, YadeBarge.name)
                                .join(YadeBarge, ConvoyStatusYade.yade_barge_id == YadeBarge.id)
                                .filter(
                                    ConvoyStatusYade.location_id == target_location_id,
                                    ConvoyStatusYade.date == entry_date,
                                )
                                .order_by(YadeBarge.name)
                                .all()
                            )
                        pdf_rows = [
                            [
                                name,
                                rec.convoy_no or "N/A",
                                rec.stock_display or "-",
                                rec.status,
                            ]
                            for rec, name in rows
                        ]
                        if not pdf_rows:
                            st.warning("No rows saved for that date.")
                        else:
                            pdf_bytes = _generate_pdf(
                                "YADE Convoy Status",
                                f"{target_location_name} � {entry_date.strftime('%d-%b-%Y')}",
                                ["YADE", "Convoy", "Stock", "Status"],
                                pdf_rows,
                            )
                            _open_pdf(pdf_bytes, f"YADE Status - {target_location_name}")
                            st.success("YADE PDF opened in a new tab.")

                    if row_cols[3].button(
                        "🗑️",
                        key=delete_key,
                        use_container_width=True,
                        help="Delete entry",
                    ):
                        st.session_state[confirm_key] = True

                    if st.session_state.get(confirm_key):
                        prompt = (
                            f"Confirm deletion of YADE snapshot for {entry_date.strftime('%d-%b-%Y')}?"
                            if can_delete_snapshots
                            else f"Request supervisor approval to delete YADE snapshot for {entry_date.strftime('%d-%b-%Y')}?"
                        )
                        st.warning(prompt)
                        confirm_cols = st.columns(2)
                        if confirm_cols[0].button(
                            "? Confirm",
                            key=f"{confirm_key}_yes",
                            use_container_width=True,
                        ):
                            try:
                                if can_delete_snapshots:
                                    _delete_convoy_snapshot("yade", entry_date)
                                    st.success("YADE snapshot deleted.")
                                else:
                                    _request_convoy_delete("yade", entry_date)
                                    st.success("Delete request sent to supervisor.")
                                st.session_state.pop(confirm_key, None)
                                import time as _t

                                _t.sleep(1)
                                _st_safe_rerun()
                            except Exception as _ex:
                                st.error(f"Delete failed: {_ex}")
                                st.session_state.pop(confirm_key, None)
                        if confirm_cols[1].button(
                            "Cancel",
                            key=f"{confirm_key}_no",
                            use_container_width=True,
                        ):
                            st.session_state.pop(confirm_key, None)

        with vessel_col:
            st.markdown("**Vessel Entries**")
            if not vessel_saved_dates:
                st.info("No Vessel entries saved yet.")
            else:
                for idx, entry_date in enumerate(vessel_saved_dates, start=1):
                    row_cols = st.columns([0.3, 1, 0.35, 0.35])
                    row_cols[0].markdown(f"**{idx}**")
                    row_cols[1].markdown(entry_date.strftime("%d-%b-%Y"))
                    view_key = f"convoy_status_view_vessel_{entry_date}"
                    delete_key = f"convoy_status_delete_vessel_{entry_date}"
                    confirm_key = f"convoy_status_confirm_delete_vessel_{entry_date}"

                    if row_cols[2].button(
                        "👁️",
                        key=view_key,
                        use_container_width=True,
                        help="View PDF",
                    ):
                        with get_session() as s:
                            rows = (
                                s.query(ConvoyStatusVessel)
                                .filter(
                                    ConvoyStatusVessel.location_id == target_location_id,
                                    ConvoyStatusVessel.date == entry_date,
                                )
                                .order_by(ConvoyStatusVessel.vessel_name)
                                .all()
                            )
                        pdf_rows = [
                            [
                                rec.vessel_name,
                                rec.shuttle_no or "N/A",
                                rec.stock_display or "-",
                                rec.status,
                            ]
                            for rec in rows
                        ]
                        if not pdf_rows:
                            st.warning("No rows saved for that date.")
                        else:
                            pdf_bytes = _generate_pdf(
                                "Vessel Convoy Status",
                                f"{target_location_name} � {entry_date.strftime('%d-%b-%Y')}",
                                ["Vessel", "Shuttle", "Stock", "Status"],
                                pdf_rows,
                            )
                            _open_pdf(pdf_bytes, f"Vessel Status - {target_location_name}")
                            st.success("Vessel PDF opened in a new tab.")

                    if row_cols[3].button(
                        "🗑️",
                        key=delete_key,
                        use_container_width=True,
                        help="Delete entry",
                    ):
                        st.session_state[confirm_key] = True

                    if st.session_state.get(confirm_key):
                        prompt = (
                            f"Confirm deletion of Vessel snapshot for {entry_date.strftime('%d-%b-%Y')}?"
                            if can_delete_snapshots
                            else f"Request supervisor approval to delete Vessel snapshot for {entry_date.strftime('%d-%b-%Y')}?"
                        )
                        st.warning(prompt)
                        confirm_cols = st.columns(2)
                        if confirm_cols[0].button(
                            "? Confirm",
                            key=f"{confirm_key}_yes",
                            use_container_width=True,
                        ):
                            try:
                                if can_delete_snapshots:
                                    _delete_convoy_snapshot("vessel", entry_date)
                                    st.success("Vessel snapshot deleted.")
                                else:
                                    _request_convoy_delete("vessel", entry_date)
                                    st.success("Delete request sent to supervisor.")
                                st.session_state.pop(confirm_key, None)
                                import time as _t

                                _t.sleep(1)
                                _st_safe_rerun()
                            except Exception as _ex:
                                st.error(f"Delete failed: {_ex}")
                                st.session_state.pop(confirm_key, None)
                        if confirm_cols[1].button(
                            "Cancel",
                            key=f"{confirm_key}_no",
                            use_container_width=True,
                        ):
                            st.session_state.pop(confirm_key, None)

# ========================= REPORTING PAGE =========================
elif page == "Reporting":
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()
    
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("Reporting") is False:
                st.error("⚠️ Reporting page is disabled for this location.")
                st.stop()
    except Exception:
        pass
    render_reports_page()

# ========================= YADE-VESSEL MAPPING =========================
elif page == "Yade-Vessel Mapping":
    header("Yade-Vessel Mapping")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()

    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("⚠️ No active location selected. Please pick Agge or Lagos (HO) to continue.")
        st.stop()

    user = st.session_state.get("auth_user") or {}
    if user:
        from auth import AuthManager

        if not AuthManager.can_access_location(user, active_location_id):
            st.error("🚫 You do not have access to this location.")
            st.stop()
    else:
        st.error("User session expired. Please sign in again.")
        st.stop()

    from location_manager import LocationManager
    from models import OTRVessel, FSOOperation

    def _combine_datetime(date_val, time_val):
        """Return a datetime that can be used for sorting."""
        if not isinstance(date_val, date):
            return datetime.min
        if isinstance(time_val, datetime):
            return time_val
        if isinstance(time_val, time):
            return datetime.combine(date_val, time_val)
        if isinstance(time_val, str):
            try:
                parts = [int(p) for p in time_val.split(":")]
            except Exception:
                parts = []
            hour = parts[0] if len(parts) > 0 else 0
            minute = parts[1] if len(parts) > 1 else 0
            second = parts[2] if len(parts) > 2 else 0
            try:
                return datetime.combine(date_val, time(hour, minute, second))
            except Exception:
                return datetime.combine(date_val, time.min)
        return datetime.combine(date_val, time.min)

    def _fetch_yade_rows(sess, location_id, limit=500):
        voyages = (
            sess.query(YadeVoyage)
            .filter(YadeVoyage.location_id == location_id)
            .order_by(YadeVoyage.date.desc(), YadeVoyage.time.desc())
            .limit(limit)
            .all()
        )
        if not voyages:
            return []
        voyage_ids = [v.id for v in voyages]
        stage_rows = sess.query(TOAYadeStage).filter(TOAYadeStage.voyage_id.in_(voyage_ids)).all()
        stage_map: Dict[int, Dict[str, TOAYadeStage]] = {}
        for stage in stage_rows:
            key = (stage.stage or "").strip().lower()
            stage_map.setdefault(stage.voyage_id, {})[key] = stage

        rows = []
        for voyage in voyages:
            per_stage = stage_map.get(voyage.id, {})
            rob = float(getattr(per_stage.get("before"), "nsv_bbl", 0.0) or 0.0)
            tob = float(getattr(per_stage.get("after"), "nsv_bbl", 0.0) or 0.0)
            rows.append(
                {
                    "id": voyage.id,
                    "Date": voyage.date,
                    "Convoy No": voyage.convoy_no or "",
                    "Yade No": voyage.yade_name or "",
                    "TOB Qty": round(tob, 2),
                    "ROB Qty": round(rob, 2),
                    "Net Offloaded": round(tob - rob, 2),
                    "SortKey": _combine_datetime(voyage.date, voyage.time),
                }
            )
        return rows

    def _fetch_vessel_rows(sess, location_id, limit=500):
        entries = (
            sess.query(OTRVessel)
            .options(joinedload(OTRVessel.vessel))
            .filter(OTRVessel.location_id == location_id)
            .order_by(OTRVessel.date.desc(), OTRVessel.id.desc())
            .limit(limit)
            .all()
        )
        rows = []
        for entry in entries:
            vessel_name = ""
            try:
                vessel_name = (entry.vessel.name if entry.vessel else "") or ""
            except Exception:
                vessel_name = ""
            rows.append(
                {
                    "id": entry.id,
                    "Date": entry.date,
                    "Shuttle No": entry.shuttle_no or "",
                    "Vessel Name": vessel_name,
                    "Net Receipt/Dispatch": round(float(entry.net_receipt_dispatch or 0.0), 2),
                    "SortKey": _combine_datetime(entry.date, entry.time or "00:00"),
                }
            )
        return rows

    def _fetch_fso_rows(sess, location_id, limit=500):
        entries = (
            sess.query(FSOOperation)
            .filter(FSOOperation.location_id == location_id)
            .order_by(FSOOperation.date.desc(), FSOOperation.time.desc())
            .limit(limit)
            .all()
        )
        rows = []
        for entry in entries:
            rows.append(
                {
                    "id": entry.id,
                    "Date": entry.date,
                    "Shuttle No": entry.shuttle_no or "",
                    "Vessel Name": entry.vessel_name or "",
                    "Qty Received": round(float(entry.net_receipt_dispatch or 0.0), 2),
                    "SortKey": _combine_datetime(entry.date, entry.time),
                }
            )
        return rows

    with get_session() as sess:
        location = LocationManager.get_location_by_id(sess, active_location_id)
        if not location:
            st.error("Location not found.")
            st.stop()

        location_name = location.name or "Unknown"
        st.info(f"📍 **Active Location:** {location_name} ({location.code})")

        allowed_locations = {"agge", "lagos (ho)"}
        user_role = (user.get("role") or "").lower()
        if user_role != "admin-operations" and (location_name or "").strip().lower() not in allowed_locations:
            st.error("⚠️ Yade-Vessel Mapping is only available for Agge, Lagos (HO), or administrators.")
            st.stop()

        yade_rows = _fetch_yade_rows(sess, active_location_id)
        vessel_rows = _fetch_vessel_rows(sess, active_location_id)
        fso_rows = _fetch_fso_rows(sess, active_location_id)
    can_delete_mapping_rows = user_role in {"admin", "supervisor"}

    yade_lookup = {row["id"]: row for row in yade_rows}
    vessel_lookup = {row["id"]: row for row in vessel_rows}
    fso_lookup = {row["id"]: row for row in fso_rows}

    yade_df = pd.DataFrame(yade_rows)
    vessel_df = pd.DataFrame(vessel_rows)
    fso_df = pd.DataFrame(fso_rows)

    for df in (yade_df, vessel_df, fso_df):
        if not df.empty and "Date" in df.columns:
            df["Date"] = pd.to_datetime(df["Date"])

    if "yvm_records" not in st.session_state:
        st.session_state["yvm_records"] = []
    if "yvm_pending_payload" not in st.session_state:
        st.session_state["yvm_pending_payload"] = None
    if "yvm_selected_yade" not in st.session_state:
        st.session_state["yvm_selected_yade"] = set()
    if "yvm_selected_vessel" not in st.session_state:
        st.session_state["yvm_selected_vessel"] = set()
    if "yvm_selected_fso" not in st.session_state:
        st.session_state["yvm_selected_fso"] = set()
    if "yvm_revision" not in st.session_state:
        st.session_state["yvm_revision"] = 0
    if "yvm_delete_target" not in st.session_state:
        st.session_state["yvm_delete_target"] = None

    def _filter_table(df: pd.DataFrame, start_value, end_value, text_value: str, text_columns: list[str]):
        if df.empty:
            return df
        filtered = df.copy()
        if start_value:
            filtered = filtered[filtered["Date"] >= pd.to_datetime(start_value)]
        if end_value:
            filtered = filtered[filtered["Date"] <= pd.to_datetime(end_value)]
        if text_value:
            needle = text_value.strip().lower()
            if needle:
                mask = pd.Series(False, index=filtered.index)
                for col in text_columns:
                    if col in filtered.columns:
                        mask = mask | filtered[col].astype(str).str.lower().str.contains(needle, na=False)
                filtered = filtered[mask]
        return filtered

    def _render_selection_table(
        df: pd.DataFrame,
        label: str,
        session_key: str,
        table_key: str,
        column_config: dict,
        *,
        height: int = 320,
    ):
        st.markdown(f"##### {label}")
        if df.empty:
            st.info(f"No {label.lower()} available for this location.")
            st.session_state[session_key] = set()
            return set()
        display_df = df.sort_values("SortKey", ascending=False).drop(columns=["SortKey"], errors="ignore").copy()
        selected_ids = st.session_state.get(session_key, set())
        display_df.insert(0, "Select", display_df["id"].apply(lambda rid: rid in selected_ids))
        display_df = display_df.set_index("id")
        widget_key = f"{table_key}_{st.session_state.get('yvm_revision', 0)}"
        edited = st.data_editor(
            display_df,
            hide_index=True,
            use_container_width=True,
            key=widget_key,
            column_config=column_config,
            disabled=[col for col in display_df.columns if col != "Select"],
            height=height,
        )
        chosen = set(int(idx) for idx in edited.index[edited["Select"]])
        st.session_state[session_key] = chosen
        return chosen

    def _comparison_dataframe(records: List[Dict[str, Any]]) -> pd.DataFrame:
        columns = [
            "S.No",
            "Date",
            "Yade Dispatch (bbls)",
            "Vessel Receipt (bbls)",
            "Difference Y vs V (bbls)",
            "FSO Receipt (bbls)",
            "Difference V vs TT (bbls)",
            "Remarks",
        ]
        if not records:
            return pd.DataFrame(columns=columns)
        sorted_rows = sorted(records, key=lambda row: (row["s_no"], row["date"]))
        payload = []
        for row in sorted_rows:
            date_value = row.get("date")
            if hasattr(date_value, "strftime"):
                date_value = date_value.strftime("%Y-%m-%d")
            payload.append(
                {
                    "S.No": row.get("s_no"),
                    "Date": date_value,
                    "Yade Dispatch (bbls)": row.get("yade_dispatch", 0.0),
                    "Vessel Receipt (bbls)": row.get("vessel_receipt", 0.0),
                    "Difference Y vs V (bbls)": row.get("diff_y_vs_v", 0.0),
                    "FSO Receipt (bbls)": row.get("fso_receipt", 0.0),
                    "Difference V vs TT (bbls)": row.get("diff_v_vs_tt", 0.0),
                    "Remarks": row.get("remarks", ""),
                }
            )
        return pd.DataFrame(payload, columns=columns)

    def _generate_mapping_pdf(df: pd.DataFrame, location_name: str, username: str) -> bytes:
        if df.empty:
            return b""
        buffer = BytesIO()
        doc = SimpleDocTemplate(
            buffer,
            pagesize=landscape(A4),
            leftMargin=0.6 * cm,
            rightMargin=0.6 * cm,
            topMargin=0.7 * cm,
            bottomMargin=0.7 * cm,
        )
        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            "yvmTitle",
            parent=styles["Heading1"],
            alignment=TA_CENTER,
            fontSize=16,
            textColor=colors.HexColor("#1f4788"),
            spaceAfter=6,
        )
        subtitle_style = ParagraphStyle(
            "yvmSubtitle",
            parent=styles["Normal"],
            alignment=TA_CENTER,
            fontSize=10,
            textColor=colors.HexColor("#5c5f66"),
            spaceAfter=8,
        )
        elements = [
            Paragraph("<b>Yade � Vessel Mapping Comparison</b>", title_style),
            Paragraph(
                f"{location_name} � Generated by {username or 'user'} on {datetime.now().strftime('%d-%b-%Y %H:%M')}",
                subtitle_style,
            ),
            Spacer(1, 6),
        ]
        header = list(df.columns)
        table_data = [header] + df.round(2).astype(str).values.tolist()
        table = Table(table_data, repeatRows=1)
        table.setStyle(
            TableStyle(
                [
                    ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#1f4788")),
                    ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
                    ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
                    ("ALIGN", (0, 0), (-1, -1), "CENTER"),
                    ("GRID", (0, 0), (-1, -1), 0.4, colors.HexColor("#dfe3eb")),
                    ("ROWBACKGROUNDS", (0, 1), (-1, -1), [colors.whitesmoke, colors.HexColor("#f7f9fc")]),
                    ("FONTSIZE", (0, 0), (-1, -1), 9),
                ]
            )
        )
        elements.append(table)
        doc.build(elements)
        buffer.seek(0)
        return buffer.read()

    yade_column_config = {
        "Select": st.column_config.CheckboxColumn("Select", help="Tick to include transaction in mapping."),
        "Date": st.column_config.DateColumn("Date", format="YYYY-MM-DD"),
        "Convoy No": st.column_config.TextColumn("Convoy No"),
        "Yade No": st.column_config.TextColumn("Yade No"),
        "TOB Qty": st.column_config.NumberColumn("TOB Qty (bbls)", format="%.2f"),
        "ROB Qty": st.column_config.NumberColumn("ROB Qty (bbls)", format="%.2f"),
        "Net Offloaded": st.column_config.NumberColumn("Net Offloaded (bbls)", format="%.2f"),
    }
    vessel_column_config = {
        "Select": st.column_config.CheckboxColumn("Select", help="Include shuttle entry in mapping."),
        "Date": st.column_config.DateColumn("Date", format="YYYY-MM-DD"),
        "Shuttle No": st.column_config.TextColumn("Shuttle No"),
        "Vessel Name": st.column_config.TextColumn("Vessel Name"),
        "Net Receipt/Dispatch": st.column_config.NumberColumn("Net R/D (bbls)", format="%.2f"),
    }
    fso_column_config = {
        "Select": st.column_config.CheckboxColumn("Select", help="Include FSO entry in mapping."),
        "Date": st.column_config.DateColumn("Date", format="YYYY-MM-DD"),
        "Shuttle No": st.column_config.TextColumn("Shuttle No"),
        "Vessel Name": st.column_config.TextColumn("Vessel Name"),
        "Qty Received": st.column_config.NumberColumn("Qty Received (bbls)", format="%.2f"),
    }

    mapping_tab, comparison_tab = st.tabs(["Mapping", "Comparison"])

    with mapping_tab:
        map_button_area = st.container()
        st.markdown("#### Mapping")
        st.caption("Select YADE, Vessel, and FSO transactions with the live filters below, then map them into a comparison row.")

        if st.session_state.get("yvm_pending_payload"):
            st.success("Selection already staged. Complete it under the Comparison tab or clear it below.")

        default_from = date.today() - timedelta(days=30)
        default_to = date.today()

        st.markdown(
            """
            <style>
            .yvm-mapping [data-testid="stDataFrame"] table,
            .yvm-mapping [data-testid="stDataEditor"] table {
                font-size:0.82rem;
            }
            .yvm-mapping .stDataFrame,
            .yvm-mapping .stDataEditor {
                border: 1px solid #dfe3e8;
                border-radius: 6px;
                margin-top: 0.1rem;
            }
            .yvm-mapping .filter-box {
                background: #f9fafc;
                padding: 0.25rem 0.45rem;
                border-radius: 6px;
                border: 1px solid #edf0f5;
                margin-bottom: 0.15rem;
            }
            .yvm-mapping .filter-box > div {
                margin-bottom: 0.12rem;
            }
            .yvm-subheader {
                font-size: 0.92rem;
                font-weight: 600;
                margin: 0 0 0.15rem 0;
            }
            </style>
            <div class="yvm-mapping">
            """,
            unsafe_allow_html=True,
        )

        yade_col, vessel_col, fso_col = st.columns(3)

        with yade_col:
            st.markdown('<p class="yvm-subheader">Yade transactions</p>', unsafe_allow_html=True)
            with st.container():
                st.markdown('<div class="filter-box">', unsafe_allow_html=True)
                yade_dates = st.columns(2)
                with yade_dates[0]:
                    st.caption("From")
                    yade_from = st.date_input(
                        "From",
                        value=default_from,
                        key="yvm_yade_from",
                        label_visibility="collapsed",
                    )
                with yade_dates[1]:
                    st.caption("To")
                    yade_to = st.date_input(
                        "To",
                        value=default_to,
                        key="yvm_yade_to",
                        label_visibility="collapsed",
                    )
                st.caption("Search")
                yade_search = st.text_input(
                    "Convoy / Yade No",
                    key="yvm_yade_search",
                    label_visibility="collapsed",
                    placeholder="Convoy / YADE No",
                )
                st.markdown("</div>", unsafe_allow_html=True)
            filtered_yade_df = _filter_table(yade_df, yade_from, yade_to, yade_search, ["Convoy No", "Yade No"])
            yade_selection = _render_selection_table(
                filtered_yade_df,
                "Yade transactions",
                "yvm_selected_yade",
                "yvm_yade",
                yade_column_config,
                height=280,
            )

        with vessel_col:
            st.markdown('<p class="yvm-subheader">Vessel transactions</p>', unsafe_allow_html=True)
            with st.container():
                st.markdown('<div class="filter-box">', unsafe_allow_html=True)
                vessel_dates = st.columns(2)
                with vessel_dates[0]:
                    st.caption("From")
                    vessel_from = st.date_input(
                        "From ",
                        value=default_from,
                        key="yvm_vessel_from",
                        label_visibility="collapsed",
                    )
                with vessel_dates[1]:
                    st.caption("To")
                    vessel_to = st.date_input(
                        "To ",
                        value=default_to,
                        key="yvm_vessel_to",
                        label_visibility="collapsed",
                    )
                st.caption("Search")
                vessel_search = st.text_input(
                    "Shuttle / Vessel",
                    key="yvm_vessel_search",
                    label_visibility="collapsed",
                    placeholder="Shuttle / Vessel",
                )
                st.markdown("</div>", unsafe_allow_html=True)
            filtered_vessel_df = _filter_table(
                vessel_df,
                vessel_from,
                vessel_to,
                vessel_search,
                ["Shuttle No", "Vessel Name"],
            )
            vessel_selection = _render_selection_table(
                filtered_vessel_df,
                "Vessel transactions",
                "yvm_selected_vessel",
                "yvm_vessel",
                vessel_column_config,
                height=280,
        )

        with fso_col:
            st.markdown('<p class="yvm-subheader">FSO transactions</p>', unsafe_allow_html=True)
            with st.container():
                st.markdown('<div class="filter-box">', unsafe_allow_html=True)
                fso_dates = st.columns(2)
                with fso_dates[0]:
                    st.caption("From")
                    fso_from = st.date_input(
                        "From  ",
                        value=default_from,
                        key="yvm_fso_from",
                        label_visibility="collapsed",
                    )
                with fso_dates[1]:
                    st.caption("To")
                    fso_to = st.date_input(
                        "To  ",
                        value=default_to,
                        key="yvm_fso_to",
                        label_visibility="collapsed",
                    )
                st.caption("Search")
                fso_search = st.text_input(
                    "Shuttle / Vessel ",
                    key="yvm_fso_search",
                    label_visibility="collapsed",
                    placeholder="Shuttle / Vessel",
                )
                st.markdown("</div>", unsafe_allow_html=True)
            filtered_fso_df = _filter_table(fso_df, fso_from, fso_to, fso_search, ["Shuttle No", "Vessel Name"])
            fso_selection = _render_selection_table(
                filtered_fso_df,
                "FSO transactions",
                "yvm_selected_fso",
                "yvm_fso",
                fso_column_config,
                height=280,
            )

        st.markdown("</div>", unsafe_allow_html=True)

        total_selected = len(yade_selection) + len(vessel_selection) + len(fso_selection)
        selection_cols = st.columns(3)
        selection_cols[0].metric("Yade selected", len(yade_selection))
        selection_cols[1].metric("Vessel selected", len(vessel_selection))
        selection_cols[2].metric("FSO selected", len(fso_selection))

        with map_button_area:
            map_clicked = st.button(
                "MAP selected transactions",
                type="primary",
                use_container_width=True,
                disabled=total_selected == 0,
            )
        if map_clicked:
            def _sum_selection(ids: set[int], lookup: Dict[int, Dict[str, Any]], field: str) -> float:
                total = 0.0
                for rec_id in ids:
                    rec = lookup.get(rec_id)
                    if not rec:
                        continue
                    try:
                        total += abs(float(rec.get(field) or 0.0))
                    except Exception:
                        continue
                return round(total, 2)

            payload = {
                "yade_ids": sorted(yade_selection),
                "vessel_ids": sorted(vessel_selection),
                "fso_ids": sorted(fso_selection),
                "yade_dispatch": _sum_selection(yade_selection, yade_lookup, "Net Offloaded"),
                "vessel_receipt": _sum_selection(vessel_selection, vessel_lookup, "Net Receipt/Dispatch"),
                "fso_receipt": _sum_selection(fso_selection, fso_lookup, "Qty Received"),
            }
            st.session_state["yvm_pending_payload"] = payload
            st.session_state["yvm_selected_yade"] = set()
            st.session_state["yvm_selected_vessel"] = set()
            st.session_state["yvm_selected_fso"] = set()
            st.session_state["yvm_revision"] = st.session_state.get("yvm_revision", 0) + 1
            st.success("Selection moved to Comparison tab. Provide the S.No, date, and remarks to complete the mapping.")

    with comparison_tab:
        st.markdown("#### Comparison")
        pending_payload = st.session_state.get("yvm_pending_payload")
        stored_rows: List[Dict[str, Any]] = st.session_state.get("yvm_records", [])
        comparison_df = _comparison_dataframe(stored_rows)
        next_s_no = (max((row["s_no"] for row in stored_rows), default=0) + 1) if stored_rows else 1
        delete_target = st.session_state.get("yvm_delete_target")

        def _remove_mapping_record(target_row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
            """Remove a stored mapping row and return it if found."""
            if not target_row:
                return None
            records = st.session_state.get("yvm_records", [])
            record_id = target_row.get("record_id")
            s_no = target_row.get("s_no")
            date_val = target_row.get("date")

            removed: Optional[Dict[str, Any]] = None
            remaining: List[Dict[str, Any]] = []

            for row in records:
                match = False
                if record_id and row.get("record_id") == record_id:
                    match = True
                elif not record_id and row.get("s_no") == s_no and row.get("date") == date_val:
                    match = True

                if match and removed is None:
                    removed = row
                    continue
                remaining.append(row)

            st.session_state["yvm_records"] = remaining
            if removed:
                try:
                    with get_session() as log_session:
                        SecurityManager.log_audit(
                            log_session,
                            user.get("username", "unknown"),
                            "DELETE",
                            resource_type="YadeVesselMapping",
                            resource_id=str(removed.get("record_id") or removed.get("s_no")),
                            details=f"Deleted Yade-Vessel mapping row S.No {removed.get('s_no')} dated {removed.get('date')}",
                            user_id=user.get("id"),
                            location_id=active_location_id,
                        )
                except Exception:
                    log_warning("Failed to log Yade-Vessel mapping deletion", exc_info=True)
            return removed

        if delete_target:
            target_date = delete_target.get("date")
            if hasattr(target_date, "strftime"):
                date_text = target_date.strftime("%Y-%m-%d")
            else:
                date_text = str(target_date or "")
            st.warning(
                f"Confirm deletion of mapping row **S.No {delete_target.get('s_no')}** dated "
                f"{date_text}?"
            )
            confirm_cols = st.columns(2)
            if confirm_cols[0].button("Yes, delete mapping", key="yvm_confirm_delete"):
                removed_row = _remove_mapping_record(delete_target)
                st.session_state["yvm_delete_target"] = None
                if removed_row:
                    st.success("Mapping row deleted.")
                else:
                    st.info("Row already deleted.")
                _st_safe_rerun()
            if confirm_cols[1].button("Cancel", key="yvm_cancel_delete"):
                st.session_state["yvm_delete_target"] = None
                _st_safe_rerun()

        download_cols = st.columns(4)
        csv_data = comparison_df.to_csv(index=False).encode("utf-8") if not comparison_df.empty else "".encode()
        xlsx_bytes = BytesIO()
        if not comparison_df.empty:
            with pd.ExcelWriter(xlsx_bytes, engine="xlsxwriter") as writer:
                comparison_df.to_excel(writer, index=False, sheet_name="Mapping")
            xlsx_bytes.seek(0)
        pdf_bytes = _generate_mapping_pdf(comparison_df, location_name, user.get("username", "")) if not comparison_df.empty else b""

        download_cols[0].download_button(
            "📥 CSV",
            data=csv_data if csv_data else "No data",
            file_name="yade_vessel_mapping.csv",
            mime="text/csv",
            use_container_width=True,
            disabled=comparison_df.empty,
        )
        download_cols[1].download_button(
            "📥 XLSX",
            data=xlsx_bytes.getvalue() if not comparison_df.empty else b"",
            file_name="yade_vessel_mapping.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
            disabled=comparison_df.empty,
        )
        download_cols[2].download_button(
            "📥 PDF",
            data=pdf_bytes or b"",
            file_name="yade_vessel_mapping.pdf",
            mime="application/pdf",
            use_container_width=True,
            disabled=comparison_df.empty,
        )
        if download_cols[3].button("👁️ View PDF", use_container_width=True, disabled=comparison_df.empty):
            if pdf_bytes:
                encoded_pdf = base64.b64encode(pdf_bytes).decode("utf-8")
                components.html(
                    f"""
                    <script>
                        const pdfWindow = window.open("");
                        pdfWindow.document.write('<iframe width="100%" height="100%" src="data:application/pdf;base64,{encoded_pdf}"></iframe>');
                    </script>
                    """,
                    height=0,
                )

        if pending_payload:
            st.info("Mapping selection received. Provide the next available S.No and date, then save to lock it in.")
            metric_cols = st.columns(3)
            metric_cols[0].metric("Yade Dispatch (bbls)", f"{pending_payload['yade_dispatch']:,.2f}")
            delta_v = pending_payload["vessel_receipt"] - pending_payload["yade_dispatch"]
            metric_cols[1].metric(
                "Vessel Receipt (bbls)",
                f"{pending_payload['vessel_receipt']:,.2f}",
                delta=f"{delta_v:,.2f} vs YADE",
            )
            delta_f = pending_payload["fso_receipt"] - pending_payload["vessel_receipt"]
            metric_cols[2].metric(
                "FSO Receipt (bbls)",
                f"{pending_payload['fso_receipt']:,.2f}",
                delta=f"{delta_f:,.2f} vs Vessel",
            )

            with st.form("yvm_finalize_mapping"):
                form_cols = st.columns([0.4, 0.5, 1.6])
                with form_cols[0]:
                    st.caption("Next S.No")
                    s_no_value = st.number_input(
                        "Next available S.No",
                        min_value=1,
                        value=next_s_no,
                        step=1,
                        label_visibility="collapsed",
                    )
                with form_cols[1]:
                    st.caption("Date")
                    mapping_date = st.date_input(
                        "Date",
                        value=date.today(),
                        label_visibility="collapsed",
                    )
                with form_cols[2]:
                    st.caption("Remarks")
                    remarks_value = st.text_input(
                        "Remarks",
                        placeholder="Add remarks (optional)",
                        label_visibility="collapsed",
                    )
                submitted = st.form_submit_button("Save comparison row", use_container_width=True)

            if st.button("Discard pending selection", type="secondary", key="yvm_discard_pending"):
                st.session_state["yvm_pending_payload"] = None
                _st_safe_rerun()

            if submitted:
                record = {
                    "record_id": str(uuid4()),
                    "s_no": int(s_no_value),
                    "date": mapping_date,
                    "yade_dispatch": pending_payload["yade_dispatch"],
                    "vessel_receipt": pending_payload["vessel_receipt"],
                    "diff_y_vs_v": round(pending_payload["vessel_receipt"] - pending_payload["yade_dispatch"], 2),
                    "fso_receipt": pending_payload["fso_receipt"],
                    "diff_v_vs_tt": round(pending_payload["fso_receipt"] - pending_payload["vessel_receipt"], 2),
                    "remarks": (remarks_value or "").strip(),
                    "source_ids": {
                        "yade_ids": pending_payload["yade_ids"],
                        "vessel_ids": pending_payload["vessel_ids"],
                        "fso_ids": pending_payload["fso_ids"],
                    },
                }
                st.session_state["yvm_records"].append(record)
                st.session_state["yvm_pending_payload"] = None
                st.success("Comparison row saved.")
                _st_safe_rerun()
        else:
            st.caption("No pending selection from the Mapping tab.")

        st.markdown("##### Saved mappings")
        if not stored_rows:
            st.info("No comparison rows captured yet.")
        else:
            st.markdown(
                """
                <style>
                .yvm-table-wrapper {
                    border: 1px solid #dfe3e8;
                    border-radius: 8px;
                    margin-top: 0.2rem;
                    background: #fff;
                }
                .yvm-table-header {
                    background: #f5f7fb;
                    border-bottom: 1px solid #dfe3e8;
                    padding: 0.15rem 0.15rem;
                    font-weight: 600;
                    font-size: 0.82rem;
                }
                .yvm-table-body {
                    max-height: 340px;
                    overflow-y: auto;
                }
                .yvm-table-row {
                    border-bottom: 1px solid #eef1f5;
                    padding: 0.05rem 0.15rem;
                }
                .yvm-table-row:last-child {
                    border-bottom: none;
                }
                .yvm-table-row:nth-child(even) {
                    background: #fbfcff;
                }
                .yvm-compare .yvm-table-row div[data-testid="column"] {
                    padding: 0 0.2rem !important;
                }
                .yvm-compare .yvm-table-row .markdown-text-container {
                    margin: -0.05rem 0 !important;
                    line-height: 1.15;
                }
                .yvm-compare .yvm-table-body button {
                    padding: 0.15rem 0.35rem;
                }
                </style>
                <div class="yvm-table-wrapper yvm-mapping yvm-compare">
                """,
                unsafe_allow_html=True,
            )
            column_widths = [0.7, 1.0, 1.2, 1.2, 1.1, 1.1, 1.1, 1.3, 0.5]
            headers = [
                "S.No",
                "Date",
                "Yade Dispatch (bbls)",
                "Vessel Receipt (bbls)",
                "Difference Y vs V",
                "FSO Receipt (bbls)",
                "Difference V vs TT",
                "Remarks",
                "Actions",
            ]

            st.markdown('<div class="yvm-table-header">', unsafe_allow_html=True)
            header_cols = st.columns(column_widths)
            for col, label in zip(header_cols, headers):
                col.markdown(f"**{label}**")
            st.markdown("</div>", unsafe_allow_html=True)

            st.markdown('<div class="yvm-table-body">', unsafe_allow_html=True)
            sorted_rows = sorted(stored_rows, key=lambda row: (row["s_no"], row["date"]))
            for idx, row_data in enumerate(sorted_rows):
                st.markdown('<div class="yvm-table-row">', unsafe_allow_html=True)
                row_cols = st.columns(column_widths)
                row_cols[0].markdown(str(row_data["s_no"]))
                row_cols[1].markdown(row_data["date"].strftime("%Y-%m-%d"))
                row_cols[2].markdown(f"{row_data['yade_dispatch']:,.2f}")
                row_cols[3].markdown(f"{row_data['vessel_receipt']:,.2f}")
                row_cols[4].markdown(f"{row_data['diff_y_vs_v']:,.2f}")
                row_cols[5].markdown(f"{row_data['fso_receipt']:,.2f}")
                row_cols[6].markdown(f"{row_data['diff_v_vs_tt']:,.2f}")
                row_cols[7].markdown(row_data.get("remarks") or "�")
                row_id = row_data.get("record_id") or f"{row_data['s_no']}_{row_data['date']}_{idx}"
                if can_delete_mapping_rows:
                    if row_cols[8].button("🗑️", key=f"yvm_remove_{row_id}", help="Request deletion"):
                        st.session_state["yvm_delete_target"] = row_data.copy()
                        _st_safe_rerun()
                else:
                    row_cols[8].markdown("�")
                st.markdown("</div>", unsafe_allow_html=True)
            st.markdown("</div></div>", unsafe_allow_html=True)

# ========================= FSO-OPERATIONS PAGE =========================
elif page == "FSO-Operations":
    header("FSO-Operations")
    
    # Check Admin-IT access restriction
    if st.session_state.get("auth_user", {}).get("role") == "admin-it":
        st.error("🚫 Access Denied: Admin-IT users do not have access to operational pages.")
        st.stop()
    
    try:
        _user_role = st.session_state.get("auth_user", {}).get("role")
        _loc_id = st.session_state.get("active_location_id")
        if _user_role not in ["admin-operations", "manager"] and _loc_id:
            from location_config import LocationConfig
            with get_session() as _s:
                _cfg = LocationConfig.get_config(_s, _loc_id)
            if _cfg.get("page_access", {}).get("FSO-Operations") is False:
                st.caption("FSO-Operations Access: **? Denied**")
                st.stop()
    except Exception:
        pass
    
    from datetime import time as dt_time, datetime, date, timedelta
    import pandas as pd
    import re
    from html import escape
    from reportlab.lib.pagesizes import A4, landscape
    from reportlab.lib import colors
    from reportlab.lib.units import cm
    from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.enums import TA_CENTER
    from io import BytesIO
    import base64
    from models import FSOOperation, Vessel, LocationVessel
    
    # ============ HELPER FUNCTIONS ============
    
    def convert_to_time_object(time_value):
        """Convert various time formats to Python time object"""
        if isinstance(time_value, dt_time):
            return time_value
        elif isinstance(time_value, str):
            try:
                parts = time_value.split(':')
                hour = int(parts[0])
                minute = int(parts[1]) if len(parts) > 1 else 0
                second = int(parts[2]) if len(parts) > 2 else 0
                return dt_time(hour, minute, second)
            except:
                raise ValueError(f"Invalid time string format: {time_value}")
        elif isinstance(time_value, datetime):
            return time_value.time()
        else:
            raise TypeError(f"Cannot convert {type(time_value)} to time object")
    
    def generate_fso_pdf(
        df,
        fso_vessel,
        date_from,
        date_to,
        total_receipts,
        total_exports,
        total_water_in,
        total_water_out,
        total_variance,
        net_water_value,
        loss_gain_value,
        total_entries,
        username,
    ):
        """Generate FSO OTR PDF report with enhanced formatting"""
        buffer = BytesIO()

        df = df.copy()
        if not df.empty:
            sort_key = pd.to_datetime(
                df["Date"].astype(str).str.strip() + " " + df["Time"].astype(str).str.strip(),
                errors="coerce",
            )
            date_key = pd.to_datetime(df["Date"], errors="coerce")
            sort_key = sort_key.fillna(date_key)
            df = (
                df.assign(_sort_key=sort_key)
                .sort_values("_sort_key", ascending=True)
                .drop(columns="_sort_key")
                .reset_index(drop=True)
            )
        
        # Create document with 0.5cm margins
        doc = SimpleDocTemplate(
            buffer, 
            pagesize=landscape(A4),
            leftMargin=0.5*cm,
            rightMargin=0.5*cm,
            topMargin=0.5*cm,
            bottomMargin=0.5*cm
        )
        
        elements = []
        styles = getSampleStyleSheet()
        
        # Custom styles
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=16,
            textColor=colors.HexColor('#1f4788'),
            spaceAfter=8,
            alignment=TA_CENTER,
            fontName='Helvetica-Bold'
        )
        
        subtitle_style = ParagraphStyle(
            'CustomSubtitle',
            parent=styles['Normal'],
            fontSize=10,
            textColor=colors.HexColor('#666666'),
            spaceAfter=6,
            alignment=TA_CENTER
        )
        
        # Title
        title = Paragraph(f"<b>FSO OUT-TURN REPORT</b><br/><font size=14>{fso_vessel}</font>", title_style)
        elements.append(title)
        elements.append(Spacer(1, 0.3*cm))
        
        # Subtitle
        subtitle = Paragraph(f"Period: <b>{date_from}</b> to <b>{date_to}</b><br/>Generated: {datetime.now().strftime('%d-%b-%Y %H:%M')}", subtitle_style)
        elements.append(subtitle)
        elements.append(Spacer(1, 0.4*cm))
        
        # Calculate available width (page width minus margins)
        page_width = landscape(A4)[0] - (1.0*cm)  # 28.7cm usable width for landscape A4
        
        # Define total table width to match summary table
        table_width = page_width
        
        # Calculate column widths proportionally
        # Total of 14 columns - distribute width proportionally
        col_widths = [
            table_width * 0.07,   # Date (7%)
            table_width * 0.045,  # Time (4.5%)
            table_width * 0.06,   # Shuttle (6%)
            table_width * 0.115,  # Vessel (11.5%)
            table_width * 0.05,   # Operation (5%)
            table_width * 0.065,  # Opening Stock (6.5%)
            table_width * 0.055,  # Opening Water (5.5%)
            table_width * 0.065,  # Closing Stock (6.5%)
            table_width * 0.055,  # Closing Water (5.5%)
            table_width * 0.065,  # Net R/E (6.5%)
            table_width * 0.055,  # Net Water (5.5%)
            table_width * 0.065,  # Vessel Qty (6.5%)
            table_width * 0.05,   # Variance (5%)
            table_width * 0.295   # Remarks (29.5%)
        ]
        
        # Verify total width matches (should be 100% = 1.0)
        # Sum of percentages: 7+4.5+6+11.5+5+6.5+5.5+6.5+5.5+6.5+5.5+6.5+5+29.5 = 110.5 ? adjust to 100
        
        # Corrected proportions (total = 100%)
        col_widths = [
            table_width * 0.07,   # Date
            table_width * 0.04,   # Time
            table_width * 0.06,   # Shuttle
            table_width * 0.11,   # Vessel
            table_width * 0.09,   # Operation
            table_width * 0.06,   # Opening Stock
            table_width * 0.055,  # Opening Water
            table_width * 0.06,   # Closing Stock
            table_width * 0.055,  # Closing Water
            table_width * 0.06,   # Net R/E
            table_width * 0.055,  # Net Water
            table_width * 0.06,   # Vessel Qty
            table_width * 0.05,   # Variance
            table_width * 0.17   # Remarks
        ]
        
        # Custom paragraph style for centered headers
        header_style = ParagraphStyle(
            'HeaderStyle',
            parent=styles['Normal'],
            fontSize=8,
            leading=9,
            alignment=TA_CENTER,
            fontName='Helvetica-Bold'
        )
        
        # Table headers with WHITE text, center-aligned
        table_data = [[
            Paragraph("<b><font color='white'>Date</font></b>", header_style),
            Paragraph("<b><font color='white'>Time</font></b>", header_style),
            Paragraph("<b><font color='white'>Shuttle<br/>No</font></b>", header_style),
            Paragraph("<b><font color='white'>Vessel<br/>Name</font></b>", header_style),
            Paragraph("<b><font color='white'>Operation</font></b>", header_style),
            Paragraph("<b><font color='white'>Opening<br/>Stock</font></b>", header_style),
            Paragraph("<b><font color='white'>Opening<br/>Water</font></b>", header_style),
            Paragraph("<b><font color='white'>Closing<br/>Stock</font></b>", header_style),
            Paragraph("<b><font color='white'>Closing<br/>Water</font></b>", header_style),
            Paragraph("<b><font color='white'>Net<br/>R/E</font></b>", header_style),
            Paragraph("<b><font color='white'>Net<br/>Water</font></b>", header_style),
            Paragraph("<b><font color='white'>Vessel<br/>Qty</font></b>", header_style),
            Paragraph("<b><font color='white'>Variance</font></b>", header_style),
            Paragraph("<b><font color='white'>Remarks</font></b>", header_style)
        ]]
        
        # Custom paragraph style for table cells (smaller font)
        cell_style = ParagraphStyle(
            'CellStyle',
            parent=styles['Normal'],
            fontSize=7,
            leading=8,
            alignment=TA_CENTER
        )
        
        # Add data rows
        for _, row in df.iterrows():
            operation_label = str(row.get("Operation", "")).strip().lower()
            variance_val = 0.0 if operation_label == "stock opening" else row["Variance"]
            if abs(variance_val) < 1.0:
                variance_color = '#28a745'
            elif abs(variance_val) < 10.0:
                variance_color = '#ffc107'
            else:
                variance_color = '#dc3545'
            
            table_data.append([
                Paragraph(row['Date'], cell_style),
                Paragraph(row['Time'], cell_style),
                Paragraph(str(row['Shuttle No']), cell_style),
                Paragraph(str(row['Vessel Name'])[:35], cell_style),
                Paragraph(str(row['Operation'])[:9], cell_style),
                Paragraph(f"{row['Opening Stock']:,.0f}", cell_style),
                Paragraph(f"{row['Opening Water']:,.0f}", cell_style),
                Paragraph(f"{row['Closing Stock']:,.0f}", cell_style),
                Paragraph(f"{row['Closing Water']:,.0f}", cell_style),
                Paragraph(f"<font color='{'#28a745' if row['Net R/E'] >= 0 else '#dc3545'}'>{row['Net R/E']:,.0f}</font>", header_style),
                Paragraph(f"{row['Net Water']:,.0f}", cell_style),
                Paragraph(f"{row['Vessel Qty']:,.0f}", cell_style),
                Paragraph(f"<font color='{variance_color}'><b>{variance_val:,.1f}</b></font>", header_style),
                Paragraph(str(row['Remarks'])[:80] if row['Remarks'] else "-", cell_style)
            ])
        
        # Create table with calculated widths
        table = Table(table_data, colWidths=col_widths, repeatRows=1)
        
        # Enhanced table styling with better contrast
        table.setStyle(TableStyle([
            # Header styling - Dark blue background with WHITE text
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1f4788')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 7),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 5),
            ('TOPPADDING', (0, 0), (-1, 0), 5),
            
            # Data rows styling
            ('BACKGROUND', (0, 1), (-1, -1), colors.HexColor('#f8f9fa')),
            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f8f9fa')]),
            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
            ('FONTSIZE', (0, 1), (-1, -1), 6),
            ('TEXTCOLOR', (0, 1), (-1, -1), colors.HexColor('#333333')),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
            ('BOX', (0, 0), (-1, -1), 1, colors.HexColor('#1f4788')),
            ('LEFTPADDING', (0, 0), (-1, -1), 2),
            ('RIGHTPADDING', (0, 0), (-1, -1), 2),
            ('TOPPADDING', (0, 1), (-1, -1), 3),
            ('BOTTOMPADDING', (0, 1), (-1, -1), 3),
        ]))
        
        elements.append(table)
        
        # Summary section - SAME WIDTH AS TABLE
        elements.append(Spacer(1, 0.4*cm))
        
        summary_style = ParagraphStyle(
            'Summary',
            parent=styles['Normal'],
            fontSize=8,
            textColor=colors.HexColor('#333333'),
            spaceAfter=3
        )
        
        summary_header_style = ParagraphStyle(
            'SummaryHeader',
            parent=styles['Normal'],
            fontSize=9,
            textColor=colors.white,
            fontName='Helvetica-Bold',
            alignment=TA_CENTER
        )
        
        elements.append(Paragraph("<b>SUMMARY STATISTICS</b>", summary_header_style))

        summary_data = [
            [
                Paragraph(f"<b>Total Receipts:</b> {total_receipts:,.2f} bbls", summary_style),
                Paragraph(f"<b>Total Exports:</b> {total_exports:,.2f} bbls", summary_style),
                Paragraph(f"<b>Water In:</b> {total_water_in:,.2f} bbls", summary_style),
                Paragraph(f"<b>Water Out:</b> {total_water_out:,.2f} bbls", summary_style),
            ],
            [
                Paragraph(f"<b>Net Water:</b> {net_water_value:,.2f} bbls", summary_style),
                Paragraph(
                    f"<b>Loss / Gain:</b> "
                    f"<font color='{'#28a745' if loss_gain_value >= 0 else '#dc3545'}'><b>{loss_gain_value:,.2f} bbls</b></font>",
                    summary_style,
                ),
                Paragraph(f"<b>Total Variance:</b> <font color='{'#28a745' if abs(total_variance) < 10 else '#dc3545'}'>{total_variance:,.2f} bbls</font>", summary_style),
                Paragraph(f"<b>Total Entries:</b> {total_entries}", summary_style),
            ],
        ]
        
        # Create summary table with SAME WIDTH as main table
        summary_col_width = table_width / 4
        summary_table = Table(summary_data, colWidths=[summary_col_width] * 4)
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.white),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),
            ('FONTSIZE', (0, 0), (-1, -1), 8),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
            ('BOX', (0, 0), (-1, -1), 1, colors.HexColor('#1f4788')),
            ('LEFTPADDING', (0, 0), (-1, -1), 5),
            ('RIGHTPADDING', (0, 0), (-1, -1), 5),
            ('TOPPADDING', (0, 0), (-1, -1), 4),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 4),
        ]))
        
        elements.append(summary_table)
        
        # Footer
        elements.append(Spacer(1, 0.3*cm))
        footer_text = f"<font size=7 color='#666666'>Generated by: {username} | OTMS - Oil Terminal Management System | {datetime.now().strftime('%d-%b-%Y %H:%M:%S')}</font>"
        elements.append(Paragraph(footer_text, subtitle_style))
        
        doc.build(elements)
        pdf_data = buffer.getvalue()
        buffer.close()
        
        return pdf_data
    
    def generate_material_balance_pdf(df, fso_vessel, date_from, date_to, total_receipts, total_exports, total_loss_gain, username):
        """Generate Material Balance PDF report"""
        from reportlab.lib.pagesizes import A4, landscape
        from reportlab.lib import colors
        from reportlab.lib.units import cm
        from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.enums import TA_CENTER
        from io import BytesIO
        
        buffer = BytesIO()
        
        # Create document with 0.5cm margins
        doc = SimpleDocTemplate(
            buffer, 
            pagesize=landscape(A4),
            leftMargin=0.5*cm,
            rightMargin=0.5*cm,
            topMargin=0.5*cm,
            bottomMargin=0.5*cm
        )
        
        elements = []
        styles = getSampleStyleSheet()
        
        # Custom styles
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=16,
            textColor=colors.HexColor('#1f4788'),
            spaceAfter=8,
            alignment=TA_CENTER,
            fontName='Helvetica-Bold'
        )
        
        subtitle_style = ParagraphStyle(
            'CustomSubtitle',
            parent=styles['Normal'],
            fontSize=10,
            textColor=colors.HexColor('#666666'),
            spaceAfter=6,
            alignment=TA_CENTER
        )
        
        # Title
        title = Paragraph(f"<b>FSO MATERIAL BALANCE REPORT</b><br/><font size=14>{fso_vessel}</font>", title_style)
        elements.append(title)
        elements.append(Spacer(1, 0.3*cm))
        
        # Subtitle
        subtitle = Paragraph(f"Period: <b>{date_from}</b> to <b>{date_to}</b><br/>Generated: {datetime.now().strftime('%d-%b-%Y %H:%M')}", subtitle_style)
        elements.append(subtitle)
        elements.append(Spacer(1, 0.4*cm))
        
        # Calculate available width
        page_width = landscape(A4)[0] - (1.0*cm)
        table_width = page_width
        
        # Column widths (8 columns)
        col_widths = [
            table_width * 0.12,   # Date
            table_width * 0.13,   # Opening Stock
            table_width * 0.12,   # Opening Water
            table_width * 0.13,   # Receipts
            table_width * 0.13,   # Exports
            table_width * 0.13,   # Closing Stock
            table_width * 0.12,   # Closing Water
            table_width * 0.12    # Loss/Gain
        ]
        
        # Custom paragraph style for centered headers
        header_style = ParagraphStyle(
            'HeaderStyle',
            parent=styles['Normal'],
            fontSize=7,
            leading=9,
            alignment=TA_CENTER,
            fontName='Helvetica-Bold'
        )
        
        # Table headers
        table_data = [[
            Paragraph("<b><font color='white'>Date</font></b>", header_style),
            Paragraph("<b><font color='white'>Opening<br/>Stock</font></b>", header_style),
            Paragraph("<b><font color='white'>Opening<br/>Water</font></b>", header_style),
            Paragraph("<b><font color='white'>Receipts</font></b>", header_style),
            Paragraph("<b><font color='white'>Exports</font></b>", header_style),
            Paragraph("<b><font color='white'>Closing<br/>Stock</font></b>", header_style),
            Paragraph("<b><font color='white'>Closing<br/>Water</font></b>", header_style),
            Paragraph("<b><font color='white'>Loss/Gain</font></b>", header_style)
        ]]
        
        # Custom cell style
        cell_style = ParagraphStyle(
            'CellStyle',
            parent=styles['Normal'],
            fontSize=7,
            leading=9,
            alignment=TA_CENTER
        )
        
        # Add data rows
        for _, row in df.iterrows():
            loss_gain_val = row['Loss/Gain']
            loss_gain_color = '#28a745' if loss_gain_val >= 0 else '#dc3545'
            
            table_data.append([
                Paragraph(row['Date'], cell_style),
                Paragraph(f"{row['Opening Stock']:,.0f}", cell_style),
                Paragraph(f"{row['Opening Water']:,.0f}", cell_style),
                Paragraph(f"{row['Receipts']:,.0f}", cell_style),
                Paragraph(f"{row['Exports']:,.0f}", cell_style),
                Paragraph(f"{row['Closing Stock']:,.0f}", cell_style),
                Paragraph(f"{row['Closing Water']:,.0f}", cell_style),
                Paragraph(f"<font color='{loss_gain_color}'><b>{loss_gain_val:,.2f}</b></font>", cell_style)
            ])
        
        # Create table
        table = Table(table_data, colWidths=col_widths, repeatRows=1)
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1f4788')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 7),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 5),
            ('TOPPADDING', (0, 0), (-1, 0), 5),
            ('BACKGROUND', (0, 1), (-1, -1), colors.HexColor('#f8f9fa')),
            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f8f9fa')]),
            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
            ('FONTSIZE', (0, 1), (-1, -1), 7),
            ('TEXTCOLOR', (0, 1), (-1, -1), colors.HexColor('#333333')),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
            ('BOX', (0, 0), (-1, -1), 1, colors.HexColor('#1f4788')),
            ('LEFTPADDING', (0, 0), (-1, -1), 3),
            ('RIGHTPADDING', (0, 0), (-1, -1), 3),
            ('TOPPADDING', (0, 1), (-1, -1), 4),
            ('BOTTOMPADDING', (0, 1), (-1, -1), 4),
        ]))
        
        elements.append(table)
        
        # Summary section
        elements.append(Spacer(1, 0.4*cm))
        
        summary_style = ParagraphStyle(
            'Summary',
            parent=styles['Normal'],
            fontSize=8,
            textColor=colors.HexColor('#333333'),
            spaceAfter=3
        )
        
        summary_header_style = ParagraphStyle(
            'SummaryHeader',
            parent=styles['Normal'],
            fontSize=9,
            textColor=colors.white,
            fontName='Helvetica-Bold',
            alignment=TA_CENTER
        )
        
        loss_gain_status = "GAIN" if total_loss_gain >= 0 else "LOSS"
        loss_gain_color = '#28a745' if total_loss_gain >= 0 else '#dc3545'
        
        summary_data = [
            [
                Paragraph("<b>SUMMARY STATISTICS</b>", summary_header_style),
                "",
                "",
                ""
            ],
            [
                Paragraph(f"<b>Total Receipts:</b> {total_receipts:,.2f} bbls", summary_style),
                Paragraph(f"<b>Total Exports:</b> {total_exports:,.2f} bbls", summary_style),
                Paragraph(f"<b>Total Loss/Gain:</b> <font color='{loss_gain_color}'>{total_loss_gain:,.2f} bbls ({loss_gain_status})</font>", summary_style),
                Paragraph(f"<b>Total Days:</b> {len(df)}", summary_style)
            ],
            [
                Paragraph(f"<b>Net Movement:</b> {(total_receipts - total_exports):,.2f} bbls", summary_style),
                Paragraph(f"<b>Avg Receipt/Day:</b> {(total_receipts/len(df) if len(df) > 0 else 0):,.2f} bbls", summary_style),
                Paragraph(f"<b>Avg Export/Day:</b> {(total_exports/len(df) if len(df) > 0 else 0):,.2f} bbls", summary_style),
                Paragraph(f"<b>Loss/Gain %:</b> {(total_loss_gain/total_receipts*100 if total_receipts > 0 else 0):.3f}%", summary_style)
            ]
        ]
        
        summary_col_width = table_width / 4
        summary_table = Table(summary_data, colWidths=[summary_col_width] * 4)
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1f4788')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
            ('BACKGROUND', (0, 1), (-1, -1), colors.white),
            ('SPAN', (0, 0), (-1, 0)),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 9),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
            ('BOX', (0, 0), (-1, -1), 1, colors.HexColor('#1f4788')),
            ('LEFTPADDING', (0, 0), (-1, -1), 5),
            ('RIGHTPADDING', (0, 0), (-1, -1), 5),
            ('TOPPADDING', (0, 0), (-1, -1), 4),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 4),
        ]))
        
        elements.append(summary_table)
        
        # Footer
        elements.append(Spacer(1, 0.3*cm))
        footer_text = f"<font size=7 color='#666666'>Generated by: {username} | OTMS - Oil Terminal Management System | {datetime.now().strftime('%d-%b-%Y %H:%M:%S')}</font>"
        elements.append(Paragraph(footer_text, subtitle_style))
        
        doc.build(elements)
        pdf_data = buffer.getvalue()
        buffer.close()
        
        return pdf_data

    # ============ MAIN CODE ============
    
    user = st.session_state.get("auth_user")
    
    if not user:
        st.error("Please login to access this page")
        st.stop()
    
    # ========== LOCATION ACCESS CHECK ==========
    active_location_id = st.session_state.get("active_location_id")
    if not active_location_id:
        st.error("No active location selected")
        st.stop()
    
    # ========== CHECK PERMISSIONS ==========
    from permission_manager import PermissionManager
    from fso_config import FSOConfig
    
    with get_session() as s:
        from location_manager import LocationManager
        from models import Location
        
        loc = LocationManager.get_location_by_id(s, active_location_id)
        if not loc:
            st.error("? Location not found.")
            st.stop()
        
        # Check if FSO-Operations is allowed
        if not PermissionManager.can_access_feature(s, active_location_id, "fso_operations", user["role"]):
            st.error("🚫 **Access Denied**")
            st.warning(f"**FSO-Operations** is not available at **{loc.name}**")
            
            allowed_locs = PermissionManager.get_allowed_locations_for_feature(s, "fso_operations")
            if allowed_locs:
                st.info(f"? This feature is available at: **{', '.join(allowed_locs)}**")
            
            st.markdown("---")
            st.caption(f"Current Location: **{loc.name} ({loc.code})**")
            st.caption("FSO-Operations Access: **? Denied**")
            st.stop()
        
        can_make_entries = PermissionManager.can_make_entries(s, user["role"], active_location_id)
        # Only operators need supervisor approval for deletion
        can_delete_direct = user["role"].lower() in ["admin-operations", "supervisor"]
        can_delete_with_approval = user["role"].lower() == "operator"
    
    # ============ FSO VESSEL SELECTOR ============
    st.markdown("---")
    
    location_code = loc.code.upper()
    can_user_select_fso = FSOConfig.can_select_fso(user, location_code)
    
    if can_user_select_fso:
        all_fso_vessels = FSOConfig.get_all_fso_vessels()
        
        if "selected_fso_vessel" not in st.session_state:
            st.session_state.selected_fso_vessel = all_fso_vessels[0]
        
        col1, col2 = st.columns([0.7, 0.3])
        
        with col1:
            st.info(f"📍 **Active Location:** {loc.name} ({loc.code})")
        
        with col2:
            selected_fso = st.selectbox(
                "⛴️ Select FSO Vessel",
                options=all_fso_vessels,
                index=all_fso_vessels.index(st.session_state.selected_fso_vessel) if st.session_state.selected_fso_vessel in all_fso_vessels else 0,
                key="fso_vessel_selector"
            )
            st.session_state.selected_fso_vessel = selected_fso
    else:
        location_fso = FSOConfig.get_fso_for_location(location_code)
        
        if not location_fso:
            st.error(f"? No FSO vessel configured for {loc.name}")
            st.stop()
        
        selected_fso = location_fso[0]
        st.session_state.selected_fso_vessel = selected_fso
        
        col1, col2 = st.columns([0.7, 0.3])
        
        with col1:
            st.info(f"📍 **Active Location:** {loc.name} ({loc.code})")
        
        with col2:
            st.info(f"⛴️ **FSO Vessel:** {selected_fso}")
    
    st.markdown("---")
    st.success(f"? **Active FSO:** {st.session_state.selected_fso_vessel}")
    
    # ============ VESSEL DROPDOWN OPTIONS FOR OTR ============
    try:
        with get_session() as s:
            assigned_vessels_query = (
                s.query(Vessel)
                .join(LocationVessel, LocationVessel.vessel_id == Vessel.id)
                .filter(
                    LocationVessel.location_id == active_location_id,
                    LocationVessel.is_active == True,
                    Vessel.status == "ACTIVE",
                )
                .order_by(Vessel.name)
                .all()
            )
    except Exception as ex:
        st.error(f"? Failed to load vessels for this location: {ex}")
        assigned_vessels_query = []

    # Only names are needed for OTR entry
    vessel_name_options = [v.name for v in assigned_vessels_query] if assigned_vessels_query else []

    # ============ FSO-OPERATIONS ============
    # FSOOperation is already imported at the top of this page
    tab_otr, tab_material_balance = st.tabs(["🧾 OTR", "📊 Material Balance"])

    # ==================== TAB 1: OTR ====================
    with tab_otr:
        st.markdown(f"### 🧾 FSO Out-Turn Report - {st.session_state.selected_fso_vessel}")
        st.caption("Record vessel operations and stock movements")
        
        # ========== FILTERS ==========
        st.markdown("#### 🔎 Filters")
        
        filter_col1, filter_col2, filter_col3, filter_col4, filter_col5 = st.columns(5)
        
        with filter_col1:
            filter_date_from = st.date_input(
                "From Date",
                value=date.today() - timedelta(days=30),
                key="fso_otr_date_from"
            )
        
        with filter_col2:
            filter_date_to = st.date_input(
                "To Date",
                value=date.today(),
                key="fso_otr_date_to"
            )
        
        with filter_col3:
            filter_shuttle = st.text_input(
                "Shuttle No",
                placeholder="Search...",
                key="fso_otr_filter_shuttle"
            )
        
        with filter_col4:
            filter_vessel = st.text_input(
                "Vessel Name",
                placeholder="Search...",
                key="fso_otr_filter_vessel"
            )
        
        with filter_col5:
            filter_operation = st.selectbox(
                "Operation",
                ["All", "Receipt", "Export", "Stock Opening"],
                key="fso_otr_filter_operation"
            )
        
        st.markdown("---")
        
        # ========== ADD NEW ENTRY ==========
        if can_make_entries:
            with st.expander("? Add New Entry", expanded=False):
                with st.form("add_fso_entry_form"):
                    st.markdown(f"##### New FSO Entry - {st.session_state.selected_fso_vessel}")
                    
                    form_col1, form_col2, form_col3, form_col4 = st.columns(4)
                    
                    with form_col1:
                        entry_date = st.date_input("Date *", value=date.today(), key="fso_new_date")
                        entry_time_input = st.text_input(
                            "Time * (HH:MM)",
                            value=datetime.now().strftime("%H:%M"),
                            placeholder="HH:MM",
                            key="fso_new_time"
                        )
                        entry_shuttle = st.text_input("Shuttle No *", placeholder="SH-001", key="fso_new_shuttle")
                    
                    with form_col2:
                        # Vessel name from vessels assigned to this location
                        if vessel_name_options:
                            entry_vessel = st.selectbox(
                                "Vessel Name *",
                                options=vessel_name_options,
                                key="fso_new_vessel",
                            )
                        else:
                            # Fallback to manual entry if no vessels are assigned yet
                            entry_vessel = st.text_input(
                                "Vessel Name *",
                                placeholder="MT Vessel",
                                key="fso_new_vessel",
                            )
                            st.caption(
                                "No vessels assigned to this location. "
                                "Assign vessels in Asset ? Location Vessel Mapping to enable dropdown."
                            )

                        entry_operation = st.selectbox(
                            "Operation *",
                            ["Receipt", "Export", "Stock Opening"],
                            key="fso_new_operation",
                        )
                        entry_vessel_qty = st.number_input(
                            "Vessel Quantity (bbls)",
                            min_value=0.0,
                            step=0.01,
                            key="fso_new_vessel_qty",
                        )

                    
                    with form_col3:
                        entry_opening = st.number_input("Opening Stock (bbls) *", min_value=0.0, step=0.01, key="fso_new_opening")
                        entry_opening_water = st.number_input("Opening Water (bbls)", min_value=0.0, step=0.01, value=0.0, key="fso_new_opening_water")
                        entry_closing = st.number_input("Closing Stock (bbls) *", min_value=0.0, step=0.01, key="fso_new_closing")
                    
                    with form_col4:
                        entry_closing_water = st.number_input("Closing Water (bbls)", min_value=0.0, step=0.01, value=0.0, key="fso_new_closing_water")
                    
                    entry_remarks = st.text_area("Remarks", key="fso_new_remarks", max_chars=500)
                    
                    # Calculate values
                    net_stock = entry_closing - entry_opening
                    net_water = entry_closing_water - entry_opening_water
                    abs_net_stock = abs(net_stock)
                    variance = abs_net_stock - entry_vessel_qty if entry_vessel_qty > 0 else 0.0
                    
                    # Display calculations
                    calc_col1, calc_col2, calc_col3 = st.columns(3)
                    
                    with calc_col1:
                        if net_stock >= 0:
                            st.success(f"**Net Stock:** +{net_stock:,.2f} bbls")
                        else:
                            st.info(f"**Net Stock:** {net_stock:,.2f} bbls")
                    
                    with calc_col2:
                        if net_water >= 0:
                            st.success(f"**Net Water:** +{net_water:,.2f} bbls")
                        else:
                            st.info(f"**Net Water:** {net_water:,.2f} bbls")
                    
                    with calc_col3:
                        if abs(variance) < 1.0:
                            st.success(f"**Variance:** {variance:,.2f} bbls ?")
                        elif abs(variance) < 10.0:
                            st.warning(f"**Variance:** {variance:,.2f} bbls ⚠️")
                        else:
                            st.error(f"**Variance:** {variance:,.2f} bbls ?")
                    
                    submit_btn = st.form_submit_button("💾 Save Entry", type="primary", use_container_width=True)
                    
                    if submit_btn:
                        time_text = (entry_time_input or "").strip()
                        if not entry_shuttle.strip():
                            st.error("? Shuttle No is required")
                        elif not entry_vessel.strip():
                            st.error("? Vessel Name is required")
                        elif not time_text:
                            st.error("? Time is required")
                        else:
                            try:
                                entry_time_obj = convert_to_time_object(time_text)
                            except Exception:
                                st.error("? Enter time in HH:MM (24h) format")
                            else:
                                try:
                                    with get_session() as s:
                                        new_entry = FSOOperation(
                                            location_id=active_location_id,
                                            fso_vessel=st.session_state.selected_fso_vessel,
                                            date=entry_date,
                                            time=entry_time_obj,
                                            shuttle_no=entry_shuttle.strip(),
                                            vessel_name=entry_vessel.strip(),
                                            operation=entry_operation,
                                            opening_stock=float(entry_opening),
                                            opening_water=float(entry_opening_water),
                                            closing_stock=float(entry_closing),
                                            closing_water=float(entry_closing_water),
                                            net_receipt_dispatch=float(net_stock),
                                            net_water=float(net_water),
                                            vessel_quantity=float(entry_vessel_qty) if entry_vessel_qty > 0 else None,
                                            variance=float(variance) if entry_vessel_qty > 0 else None,
                                            remarks=entry_remarks.strip() if entry_remarks else None,
                                            created_by=user["username"],
                                            created_at=datetime.now(),
                                        )
                                        
                                        s.add(new_entry)
                                        # Ensure ID is generated before audit logging
                                        s.flush()
                                        
                                        from security import SecurityManager
                                        SecurityManager.log_audit(
                                            s,
                                            user["username"],
                                            "CREATE",
                                            resource_type="FSOOperation",
                                            resource_id=str(new_entry.id),
                                            location_id=active_location_id,
                                            details=f"FSO: {st.session_state.selected_fso_vessel}, Vessel: {entry_vessel}",
                                            user_id=user.get("id"),
                                        )
                                        s.commit()
                                        new_id = new_entry.id
                                    st.success(f"? Entry saved! ID: {new_id}")
                                    st.balloons()
                                    import time
                                    time.sleep(1)
                                    _st_safe_rerun()
                            
                                except Exception as ex:
                                    st.error(f"? Failed to save: {ex}")
                                    import traceback
                                    with st.expander("⚠️ Error Details"):
                                        st.code(traceback.format_exc())
        else:
            st.info("ℹ️ You don't have permission to add entries")
        
        st.markdown("---")

        
        # ========== LOAD AND DISPLAY DATA ==========
        try:
            with get_session() as s:
                query = s.query(FSOOperation).filter(
                    FSOOperation.location_id == active_location_id,
                    FSOOperation.fso_vessel == st.session_state.selected_fso_vessel,
                    FSOOperation.date >= filter_date_from,
                    FSOOperation.date <= filter_date_to
                )
                
                if filter_shuttle:
                    query = query.filter(FSOOperation.shuttle_no.contains(filter_shuttle))
                
                if filter_vessel:
                    query = query.filter(FSOOperation.vessel_name.contains(filter_vessel))
                
                if filter_operation != "All":
                    query = query.filter(FSOOperation.operation == filter_operation)
                
                entries = query.order_by(FSOOperation.date.desc(), FSOOperation.time.desc()).all()
            
            if not entries:
                st.info(f"ℹ️ No entries found for **{st.session_state.selected_fso_vessel}**. Add your first entry above!")
            else:
                st.markdown(f"#### ⛴️ FSO Entries ({len(entries)} records)")
                
                # Create DataFrame for full data (used in PDF)
                data = []
                for entry in entries:
                    try:
                        if isinstance(entry.time, dt_time):
                            time_str = entry.time.strftime("%H:%M")
                        elif isinstance(entry.time, str):
                            time_str = entry.time
                        else:
                            time_str = str(entry.time)
                    except:
                        time_str = "N/A"
                    
                    vessel_qty = float(entry.vessel_quantity or 0.0)
                    net_re = float(entry.net_receipt_dispatch or 0.0)
                    display_variance = abs(net_re) - vessel_qty

                    data.append({
                        "ID": entry.id,
                        "Date": entry.date.strftime("%Y-%m-%d"),
                        "Time": time_str,
                        "Shuttle No": entry.shuttle_no,
                        "Vessel Name": entry.vessel_name,
                        "Operation": entry.operation,
                        "Opening Stock": entry.opening_stock,
                        "Opening Water": getattr(entry, 'opening_water', 0.0),
                        "Closing Stock": entry.closing_stock,
                        "Closing Water": getattr(entry, 'closing_water', 0.0),
                        "Net R/E": entry.net_receipt_dispatch,
                        "Net Water": getattr(entry, 'net_water', 0.0),
                        "Vessel Qty": vessel_qty,
                        "Variance": display_variance,
                        "Remarks": entry.remarks if entry.remarks else "",
                        "Created By": entry.created_by,
                        "Updated By": getattr(entry, 'updated_by', None),
                        "Updated At": getattr(entry, 'updated_at', None)
                    })

                df = pd.DataFrame(data)
                if not df.empty:
                    sort_key = pd.to_datetime(
                        df["Date"].astype(str).str.strip() + " " + df["Time"].astype(str).str.strip(),
                        errors="coerce",
                    )
                    date_key = pd.to_datetime(df["Date"], errors="coerce")
                    sort_key = sort_key.fillna(date_key)
                    df = (
                        df.assign(_sort_key=sort_key)
                        .sort_values("_sort_key", ascending=True)
                        .drop(columns="_sort_key")
                        .reset_index(drop=True)
                    )
            
                # ========== ULTRA-COMPACT TABLE DISPLAY ==========
                
                st.markdown("---")
                
                # Table header
                st.markdown("""
                    <style>
                    .compact-table {
                        font-size: 0.85rem;
                        line-height: 1.4;
                    }
                    .table-header {
                        background: #1f4788;
                        color: white;
                        font-weight: bold;
                        padding: 8px;
                        border-radius: 5px 5px 0 0;
                    }
                    .table-row {
                        border: 1px solid #dee2e6;
                        padding: 8px;
                        margin-bottom: 5px;
                        border-radius: 5px;
                        background: white;
                        transition: background 0.2s;
                    }
                    .table-row:hover {
                        background: #f8f9fa;
                    }
                    </style>
                """, unsafe_allow_html=True)
                
                # Display each entry as a single compact row
                for idx, row in df.iterrows():
                    entry_id = row["ID"]
                    
                    # Build variance badge
                    variance_val = row['Variance']
                    if abs(variance_val) < 1.0:
                        var_color = "#28a745"
                        var_icon = "?"
                    elif abs(variance_val) < 10.0:
                        var_color = "#ffc107"
                        var_icon = "⚠️"
                    else:
                        var_color = "#dc3545"
                        var_icon = "?"
                    
                    # Build net R/E color
                    net_val = row['Net R/E']
                    net_color = "#28a745" if net_val >= 0 else "#dc3545"
                    net_sign = "+" if net_val >= 0 else ""
                    
                    with st.container():
                        # Single row with all info
                        col1, col2, col3, col4, col5, col6, col7, col8, col9 = st.columns([1, 1.2, 1.5, 1, 1, 1, 1, 1.5, 0.8])
                        
                        with col1:
                            date_label = escape(str(row["Date"]))
                            creator_val = row.get("Created By")
                            if isinstance(creator_val, str):
                                creator_val = creator_val.strip()
                            creator_display = "-" if not creator_val else escape(str(creator_val))
                            updated_by = row.get("Updated By")
                            updated_at = row.get("Updated At")
                            badge_html = ""
                            if updated_by:
                                tooltip_ts = ""
                                if updated_at:
                                    try:
                                        tooltip_ts = pd.to_datetime(updated_at).strftime("%Y-%m-%d %H:%M")
                                    except Exception:
                                        tooltip_ts = str(updated_at)
                                tooltip_text = f"Edited by {updated_by}"
                                if tooltip_ts:
                                    tooltip_text += f" on {tooltip_ts}"
                                badge_html = f" <span style='color:#f59e0b;' title='{escape(tooltip_text, quote=True)}'>⏱️</span>"
                            user_line = f"By {creator_display}{badge_html}"
                            st.markdown(
                                f"**{date_label}**<br/><span style='color:#6b7280; font-size:0.75rem;'>{user_line}</span>",
                                unsafe_allow_html=True
                            )
                        
                        with col2:
                            st.markdown(f"**Shuttle:**<br/>{row['Shuttle No']}", unsafe_allow_html=True)
                        
                        with col3:
                            st.markdown(f"**Vessel:**<br/>{row['Vessel Name'][:25]}", unsafe_allow_html=True)
                        
                        with col4:
                            st.markdown(f"**Open:**<br/><span style='color: #666;'>{row['Opening Stock']:,.0f}</span>", unsafe_allow_html=True)
                        
                        with col5:
                            st.markdown(f"**Close:**<br/><span style='color: #666;'>{row['Closing Stock']:,.0f}</span>", unsafe_allow_html=True)
                        
                        with col6:
                            st.markdown(f"**Net R/E:**<br/><span style='color: {net_color}; font-weight: bold;'>{net_sign}{net_val:,.0f}</span>", unsafe_allow_html=True)
                        
                        with col7:
                            st.markdown(f"**Variance:**<br/><span style='color: {var_color}; font-weight: bold;'>{variance_val:,.1f} {var_icon}</span>", unsafe_allow_html=True)
                        
                        with col8:
                            if row['Remarks']:
                                st.markdown(f"**Remarks:**<br/><span style='color: #666; font-size: 0.8rem;'>{row['Remarks'][:40]}...</span>", unsafe_allow_html=True)
                            else:
                                st.markdown("**Remarks:**<br/><span style='color: #999;'>-</span>", unsafe_allow_html=True)
                        
                        with col9:
                            # Action buttons
                            btn_col1, btn_col2 = st.columns(2)
                            
                            with btn_col1:
                                if st.button("✏️", key=f"edit_fso_{entry_id}", help="Edit", use_container_width=True):
                                    allow_edit = True
                                    with get_session() as _lock_s:
                                        entry_obj = (
                                            _lock_s.query(FSOOperation)
                                            .filter(FSOOperation.id == entry_id)
                                            .one_or_none()
                                        )
                                        if entry_obj and _deny_edit_for_lock(
                                            entry_obj,
                                            "FSOOperation",
                                            f"{entry_obj.vessel_name or entry_obj.id}",
                                        ):
                                            allow_edit = False
                                    if allow_edit:
                                        st.session_state[f"editing_fso_{entry_id}"] = True
                                        _st_safe_rerun()
                            
                            with btn_col2:
                                if can_delete_direct or can_delete_with_approval:
                                    if st.button("🗑️", key=f"delete_fso_{entry_id}", help="Delete", use_container_width=True):
                                        st.session_state[f"confirm_delete_fso_{entry_id}"] = True
                                        _st_safe_rerun()
                        
                        # Edit form (expands below when clicked)
                        if st.session_state.get(f"editing_fso_{entry_id}", False):
                            st.markdown("---")
                            with st.form(f"edit_form_fso_{entry_id}"):
                                st.markdown("#### ✏️ Edit Entry")
                                
                                with get_session() as s:
                                    original_entry = s.query(FSOOperation).filter(FSOOperation.id == entry_id).first()

                                if original_entry and _deny_edit_for_lock(
                                    original_entry,
                                    "FSOOperation",
                                    f"{original_entry.vessel_name or entry_id}",
                                ):
                                    st.session_state.pop(f"editing_fso_{entry_id}", None)
                                    _st_safe_rerun()
                                
                                ecol1, ecol2, ecol3, ecol4 = st.columns(4)
                                
                                with ecol1:
                                    edit_date = st.date_input("Date", value=original_entry.date)
                                    try:
                                        if isinstance(original_entry.time, dt_time):
                                            time_val = original_entry.time
                                        else:
                                            time_val = convert_to_time_object(original_entry.time)
                                    except:
                                        time_val = datetime.now().time()
                                    
                                    edit_time = st.text_input(
                                        "Time (HH:MM)",
                                        value=time_val.strftime("%H:%M"),
                                        key=f"fso_edit_time_{entry_id}"
                                    )
                                    edit_shuttle = st.text_input("Shuttle No", value=original_entry.shuttle_no)
                                
                                with ecol2:
                                    edit_vessel = st.text_input("Vessel Name", value=original_entry.vessel_name)
                                    edit_operation = st.selectbox("Operation", ["Receipt", "Export", "Stock Opening"], 
                                                                 index=["Receipt", "Export", "Stock Opening"].index(original_entry.operation) if original_entry.operation in ["Receipt", "Export", "Stock Opening"] else 0)
                                    edit_vessel_qty = st.number_input("Vessel Qty", value=float(original_entry.vessel_quantity) if original_entry.vessel_quantity else 0.0)
                                
                                with ecol3:
                                    edit_opening = st.number_input("Opening Stock", value=float(original_entry.opening_stock))
                                    edit_opening_water = st.number_input("Opening Water", value=float(getattr(original_entry, 'opening_water', 0.0)))
                                    edit_closing = st.number_input("Closing Stock", value=float(original_entry.closing_stock))
                                
                                with ecol4:
                                    edit_closing_water = st.number_input("Closing Water", value=float(getattr(original_entry, 'closing_water', 0.0)))
                                
                                edit_remarks = st.text_area("Remarks", value=original_entry.remarks if original_entry.remarks else "")
                                
                                new_net_stock = edit_closing - edit_opening
                                new_net_water = edit_closing_water - edit_opening_water
                                new_variance = abs(new_net_stock) - edit_vessel_qty if edit_vessel_qty > 0 else 0.0
                                
                                st.info(f"Net Stock: {new_net_stock:,.2f} | Net Water: {new_net_water:,.2f} | Variance: {new_variance:,.2f}")
                                
                                save_col, cancel_col = st.columns(2)
                                
                                with save_col:
                                    if st.form_submit_button("💾 Save Changes", type="primary", use_container_width=True):
                                        time_text = (edit_time or "").strip()
                                        parsed_time = None
                                        if not time_text:
                                            st.error("? Time is required")
                                        else:
                                            try:
                                                parsed_time = convert_to_time_object(time_text)
                                            except Exception:
                                                st.error("? Enter time in HH:MM (24h) format")
                                        if parsed_time:
                                            try:
                                                with get_session() as s:
                                                    entry_to_update = s.query(FSOOperation).filter(FSOOperation.id == entry_id).first()
                                                    
                                                    entry_to_update.date = edit_date
                                                    entry_to_update.time = parsed_time
                                                    entry_to_update.shuttle_no = edit_shuttle
                                                    entry_to_update.vessel_name = edit_vessel
                                                    entry_to_update.operation = edit_operation
                                                    entry_to_update.opening_stock = float(edit_opening)
                                                    entry_to_update.opening_water = float(edit_opening_water)
                                                    entry_to_update.closing_stock = float(edit_closing)
                                                    entry_to_update.closing_water = float(edit_closing_water)
                                                    entry_to_update.net_receipt_dispatch = float(new_net_stock)
                                                    entry_to_update.net_water = float(new_net_water)
                                                    entry_to_update.vessel_quantity = float(edit_vessel_qty) if edit_vessel_qty > 0 else None
                                                    entry_to_update.variance = float(new_variance) if edit_vessel_qty > 0 else None
                                                    entry_to_update.remarks = edit_remarks.strip() if edit_remarks else None
                                                    entry_to_update.updated_by = user["username"]
                                                    entry_to_update.updated_at = datetime.now()
                                                    
                                                    s.commit()
                                                    
                                                    # ----------------------- Audit log for FSO operation update -----------------------
                                                    try:
                                                        from security import SecurityManager  # type: ignore
                                                        user_ctx = st.session_state.get("auth_user") or {}
                                                        username = user_ctx.get("username", "unknown")
                                                        user_id = user_ctx.get("id")
                                                        location_id = active_location_id
                                                        res_id = str(entry_to_update.id)
                                                        SecurityManager.log_audit(
                                                            None,
                                                            username,
                                                            "UPDATE",
                                                            resource_type="FSOOperation",
                                                            resource_id=res_id,
                                                            details=f"Updated FSO operation {res_id}",
                                                            user_id=user_id,
                                                            location_id=location_id,
                                                        )
                                                    except Exception:
                                                        pass
                                                    
                                                    st.success("? Entry updated!")
                                                    del st.session_state[f"editing_fso_{entry_id}"]
                                                    import time
                                                    time.sleep(1)
                                                    _st_safe_rerun()
                                            
                                            except Exception as ex:
                                                st.error(f"? Update failed: {ex}")
                                
                                with cancel_col:
                                    if st.form_submit_button("? Cancel", use_container_width=True):
                                        del st.session_state[f"editing_fso_{entry_id}"]
                                        _st_safe_rerun()
                        
                        # Delete confirmation (expands below when clicked)
                        if st.session_state.get(f"confirm_delete_fso_{entry_id}", False):
                            st.markdown("---")
                            st.warning("⚠️ **Confirm Delete**")
                            
                            def _execute_fso_delete(approver_label: str):
                                try:
                                    # Delete the entry and capture details before deletion
                                    with get_session() as s:
                                        entry_to_delete = s.query(FSOOperation).filter(FSOOperation.id == entry_id).first()
                                        del_details = ""
                                        if entry_to_delete:
                                            del_details = (
                                                f"{entry_to_delete.vessel_name or 'Unknown'} - {entry_to_delete.shuttle_no or ''}"
                                            )
                                            _archive_record_for_delete(
                                                s,
                                                entry_to_delete,
                                                "FSOOperation",
                                                reason=f"Marked FSO operation {del_details} for deletion. Approved by {approver_label}.",
                                                label=str(entry_id),
                                            )
                                        s.commit()
                                    TaskManager.complete_tasks_for_resource(
                                        "FSOOperation",
                                        entry_id,
                                        user.get("username", "unknown"),
                                        notes=f"Approved by {approver_label}",
                                    )
                                    st.success("? Entry deleted!")
                                    del st.session_state[f"confirm_delete_fso_{entry_id}"]
                                    import time

                                    time.sleep(1)
                                    _st_safe_rerun()
                                except Exception as ex:
                                    st.error(f"? Delete failed: {ex}")

                            if can_delete_direct:
                                st.write("Are you sure you want to delete this entry?")
                                del_col1, del_col2 = st.columns(2)

                                with del_col1:
                                    if st.button("🗑️ Yes, Delete", key=f"confirm_del_{entry_id}", type="primary", use_container_width=True):
                                        approver_name = user.get("username", "admin")
                                        _execute_fso_delete(f"{approver_name} ({user.get('role')})")

                                with del_col2:
                                    if st.button("? Cancel", key=f"cancel_del_{entry_id}", use_container_width=True):
                                        del st.session_state[f"confirm_delete_fso_{entry_id}"]
                                        _st_safe_rerun()

                            elif can_delete_with_approval:
                                remote_task = _render_remote_delete_request_ui(
                                    "FSOOperation",
                                    entry_id,
                                    f"FSO entry #{entry_id}",
                                    "FSO Operations",
                                    metadata={
                                        "date": row["Date"],
                                        "shuttle": row["Shuttle No"],
                                        "vessel": row["Vessel Name"],
                                    },
                                )
                                if remote_task and remote_task.get("status") == TaskStatus.APPROVED.value:
                                    approver_label = remote_task.get("approved_by") or "Supervisor"
                                    if st.button(
                                        "Delete with approved request",
                                        key=f"fso_remote_delete_{entry_id}",
                                        type="primary",
                                        use_container_width=True,
                                    ):
                                        _execute_fso_delete(f"{approver_label} (remote)")

                                st.write("Enter supervisor code to confirm deletion:")

                                with st.form(f"delete_confirm_fso_{entry_id}"):
                                    sup_username, sup_label = _supervisor_dropdown(
                                        "Supervisor",
                                        f"fso_delete_sup_{entry_id}",
                                        active_location_id,
                                    )
                                    supervisor_code = st.text_input("Supervisor Code", type="password")

                                    del_col1, del_col2 = st.columns(2)

                                    with del_col1:
                                        if st.form_submit_button("🗑️ Confirm Delete", type="primary", use_container_width=True):
                                            if not supervisor_code:
                                                st.error("Supervisor code is required.")
                                            elif not sup_username:
                                                st.error("No supervisor available for approval.")
                                            elif SecurityManager.verify_supervisor_code(supervisor_code, sup_username):
                                                label = sup_label or sup_username or "Supervisor"
                                                _execute_fso_delete(f"{label}")
                                            else:
                                                st.error("? Invalid supervisor code!")

                                    with del_col2:
                                        if st.form_submit_button("? Cancel", use_container_width=True):
                                            del st.session_state[f"confirm_delete_fso_{entry_id}"]
                                            _st_safe_rerun()
                        
                        st.markdown("---")
                
                # Summary statistics
                st.markdown("---")
                st.markdown("#### 📊 Summary")

                def _normalize_operation_value(value):
                    return (str(value).strip().lower()) if value else ""

                def _safe_float(value):
                    try:
                        return float(value or 0.0)
                    except (TypeError, ValueError):
                        return 0.0

                total_receipts = sum(
                    max(_safe_float(e.net_receipt_dispatch), 0.0)
                    for e in entries
                    if _normalize_operation_value(e.operation) == "receipt"
                )
                total_exports = sum(
                    abs(_safe_float(e.net_receipt_dispatch))
                    for e in entries
                    if _normalize_operation_value(e.operation) == "export"
                )
                total_water_in = sum(
                    _safe_float(getattr(e, 'net_water', 0.0))
                    for e in entries
                    if _safe_float(getattr(e, 'net_water', 0.0)) > 0
                )
                total_water_out = sum(
                    abs(_safe_float(getattr(e, 'net_water', 0.0)))
                    for e in entries
                    if _safe_float(getattr(e, 'net_water', 0.0)) < 0
                )
                loss_gain_value = sum(
                    _safe_float(e.net_receipt_dispatch)
                    for e in entries
                    if _normalize_operation_value(e.operation) == "stock opening"
                )
                net_water_value = total_water_in - total_water_out
                total_entries = len(entries)

                total_variance = 0.0
                for entry in entries:
                    if _normalize_operation_value(entry.operation) == "export":
                        continue
                    vessel_qty = _safe_float(entry.vessel_quantity)
                    net_val = _safe_float(entry.net_receipt_dispatch)
                    total_variance += abs(net_val) - vessel_qty

                row1_cols = st.columns(4)
                row1_cols[0].metric("Total Receipts", f"{total_receipts:,.2f} bbls")
                row1_cols[1].metric("Total Exports", f"{total_exports:,.2f} bbls")
                row1_cols[2].metric("Water In", f"{total_water_in:,.2f} bbls")
                row1_cols[3].metric("Water Out", f"{total_water_out:,.2f} bbls")

                row2_cols = st.columns(4)
                row2_cols[0].metric("Net Water", f"{net_water_value:,.2f} bbls")
                row2_cols[1].metric("Loss / Gain", f"{loss_gain_value:,.2f} bbls")
                variance_abs = abs(total_variance)
                variance_delta = "Good" if variance_abs < 1.0 else "OK" if variance_abs < 10.0 else "Check"
                row2_cols[2].metric("Total Variance", f"{total_variance:,.2f} bbls", delta=variance_delta)
                row2_cols[3].metric("Total Entries", f"{total_entries}")
                
                # Export options
                st.markdown("---")
                st.markdown("#### 📤 Export")
                
                export_col1, export_col2, export_col3, export_col4 = st.columns(4)
                
                with export_col1:
                    csv = df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="📥 Download CSV",
                        data=csv,
                        file_name=f"FSO_OTR_{st.session_state.selected_fso_vessel}_{date.today()}.csv",
                        mime="text/csv"
                    )
                
                with export_col2:
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        df.to_excel(writer, index=False, sheet_name='FSO OTR')
                    excel_data = output.getvalue()
                    
                    st.download_button(
                        label="⬇️ Download Excel",
                        data=excel_data,
                        file_name=f"FSO_OTR_{st.session_state.selected_fso_vessel}_{date.today()}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                
                with export_col3:
                    if st.button("📥 Download PDF", use_container_width=True):
                        try:
                            pdf_data = generate_fso_pdf(
                                df,
                                st.session_state.selected_fso_vessel,
                                filter_date_from.strftime("%d-%b-%Y"),
                                filter_date_to.strftime("%d-%b-%Y"),
                                total_receipts,
                                total_exports,
                                total_water_in,
                                total_water_out,
                                total_variance,
                                net_water_value,
                                loss_gain_value,
                                total_entries,
                                user["username"],
                            )
                            
                            st.download_button(
                                label="💾 Save PDF File",
                                data=pdf_data,
                                file_name=f"FSO_OTR_{st.session_state.selected_fso_vessel}_{date.today()}.pdf",
                                mime="application/pdf",
                                key="download_pdf_btn"
                            )
                        except Exception as ex:
                            st.error(f"? PDF generation failed: {ex}")
                
                with export_col4:
                    if st.button("👁️ View PDF", key="fso_otr_pdf_view", use_container_width=True):
                        try:
                            pdf_data = generate_fso_pdf(
                                df,
                                st.session_state.selected_fso_vessel,
                                filter_date_from.strftime("%d-%b-%Y"),
                                filter_date_to.strftime("%d-%b-%Y"),
                                total_receipts,
                                total_exports,
                                total_water_in,
                                total_water_out,
                                total_variance,
                                net_water_value,
                                loss_gain_value,
                                total_entries,
                                user["username"],
                            )
                            
                            # Encode to base64
                            base64_pdf = base64.b64encode(pdf_data).decode('utf-8')
                            
                            # JavaScript to open in new tab
                            pdf_html = f"""
                            <script>
                                var pdfWindow = window.open("");
                                pdfWindow.document.write(
                                    '<html><head><title>FSO OTR Report - {st.session_state.selected_fso_vessel}</title></head>' +
                                    '<body style="margin:0"><iframe width="100%" height="100%" src="data:application/pdf;base64,{base64_pdf}"></iframe></body></html>'
                                );
                            </script>
                            """
                            
                            import streamlit.components.v1 as components
                            components.html(pdf_html, height=0)
                            st.success("? PDF opened in new tab!")
                            
                        except Exception as ex:
                            st.error(f"? PDF generation failed: {ex}")
                            import traceback
                            with st.expander("⚠️ Error Details"):
                                st.code(traceback.format_exc())
        
        except Exception as ex:
            st.error(f"? Failed to load: {ex}")
            import traceback
            with st.expander("⚠️ Error Details"):
                st.code(traceback.format_exc())
    
    # ==================== TAB 2: MATERIAL BALANCE ====================
    with tab_material_balance:
        st.markdown(f"### 📊 FSO Material Balance - {st.session_state.selected_fso_vessel}")
        st.caption("Auto-calculated material balance (06:01 - 06:00) | Updates automatically when data is saved")

        # Determine full FSO data range (keeps opening/closing constant)
        with get_session() as s_bounds:
            from sqlalchemy import func as sa_func
            min_max = (
                s_bounds.query(sa_func.min(FSOOperation.date), sa_func.max(FSOOperation.date))
                .filter(
                    FSOOperation.location_id == active_location_id,
                    FSOOperation.fso_vessel == st.session_state.selected_fso_vessel,
                )
                .first()
            )
        min_fso_date, max_fso_date = (min_max or (None, None))
        if not min_fso_date or not max_fso_date:
            st.info("No FSO material balance data available yet for this vessel.")
            st.stop()

        default_fso_from = max(max_fso_date - timedelta(days=30), min_fso_date)
        default_fso_to = max_fso_date

        
        # Date range selector (for filtering display, not for calculation trigger)
        st.markdown("#### 📆 Display Period")
        
        mb_col1, mb_col2, mb_col3 = st.columns([1, 1, 2])
        
        with mb_col1:
            mb_date_from = st.date_input(
                "From Date",
                value=default_fso_from,
                min_value=min_fso_date,
                max_value=max_fso_date,
                key="mb_date_from"
            )
        
        with mb_col2:
            mb_date_to = st.date_input(
                "To Date",
                value=default_fso_to,
                min_value=min_fso_date,
                max_value=max_fso_date,
                key="mb_date_to"
            )

        if mb_date_from < min_fso_date:
            mb_date_from = min_fso_date
            st.session_state["mb_date_from"] = mb_date_from

        with mb_col3:
            st.info(f"📅 Showing: {mb_date_from.strftime('%d-%b-%Y')} to {mb_date_to.strftime('%d-%b-%Y')}")
        
        st.markdown("---")
        
        # AUTO-CALCULATE Material Balance (no button needed)
        try:
            with get_session() as s:
                # Fetch all entries for calculation
                # We need to fetch from a wider range to properly calculate 06:01-06:00 periods
                extended_date_from = min_fso_date - timedelta(days=1)  # Get previous day for 06:01 calculation
                extended_date_to = max_fso_date + timedelta(days=1)  # Get next day for 06:00 calculation
                
                all_entries = s.query(FSOOperation).filter(
                    FSOOperation.location_id == active_location_id,
                    FSOOperation.fso_vessel == st.session_state.selected_fso_vessel,
                    FSOOperation.date >= extended_date_from,
                    FSOOperation.date <= extended_date_to
                ).order_by(FSOOperation.date, FSOOperation.time).all()
            
            if not all_entries:
                st.warning("⚠️ No data available for material balance calculation.")
                st.info("ℹ️ Add entries in the **OTR** tab to see material balance here.")
            else:
                # Process material balance by date
                material_balance_data = []
                
                # Generate full date range for computation (filters will hide rows later)
                calc_start = min_fso_date
                calc_end = max_fso_date
                current_date = calc_start
                while current_date <= calc_end:
                    # Define period: 06:01 of current_date to 06:00 of next_date
                    period_start = datetime.combine(current_date, dt_time(6, 1))
                    period_end = datetime.combine(current_date + timedelta(days=1), dt_time(6, 0))
                    
                    # Get entries within this period
                    period_entries = []
                    for entry in all_entries:
                        try:
                            # Convert entry time to datetime
                            if isinstance(entry.time, dt_time):
                                entry_time = entry.time
                            else:
                                entry_time = convert_to_time_object(entry.time)
                            
                            entry_datetime = datetime.combine(entry.date, entry_time)
                            
                            if period_start <= entry_datetime <= period_end:
                                period_entries.append(entry)
                        except:
                            continue
                    
                    if not period_entries:
                        # No entries for this date, skip
                        current_date += timedelta(days=1)
                        continue
                    
                    # Sort period entries by datetime
                    period_entries.sort(key=lambda e: datetime.combine(
                        e.date, 
                        e.time if isinstance(e.time, dt_time) else convert_to_time_object(e.time)
                    ))
                    
                    # 1. OPENING STOCK & WATER - First entry of the period
                    first_entry = period_entries[0]
                    opening_stock = first_entry.opening_stock
                    opening_water = getattr(first_entry, 'opening_water', 0.0)
                    if getattr(first_entry, "operation", "") == "Stock Opening":
                        try:
                            opening_stock = float(first_entry.closing_stock or opening_stock or 0.0)
                        except Exception:
                            opening_stock = float(opening_stock or 0.0)
                        try:
                            opening_water = float(getattr(first_entry, 'closing_water', opening_water) or 0.0)
                        except Exception:
                            opening_water = float(opening_water or 0.0)
                    
                    # 2. RECEIPTS - Sum of Net R/E where operation is "Receipt"
                    receipts = sum(
                        e.net_receipt_dispatch 
                        for e in period_entries 
                        if e.operation == "Receipt" and e.net_receipt_dispatch > 0
                    )
                    
                    # 3. EXPORTS - Sum of absolute Net R/E where operation is "Export"
                    exports = sum(
                        abs(e.net_receipt_dispatch) 
                        for e in period_entries 
                        if e.operation == "Export" and e.net_receipt_dispatch < 0
                    )
                    
                    # 4. CLOSING STOCK & WATER - Last entry of the period
                    last_entry = period_entries[-1]
                    closing_stock = last_entry.closing_stock
                    closing_water = getattr(last_entry, 'closing_water', 0.0)
                    
                    # 5. LOSS/GAIN CALCULATION
                    # Find Stock Opening operation in this period
                    stock_opening_entries = [e for e in period_entries if e.operation == "Stock Opening"]
                    
                    if stock_opening_entries:
                        # Method 1: Stock Opening exists
                        stock_opening_entry = stock_opening_entries[0]
                        stock_opening_closing = stock_opening_entry.closing_stock
                        
                        # Find last entry BEFORE Stock Opening
                        try:
                            stock_opening_time = stock_opening_entry.time if isinstance(stock_opening_entry.time, dt_time) else convert_to_time_object(stock_opening_entry.time)
                            stock_opening_datetime = datetime.combine(stock_opening_entry.date, stock_opening_time)
                            
                            entries_before_opening = [
                                e for e in period_entries 
                                if datetime.combine(
                                    e.date, 
                                    e.time if isinstance(e.time, dt_time) else convert_to_time_object(e.time)
                                ) < stock_opening_datetime
                            ]
                            
                            if entries_before_opening:
                                last_before_opening = entries_before_opening[-1]
                                last_operation_closing = last_before_opening.closing_stock
                                
                                # Loss/Gain = Stock Opening Closing - Last Operation Closing
                                loss_gain = stock_opening_closing - last_operation_closing
                            else:
                                # No entries before Stock Opening, calculate from opening
                                loss_gain = stock_opening_closing - opening_stock
                        except:
                            loss_gain = 0.0
                    else:
                        # Method 2: No Stock Opening - Calculate from balance
                        # Loss/Gain = Closing - (Opening + Receipts - Exports)
                        theoretical_closing = opening_stock + receipts - exports
                        loss_gain = closing_stock - theoretical_closing
                    
                    # Add to material balance data
                    material_balance_data.append({
                        "Date": current_date.strftime("%Y-%m-%d"),
                        "Opening Stock": opening_stock,
                        "Opening Water": opening_water,
                        "Receipts": receipts,
                        "Exports": exports,
                        "Closing Stock": closing_stock,
                        "Closing Water": closing_water,
                        "Loss/Gain": loss_gain
                    })
                    
                    current_date += timedelta(days=1)
                
                if not material_balance_data:
                    st.warning("⚠️ No material balance data available for the selected period.")
                    st.info("ℹ️ Make sure entries exist between 06:01 and 06:00 for each day.")
                else:
                    # Create DataFrame for full range then apply view filters
                    mb_df_full = pd.DataFrame(material_balance_data)

                    # Cache the raw MB data so other dashboard sections (e.g. Utapate summary cards)
                    # can reuse the "Exports (bbls)" column without recomputing.
                    try:
                        mb_cache_df = mb_df_full.copy()
                        mb_cache_df["Date"] = pd.to_datetime(mb_cache_df["Date"], errors="coerce").dt.date
                        mb_cache_df["Location"] = getattr(loc, "code", "") or ""
                        mb_cache_df["FSO Vessel"] = st.session_state.selected_fso_vessel
                        st.session_state["fso_material_balance_df"] = mb_cache_df
                        st.session_state["fso_mb_df"] = mb_cache_df
                        st.session_state["fso_mb_table"] = mb_cache_df
                    except Exception:
                        st.session_state["fso_material_balance_df"] = mb_df_full.copy()
                    
                    if mb_df_full.empty:
                        st.warning("dY\"- No material balance data available for this vessel.")
                        st.stop()
                    
                    mb_df_full["Date"] = pd.to_datetime(mb_df_full["Date"], errors="coerce")
                    mb_df_full = mb_df_full.dropna(subset=["Date"]).sort_values("Date").reset_index(drop=True)
                    total_days = len(mb_df_full)
                    
                    opening_stock_full = float(mb_df_full["Opening Stock"].iloc[0]) if total_days else 0.0
                    closing_stock_full = float(mb_df_full["Closing Stock"].iloc[-1]) if total_days else 0.0
                    
                    view_mask = (
                        (mb_df_full["Date"].dt.date >= mb_date_from) &
                        (mb_df_full["Date"].dt.date <= mb_date_to)
                    )
                    mb_df = mb_df_full.loc[view_mask].copy()
                    shown_days = len(mb_df)
                    if shown_days == 0:
                        st.info("dY\"- No material balance rows within the selected display period.")
                    
                    if not mb_df.empty:
                        mb_df["Date"] = mb_df["Date"].dt.strftime("%Y-%m-%d")
                    
                    st.markdown(f"#### 📊 Material Balance Report ({shown_days} / {total_days} days)")
                    st.caption("? Auto-updates when new entries are saved in OTR section")
                    
                    # Display as styled dataframe with variance coloring
                    rename_map = {
                        "Opening Stock": "Opening Stock (bbls)",
                        "Opening Water": "Opening Water (bbls)",
                        "Receipts": "Receipts (bbls)",
                        "Exports": "Exports (bbls)",
                        "Closing Stock": "Closing Stock (bbls)",
                        "Closing Water": "Closing Water (bbls)",
                        "Loss/Gain": "Loss/Gain (bbls)"
                    }
                    display_columns = ["Date"] + list(rename_map.keys())
                    display_df = mb_df[display_columns].copy()
                    display_df = display_df.rename(columns=rename_map)
                    
                    variance_column = rename_map["Loss/Gain"]
                    
                    def _variance_color(val):
                        if pd.isna(val):
                            return ""
                        color = "#16a34a" if val >= 0 else "#dc2626"
                        return f"color: {color}; font-weight: 600;"
                    
                    style_formats = {col_label: "{:,.2f}" for col_label in rename_map.values()}
                    styled_df = (
                        display_df.style
                        .format(style_formats, na_rep="-")
                        .applymap(_variance_color, subset=[variance_column])
                    )
                    
                    st.dataframe(
                        styled_df,
                        use_container_width=True,
                        hide_index=True
                    )
                    
                    # Summary Statistics
                    st.markdown("---")
                    st.markdown("#### 📊 Summary")
                    
                    summary_col1, summary_col2, summary_col3, summary_col4, summary_col5 = st.columns(5)
                    
                    total_receipts = mb_df["Receipts"].sum()
                    total_exports = mb_df["Exports"].sum()
                    total_loss_gain = mb_df["Loss/Gain"].sum()
                    opening_metric = opening_stock_full
                    closing_metric = closing_stock_full
                    
                    with summary_col1:
                        st.metric("Total Receipts", f"{total_receipts:,.0f} bbls")
                    
                    with summary_col2:
                        st.metric("Total Exports", f"{total_exports:,.0f} bbls")
                    
                    with summary_col3:
                        st.metric("Total Loss/Gain", f"{total_loss_gain:,.2f} bbls", 
                                delta="Gain" if total_loss_gain >= 0 else "Loss",
                                delta_color="normal" if total_loss_gain >= 0 else "inverse")
                    
                    with summary_col4:
                        st.metric("Opening Stock (full range)", f"{opening_metric:,.0f} bbls")
                    
                    with summary_col5:
                        st.metric("Closing Stock (full range)", f"{closing_metric:,.0f} bbls")

                    st.caption("Opening/Closing values always reference the full data range; other totals follow the active filters.")
                    
                    # Export Material Balance
                    st.markdown("---")
                    st.markdown("#### 📤 Export Material Balance")
                    
                    mb_export_col1, mb_export_col2, mb_export_col3, mb_export_col4 = st.columns(4)
                    
                    # CSV Export
                    with mb_export_col1:
                        csv_mb = mb_df.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="📥 Download CSV",
                            data=csv_mb,
                            file_name=f"FSO_Material_Balance_{st.session_state.selected_fso_vessel}_{date.today()}.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                    
                    # Excel Export
                    with mb_export_col2:
                        mb_output = BytesIO()
                        with pd.ExcelWriter(mb_output, engine='openpyxl') as writer:
                            mb_df.to_excel(writer, index=False, sheet_name='Material Balance')
                        mb_excel_data = mb_output.getvalue()
                        
                        st.download_button(
                            label="⬇️ Download Excel",
                            data=mb_excel_data,
                            file_name=f"FSO_Material_Balance_{st.session_state.selected_fso_vessel}_{date.today()}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
                    
                    # PDF Download
                    with mb_export_col3:
                        if st.button("📥 Download PDF", key="mb_pdf_download", use_container_width=True):
                            try:
                                # Generate Material Balance PDF
                                mb_pdf_data = generate_material_balance_pdf(
                                    mb_df,
                                    st.session_state.selected_fso_vessel,
                                    mb_date_from.strftime("%d-%b-%Y"),
                                    mb_date_to.strftime("%d-%b-%Y"),
                                    total_receipts,
                                    total_exports,
                                    total_loss_gain,
                                    user["username"]
                                )
                                
                                st.download_button(
                                    label="💾 Save PDF File",
                                    data=mb_pdf_data,
                                    file_name=f"FSO_Material_Balance_{st.session_state.selected_fso_vessel}_{date.today()}.pdf",
                                    mime="application/pdf",
                                    key="mb_save_pdf_btn",
                                    use_container_width=True
                                )
                            except Exception as ex:
                                st.error(f"? PDF generation failed: {ex}")
                    
                    # PDF View
                    with mb_export_col4:
                        if st.button("👁️ View PDF", key="mb_pdf_view_fso", use_container_width=True):
                            try:
                                # Generate Material Balance PDF
                                mb_pdf_data = generate_material_balance_pdf(
                                    mb_df,
                                    st.session_state.selected_fso_vessel,
                                    mb_date_from.strftime("%d-%b-%Y"),
                                    mb_date_to.strftime("%d-%b-%Y"),
                                    total_receipts,
                                    total_exports,
                                    total_loss_gain,
                                    user["username"]
                                )
                                
                                # Encode to base64
                                base64_pdf = base64.b64encode(mb_pdf_data).decode('utf-8')
                                
                                # JavaScript to open in new tab
                                pdf_html = f"""
                                <script>
                                    var pdfWindow = window.open("");
                                    pdfWindow.document.write(
                                        '<html><head><title>FSO Material Balance - {st.session_state.selected_fso_vessel}</title></head>' +
                                        '<body style="margin:0"><iframe width="100%" height="100%" src="data:application/pdf;base64,{base64_pdf}"></iframe></body></html>'
                                    );
                                </script>
                                """
                                
                                import streamlit.components.v1 as components
                                components.html(pdf_html, height=0)
                                st.success("? PDF opened in new tab!")
                                
                            except Exception as ex:
                                st.error(f"? PDF view failed: {ex}")
                                import traceback
                                with st.expander("⚠️ Error Details"):
                                    st.code(traceback.format_exc())
                    
                    # Visualization
                    st.markdown("---")
                    st.markdown("#### 📈 Visual Trends")
                    
                    # Check if plotly is available
                    try:
                        import plotly.graph_objects as go
                        
                        # Create trend chart
                        fig = go.Figure()
                        
                        fig.add_trace(go.Scatter(
                            x=mb_df["Date"],
                            y=mb_df["Opening Stock"],
                            mode='lines+markers',
                            name='Opening Stock',
                            line=dict(color='#3b82f6', width=2),
                            marker=dict(size=6)
                        ))
                        
                        fig.add_trace(go.Scatter(
                            x=mb_df["Date"],
                            y=mb_df["Closing Stock"],
                            mode='lines+markers',
                            name='Closing Stock',
                            line=dict(color='#10b981', width=2),
                            marker=dict(size=6)
                        ))
                        
                        fig.add_trace(go.Bar(
                            x=mb_df["Date"],
                            y=mb_df["Receipts"],
                            name='Receipts',
                            marker_color='#60a5fa',
                            opacity=0.7
                        ))
                        
                        fig.add_trace(go.Bar(
                            x=mb_df["Date"],
                            y=mb_df["Exports"],
                            name='Exports',
                            marker_color='#f97316',
                            opacity=0.7
                        ))
                        
                        fig.update_layout(
                            title=f"FSO Material Balance Trends - {st.session_state.selected_fso_vessel}",
                            xaxis_title="Date",
                            yaxis_title="Volume (bbls)",
                            barmode='group',
                            hovermode='x unified',
                            height=500,
                            template='plotly_white'
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Loss/Gain chart
                        fig_lg = go.Figure()
                        
                        colors_lg = ['#10b981' if x >= 0 else '#ef4444' for x in mb_df["Loss/Gain"]]
                        
                        fig_lg.add_trace(go.Bar(
                            x=mb_df["Date"],
                            y=mb_df["Loss/Gain"],
                            name='Loss/Gain',
                            marker_color=colors_lg,
                            text=mb_df["Loss/Gain"].apply(lambda x: f"{x:,.1f}"),
                            textposition='outside'
                        ))
                        
                        fig_lg.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5)
                        
                        fig_lg.update_layout(
                            title="Daily Loss/Gain Analysis",
                            xaxis_title="Date",
                            yaxis_title="Loss/Gain (bbls)",
                            hovermode='x',
                            height=400,
                            template='plotly_white',
                            showlegend=False
                        )
                        
                        st.plotly_chart(fig_lg, use_container_width=True)
                        
                    except ImportError:
                        st.info("ℹ️ Install plotly to see visual charts: `pip install plotly`")
        
        except Exception as ex:
            st.error(f"? Failed to calculate material balance: {ex}")
            import traceback
            with st.expander("⚠️ Error Details"):
                st.code(traceback.format_exc())
# ========================= PAGE RENDERING FUNCTIONS =========================

def render_home_page():
    st.title("Oil Terminal Management System")
    st.markdown("### Welcome to OTMS")
    st.write("Select an option from the sidebar to get started.")
    
    # Display summary statistics
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Active Tanks", "5")
    
    with col2:
        st.metric("Recent Transactions", "12")
    
    with col3:
        st.metric("YADE Voyages", "3")

def render_tanks_page():
    st.title("Tanks Management")
    
    tab1, tab2 = st.tabs(["Tank Status", "Tank Master"])
    
    with tab1:
        st.subheader("Current Tank Status")
        try:
            with get_session() as s:
                tanks = s.query(Tank).all()
                statuses = s.query(TankStatus).all()
                
                # Create status lookup
                status_map = {s.tank_id: s for s in statuses}
                
                # Prepare data for display
                data = []
                for t in tanks:
                    status = status_map.get(t.id)
                    data.append({
                        "Tank ID": t.id,
                        "Name": t.name,
                        "Type": t.type,
                        "Capacity (bbl)": t.capacity_bbl,
                        "Current Level (%)": status.level_pct if status else 0,
                        "Product": status.product if status else "Empty",
                        "Last Updated": status.updated_at if status else "N/A"
                    })
                
                if data:
                    st.dataframe(pd.DataFrame(data), use_container_width=True, hide_index=True)
                else:
                    st.info("No tanks found in the database.")
        except Exception as e:
            st.error(f"Error loading tank data: {e}")
    
    with tab2:
        st.subheader("Tank Master Data")
        # Tank management UI would go here

def render_transactions_page():
    st.title("Transactions")
    
    tab1, tab2 = st.tabs(["View Transactions", "New Transaction"])
    
    with tab1:
        st.subheader("Recent Transactions")
        try:
            with get_session() as s:
                txs = s.query(TankTransaction).order_by(TankTransaction.timestamp.desc()).limit(10).all()
                
                if txs:
                    data = [{
                        "ID": tx.id,
                        "Tank": tx.tank_id,
                        "Operation": tx.operation.value if hasattr(tx.operation, 'value') else tx.operation,
                        "Quantity (bbl)": tx.qty_bbls,
                        "Timestamp": tx.timestamp,
                        "Operator": tx.operator_name
                    } for tx in txs]
                    
                    st.dataframe(pd.DataFrame(data), use_container_width=True, hide_index=True)
                else:
                    st.info("No transactions found.")
        except Exception as e:
            st.error(f"Error loading transaction data: {e}")
    
    with tab2:
        st.subheader("Create New Transaction")
        # New transaction form would go here

def render_yade_page():
    st.title("YADE Voyages")
    
    tab1, tab2 = st.tabs(["View Voyages", "New Voyage"])
    
    with tab1:
        st.subheader("Recent YADE Voyages")
        try:
            with get_session() as s:
                voyages = s.query(YadeVoyage).order_by(YadeVoyage.date.desc(), YadeVoyage.time.desc()).limit(10).all()
                
                if voyages:
                    data = [{
                        "ID": v.id,
                        "Date": v.date,
                        "Time": v.time,
                        "YADE Name": v.yade_name,
                        "Convoy No": v.convoy_no,
                        "Destination": v.destination.value if hasattr(v.destination, 'value') else v.destination,
                        "Loading Berth": v.loading_berth.value if hasattr(v.loading_berth, 'value') else v.loading_berth
                    } for v in voyages]
                    
                    st.dataframe(pd.DataFrame(data), use_container_width=True, hide_index=True)
                else:
                    st.info("No YADE voyages found.")
        except Exception as e:
            st.error(f"Error loading YADE voyage data: {e}")
    
    with tab2:
        st.subheader("Create New YADE Voyage")
        # New YADE voyage form would go here

def render_assets_page():
    st.title("Assets & Settings")
    
    tab1, tab2, tab3 = st.tabs(["Tanks", "YADE Barges", "Calibration"])
    
    with tab1:
        st.subheader("Tank Management")
        # Tank management UI would go here
    
    with tab2:
        st.subheader("YADE Barge Management")
        # YADE barge management UI would go here
    
    with tab3:
        st.subheader("Calibration Data")
        # Calibration data management UI would go here

# ========================= MAIN APP INITIALIZATION =========================
if __name__ == "__main__":
    # Initialize session state variables
    if "auth_user" not in st.session_state:
        st.session_state.auth_user = None  # {"username": "...", "role": "admin"|"user"}
    
    if "calib_preview" not in st.session_state:
        st.session_state.calib_preview = None
    
    # Page navigation
    st.set_page_config(
        page_title="Oil Terminal Management System",
        page_icon="🛢️",
        layout="wide",
    )

# === helper added safely at EOF ===
def with_icon(label: str, emoji: str) -> str:
    """Prepend an emoji to a label (visual only)."""
    return f"{emoji} {label}".strip()
